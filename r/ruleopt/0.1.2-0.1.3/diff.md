# Comparing `tmp/ruleopt-0.1.2-cp39-cp39-win_amd64.whl.zip` & `tmp/ruleopt-0.1.3-cp39-cp39-macosx_11_0_arm64.whl.zip`

## zipinfo {}

```diff
@@ -1,31 +1,40 @@
-Zip file size: 305537 bytes, number of entries: 29
--rw-rw-rw-  2.0 fat      257 b- defN 24-Apr-02 09:59 ruleopt/__init__.py
--rw-rw-rw-  2.0 fat       96 b- defN 24-Apr-02 09:59 ruleopt/aux_classes/__init__.py
--rw-rw-rw-  2.0 fat  1367569 b- defN 24-Apr-02 10:01 ruleopt/aux_classes/aux_classes.c
--rw-rw-rw-  2.0 fat   206848 b- defN 24-Apr-02 10:01 ruleopt/aux_classes/aux_classes.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat      280 b- defN 24-Apr-02 09:59 ruleopt/estimator/__init__.py
--rw-rw-rw-  2.0 fat    26086 b- defN 24-Apr-02 09:59 ruleopt/estimator/base.py
--rw-rw-rw-  2.0 fat    12714 b- defN 24-Apr-02 09:59 ruleopt/estimator/lightgbm_.py
--rw-rw-rw-  2.0 fat    11558 b- defN 24-Apr-02 09:59 ruleopt/estimator/xgboost_.py
--rw-rw-rw-  2.0 fat      126 b- defN 24-Apr-02 09:59 ruleopt/estimator/sklearn_/__init__.py
--rw-rw-rw-  2.0 fat     6845 b- defN 24-Apr-02 09:59 ruleopt/estimator/sklearn_/base_sklearn.py
--rw-rw-rw-  2.0 fat    21519 b- defN 24-Apr-02 09:59 ruleopt/estimator/sklearn_/rug.py
--rw-rw-rw-  2.0 fat     5662 b- defN 24-Apr-02 09:59 ruleopt/estimator/sklearn_/rux.py
--rw-rw-rw-  2.0 fat       68 b- defN 24-Apr-02 09:59 ruleopt/explainer/__init__.py
--rw-rw-rw-  2.0 fat     8993 b- defN 24-Apr-02 09:59 ruleopt/explainer/explainer.py
--rw-rw-rw-  2.0 fat      137 b- defN 24-Apr-02 09:59 ruleopt/rule_cost/__init__.py
--rw-rw-rw-  2.0 fat     5252 b- defN 24-Apr-02 09:59 ruleopt/rule_cost/rule_cost.py
--rw-rw-rw-  2.0 fat      293 b- defN 24-Apr-02 09:59 ruleopt/solver/__init__.py
--rw-rw-rw-  2.0 fat     3233 b- defN 24-Apr-02 09:59 ruleopt/solver/base.py
--rw-rw-rw-  2.0 fat     4043 b- defN 24-Apr-02 09:59 ruleopt/solver/cplex_solver.py
--rw-rw-rw-  2.0 fat     3890 b- defN 24-Apr-02 09:59 ruleopt/solver/gurobi_solver.py
--rw-rw-rw-  2.0 fat     5080 b- defN 24-Apr-02 09:59 ruleopt/solver/ortools_solver.py
--rw-rw-rw-  2.0 fat     9596 b- defN 24-Apr-02 09:59 ruleopt/solver/unc_solver.py
--rw-rw-rw-  2.0 fat      124 b- defN 24-Apr-02 09:59 ruleopt/utils/__init__.py
--rw-rw-rw-  2.0 fat     1086 b- defN 24-Apr-02 09:59 ruleopt/utils/utils.py
--rw-rw-rw-  2.0 fat     1135 b- defN 24-Apr-02 10:01 ruleopt-0.1.2.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     4136 b- defN 24-Apr-02 10:01 ruleopt-0.1.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 24-Apr-02 10:01 ruleopt-0.1.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 24-Apr-02 10:01 ruleopt-0.1.2.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     2479 b- defN 24-Apr-02 10:01 ruleopt-0.1.2.dist-info/RECORD
-29 files, 1709213 bytes uncompressed, 301541 bytes compressed:  82.4%
+Zip file size: 311996 bytes, number of entries: 38
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/estimator/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/utils/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/solver/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/rule_cost/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/explainer/
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/aux_classes/
+-rw-r--r--  2.0 unx      247 b- defN 24-Apr-06 08:23 ruleopt/__init__.py
+drwxr-xr-x  2.0 unx        0 b- stor 24-Apr-06 08:24 ruleopt/estimator/sklearn_/
+-rw-r--r--  2.0 unx      271 b- defN 24-Apr-06 08:23 ruleopt/estimator/__init__.py
+-rw-r--r--  2.0 unx    12387 b- defN 24-Apr-06 08:23 ruleopt/estimator/lightgbm_.py
+-rw-r--r--  2.0 unx    11252 b- defN 24-Apr-06 08:23 ruleopt/estimator/xgboost_.py
+-rw-r--r--  2.0 unx    25384 b- defN 24-Apr-06 08:23 ruleopt/estimator/base.py
+-rw-r--r--  2.0 unx     6653 b- defN 24-Apr-06 08:23 ruleopt/estimator/sklearn_/base_sklearn.py
+-rw-r--r--  2.0 unx     5513 b- defN 24-Apr-06 08:23 ruleopt/estimator/sklearn_/rux.py
+-rw-r--r--  2.0 unx      119 b- defN 24-Apr-06 08:23 ruleopt/estimator/sklearn_/__init__.py
+-rw-r--r--  2.0 unx    20971 b- defN 24-Apr-06 08:23 ruleopt/estimator/sklearn_/rug.py
+-rw-r--r--  2.0 unx      120 b- defN 24-Apr-06 08:23 ruleopt/utils/__init__.py
+-rw-r--r--  2.0 unx     1053 b- defN 24-Apr-06 08:23 ruleopt/utils/utils.py
+-rw-r--r--  2.0 unx     9684 b- defN 24-Apr-06 08:23 ruleopt/solver/unc_solver.py
+-rw-r--r--  2.0 unx     4975 b- defN 24-Apr-06 08:23 ruleopt/solver/ortools_solver.py
+-rw-r--r--  2.0 unx      286 b- defN 24-Apr-06 08:23 ruleopt/solver/__init__.py
+-rw-r--r--  2.0 unx     3756 b- defN 24-Apr-06 08:23 ruleopt/solver/gurobi_solver.py
+-rw-r--r--  2.0 unx     3957 b- defN 24-Apr-06 08:23 ruleopt/solver/cplex_solver.py
+-rw-r--r--  2.0 unx     3149 b- defN 24-Apr-06 08:23 ruleopt/solver/base.py
+-rw-r--r--  2.0 unx     5079 b- defN 24-Apr-06 08:23 ruleopt/rule_cost/rule_cost.py
+-rw-r--r--  2.0 unx      134 b- defN 24-Apr-06 08:23 ruleopt/rule_cost/__init__.py
+-rw-r--r--  2.0 unx     8771 b- defN 24-Apr-06 08:23 ruleopt/explainer/explainer.py
+-rw-r--r--  2.0 unx       65 b- defN 24-Apr-06 08:23 ruleopt/explainer/__init__.py
+-rw-r--r--  2.0 unx       91 b- defN 24-Apr-06 08:23 ruleopt/aux_classes/__init__.py
+-rwxr-xr-x  2.0 unx   265440 b- defN 24-Apr-06 08:24 ruleopt/aux_classes/aux_classes.cpython-39-darwin.so
+-rw-r--r--  2.0 unx  1406238 b- defN 24-Apr-06 08:24 ruleopt/aux_classes/aux_classes.c
+-rw-rw-r--  2.0 unx     2510 b- defN 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/RECORD
+-rw-r--r--  2.0 unx     1112 b- defN 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx      108 b- defN 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/top_level.txt
+-rw-r--r--  2.0 unx     4060 b- defN 24-Apr-06 08:24 ruleopt-0.1.3.dist-info/METADATA
+38 files, 1803393 bytes uncompressed, 306988 bytes compressed:  83.0%
```

## zipnote {}

```diff
@@ -1,88 +1,115 @@
-Filename: ruleopt/__init__.py
+Filename: ruleopt/
 Comment: 
 
-Filename: ruleopt/aux_classes/__init__.py
+Filename: ruleopt-0.1.3.dist-info/
 Comment: 
 
-Filename: ruleopt/aux_classes/aux_classes.c
+Filename: ruleopt/estimator/
 Comment: 
 
-Filename: ruleopt/aux_classes/aux_classes.cp39-win_amd64.pyd
+Filename: ruleopt/utils/
 Comment: 
 
-Filename: ruleopt/estimator/__init__.py
+Filename: ruleopt/solver/
 Comment: 
 
-Filename: ruleopt/estimator/base.py
+Filename: ruleopt/rule_cost/
+Comment: 
+
+Filename: ruleopt/explainer/
+Comment: 
+
+Filename: ruleopt/aux_classes/
+Comment: 
+
+Filename: ruleopt/__init__.py
+Comment: 
+
+Filename: ruleopt/estimator/sklearn_/
+Comment: 
+
+Filename: ruleopt/estimator/__init__.py
 Comment: 
 
 Filename: ruleopt/estimator/lightgbm_.py
 Comment: 
 
 Filename: ruleopt/estimator/xgboost_.py
 Comment: 
 
-Filename: ruleopt/estimator/sklearn_/__init__.py
+Filename: ruleopt/estimator/base.py
 Comment: 
 
 Filename: ruleopt/estimator/sklearn_/base_sklearn.py
 Comment: 
 
-Filename: ruleopt/estimator/sklearn_/rug.py
+Filename: ruleopt/estimator/sklearn_/rux.py
 Comment: 
 
-Filename: ruleopt/estimator/sklearn_/rux.py
+Filename: ruleopt/estimator/sklearn_/__init__.py
 Comment: 
 
-Filename: ruleopt/explainer/__init__.py
+Filename: ruleopt/estimator/sklearn_/rug.py
 Comment: 
 
-Filename: ruleopt/explainer/explainer.py
+Filename: ruleopt/utils/__init__.py
 Comment: 
 
-Filename: ruleopt/rule_cost/__init__.py
+Filename: ruleopt/utils/utils.py
 Comment: 
 
-Filename: ruleopt/rule_cost/rule_cost.py
+Filename: ruleopt/solver/unc_solver.py
+Comment: 
+
+Filename: ruleopt/solver/ortools_solver.py
 Comment: 
 
 Filename: ruleopt/solver/__init__.py
 Comment: 
 
-Filename: ruleopt/solver/base.py
+Filename: ruleopt/solver/gurobi_solver.py
 Comment: 
 
 Filename: ruleopt/solver/cplex_solver.py
 Comment: 
 
-Filename: ruleopt/solver/gurobi_solver.py
+Filename: ruleopt/solver/base.py
 Comment: 
 
-Filename: ruleopt/solver/ortools_solver.py
+Filename: ruleopt/rule_cost/rule_cost.py
 Comment: 
 
-Filename: ruleopt/solver/unc_solver.py
+Filename: ruleopt/rule_cost/__init__.py
 Comment: 
 
-Filename: ruleopt/utils/__init__.py
+Filename: ruleopt/explainer/explainer.py
 Comment: 
 
-Filename: ruleopt/utils/utils.py
+Filename: ruleopt/explainer/__init__.py
+Comment: 
+
+Filename: ruleopt/aux_classes/__init__.py
+Comment: 
+
+Filename: ruleopt/aux_classes/aux_classes.cpython-39-darwin.so
+Comment: 
+
+Filename: ruleopt/aux_classes/aux_classes.c
 Comment: 
 
-Filename: ruleopt-0.1.2.dist-info/LICENSE
+Filename: ruleopt-0.1.3.dist-info/RECORD
 Comment: 
 
-Filename: ruleopt-0.1.2.dist-info/METADATA
+Filename: ruleopt-0.1.3.dist-info/LICENSE
 Comment: 
 
-Filename: ruleopt-0.1.2.dist-info/WHEEL
+Filename: ruleopt-0.1.3.dist-info/WHEEL
 Comment: 
 
-Filename: ruleopt-0.1.2.dist-info/top_level.txt
+Filename: ruleopt-0.1.3.dist-info/top_level.txt
 Comment: 
 
-Filename: ruleopt-0.1.2.dist-info/RECORD
+Filename: ruleopt-0.1.3.dist-info/METADATA
 Comment: 
 
 Zip file comment:
```

## filetype from file(1)

```diff
@@ -1 +1 @@
-Zip archive data, at least v2.0 to extract, compression method=deflate
+Zip archive data, at least v2.0 to extract, compression method=store
```

## ruleopt/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-from .estimator import (RUGClassifier, RUXClassifier, RUXLGBMClassifier, RUXXGBClassifier)
-from .explainer import Explainer
-
-__all__ = [
-    "RUGClassifier",
-    "RUXClassifier",
-    "RUXLGBMClassifier",
-    "RUXXGBClassifier",
-    "Explainer",]
-
+from .estimator import (RUGClassifier, RUXClassifier, RUXLGBMClassifier, RUXXGBClassifier)
+from .explainer import Explainer
+
+__all__ = [
+    "RUGClassifier",
+    "RUXClassifier",
+    "RUXLGBMClassifier",
+    "RUXXGBClassifier",
+    "Explainer",]
+
```

## ruleopt/aux_classes/__init__.py

 * *Ordering differences only*

```diff
@@ -1,6 +1,6 @@
-from .aux_classes import (Rule, Coefficients)
-
-
-__all__ = [
-    "Rule",
+from .aux_classes import (Rule, Coefficients)
+
+
+__all__ = [
+    "Rule",
     "Coefficients"]
```

## ruleopt/aux_classes/aux_classes.c

```diff
@@ -1,27 +1,26 @@
 /* Generated by Cython 3.0.10 */
 
 /* BEGIN: Cython Metadata
 {
     "distutils": {
         "depends": [
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h",
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h",
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h",
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h",
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h"
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h",
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include/numpy/arrayscalars.h",
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h",
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h",
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include/numpy/ufuncobject.h"
         ],
         "extra_compile_args": [
-            "/O2",
-            "/favor:ATOM",
-            "/fp:fast",
+            "-Ofast",
+            "-funroll-loops",
             "-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION"
         ],
         "include_dirs": [
-            "C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-build-env-f656rhlf\\overlay\\Lib\\site-packages\\numpy\\core\\include"
+            "/private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/core/include"
         ],
         "language": "c",
         "name": "ruleopt.aux_classes.aux_classes",
         "sources": [
             "ruleopt/aux_classes/aux_classes.pyx"
         ]
     },
@@ -1526,18 +1525,18 @@
   #undef _Complex_I
   #define _Complex_I 1.0fj
 #endif
 
 /* #### Code section: filename_table ### */
 
 static const char *__pyx_f[] = {
-  "ruleopt\\\\aux_classes\\\\aux_classes.pyx",
+  "ruleopt/aux_classes/aux_classes.pyx",
   "<stringsource>",
   "__init__.cython-30.pxd",
-  "ruleopt\\\\aux_classes\\\\aux_classes.pxd",
+  "ruleopt/aux_classes/aux_classes.pxd",
   "type.pxd",
 };
 /* #### Code section: utility_code_proto_before_types ### */
 /* ForceInitThreads.proto */
 #ifndef __PYX_FORCE_INIT_THREADS
   #define __PYX_FORCE_INIT_THREADS 0
 #endif
@@ -1676,177 +1675,177 @@
   Py_ssize_t strides[8];
   Py_ssize_t suboffsets[8];
 } __Pyx_memviewslice;
 #define __Pyx_MemoryView_Len(m)  (m.shape[0])
 
 /* #### Code section: numeric_typedefs ### */
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":730
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":730
  * # in Cython to enable them only on the right systems.
  * 
  * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t
  */
 typedef npy_int8 __pyx_t_5numpy_int8_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":731
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":731
  * 
  * ctypedef npy_int8       int8_t
  * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int32      int32_t
  * ctypedef npy_int64      int64_t
  */
 typedef npy_int16 __pyx_t_5numpy_int16_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":732
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":732
  * ctypedef npy_int8       int8_t
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int64      int64_t
  * #ctypedef npy_int96      int96_t
  */
 typedef npy_int32 __pyx_t_5numpy_int32_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":733
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":733
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t
  * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_int96      int96_t
  * #ctypedef npy_int128     int128_t
  */
 typedef npy_int64 __pyx_t_5numpy_int64_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":737
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":737
  * #ctypedef npy_int128     int128_t
  * 
  * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t
  */
 typedef npy_uint8 __pyx_t_5numpy_uint8_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":738
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":738
  * 
  * ctypedef npy_uint8      uint8_t
  * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint32     uint32_t
  * ctypedef npy_uint64     uint64_t
  */
 typedef npy_uint16 __pyx_t_5numpy_uint16_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":739
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":739
  * ctypedef npy_uint8      uint8_t
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint64     uint64_t
  * #ctypedef npy_uint96     uint96_t
  */
 typedef npy_uint32 __pyx_t_5numpy_uint32_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":740
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":740
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t
  * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_uint96     uint96_t
  * #ctypedef npy_uint128    uint128_t
  */
 typedef npy_uint64 __pyx_t_5numpy_uint64_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":744
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":744
  * #ctypedef npy_uint128    uint128_t
  * 
  * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_float64    float64_t
  * #ctypedef npy_float80    float80_t
  */
 typedef npy_float32 __pyx_t_5numpy_float32_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":745
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":745
  * 
  * ctypedef npy_float32    float32_t
  * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_float80    float80_t
  * #ctypedef npy_float128   float128_t
  */
 typedef npy_float64 __pyx_t_5numpy_float64_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":754
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":754
  * # The int types are mapped a bit surprising --
  * # numpy.int corresponds to 'l' and numpy.long to 'q'
  * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
  * ctypedef npy_longlong   longlong_t
  * 
  */
 typedef npy_long __pyx_t_5numpy_int_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":755
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":755
  * # numpy.int corresponds to 'l' and numpy.long to 'q'
  * ctypedef npy_long       int_t
  * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_ulong      uint_t
  */
 typedef npy_longlong __pyx_t_5numpy_longlong_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":757
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":757
  * ctypedef npy_longlong   longlong_t
  * 
  * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
  * ctypedef npy_ulonglong  ulonglong_t
  * 
  */
 typedef npy_ulong __pyx_t_5numpy_uint_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":758
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":758
  * 
  * ctypedef npy_ulong      uint_t
  * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_intp       intp_t
  */
 typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":760
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":760
  * ctypedef npy_ulonglong  ulonglong_t
  * 
  * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uintp      uintp_t
  * 
  */
 typedef npy_intp __pyx_t_5numpy_intp_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":761
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":761
  * 
  * ctypedef npy_intp       intp_t
  * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_double     float_t
  */
 typedef npy_uintp __pyx_t_5numpy_uintp_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":763
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":763
  * ctypedef npy_uintp      uintp_t
  * 
  * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
  * ctypedef npy_double     double_t
  * ctypedef npy_longdouble longdouble_t
  */
 typedef npy_double __pyx_t_5numpy_float_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":764
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":764
  * 
  * ctypedef npy_double     float_t
  * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
  * ctypedef npy_longdouble longdouble_t
  * 
  */
 typedef npy_double __pyx_t_5numpy_double_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":765
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":765
  * ctypedef npy_double     float_t
  * ctypedef npy_double     double_t
  * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_cfloat      cfloat_t
  */
 typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
@@ -1908,42 +1907,42 @@
 struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Coefficients;
 struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule;
 struct __pyx_array_obj;
 struct __pyx_MemviewEnum_obj;
 struct __pyx_memoryview_obj;
 struct __pyx_memoryviewslice_obj;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":767
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":767
  * ctypedef npy_longdouble longdouble_t
  * 
  * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
  * ctypedef npy_cdouble     cdouble_t
  * ctypedef npy_clongdouble clongdouble_t
  */
 typedef npy_cfloat __pyx_t_5numpy_cfloat_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":768
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":768
  * 
  * ctypedef npy_cfloat      cfloat_t
  * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
  * ctypedef npy_clongdouble clongdouble_t
  * 
  */
 typedef npy_cdouble __pyx_t_5numpy_cdouble_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":769
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":769
  * ctypedef npy_cfloat      cfloat_t
  * ctypedef npy_cdouble     cdouble_t
  * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_cdouble     complex_t
  */
 typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":771
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":771
  * ctypedef npy_clongdouble clongdouble_t
  * 
  * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew1(a):
  */
 typedef npy_cdouble __pyx_t_5numpy_complex_t;
@@ -1980,15 +1979,15 @@
 
 
 /* "ruleopt/aux_classes/aux_classes.pxd":19
  *     bint na
  * 
  * cdef class Rule:             # <<<<<<<<<<<<<<
  *     cdef ClauseStruct* clauses
- *     cdef int n_clauses
+ *     cdef public int n_clauses
  */
 struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule {
   PyObject_HEAD
   struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_vtab;
   struct __pyx_t_7ruleopt_11aux_classes_11aux_classes_ClauseStruct *clauses;
   int n_clauses;
   PyObject *label;
@@ -2080,14 +2079,15 @@
  * cdef class Rule:             # <<<<<<<<<<<<<<
  *     def __cinit__(self):
  *         """
  */
 
 struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule {
   PyObject *(*add_clause)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, int, double, double, int, int __pyx_skip_dispatch);
+  PyObject *(*_get_clause)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, int, int __pyx_skip_dispatch);
   int (*_check_rule_nogil)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice);
   int (*_check_clause_nogil)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice, int);
   int (*check_rule)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice, int __pyx_skip_dispatch);
 };
 static struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_vtabptr_7ruleopt_11aux_classes_11aux_classes_Rule;
 
 
@@ -3277,14 +3277,15 @@
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_7ndarray_4base_base(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE PyArray_Descr *__pyx_f_5numpy_7ndarray_5descr_descr(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE int __pyx_f_5numpy_7ndarray_4ndim_ndim(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_5shape_shape(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_7strides_strides(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE npy_intp __pyx_f_5numpy_7ndarray_4size_size(PyArrayObject *__pyx_v_self); /* proto*/
 static CYTHON_INLINE char *__pyx_f_5numpy_7ndarray_4data_data(PyArrayObject *__pyx_v_self); /* proto*/
+static PyObject *__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__get_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_index, int __pyx_skip_dispatch); /* proto*/
 static PyObject *__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na, int __pyx_skip_dispatch); /* proto*/
 static int __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__check_rule_nogil(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X); /* proto*/
 static int __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__check_clause_nogil(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X, int __pyx_v_idx); /* proto*/
 static int __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X, int __pyx_skip_dispatch); /* proto*/
 
 /* Module declarations from "libc.string" */
 
@@ -3391,15 +3392,15 @@
 static const char __pyx_k_np[] = "np";
 static const char __pyx_k_ub[] = "ub";
 static const char __pyx_k__15[] = "";
 static const char __pyx_k__16[] = "]";
 static const char __pyx_k__17[] = " < ";
 static const char __pyx_k__18[] = " <= ";
 static const char __pyx_k__19[] = "\n";
-static const char __pyx_k__50[] = "?";
+static const char __pyx_k__52[] = "?";
 static const char __pyx_k_abc[] = "abc";
 static const char __pyx_k_and[] = " and ";
 static const char __pyx_k_got[] = " (got ";
 static const char __pyx_k_new[] = "__new__";
 static const char __pyx_k_obj[] = "obj";
 static const char __pyx_k_sys[] = "sys";
 static const char __pyx_k_9_2f[] = "<9.2f";
@@ -3464,21 +3465,23 @@
 static const char __pyx_k_itemsize[] = "itemsize";
 static const char __pyx_k_pyx_type[] = "__pyx_type";
 static const char __pyx_k_register[] = "register";
 static const char __pyx_k_setstate[] = "__setstate__";
 static const char __pyx_k_TypeError[] = "TypeError";
 static const char __pyx_k_enumerate[] = "enumerate";
 static const char __pyx_k_isenabled[] = "isenabled";
+static const char __pyx_k_n_clauses[] = "n_clauses";
 static const char __pyx_k_na_string[] = "na_string";
 static const char __pyx_k_pyx_state[] = "__pyx_state";
 static const char __pyx_k_reduce_ex[] = "__reduce_ex__";
 static const char __pyx_k_IndexError[] = "IndexError";
 static const char __pyx_k_ValueError[] = "ValueError";
 static const char __pyx_k_add_clause[] = "add_clause";
 static const char __pyx_k_check_rule[] = "check_rule";
+static const char __pyx_k_get_clause[] = "_get_clause";
 static const char __pyx_k_print_text[] = "print_text";
 static const char __pyx_k_pyx_result[] = "__pyx_result";
 static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
 static const char __pyx_k_ImportError[] = "ImportError";
 static const char __pyx_k_MemoryError[] = "MemoryError";
 static const char __pyx_k_PickleError[] = "PickleError";
 static const char __pyx_k_collections[] = "collections";
@@ -3501,14 +3504,15 @@
 static const char __pyx_k_Rule_check_rule[] = "Rule.check_rule";
 static const char __pyx_k_View_MemoryView[] = "View.MemoryView";
 static const char __pyx_k_allocate_buffer[] = "allocate_buffer";
 static const char __pyx_k_collections_abc[] = "collections.abc";
 static const char __pyx_k_dtype_is_object[] = "dtype_is_object";
 static const char __pyx_k_pyx_PickleError[] = "__pyx_PickleError";
 static const char __pyx_k_setstate_cython[] = "__setstate_cython__";
+static const char __pyx_k_Rule__get_clause[] = "Rule._get_clause";
 static const char __pyx_k_pyx_unpickle_Enum[] = "__pyx_unpickle_Enum";
 static const char __pyx_k_asyncio_coroutines[] = "asyncio.coroutines";
 static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
 static const char __pyx_k_strided_and_direct[] = "<strided and direct>";
 static const char __pyx_k_Coefficients_cleanup[] = "Coefficients.cleanup";
 static const char __pyx_k_Rule___reduce_cython[] = "Rule.__reduce_cython__";
 static const char __pyx_k_strided_and_indirect[] = "<strided and indirect>";
@@ -3525,15 +3529,15 @@
 static const char __pyx_k_Step_may_not_be_zero_axis_d[] = "Step may not be zero (axis %d)";
 static const char __pyx_k_itemsize_0_for_cython_array[] = "itemsize <= 0 for cython.array";
 static const char __pyx_k_Coefficients___reduce_cython[] = "Coefficients.__reduce_cython__";
 static const char __pyx_k_unable_to_allocate_array_data[] = "unable to allocate array data.";
 static const char __pyx_k_Coefficients___setstate_cython[] = "Coefficients.__setstate_cython__";
 static const char __pyx_k_strided_and_direct_or_indirect[] = "<strided and direct or indirect>";
 static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
-static const char __pyx_k_ruleopt_aux_classes_aux_classes[] = "ruleopt\\aux_classes\\aux_classes.pyx";
+static const char __pyx_k_ruleopt_aux_classes_aux_classes[] = "ruleopt/aux_classes/aux_classes.pyx";
 static const char __pyx_k_All_dimensions_preceding_dimensi[] = "All dimensions preceding dimension %d must be indexed and not sliced";
 static const char __pyx_k_Buffer_view_does_not_expose_stri[] = "Buffer view does not expose strides";
 static const char __pyx_k_Can_only_create_a_buffer_that_is[] = "Can only create a buffer that is contiguous in memory.";
 static const char __pyx_k_Cannot_assign_to_read_only_memor[] = "Cannot assign to read-only memoryview";
 static const char __pyx_k_Cannot_create_writable_memory_vi[] = "Cannot create writable memory view from read-only memoryview";
 static const char __pyx_k_Cannot_transpose_memoryview_with[] = "Cannot transpose memoryview with indirect dimensions";
 static const char __pyx_k_Empty_shape_tuple_for_cython_arr[] = "Empty shape tuple for cython.array";
@@ -3601,29 +3605,33 @@
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_12Coefficients_5costs___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Coefficients *__pyx_v_self); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_12Coefficients_5costs_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Coefficients *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_12Coefficients_4__reduce_cython__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Coefficients *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_12Coefficients_6__setstate_cython__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Coefficients *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule___cinit__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static Py_ssize_t __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_2__len__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static void __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_4__dealloc__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6__eq__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8_get_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_index); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
+static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5label___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5label_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5label_4__del__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6weight___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6weight_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6weight_4__del__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
 static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist_4__del__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_18__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self); /* proto */
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_20__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
 static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes___pyx_unpickle_Coefficients(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
 static PyObject *__pyx_tp_new_7ruleopt_11aux_classes_11aux_classes_Coefficients(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new_7ruleopt_11aux_classes_11aux_classes_Rule(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new_array(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new_Enum(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new_memoryview(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new__memoryviewslice(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
@@ -3739,14 +3747,15 @@
   PyObject *__pyx_kp_u_None;
   PyObject *__pyx_n_b_O;
   PyObject *__pyx_kp_u_Out_of_bounds_on_buffer_access_a;
   PyObject *__pyx_n_s_PickleError;
   PyObject *__pyx_n_s_Rule;
   PyObject *__pyx_n_s_Rule___reduce_cython;
   PyObject *__pyx_n_s_Rule___setstate_cython;
+  PyObject *__pyx_n_s_Rule__get_clause;
   PyObject *__pyx_n_s_Rule_add_clause;
   PyObject *__pyx_n_s_Rule_check_rule;
   PyObject *__pyx_n_s_Rule_to_dict;
   PyObject *__pyx_n_s_Rule_to_text;
   PyObject *__pyx_n_s_Sequence;
   PyObject *__pyx_kp_s_Step_may_not_be_zero_axis_d;
   PyObject *__pyx_n_s_TypeError;
@@ -3757,15 +3766,15 @@
   PyObject *__pyx_kp_u__15;
   PyObject *__pyx_kp_u__16;
   PyObject *__pyx_kp_u__17;
   PyObject *__pyx_kp_u__18;
   PyObject *__pyx_kp_u__19;
   PyObject *__pyx_kp_u__2;
   PyObject *__pyx_n_s__3;
-  PyObject *__pyx_n_s__50;
+  PyObject *__pyx_n_s__52;
   PyObject *__pyx_kp_u__6;
   PyObject *__pyx_kp_u__7;
   PyObject *__pyx_n_s_abc;
   PyObject *__pyx_n_s_add_clause;
   PyObject *__pyx_n_s_allocate_buffer;
   PyObject *__pyx_kp_u_and;
   PyObject *__pyx_kp_u_and_not_null;
@@ -3800,14 +3809,15 @@
   PyObject *__pyx_n_s_feature_names;
   PyObject *__pyx_n_s_flags;
   PyObject *__pyx_n_s_float64;
   PyObject *__pyx_n_s_format;
   PyObject *__pyx_n_s_fortran;
   PyObject *__pyx_n_u_fortran;
   PyObject *__pyx_kp_u_gc;
+  PyObject *__pyx_n_s_get_clause;
   PyObject *__pyx_n_s_getstate;
   PyObject *__pyx_kp_u_got;
   PyObject *__pyx_kp_u_got_differing_extents_in_dimensi;
   PyObject *__pyx_n_s_i;
   PyObject *__pyx_n_s_id;
   PyObject *__pyx_n_s_import;
   PyObject *__pyx_n_s_index;
@@ -3818,14 +3828,15 @@
   PyObject *__pyx_n_s_itemsize;
   PyObject *__pyx_kp_s_itemsize_0_for_cython_array;
   PyObject *__pyx_n_s_lb;
   PyObject *__pyx_n_u_lb;
   PyObject *__pyx_n_s_main;
   PyObject *__pyx_n_s_memview;
   PyObject *__pyx_n_s_mode;
+  PyObject *__pyx_n_s_n_clauses;
   PyObject *__pyx_n_s_na;
   PyObject *__pyx_n_u_na;
   PyObject *__pyx_n_s_na_string;
   PyObject *__pyx_n_s_name;
   PyObject *__pyx_n_s_name_2;
   PyObject *__pyx_n_s_ndim;
   PyObject *__pyx_n_s_new;
@@ -3918,26 +3929,28 @@
   PyObject *__pyx_tuple__32;
   PyObject *__pyx_tuple__34;
   PyObject *__pyx_tuple__36;
   PyObject *__pyx_tuple__38;
   PyObject *__pyx_tuple__40;
   PyObject *__pyx_tuple__42;
   PyObject *__pyx_tuple__44;
-  PyObject *__pyx_tuple__45;
+  PyObject *__pyx_tuple__46;
+  PyObject *__pyx_tuple__47;
   PyObject *__pyx_codeobj__31;
   PyObject *__pyx_codeobj__33;
   PyObject *__pyx_codeobj__35;
   PyObject *__pyx_codeobj__37;
   PyObject *__pyx_codeobj__39;
   PyObject *__pyx_codeobj__41;
   PyObject *__pyx_codeobj__43;
-  PyObject *__pyx_codeobj__46;
-  PyObject *__pyx_codeobj__47;
+  PyObject *__pyx_codeobj__45;
   PyObject *__pyx_codeobj__48;
   PyObject *__pyx_codeobj__49;
+  PyObject *__pyx_codeobj__50;
+  PyObject *__pyx_codeobj__51;
 } __pyx_mstate;
 
 #if CYTHON_USE_MODULE_STATE
 #ifdef __cplusplus
 namespace {
   extern struct PyModuleDef __pyx_moduledef;
 } /* anonymous namespace */
@@ -4038,14 +4051,15 @@
   Py_CLEAR(clear_module_state->__pyx_kp_u_None);
   Py_CLEAR(clear_module_state->__pyx_n_b_O);
   Py_CLEAR(clear_module_state->__pyx_kp_u_Out_of_bounds_on_buffer_access_a);
   Py_CLEAR(clear_module_state->__pyx_n_s_PickleError);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule___reduce_cython);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule___setstate_cython);
+  Py_CLEAR(clear_module_state->__pyx_n_s_Rule__get_clause);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule_add_clause);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule_check_rule);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule_to_dict);
   Py_CLEAR(clear_module_state->__pyx_n_s_Rule_to_text);
   Py_CLEAR(clear_module_state->__pyx_n_s_Sequence);
   Py_CLEAR(clear_module_state->__pyx_kp_s_Step_may_not_be_zero_axis_d);
   Py_CLEAR(clear_module_state->__pyx_n_s_TypeError);
@@ -4056,15 +4070,15 @@
   Py_CLEAR(clear_module_state->__pyx_kp_u__15);
   Py_CLEAR(clear_module_state->__pyx_kp_u__16);
   Py_CLEAR(clear_module_state->__pyx_kp_u__17);
   Py_CLEAR(clear_module_state->__pyx_kp_u__18);
   Py_CLEAR(clear_module_state->__pyx_kp_u__19);
   Py_CLEAR(clear_module_state->__pyx_kp_u__2);
   Py_CLEAR(clear_module_state->__pyx_n_s__3);
-  Py_CLEAR(clear_module_state->__pyx_n_s__50);
+  Py_CLEAR(clear_module_state->__pyx_n_s__52);
   Py_CLEAR(clear_module_state->__pyx_kp_u__6);
   Py_CLEAR(clear_module_state->__pyx_kp_u__7);
   Py_CLEAR(clear_module_state->__pyx_n_s_abc);
   Py_CLEAR(clear_module_state->__pyx_n_s_add_clause);
   Py_CLEAR(clear_module_state->__pyx_n_s_allocate_buffer);
   Py_CLEAR(clear_module_state->__pyx_kp_u_and);
   Py_CLEAR(clear_module_state->__pyx_kp_u_and_not_null);
@@ -4099,14 +4113,15 @@
   Py_CLEAR(clear_module_state->__pyx_n_s_feature_names);
   Py_CLEAR(clear_module_state->__pyx_n_s_flags);
   Py_CLEAR(clear_module_state->__pyx_n_s_float64);
   Py_CLEAR(clear_module_state->__pyx_n_s_format);
   Py_CLEAR(clear_module_state->__pyx_n_s_fortran);
   Py_CLEAR(clear_module_state->__pyx_n_u_fortran);
   Py_CLEAR(clear_module_state->__pyx_kp_u_gc);
+  Py_CLEAR(clear_module_state->__pyx_n_s_get_clause);
   Py_CLEAR(clear_module_state->__pyx_n_s_getstate);
   Py_CLEAR(clear_module_state->__pyx_kp_u_got);
   Py_CLEAR(clear_module_state->__pyx_kp_u_got_differing_extents_in_dimensi);
   Py_CLEAR(clear_module_state->__pyx_n_s_i);
   Py_CLEAR(clear_module_state->__pyx_n_s_id);
   Py_CLEAR(clear_module_state->__pyx_n_s_import);
   Py_CLEAR(clear_module_state->__pyx_n_s_index);
@@ -4117,14 +4132,15 @@
   Py_CLEAR(clear_module_state->__pyx_n_s_itemsize);
   Py_CLEAR(clear_module_state->__pyx_kp_s_itemsize_0_for_cython_array);
   Py_CLEAR(clear_module_state->__pyx_n_s_lb);
   Py_CLEAR(clear_module_state->__pyx_n_u_lb);
   Py_CLEAR(clear_module_state->__pyx_n_s_main);
   Py_CLEAR(clear_module_state->__pyx_n_s_memview);
   Py_CLEAR(clear_module_state->__pyx_n_s_mode);
+  Py_CLEAR(clear_module_state->__pyx_n_s_n_clauses);
   Py_CLEAR(clear_module_state->__pyx_n_s_na);
   Py_CLEAR(clear_module_state->__pyx_n_u_na);
   Py_CLEAR(clear_module_state->__pyx_n_s_na_string);
   Py_CLEAR(clear_module_state->__pyx_n_s_name);
   Py_CLEAR(clear_module_state->__pyx_n_s_name_2);
   Py_CLEAR(clear_module_state->__pyx_n_s_ndim);
   Py_CLEAR(clear_module_state->__pyx_n_s_new);
@@ -4217,26 +4233,28 @@
   Py_CLEAR(clear_module_state->__pyx_tuple__32);
   Py_CLEAR(clear_module_state->__pyx_tuple__34);
   Py_CLEAR(clear_module_state->__pyx_tuple__36);
   Py_CLEAR(clear_module_state->__pyx_tuple__38);
   Py_CLEAR(clear_module_state->__pyx_tuple__40);
   Py_CLEAR(clear_module_state->__pyx_tuple__42);
   Py_CLEAR(clear_module_state->__pyx_tuple__44);
-  Py_CLEAR(clear_module_state->__pyx_tuple__45);
+  Py_CLEAR(clear_module_state->__pyx_tuple__46);
+  Py_CLEAR(clear_module_state->__pyx_tuple__47);
   Py_CLEAR(clear_module_state->__pyx_codeobj__31);
   Py_CLEAR(clear_module_state->__pyx_codeobj__33);
   Py_CLEAR(clear_module_state->__pyx_codeobj__35);
   Py_CLEAR(clear_module_state->__pyx_codeobj__37);
   Py_CLEAR(clear_module_state->__pyx_codeobj__39);
   Py_CLEAR(clear_module_state->__pyx_codeobj__41);
   Py_CLEAR(clear_module_state->__pyx_codeobj__43);
-  Py_CLEAR(clear_module_state->__pyx_codeobj__46);
-  Py_CLEAR(clear_module_state->__pyx_codeobj__47);
+  Py_CLEAR(clear_module_state->__pyx_codeobj__45);
   Py_CLEAR(clear_module_state->__pyx_codeobj__48);
   Py_CLEAR(clear_module_state->__pyx_codeobj__49);
+  Py_CLEAR(clear_module_state->__pyx_codeobj__50);
+  Py_CLEAR(clear_module_state->__pyx_codeobj__51);
   return 0;
 }
 #endif
 /* #### Code section: module_state_traverse ### */
 #if CYTHON_USE_MODULE_STATE
 static int __pyx_m_traverse(PyObject *m, visitproc visit, void *arg) {
   __pyx_mstate *traverse_module_state = __pyx_mstate(m);
@@ -4315,14 +4333,15 @@
   Py_VISIT(traverse_module_state->__pyx_kp_u_None);
   Py_VISIT(traverse_module_state->__pyx_n_b_O);
   Py_VISIT(traverse_module_state->__pyx_kp_u_Out_of_bounds_on_buffer_access_a);
   Py_VISIT(traverse_module_state->__pyx_n_s_PickleError);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule___reduce_cython);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule___setstate_cython);
+  Py_VISIT(traverse_module_state->__pyx_n_s_Rule__get_clause);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule_add_clause);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule_check_rule);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule_to_dict);
   Py_VISIT(traverse_module_state->__pyx_n_s_Rule_to_text);
   Py_VISIT(traverse_module_state->__pyx_n_s_Sequence);
   Py_VISIT(traverse_module_state->__pyx_kp_s_Step_may_not_be_zero_axis_d);
   Py_VISIT(traverse_module_state->__pyx_n_s_TypeError);
@@ -4333,15 +4352,15 @@
   Py_VISIT(traverse_module_state->__pyx_kp_u__15);
   Py_VISIT(traverse_module_state->__pyx_kp_u__16);
   Py_VISIT(traverse_module_state->__pyx_kp_u__17);
   Py_VISIT(traverse_module_state->__pyx_kp_u__18);
   Py_VISIT(traverse_module_state->__pyx_kp_u__19);
   Py_VISIT(traverse_module_state->__pyx_kp_u__2);
   Py_VISIT(traverse_module_state->__pyx_n_s__3);
-  Py_VISIT(traverse_module_state->__pyx_n_s__50);
+  Py_VISIT(traverse_module_state->__pyx_n_s__52);
   Py_VISIT(traverse_module_state->__pyx_kp_u__6);
   Py_VISIT(traverse_module_state->__pyx_kp_u__7);
   Py_VISIT(traverse_module_state->__pyx_n_s_abc);
   Py_VISIT(traverse_module_state->__pyx_n_s_add_clause);
   Py_VISIT(traverse_module_state->__pyx_n_s_allocate_buffer);
   Py_VISIT(traverse_module_state->__pyx_kp_u_and);
   Py_VISIT(traverse_module_state->__pyx_kp_u_and_not_null);
@@ -4376,14 +4395,15 @@
   Py_VISIT(traverse_module_state->__pyx_n_s_feature_names);
   Py_VISIT(traverse_module_state->__pyx_n_s_flags);
   Py_VISIT(traverse_module_state->__pyx_n_s_float64);
   Py_VISIT(traverse_module_state->__pyx_n_s_format);
   Py_VISIT(traverse_module_state->__pyx_n_s_fortran);
   Py_VISIT(traverse_module_state->__pyx_n_u_fortran);
   Py_VISIT(traverse_module_state->__pyx_kp_u_gc);
+  Py_VISIT(traverse_module_state->__pyx_n_s_get_clause);
   Py_VISIT(traverse_module_state->__pyx_n_s_getstate);
   Py_VISIT(traverse_module_state->__pyx_kp_u_got);
   Py_VISIT(traverse_module_state->__pyx_kp_u_got_differing_extents_in_dimensi);
   Py_VISIT(traverse_module_state->__pyx_n_s_i);
   Py_VISIT(traverse_module_state->__pyx_n_s_id);
   Py_VISIT(traverse_module_state->__pyx_n_s_import);
   Py_VISIT(traverse_module_state->__pyx_n_s_index);
@@ -4394,14 +4414,15 @@
   Py_VISIT(traverse_module_state->__pyx_n_s_itemsize);
   Py_VISIT(traverse_module_state->__pyx_kp_s_itemsize_0_for_cython_array);
   Py_VISIT(traverse_module_state->__pyx_n_s_lb);
   Py_VISIT(traverse_module_state->__pyx_n_u_lb);
   Py_VISIT(traverse_module_state->__pyx_n_s_main);
   Py_VISIT(traverse_module_state->__pyx_n_s_memview);
   Py_VISIT(traverse_module_state->__pyx_n_s_mode);
+  Py_VISIT(traverse_module_state->__pyx_n_s_n_clauses);
   Py_VISIT(traverse_module_state->__pyx_n_s_na);
   Py_VISIT(traverse_module_state->__pyx_n_u_na);
   Py_VISIT(traverse_module_state->__pyx_n_s_na_string);
   Py_VISIT(traverse_module_state->__pyx_n_s_name);
   Py_VISIT(traverse_module_state->__pyx_n_s_name_2);
   Py_VISIT(traverse_module_state->__pyx_n_s_ndim);
   Py_VISIT(traverse_module_state->__pyx_n_s_new);
@@ -4494,26 +4515,28 @@
   Py_VISIT(traverse_module_state->__pyx_tuple__32);
   Py_VISIT(traverse_module_state->__pyx_tuple__34);
   Py_VISIT(traverse_module_state->__pyx_tuple__36);
   Py_VISIT(traverse_module_state->__pyx_tuple__38);
   Py_VISIT(traverse_module_state->__pyx_tuple__40);
   Py_VISIT(traverse_module_state->__pyx_tuple__42);
   Py_VISIT(traverse_module_state->__pyx_tuple__44);
-  Py_VISIT(traverse_module_state->__pyx_tuple__45);
+  Py_VISIT(traverse_module_state->__pyx_tuple__46);
+  Py_VISIT(traverse_module_state->__pyx_tuple__47);
   Py_VISIT(traverse_module_state->__pyx_codeobj__31);
   Py_VISIT(traverse_module_state->__pyx_codeobj__33);
   Py_VISIT(traverse_module_state->__pyx_codeobj__35);
   Py_VISIT(traverse_module_state->__pyx_codeobj__37);
   Py_VISIT(traverse_module_state->__pyx_codeobj__39);
   Py_VISIT(traverse_module_state->__pyx_codeobj__41);
   Py_VISIT(traverse_module_state->__pyx_codeobj__43);
-  Py_VISIT(traverse_module_state->__pyx_codeobj__46);
-  Py_VISIT(traverse_module_state->__pyx_codeobj__47);
+  Py_VISIT(traverse_module_state->__pyx_codeobj__45);
   Py_VISIT(traverse_module_state->__pyx_codeobj__48);
   Py_VISIT(traverse_module_state->__pyx_codeobj__49);
+  Py_VISIT(traverse_module_state->__pyx_codeobj__50);
+  Py_VISIT(traverse_module_state->__pyx_codeobj__51);
   return 0;
 }
 #endif
 /* #### Code section: module_state_defines ### */
 #define __pyx_d __pyx_mstate_global->__pyx_d
 #define __pyx_b __pyx_mstate_global->__pyx_b
 #define __pyx_cython_runtime __pyx_mstate_global->__pyx_cython_runtime
@@ -4622,14 +4645,15 @@
 #define __pyx_kp_u_None __pyx_mstate_global->__pyx_kp_u_None
 #define __pyx_n_b_O __pyx_mstate_global->__pyx_n_b_O
 #define __pyx_kp_u_Out_of_bounds_on_buffer_access_a __pyx_mstate_global->__pyx_kp_u_Out_of_bounds_on_buffer_access_a
 #define __pyx_n_s_PickleError __pyx_mstate_global->__pyx_n_s_PickleError
 #define __pyx_n_s_Rule __pyx_mstate_global->__pyx_n_s_Rule
 #define __pyx_n_s_Rule___reduce_cython __pyx_mstate_global->__pyx_n_s_Rule___reduce_cython
 #define __pyx_n_s_Rule___setstate_cython __pyx_mstate_global->__pyx_n_s_Rule___setstate_cython
+#define __pyx_n_s_Rule__get_clause __pyx_mstate_global->__pyx_n_s_Rule__get_clause
 #define __pyx_n_s_Rule_add_clause __pyx_mstate_global->__pyx_n_s_Rule_add_clause
 #define __pyx_n_s_Rule_check_rule __pyx_mstate_global->__pyx_n_s_Rule_check_rule
 #define __pyx_n_s_Rule_to_dict __pyx_mstate_global->__pyx_n_s_Rule_to_dict
 #define __pyx_n_s_Rule_to_text __pyx_mstate_global->__pyx_n_s_Rule_to_text
 #define __pyx_n_s_Sequence __pyx_mstate_global->__pyx_n_s_Sequence
 #define __pyx_kp_s_Step_may_not_be_zero_axis_d __pyx_mstate_global->__pyx_kp_s_Step_may_not_be_zero_axis_d
 #define __pyx_n_s_TypeError __pyx_mstate_global->__pyx_n_s_TypeError
@@ -4640,15 +4664,15 @@
 #define __pyx_kp_u__15 __pyx_mstate_global->__pyx_kp_u__15
 #define __pyx_kp_u__16 __pyx_mstate_global->__pyx_kp_u__16
 #define __pyx_kp_u__17 __pyx_mstate_global->__pyx_kp_u__17
 #define __pyx_kp_u__18 __pyx_mstate_global->__pyx_kp_u__18
 #define __pyx_kp_u__19 __pyx_mstate_global->__pyx_kp_u__19
 #define __pyx_kp_u__2 __pyx_mstate_global->__pyx_kp_u__2
 #define __pyx_n_s__3 __pyx_mstate_global->__pyx_n_s__3
-#define __pyx_n_s__50 __pyx_mstate_global->__pyx_n_s__50
+#define __pyx_n_s__52 __pyx_mstate_global->__pyx_n_s__52
 #define __pyx_kp_u__6 __pyx_mstate_global->__pyx_kp_u__6
 #define __pyx_kp_u__7 __pyx_mstate_global->__pyx_kp_u__7
 #define __pyx_n_s_abc __pyx_mstate_global->__pyx_n_s_abc
 #define __pyx_n_s_add_clause __pyx_mstate_global->__pyx_n_s_add_clause
 #define __pyx_n_s_allocate_buffer __pyx_mstate_global->__pyx_n_s_allocate_buffer
 #define __pyx_kp_u_and __pyx_mstate_global->__pyx_kp_u_and
 #define __pyx_kp_u_and_not_null __pyx_mstate_global->__pyx_kp_u_and_not_null
@@ -4683,14 +4707,15 @@
 #define __pyx_n_s_feature_names __pyx_mstate_global->__pyx_n_s_feature_names
 #define __pyx_n_s_flags __pyx_mstate_global->__pyx_n_s_flags
 #define __pyx_n_s_float64 __pyx_mstate_global->__pyx_n_s_float64
 #define __pyx_n_s_format __pyx_mstate_global->__pyx_n_s_format
 #define __pyx_n_s_fortran __pyx_mstate_global->__pyx_n_s_fortran
 #define __pyx_n_u_fortran __pyx_mstate_global->__pyx_n_u_fortran
 #define __pyx_kp_u_gc __pyx_mstate_global->__pyx_kp_u_gc
+#define __pyx_n_s_get_clause __pyx_mstate_global->__pyx_n_s_get_clause
 #define __pyx_n_s_getstate __pyx_mstate_global->__pyx_n_s_getstate
 #define __pyx_kp_u_got __pyx_mstate_global->__pyx_kp_u_got
 #define __pyx_kp_u_got_differing_extents_in_dimensi __pyx_mstate_global->__pyx_kp_u_got_differing_extents_in_dimensi
 #define __pyx_n_s_i __pyx_mstate_global->__pyx_n_s_i
 #define __pyx_n_s_id __pyx_mstate_global->__pyx_n_s_id
 #define __pyx_n_s_import __pyx_mstate_global->__pyx_n_s_import
 #define __pyx_n_s_index __pyx_mstate_global->__pyx_n_s_index
@@ -4701,14 +4726,15 @@
 #define __pyx_n_s_itemsize __pyx_mstate_global->__pyx_n_s_itemsize
 #define __pyx_kp_s_itemsize_0_for_cython_array __pyx_mstate_global->__pyx_kp_s_itemsize_0_for_cython_array
 #define __pyx_n_s_lb __pyx_mstate_global->__pyx_n_s_lb
 #define __pyx_n_u_lb __pyx_mstate_global->__pyx_n_u_lb
 #define __pyx_n_s_main __pyx_mstate_global->__pyx_n_s_main
 #define __pyx_n_s_memview __pyx_mstate_global->__pyx_n_s_memview
 #define __pyx_n_s_mode __pyx_mstate_global->__pyx_n_s_mode
+#define __pyx_n_s_n_clauses __pyx_mstate_global->__pyx_n_s_n_clauses
 #define __pyx_n_s_na __pyx_mstate_global->__pyx_n_s_na
 #define __pyx_n_u_na __pyx_mstate_global->__pyx_n_u_na
 #define __pyx_n_s_na_string __pyx_mstate_global->__pyx_n_s_na_string
 #define __pyx_n_s_name __pyx_mstate_global->__pyx_n_s_name
 #define __pyx_n_s_name_2 __pyx_mstate_global->__pyx_n_s_name_2
 #define __pyx_n_s_ndim __pyx_mstate_global->__pyx_n_s_ndim
 #define __pyx_n_s_new __pyx_mstate_global->__pyx_n_s_new
@@ -4801,26 +4827,28 @@
 #define __pyx_tuple__32 __pyx_mstate_global->__pyx_tuple__32
 #define __pyx_tuple__34 __pyx_mstate_global->__pyx_tuple__34
 #define __pyx_tuple__36 __pyx_mstate_global->__pyx_tuple__36
 #define __pyx_tuple__38 __pyx_mstate_global->__pyx_tuple__38
 #define __pyx_tuple__40 __pyx_mstate_global->__pyx_tuple__40
 #define __pyx_tuple__42 __pyx_mstate_global->__pyx_tuple__42
 #define __pyx_tuple__44 __pyx_mstate_global->__pyx_tuple__44
-#define __pyx_tuple__45 __pyx_mstate_global->__pyx_tuple__45
+#define __pyx_tuple__46 __pyx_mstate_global->__pyx_tuple__46
+#define __pyx_tuple__47 __pyx_mstate_global->__pyx_tuple__47
 #define __pyx_codeobj__31 __pyx_mstate_global->__pyx_codeobj__31
 #define __pyx_codeobj__33 __pyx_mstate_global->__pyx_codeobj__33
 #define __pyx_codeobj__35 __pyx_mstate_global->__pyx_codeobj__35
 #define __pyx_codeobj__37 __pyx_mstate_global->__pyx_codeobj__37
 #define __pyx_codeobj__39 __pyx_mstate_global->__pyx_codeobj__39
 #define __pyx_codeobj__41 __pyx_mstate_global->__pyx_codeobj__41
 #define __pyx_codeobj__43 __pyx_mstate_global->__pyx_codeobj__43
-#define __pyx_codeobj__46 __pyx_mstate_global->__pyx_codeobj__46
-#define __pyx_codeobj__47 __pyx_mstate_global->__pyx_codeobj__47
+#define __pyx_codeobj__45 __pyx_mstate_global->__pyx_codeobj__45
 #define __pyx_codeobj__48 __pyx_mstate_global->__pyx_codeobj__48
 #define __pyx_codeobj__49 __pyx_mstate_global->__pyx_codeobj__49
+#define __pyx_codeobj__50 __pyx_mstate_global->__pyx_codeobj__50
+#define __pyx_codeobj__51 __pyx_mstate_global->__pyx_codeobj__51
 /* #### Code section: module_code ### */
 
 /* "View.MemoryView":131
  *         cdef bint dtype_is_object
  * 
  *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
  *                   mode="c", bint allocate_buffer=True):
@@ -18441,261 +18469,261 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":245
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":245
  * 
  *         @property
  *         cdef inline PyObject* base(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a borrowed reference to the object owning the data/memory.
  *             """
  */
 
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_7ndarray_4base_base(PyArrayObject *__pyx_v_self) {
   PyObject *__pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":248
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":248
  *             """Returns a borrowed reference to the object owning the data/memory.
  *             """
  *             return PyArray_BASE(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __pyx_r = PyArray_BASE(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":245
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":245
  * 
  *         @property
  *         cdef inline PyObject* base(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a borrowed reference to the object owning the data/memory.
  *             """
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":251
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":251
  * 
  *         @property
  *         cdef inline dtype descr(self):             # <<<<<<<<<<<<<<
  *             """Returns an owned reference to the dtype of the array.
  *             """
  */
 
 static CYTHON_INLINE PyArray_Descr *__pyx_f_5numpy_7ndarray_5descr_descr(PyArrayObject *__pyx_v_self) {
   PyArray_Descr *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   PyArray_Descr *__pyx_t_1;
   __Pyx_RefNannySetupContext("descr", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":254
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":254
  *             """Returns an owned reference to the dtype of the array.
  *             """
  *             return <dtype>PyArray_DESCR(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __Pyx_XDECREF((PyObject *)__pyx_r);
   __pyx_t_1 = PyArray_DESCR(__pyx_v_self);
   __Pyx_INCREF((PyObject *)((PyArray_Descr *)__pyx_t_1));
   __pyx_r = ((PyArray_Descr *)__pyx_t_1);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":251
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":251
  * 
  *         @property
  *         cdef inline dtype descr(self):             # <<<<<<<<<<<<<<
  *             """Returns an owned reference to the dtype of the array.
  *             """
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF((PyObject *)__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":257
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":257
  * 
  *         @property
  *         cdef inline int ndim(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns the number of dimensions in the array.
  *             """
  */
 
 static CYTHON_INLINE int __pyx_f_5numpy_7ndarray_4ndim_ndim(PyArrayObject *__pyx_v_self) {
   int __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":260
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":260
  *             """Returns the number of dimensions in the array.
  *             """
  *             return PyArray_NDIM(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __pyx_r = PyArray_NDIM(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":257
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":257
  * 
  *         @property
  *         cdef inline int ndim(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns the number of dimensions in the array.
  *             """
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":263
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":263
  * 
  *         @property
  *         cdef inline npy_intp *shape(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a pointer to the dimensions/shape of the array.
  *             The number of elements matches the number of dimensions of the array (ndim).
  */
 
 static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_5shape_shape(PyArrayObject *__pyx_v_self) {
   npy_intp *__pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":268
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":268
  *             Can return NULL for 0-dimensional arrays.
  *             """
  *             return PyArray_DIMS(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __pyx_r = PyArray_DIMS(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":263
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":263
  * 
  *         @property
  *         cdef inline npy_intp *shape(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a pointer to the dimensions/shape of the array.
  *             The number of elements matches the number of dimensions of the array (ndim).
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":271
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":271
  * 
  *         @property
  *         cdef inline npy_intp *strides(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a pointer to the strides of the array.
  *             The number of elements matches the number of dimensions of the array (ndim).
  */
 
 static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_7strides_strides(PyArrayObject *__pyx_v_self) {
   npy_intp *__pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":275
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":275
  *             The number of elements matches the number of dimensions of the array (ndim).
  *             """
  *             return PyArray_STRIDES(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __pyx_r = PyArray_STRIDES(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":271
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":271
  * 
  *         @property
  *         cdef inline npy_intp *strides(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns a pointer to the strides of the array.
  *             The number of elements matches the number of dimensions of the array (ndim).
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":278
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":278
  * 
  *         @property
  *         cdef inline npy_intp size(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns the total size (in number of elements) of the array.
  *             """
  */
 
 static CYTHON_INLINE npy_intp __pyx_f_5numpy_7ndarray_4size_size(PyArrayObject *__pyx_v_self) {
   npy_intp __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":281
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":281
  *             """Returns the total size (in number of elements) of the array.
  *             """
  *             return PyArray_SIZE(self)             # <<<<<<<<<<<<<<
  * 
  *         @property
  */
   __pyx_r = PyArray_SIZE(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":278
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":278
  * 
  *         @property
  *         cdef inline npy_intp size(self) nogil:             # <<<<<<<<<<<<<<
  *             """Returns the total size (in number of elements) of the array.
  *             """
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":284
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":284
  * 
  *         @property
  *         cdef inline char* data(self) nogil:             # <<<<<<<<<<<<<<
  *             """The pointer to the data buffer as a char*.
  *             This is provided for legacy reasons to avoid direct struct field access.
  */
 
 static CYTHON_INLINE char *__pyx_f_5numpy_7ndarray_4data_data(PyArrayObject *__pyx_v_self) {
   char *__pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":290
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":290
  *             of `PyArray_DATA()` instead, which returns a 'void*'.
  *             """
  *             return PyArray_BYTES(self)             # <<<<<<<<<<<<<<
  * 
  *     ctypedef unsigned char      npy_bool
  */
   __pyx_r = PyArray_BYTES(__pyx_v_self);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":284
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":284
  * 
  *         @property
  *         cdef inline char* data(self) nogil:             # <<<<<<<<<<<<<<
  *             """The pointer to the data buffer as a char*.
  *             This is provided for legacy reasons to avoid direct struct field access.
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":773
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":773
  * ctypedef npy_cdouble     complex_t
  * 
  * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  */
 
@@ -18704,29 +18732,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew1", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":774
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":774
  * 
  * cdef inline object PyArray_MultiIterNew1(a):
  *     return PyArray_MultiIterNew(1, <void*>a)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):
  */
   __Pyx_XDECREF(__pyx_r);
   __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 774, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":773
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":773
  * ctypedef npy_cdouble     complex_t
  * 
  * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  */
 
@@ -18737,15 +18765,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":776
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":776
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  */
 
@@ -18754,29 +18782,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew2", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":777
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":777
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):
  */
   __Pyx_XDECREF(__pyx_r);
   __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 777, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":776
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":776
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  */
 
@@ -18787,15 +18815,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":779
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":779
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  */
 
@@ -18804,29 +18832,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew3", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":780
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":780
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
  */
   __Pyx_XDECREF(__pyx_r);
   __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 780, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":779
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":779
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  */
 
@@ -18837,15 +18865,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":782
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":782
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  */
 
@@ -18854,29 +18882,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew4", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":783
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":783
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
  */
   __Pyx_XDECREF(__pyx_r);
   __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 783, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":782
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":782
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  */
 
@@ -18887,15 +18915,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":785
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":785
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  */
 
@@ -18904,29 +18932,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew5", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":786
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":786
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)             # <<<<<<<<<<<<<<
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  */
   __Pyx_XDECREF(__pyx_r);
   __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 786, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":785
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":785
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  */
 
@@ -18937,217 +18965,217 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":788
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":788
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape
  */
 
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr *__pyx_v_d) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("PyDataType_SHAPE", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":789
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":789
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
  *         return <tuple>d.subarray.shape
  *     else:
  */
   __pyx_t_1 = PyDataType_HASSUBARRAY(__pyx_v_d);
   if (__pyx_t_1) {
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":790
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":790
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape             # <<<<<<<<<<<<<<
  *     else:
  *         return ()
  */
     __Pyx_XDECREF(__pyx_r);
     __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));
     __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);
     goto __pyx_L0;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":789
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":789
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
  *         return <tuple>d.subarray.shape
  *     else:
  */
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":792
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":792
  *         return <tuple>d.subarray.shape
  *     else:
  *         return ()             # <<<<<<<<<<<<<<
  * 
  * 
  */
   /*else*/ {
     __Pyx_XDECREF(__pyx_r);
     __Pyx_INCREF(__pyx_empty_tuple);
     __pyx_r = __pyx_empty_tuple;
     goto __pyx_L0;
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":788
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":788
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":968
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":968
  *     int _import_umath() except -1
  * 
  * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)
  */
 
 static CYTHON_INLINE void __pyx_f_5numpy_set_array_base(PyArrayObject *__pyx_v_arr, PyObject *__pyx_v_base) {
   int __pyx_t_1;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":969
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":969
  * 
  * cdef inline void set_array_base(ndarray arr, object base):
  *     Py_INCREF(base) # important to do this before stealing the reference below!             # <<<<<<<<<<<<<<
  *     PyArray_SetBaseObject(arr, base)
  * 
  */
   Py_INCREF(__pyx_v_base);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":970
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":970
  * cdef inline void set_array_base(ndarray arr, object base):
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object get_array_base(ndarray arr):
  */
   __pyx_t_1 = PyArray_SetBaseObject(__pyx_v_arr, __pyx_v_base); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(2, 970, __pyx_L1_error)
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":968
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":968
  *     int _import_umath() except -1
  * 
  * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)
  */
 
   /* function exit code */
   goto __pyx_L0;
   __pyx_L1_error:;
   __Pyx_AddTraceback("numpy.set_array_base", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_L0:;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":972
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":972
  *     PyArray_SetBaseObject(arr, base)
  * 
  * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  */
 
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_get_array_base(PyArrayObject *__pyx_v_arr) {
   PyObject *__pyx_v_base;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("get_array_base", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":973
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":973
  * 
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)             # <<<<<<<<<<<<<<
  *     if base is NULL:
  *         return None
  */
   __pyx_v_base = PyArray_BASE(__pyx_v_arr);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":974
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":974
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)
  *     if base is NULL:             # <<<<<<<<<<<<<<
  *         return None
  *     return <object>base
  */
   __pyx_t_1 = (__pyx_v_base == NULL);
   if (__pyx_t_1) {
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":975
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":975
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  *         return None             # <<<<<<<<<<<<<<
  *     return <object>base
  * 
  */
     __Pyx_XDECREF(__pyx_r);
     __pyx_r = Py_None; __Pyx_INCREF(Py_None);
     goto __pyx_L0;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":974
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":974
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)
  *     if base is NULL:             # <<<<<<<<<<<<<<
  *         return None
  *     return <object>base
  */
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":976
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":976
  *     if base is NULL:
  *         return None
  *     return <object>base             # <<<<<<<<<<<<<<
  * 
  * # Versions of the import_* functions which are more suitable for
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(((PyObject *)__pyx_v_base));
   __pyx_r = ((PyObject *)__pyx_v_base);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":972
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":972
  *     PyArray_SetBaseObject(arr, base)
  * 
  * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":980
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":980
  * # Versions of the import_* functions which are more suitable for
  * # Cython code.
  * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         __pyx_import_array()
  */
 
@@ -19163,15 +19191,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_array", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":981
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":981
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
   {
@@ -19179,68 +19207,68 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":982
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":982
  * cdef inline int import_array() except -1:
  *     try:
  *         __pyx_import_array()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")
  */
       __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 982, __pyx_L3_error)
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":981
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":981
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":983
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":983
  *     try:
  *         __pyx_import_array()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
       if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 983, __pyx_L5_except_error)
       __Pyx_XGOTREF(__pyx_t_5);
       __Pyx_XGOTREF(__pyx_t_6);
       __Pyx_XGOTREF(__pyx_t_7);
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":984
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":984
  *         __pyx_import_array()
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_umath() except -1:
  */
       __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 984, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
       __PYX_ERR(2, 984, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":981
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":981
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
     __pyx_L5_except_error:;
@@ -19248,15 +19276,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":980
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":980
  * # Versions of the import_* functions which are more suitable for
  * # Cython code.
  * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         __pyx_import_array()
  */
 
@@ -19271,15 +19299,15 @@
   __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":986
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":986
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -19295,15 +19323,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_umath", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":987
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":987
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
   {
@@ -19311,68 +19339,68 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":988
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":988
  * cdef inline int import_umath() except -1:
  *     try:
  *         _import_umath()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")
  */
       __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 988, __pyx_L3_error)
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":987
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":987
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":989
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":989
  *     try:
  *         _import_umath()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
       if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 989, __pyx_L5_except_error)
       __Pyx_XGOTREF(__pyx_t_5);
       __Pyx_XGOTREF(__pyx_t_6);
       __Pyx_XGOTREF(__pyx_t_7);
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":990
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":990
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_ufunc() except -1:
  */
       __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 990, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
       __PYX_ERR(2, 990, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":987
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":987
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     __pyx_L5_except_error:;
@@ -19380,15 +19408,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":986
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":986
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -19403,15 +19431,15 @@
   __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":992
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":992
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -19427,15 +19455,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_ufunc", 1);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":993
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":993
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
   {
@@ -19443,68 +19471,68 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":994
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":994
  * cdef inline int import_ufunc() except -1:
  *     try:
  *         _import_umath()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")
  */
       __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 994, __pyx_L3_error)
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":993
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":993
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":995
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":995
  *     try:
  *         _import_umath()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
       if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 995, __pyx_L5_except_error)
       __Pyx_XGOTREF(__pyx_t_5);
       __Pyx_XGOTREF(__pyx_t_6);
       __Pyx_XGOTREF(__pyx_t_7);
 
-      /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":996
+      /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":996
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * 
  */
       __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 996, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
       __PYX_ERR(2, 996, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
 
-    /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":993
+    /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":993
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     __pyx_L5_except_error:;
@@ -19512,15 +19540,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":992
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":992
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -19535,170 +19563,170 @@
   __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":999
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":999
  * 
  * 
  * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.timedelta64)`
  */
 
 static CYTHON_INLINE int __pyx_f_5numpy_is_timedelta64_object(PyObject *__pyx_v_obj) {
   int __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1011
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1011
  *     bool
  *     """
  *     return PyObject_TypeCheck(obj, &PyTimedeltaArrType_Type)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyTimedeltaArrType_Type));
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":999
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":999
  * 
  * 
  * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.timedelta64)`
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1014
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1014
  * 
  * 
  * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.datetime64)`
  */
 
 static CYTHON_INLINE int __pyx_f_5numpy_is_datetime64_object(PyObject *__pyx_v_obj) {
   int __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1026
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1026
  *     bool
  *     """
  *     return PyObject_TypeCheck(obj, &PyDatetimeArrType_Type)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyDatetimeArrType_Type));
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1014
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1014
  * 
  * 
  * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.datetime64)`
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1029
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1029
  * 
  * 
  * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy datetime64 object
  */
 
 static CYTHON_INLINE npy_datetime __pyx_f_5numpy_get_datetime64_value(PyObject *__pyx_v_obj) {
   npy_datetime __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1036
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1036
  *     also needed.  That can be found using `get_datetime64_unit`.
  *     """
  *     return (<PyDatetimeScalarObject*>obj).obval             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = ((PyDatetimeScalarObject *)__pyx_v_obj)->obval;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1029
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1029
  * 
  * 
  * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy datetime64 object
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1039
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1039
  * 
  * 
  * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy timedelta64 object
  */
 
 static CYTHON_INLINE npy_timedelta __pyx_f_5numpy_get_timedelta64_value(PyObject *__pyx_v_obj) {
   npy_timedelta __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1043
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1043
  *     returns the int64 value underlying scalar numpy timedelta64 object
  *     """
  *     return (<PyTimedeltaScalarObject*>obj).obval             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = ((PyTimedeltaScalarObject *)__pyx_v_obj)->obval;
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1039
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1039
  * 
  * 
  * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy timedelta64 object
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1046
+/* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1046
  * 
  * 
  * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the unit part of the dtype for a numpy datetime64 object.
  */
 
 static CYTHON_INLINE NPY_DATETIMEUNIT __pyx_f_5numpy_get_datetime64_unit(PyObject *__pyx_v_obj) {
   NPY_DATETIMEUNIT __pyx_r;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1050
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1050
  *     returns the unit part of the dtype for a numpy datetime64 object.
  *     """
  *     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base             # <<<<<<<<<<<<<<
  */
   __pyx_r = ((NPY_DATETIMEUNIT)((PyDatetimeScalarObject *)__pyx_v_obj)->obmeta.base);
   goto __pyx_L0;
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":1046
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":1046
  * 
  * 
  * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the unit part of the dtype for a numpy datetime64 object.
  */
 
@@ -21098,15 +21126,15 @@
   if (__pyx_t_1) {
 
     /* "ruleopt/aux_classes/aux_classes.pyx":75
  *     def __dealloc__(self):
  *         if self.n_clauses > 0:
  *             free(self.clauses)             # <<<<<<<<<<<<<<
  * 
- *     cpdef add_clause(self, int feature, double ub, double lb, bint na):
+ *     def __eq__(self, other):
  */
     free(__pyx_v_self->clauses);
 
     /* "ruleopt/aux_classes/aux_classes.pyx":74
  * 
  *     def __dealloc__(self):
  *         if self.n_clauses > 0:             # <<<<<<<<<<<<<<
@@ -21125,20 +21153,619 @@
 
   /* function exit code */
 }
 
 /* "ruleopt/aux_classes/aux_classes.pyx":77
  *             free(self.clauses)
  * 
+ *     def __eq__(self, other):             # <<<<<<<<<<<<<<
+ *         if not isinstance(other, Rule):
+ *             return False
+ */
+
+/* Python wrapper */
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7__eq__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7__eq__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
+  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
+  PyObject *__pyx_r = 0;
+  __Pyx_RefNannyDeclarations
+  __Pyx_RefNannySetupContext("__eq__ (wrapper)", 0);
+  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6__eq__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), ((PyObject *)__pyx_v_other));
+
+  /* function exit code */
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6__eq__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_other) {
+  PyObject *__pyx_v_self_clauses = NULL;
+  PyObject *__pyx_v_other_clauses = NULL;
+  int __pyx_7genexpr__pyx_v_i;
+  PyObject *__pyx_8genexpr1__pyx_v_i = NULL;
+  PyObject *__pyx_r = NULL;
+  __Pyx_RefNannyDeclarations
+  int __pyx_t_1;
+  int __pyx_t_2;
+  PyObject *__pyx_t_3 = NULL;
+  PyObject *__pyx_t_4 = NULL;
+  PyObject *__pyx_t_5 = NULL;
+  int __pyx_t_6;
+  int __pyx_t_7;
+  int __pyx_t_8;
+  Py_ssize_t __pyx_t_9;
+  PyObject *(*__pyx_t_10)(PyObject *);
+  PyObject *__pyx_t_11 = NULL;
+  PyObject *__pyx_t_12 = NULL;
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  __Pyx_RefNannySetupContext("__eq__", 1);
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":78
+ * 
+ *     def __eq__(self, other):
+ *         if not isinstance(other, Rule):             # <<<<<<<<<<<<<<
+ *             return False
+ * 
+ */
+  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_other, __pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule); 
+  __pyx_t_2 = (!__pyx_t_1);
+  if (__pyx_t_2) {
+
+    /* "ruleopt/aux_classes/aux_classes.pyx":79
+ *     def __eq__(self, other):
+ *         if not isinstance(other, Rule):
+ *             return False             # <<<<<<<<<<<<<<
+ * 
+ *         if self.n_clauses != other.n_clauses:
+ */
+    __Pyx_XDECREF(__pyx_r);
+    __Pyx_INCREF(Py_False);
+    __pyx_r = Py_False;
+    goto __pyx_L0;
+
+    /* "ruleopt/aux_classes/aux_classes.pyx":78
+ * 
+ *     def __eq__(self, other):
+ *         if not isinstance(other, Rule):             # <<<<<<<<<<<<<<
+ *             return False
+ * 
+ */
+  }
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":81
+ *             return False
+ * 
+ *         if self.n_clauses != other.n_clauses:             # <<<<<<<<<<<<<<
+ *             return False
+ * 
+ */
+  __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->n_clauses); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 81, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_3);
+  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_n_clauses); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 81, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_4);
+  __pyx_t_5 = PyObject_RichCompare(__pyx_t_3, __pyx_t_4, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 81, __pyx_L1_error)
+  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
+  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(0, 81, __pyx_L1_error)
+  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
+  if (__pyx_t_2) {
+
+    /* "ruleopt/aux_classes/aux_classes.pyx":82
+ * 
+ *         if self.n_clauses != other.n_clauses:
+ *             return False             # <<<<<<<<<<<<<<
+ * 
+ *         self_clauses = {self._get_clause(i) for i in range(self.n_clauses)}
+ */
+    __Pyx_XDECREF(__pyx_r);
+    __Pyx_INCREF(Py_False);
+    __pyx_r = Py_False;
+    goto __pyx_L0;
+
+    /* "ruleopt/aux_classes/aux_classes.pyx":81
+ *             return False
+ * 
+ *         if self.n_clauses != other.n_clauses:             # <<<<<<<<<<<<<<
+ *             return False
+ * 
+ */
+  }
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":84
+ *             return False
+ * 
+ *         self_clauses = {self._get_clause(i) for i in range(self.n_clauses)}             # <<<<<<<<<<<<<<
+ *         other_clauses = {other._get_clause(i) for i in range(other.n_clauses)}
+ * 
+ */
+  { /* enter inner scope */
+    __pyx_t_5 = PySet_New(NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 84, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_5);
+    __pyx_t_6 = __pyx_v_self->n_clauses;
+    __pyx_t_7 = __pyx_t_6;
+    for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
+      __pyx_7genexpr__pyx_v_i = __pyx_t_8;
+      __pyx_t_4 = ((struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self->__pyx_vtab)->_get_clause(__pyx_v_self, __pyx_7genexpr__pyx_v_i, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 84, __pyx_L1_error)
+      __Pyx_GOTREF(__pyx_t_4);
+      if (unlikely(PySet_Add(__pyx_t_5, (PyObject*)__pyx_t_4))) __PYX_ERR(0, 84, __pyx_L1_error)
+      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
+    }
+  } /* exit inner scope */
+  __pyx_v_self_clauses = ((PyObject*)__pyx_t_5);
+  __pyx_t_5 = 0;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":85
+ * 
+ *         self_clauses = {self._get_clause(i) for i in range(self.n_clauses)}
+ *         other_clauses = {other._get_clause(i) for i in range(other.n_clauses)}             # <<<<<<<<<<<<<<
+ * 
+ *         return self_clauses == other_clauses
+ */
+  { /* enter inner scope */
+    __pyx_t_5 = PySet_New(NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 85, __pyx_L9_error)
+    __Pyx_GOTREF(__pyx_t_5);
+    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_n_clauses); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 85, __pyx_L9_error)
+    __Pyx_GOTREF(__pyx_t_4);
+    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_range, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 85, __pyx_L9_error)
+    __Pyx_GOTREF(__pyx_t_3);
+    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
+    if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
+      __pyx_t_4 = __pyx_t_3; __Pyx_INCREF(__pyx_t_4);
+      __pyx_t_9 = 0;
+      __pyx_t_10 = NULL;
+    } else {
+      __pyx_t_9 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 85, __pyx_L9_error)
+      __Pyx_GOTREF(__pyx_t_4);
+      __pyx_t_10 = __Pyx_PyObject_GetIterNextFunc(__pyx_t_4); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 85, __pyx_L9_error)
+    }
+    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+    for (;;) {
+      if (likely(!__pyx_t_10)) {
+        if (likely(PyList_CheckExact(__pyx_t_4))) {
+          {
+            Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_4);
+            #if !CYTHON_ASSUME_SAFE_MACROS
+            if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 85, __pyx_L9_error)
+            #endif
+            if (__pyx_t_9 >= __pyx_temp) break;
+          }
+          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
+          __pyx_t_3 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_9); __Pyx_INCREF(__pyx_t_3); __pyx_t_9++; if (unlikely((0 < 0))) __PYX_ERR(0, 85, __pyx_L9_error)
+          #else
+          __pyx_t_3 = __Pyx_PySequence_ITEM(__pyx_t_4, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 85, __pyx_L9_error)
+          __Pyx_GOTREF(__pyx_t_3);
+          #endif
+        } else {
+          {
+            Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_4);
+            #if !CYTHON_ASSUME_SAFE_MACROS
+            if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 85, __pyx_L9_error)
+            #endif
+            if (__pyx_t_9 >= __pyx_temp) break;
+          }
+          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
+          __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_9); __Pyx_INCREF(__pyx_t_3); __pyx_t_9++; if (unlikely((0 < 0))) __PYX_ERR(0, 85, __pyx_L9_error)
+          #else
+          __pyx_t_3 = __Pyx_PySequence_ITEM(__pyx_t_4, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 85, __pyx_L9_error)
+          __Pyx_GOTREF(__pyx_t_3);
+          #endif
+        }
+      } else {
+        __pyx_t_3 = __pyx_t_10(__pyx_t_4);
+        if (unlikely(!__pyx_t_3)) {
+          PyObject* exc_type = PyErr_Occurred();
+          if (exc_type) {
+            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
+            else __PYX_ERR(0, 85, __pyx_L9_error)
+          }
+          break;
+        }
+        __Pyx_GOTREF(__pyx_t_3);
+      }
+      __Pyx_XDECREF_SET(__pyx_8genexpr1__pyx_v_i, __pyx_t_3);
+      __pyx_t_3 = 0;
+      __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_get_clause); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 85, __pyx_L9_error)
+      __Pyx_GOTREF(__pyx_t_11);
+      __pyx_t_12 = NULL;
+      __pyx_t_6 = 0;
+      #if CYTHON_UNPACK_METHODS
+      if (likely(PyMethod_Check(__pyx_t_11))) {
+        __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_11);
+        if (likely(__pyx_t_12)) {
+          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
+          __Pyx_INCREF(__pyx_t_12);
+          __Pyx_INCREF(function);
+          __Pyx_DECREF_SET(__pyx_t_11, function);
+          __pyx_t_6 = 1;
+        }
+      }
+      #endif
+      {
+        PyObject *__pyx_callargs[2] = {__pyx_t_12, __pyx_8genexpr1__pyx_v_i};
+        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_11, __pyx_callargs+1-__pyx_t_6, 1+__pyx_t_6);
+        __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
+        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 85, __pyx_L9_error)
+        __Pyx_GOTREF(__pyx_t_3);
+        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
+      }
+      if (unlikely(PySet_Add(__pyx_t_5, (PyObject*)__pyx_t_3))) __PYX_ERR(0, 85, __pyx_L9_error)
+      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+    }
+    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
+    __Pyx_XDECREF(__pyx_8genexpr1__pyx_v_i); __pyx_8genexpr1__pyx_v_i = 0;
+    goto __pyx_L13_exit_scope;
+    __pyx_L9_error:;
+    __Pyx_XDECREF(__pyx_8genexpr1__pyx_v_i); __pyx_8genexpr1__pyx_v_i = 0;
+    goto __pyx_L1_error;
+    __pyx_L13_exit_scope:;
+  } /* exit inner scope */
+  __pyx_v_other_clauses = ((PyObject*)__pyx_t_5);
+  __pyx_t_5 = 0;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":87
+ *         other_clauses = {other._get_clause(i) for i in range(other.n_clauses)}
+ * 
+ *         return self_clauses == other_clauses             # <<<<<<<<<<<<<<
+ * 
+ * 
+ */
+  __Pyx_XDECREF(__pyx_r);
+  __pyx_t_5 = PyObject_RichCompare(__pyx_v_self_clauses, __pyx_v_other_clauses, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 87, __pyx_L1_error)
+  __pyx_r = __pyx_t_5;
+  __pyx_t_5 = 0;
+  goto __pyx_L0;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":77
+ *             free(self.clauses)
+ * 
+ *     def __eq__(self, other):             # <<<<<<<<<<<<<<
+ *         if not isinstance(other, Rule):
+ *             return False
+ */
+
+  /* function exit code */
+  __pyx_L1_error:;
+  __Pyx_XDECREF(__pyx_t_3);
+  __Pyx_XDECREF(__pyx_t_4);
+  __Pyx_XDECREF(__pyx_t_5);
+  __Pyx_XDECREF(__pyx_t_11);
+  __Pyx_XDECREF(__pyx_t_12);
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.__eq__", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = NULL;
+  __pyx_L0:;
+  __Pyx_XDECREF(__pyx_v_self_clauses);
+  __Pyx_XDECREF(__pyx_v_other_clauses);
+  __Pyx_XDECREF(__pyx_8genexpr1__pyx_v_i);
+  __Pyx_XGIVEREF(__pyx_r);
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+/* "ruleopt/aux_classes/aux_classes.pyx":90
+ * 
+ * 
+ *     cpdef tuple _get_clause(self, int index):             # <<<<<<<<<<<<<<
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub
+ */
+
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause(PyObject *__pyx_v_self, 
+#if CYTHON_METH_FASTCALL
+PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
+#else
+PyObject *__pyx_args, PyObject *__pyx_kwds
+#endif
+); /*proto*/
+static PyObject *__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__get_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_index, int __pyx_skip_dispatch) {
+  int __pyx_v_feature;
+  double __pyx_v_ub;
+  double __pyx_v_lb;
+  int __pyx_v_na;
+  PyObject *__pyx_r = NULL;
+  __Pyx_RefNannyDeclarations
+  PyObject *__pyx_t_1 = NULL;
+  PyObject *__pyx_t_2 = NULL;
+  PyObject *__pyx_t_3 = NULL;
+  PyObject *__pyx_t_4 = NULL;
+  PyObject *__pyx_t_5 = NULL;
+  int __pyx_t_6;
+  double __pyx_t_7;
+  int __pyx_t_8;
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  __Pyx_RefNannySetupContext("_get_clause", 1);
+  /* Check if called by wrapper */
+  if (unlikely(__pyx_skip_dispatch)) ;
+  /* Check if overridden in Python */
+  else if (unlikely((Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0) || __Pyx_PyType_HasFeature(Py_TYPE(((PyObject *)__pyx_v_self)), (Py_TPFLAGS_IS_ABSTRACT | Py_TPFLAGS_HEAPTYPE)))) {
+    #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
+    static PY_UINT64_T __pyx_tp_dict_version = __PYX_DICT_VERSION_INIT, __pyx_obj_dict_version = __PYX_DICT_VERSION_INIT;
+    if (unlikely(!__Pyx_object_dict_version_matches(((PyObject *)__pyx_v_self), __pyx_tp_dict_version, __pyx_obj_dict_version))) {
+      PY_UINT64_T __pyx_typedict_guard = __Pyx_get_tp_dict_version(((PyObject *)__pyx_v_self));
+      #endif
+      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get_clause); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 90, __pyx_L1_error)
+      __Pyx_GOTREF(__pyx_t_1);
+      if (!__Pyx_IsSameCFunction(__pyx_t_1, (void*) __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause)) {
+        __Pyx_XDECREF(__pyx_r);
+        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_index); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 90, __pyx_L1_error)
+        __Pyx_GOTREF(__pyx_t_3);
+        __Pyx_INCREF(__pyx_t_1);
+        __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
+        __pyx_t_6 = 0;
+        #if CYTHON_UNPACK_METHODS
+        if (unlikely(PyMethod_Check(__pyx_t_4))) {
+          __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
+          if (likely(__pyx_t_5)) {
+            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
+            __Pyx_INCREF(__pyx_t_5);
+            __Pyx_INCREF(function);
+            __Pyx_DECREF_SET(__pyx_t_4, function);
+            __pyx_t_6 = 1;
+          }
+        }
+        #endif
+        {
+          PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_3};
+          __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+1-__pyx_t_6, 1+__pyx_t_6);
+          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
+          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 90, __pyx_L1_error)
+          __Pyx_GOTREF(__pyx_t_2);
+          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
+        }
+        if (!(likely(PyTuple_CheckExact(__pyx_t_2))||((__pyx_t_2) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_t_2))) __PYX_ERR(0, 90, __pyx_L1_error)
+        __pyx_r = ((PyObject*)__pyx_t_2);
+        __pyx_t_2 = 0;
+        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+        goto __pyx_L0;
+      }
+      #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
+      __pyx_tp_dict_version = __Pyx_get_tp_dict_version(((PyObject *)__pyx_v_self));
+      __pyx_obj_dict_version = __Pyx_get_object_dict_version(((PyObject *)__pyx_v_self));
+      if (unlikely(__pyx_typedict_guard != __pyx_tp_dict_version)) {
+        __pyx_tp_dict_version = __pyx_obj_dict_version = __PYX_DICT_VERSION_INIT;
+      }
+      #endif
+      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+      #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
+    }
+    #endif
+  }
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":91
+ * 
+ *     cpdef tuple _get_clause(self, int index):
+ *         cdef int feature = self.clauses[index].feature             # <<<<<<<<<<<<<<
+ *         cdef double ub = self.clauses[index].ub
+ *         cdef double lb = self.clauses[index].lb
+ */
+  __pyx_t_6 = (__pyx_v_self->clauses[__pyx_v_index]).feature;
+  __pyx_v_feature = __pyx_t_6;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":92
+ *     cpdef tuple _get_clause(self, int index):
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub             # <<<<<<<<<<<<<<
+ *         cdef double lb = self.clauses[index].lb
+ *         cdef bint na = self.clauses[index].na
+ */
+  __pyx_t_7 = (__pyx_v_self->clauses[__pyx_v_index]).ub;
+  __pyx_v_ub = __pyx_t_7;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":93
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub
+ *         cdef double lb = self.clauses[index].lb             # <<<<<<<<<<<<<<
+ *         cdef bint na = self.clauses[index].na
+ * 
+ */
+  __pyx_t_7 = (__pyx_v_self->clauses[__pyx_v_index]).lb;
+  __pyx_v_lb = __pyx_t_7;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":94
+ *         cdef double ub = self.clauses[index].ub
+ *         cdef double lb = self.clauses[index].lb
+ *         cdef bint na = self.clauses[index].na             # <<<<<<<<<<<<<<
+ * 
+ *         return feature, ub, lb, na
+ */
+  __pyx_t_8 = (__pyx_v_self->clauses[__pyx_v_index]).na;
+  __pyx_v_na = __pyx_t_8;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":96
+ *         cdef bint na = self.clauses[index].na
+ * 
+ *         return feature, ub, lb, na             # <<<<<<<<<<<<<<
+ * 
+ *     cpdef add_clause(self, int feature, double ub, double lb, bint na):
+ */
+  __Pyx_XDECREF(__pyx_r);
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_feature); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 96, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_1);
+  __pyx_t_2 = PyFloat_FromDouble(__pyx_v_ub); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 96, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_2);
+  __pyx_t_4 = PyFloat_FromDouble(__pyx_v_lb); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 96, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_4);
+  __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_na); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 96, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_3);
+  __pyx_t_5 = PyTuple_New(4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 96, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_5);
+  __Pyx_GIVEREF(__pyx_t_1);
+  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_1)) __PYX_ERR(0, 96, __pyx_L1_error);
+  __Pyx_GIVEREF(__pyx_t_2);
+  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_2)) __PYX_ERR(0, 96, __pyx_L1_error);
+  __Pyx_GIVEREF(__pyx_t_4);
+  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_t_4)) __PYX_ERR(0, 96, __pyx_L1_error);
+  __Pyx_GIVEREF(__pyx_t_3);
+  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_3)) __PYX_ERR(0, 96, __pyx_L1_error);
+  __pyx_t_1 = 0;
+  __pyx_t_2 = 0;
+  __pyx_t_4 = 0;
+  __pyx_t_3 = 0;
+  __pyx_r = ((PyObject*)__pyx_t_5);
+  __pyx_t_5 = 0;
+  goto __pyx_L0;
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":90
+ * 
+ * 
+ *     cpdef tuple _get_clause(self, int index):             # <<<<<<<<<<<<<<
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub
+ */
+
+  /* function exit code */
+  __pyx_L1_error:;
+  __Pyx_XDECREF(__pyx_t_1);
+  __Pyx_XDECREF(__pyx_t_2);
+  __Pyx_XDECREF(__pyx_t_3);
+  __Pyx_XDECREF(__pyx_t_4);
+  __Pyx_XDECREF(__pyx_t_5);
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule._get_clause", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = 0;
+  __pyx_L0:;
+  __Pyx_XGIVEREF(__pyx_r);
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+/* Python wrapper */
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause(PyObject *__pyx_v_self, 
+#if CYTHON_METH_FASTCALL
+PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
+#else
+PyObject *__pyx_args, PyObject *__pyx_kwds
+#endif
+); /*proto*/
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause = {"_get_clause", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause(PyObject *__pyx_v_self, 
+#if CYTHON_METH_FASTCALL
+PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
+#else
+PyObject *__pyx_args, PyObject *__pyx_kwds
+#endif
+) {
+  int __pyx_v_index;
+  #if !CYTHON_METH_FASTCALL
+  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
+  #endif
+  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
+  PyObject* values[1] = {0};
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  PyObject *__pyx_r = 0;
+  __Pyx_RefNannyDeclarations
+  __Pyx_RefNannySetupContext("_get_clause (wrapper)", 0);
+  #if !CYTHON_METH_FASTCALL
+  #if CYTHON_ASSUME_SAFE_MACROS
+  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
+  #else
+  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
+  #endif
+  #endif
+  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
+  {
+    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_index,0};
+    if (__pyx_kwds) {
+      Py_ssize_t kw_args;
+      switch (__pyx_nargs) {
+        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
+        CYTHON_FALLTHROUGH;
+        case  0: break;
+        default: goto __pyx_L5_argtuple_error;
+      }
+      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
+      switch (__pyx_nargs) {
+        case  0:
+        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_index)) != 0)) {
+          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
+          kw_args--;
+        }
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 90, __pyx_L3_error)
+        else goto __pyx_L5_argtuple_error;
+      }
+      if (unlikely(kw_args > 0)) {
+        const Py_ssize_t kwd_pos_args = __pyx_nargs;
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "_get_clause") < 0)) __PYX_ERR(0, 90, __pyx_L3_error)
+      }
+    } else if (unlikely(__pyx_nargs != 1)) {
+      goto __pyx_L5_argtuple_error;
+    } else {
+      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
+    }
+    __pyx_v_index = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 90, __pyx_L3_error)
+  }
+  goto __pyx_L6_skip;
+  __pyx_L5_argtuple_error:;
+  __Pyx_RaiseArgtupleInvalid("_get_clause", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 90, __pyx_L3_error)
+  __pyx_L6_skip:;
+  goto __pyx_L4_argument_unpacking_done;
+  __pyx_L3_error:;
+  {
+    Py_ssize_t __pyx_temp;
+    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
+      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
+    }
+  }
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule._get_clause", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __Pyx_RefNannyFinishContext();
+  return NULL;
+  __pyx_L4_argument_unpacking_done:;
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8_get_clause(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_index);
+
+  /* function exit code */
+  {
+    Py_ssize_t __pyx_temp;
+    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
+      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
+    }
+  }
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8_get_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_index) {
+  PyObject *__pyx_r = NULL;
+  __Pyx_RefNannyDeclarations
+  PyObject *__pyx_t_1 = NULL;
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  __Pyx_RefNannySetupContext("_get_clause", 1);
+  __Pyx_XDECREF(__pyx_r);
+  __pyx_t_1 = __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__get_clause(__pyx_v_self, __pyx_v_index, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 90, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_1);
+  __pyx_r = __pyx_t_1;
+  __pyx_t_1 = 0;
+  goto __pyx_L0;
+
+  /* function exit code */
+  __pyx_L1_error:;
+  __Pyx_XDECREF(__pyx_t_1);
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule._get_clause", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = NULL;
+  __pyx_L0:;
+  __Pyx_XGIVEREF(__pyx_r);
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+/* "ruleopt/aux_classes/aux_classes.pyx":98
+ *         return feature, ub, lb, na
+ * 
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na):             # <<<<<<<<<<<<<<
  *         """
  *         Adds a new clause to the rule or updates an existing clause for the given feature.
  */
 
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
 static PyObject *__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na, int __pyx_skip_dispatch) {
@@ -21170,25 +21797,25 @@
   /* Check if overridden in Python */
   else if (unlikely((Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0) || __Pyx_PyType_HasFeature(Py_TYPE(((PyObject *)__pyx_v_self)), (Py_TPFLAGS_IS_ABSTRACT | Py_TPFLAGS_HEAPTYPE)))) {
     #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
     static PY_UINT64_T __pyx_tp_dict_version = __PYX_DICT_VERSION_INIT, __pyx_obj_dict_version = __PYX_DICT_VERSION_INIT;
     if (unlikely(!__Pyx_object_dict_version_matches(((PyObject *)__pyx_v_self), __pyx_tp_dict_version, __pyx_obj_dict_version))) {
       PY_UINT64_T __pyx_typedict_guard = __Pyx_get_tp_dict_version(((PyObject *)__pyx_v_self));
       #endif
-      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_add_clause); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 77, __pyx_L1_error)
+      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_add_clause); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 98, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_1);
-      if (!__Pyx_IsSameCFunction(__pyx_t_1, (void*) __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause)) {
+      if (!__Pyx_IsSameCFunction(__pyx_t_1, (void*) __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause)) {
         __Pyx_XDECREF(__pyx_r);
-        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_feature); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 77, __pyx_L1_error)
+        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_feature); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 98, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_3);
-        __pyx_t_4 = PyFloat_FromDouble(__pyx_v_ub); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 77, __pyx_L1_error)
+        __pyx_t_4 = PyFloat_FromDouble(__pyx_v_ub); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 98, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_4);
-        __pyx_t_5 = PyFloat_FromDouble(__pyx_v_lb); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 77, __pyx_L1_error)
+        __pyx_t_5 = PyFloat_FromDouble(__pyx_v_lb); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 98, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_5);
-        __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_na); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 77, __pyx_L1_error)
+        __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_na); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 98, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_6);
         __Pyx_INCREF(__pyx_t_1);
         __pyx_t_7 = __pyx_t_1; __pyx_t_8 = NULL;
         __pyx_t_9 = 0;
         #if CYTHON_UNPACK_METHODS
         if (unlikely(PyMethod_Check(__pyx_t_7))) {
           __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_7);
@@ -21205,15 +21832,15 @@
           PyObject *__pyx_callargs[5] = {__pyx_t_8, __pyx_t_3, __pyx_t_4, __pyx_t_5, __pyx_t_6};
           __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+1-__pyx_t_9, 4+__pyx_t_9);
           __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
           __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
           __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
           __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
           __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
-          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 77, __pyx_L1_error)
+          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 98, __pyx_L1_error)
           __Pyx_GOTREF(__pyx_t_2);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         }
         __pyx_r = __pyx_t_2;
         __pyx_t_2 = 0;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         goto __pyx_L0;
@@ -21227,46 +21854,46 @@
       #endif
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
     }
     #endif
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":92
+  /* "ruleopt/aux_classes/aux_classes.pyx":113
  *             A flag indicating whether NaN values should be considered as matching this clause.
  *         """
  *         cdef bint check_exist = 0             # <<<<<<<<<<<<<<
  *         cdef int i
  * 
  */
   __pyx_v_check_exist = 0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":96
+  /* "ruleopt/aux_classes/aux_classes.pyx":117
  * 
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):             # <<<<<<<<<<<<<<
  *                 if feature == self.clauses[i].feature:
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)
  */
   __pyx_t_9 = __pyx_v_self->n_clauses;
   __pyx_t_10 = __pyx_t_9;
   for (__pyx_t_11 = 0; __pyx_t_11 < __pyx_t_10; __pyx_t_11+=1) {
     __pyx_v_i = __pyx_t_11;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":97
+    /* "ruleopt/aux_classes/aux_classes.pyx":118
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):
  *                 if feature == self.clauses[i].feature:             # <<<<<<<<<<<<<<
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)
  */
     __pyx_t_12 = (__pyx_v_feature == (__pyx_v_self->clauses[__pyx_v_i]).feature);
     if (__pyx_t_12) {
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":98
+      /* "ruleopt/aux_classes/aux_classes.pyx":119
  *             for i in range(self.n_clauses):
  *                 if feature == self.clauses[i].feature:
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)             # <<<<<<<<<<<<<<
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)
  *                     check_exist = 1
  */
       __pyx_t_13 = __pyx_v_lb;
@@ -21275,15 +21902,15 @@
       if (__pyx_t_12) {
         __pyx_t_15 = __pyx_t_13;
       } else {
         __pyx_t_15 = __pyx_t_14;
       }
       (__pyx_v_self->clauses[__pyx_v_i]).lb = __pyx_t_15;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":99
+      /* "ruleopt/aux_classes/aux_classes.pyx":120
  *                 if feature == self.clauses[i].feature:
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)             # <<<<<<<<<<<<<<
  *                     check_exist = 1
  *                     break
  */
       __pyx_t_15 = __pyx_v_ub;
@@ -21292,118 +21919,118 @@
       if (__pyx_t_12) {
         __pyx_t_14 = __pyx_t_15;
       } else {
         __pyx_t_14 = __pyx_t_13;
       }
       (__pyx_v_self->clauses[__pyx_v_i]).ub = __pyx_t_14;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":100
+      /* "ruleopt/aux_classes/aux_classes.pyx":121
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)
  *                     check_exist = 1             # <<<<<<<<<<<<<<
  *                     break
  * 
  */
       __pyx_v_check_exist = 1;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":101
+      /* "ruleopt/aux_classes/aux_classes.pyx":122
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)
  *                     check_exist = 1
  *                     break             # <<<<<<<<<<<<<<
  * 
  *         if check_exist == 0:
  */
       goto __pyx_L4_break;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":97
+      /* "ruleopt/aux_classes/aux_classes.pyx":118
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):
  *                 if feature == self.clauses[i].feature:             # <<<<<<<<<<<<<<
  *                     self.clauses[i].lb = max(self.clauses[i].lb, lb)
  *                     self.clauses[i].ub = min(self.clauses[i].ub, ub)
  */
     }
   }
   __pyx_L4_break:;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":103
+  /* "ruleopt/aux_classes/aux_classes.pyx":124
  *                     break
  * 
  *         if check_exist == 0:             # <<<<<<<<<<<<<<
  *             self.clauses = <ClauseStruct*>realloc(self.clauses, (self.n_clauses + 1) * sizeof(ClauseStruct))
  * 
  */
   __pyx_t_12 = (__pyx_v_check_exist == 0);
   if (__pyx_t_12) {
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":104
+    /* "ruleopt/aux_classes/aux_classes.pyx":125
  * 
  *         if check_exist == 0:
  *             self.clauses = <ClauseStruct*>realloc(self.clauses, (self.n_clauses + 1) * sizeof(ClauseStruct))             # <<<<<<<<<<<<<<
  * 
  *             self.clauses[self.n_clauses].feature = feature
  */
     __pyx_v_self->clauses = ((struct __pyx_t_7ruleopt_11aux_classes_11aux_classes_ClauseStruct *)realloc(__pyx_v_self->clauses, ((__pyx_v_self->n_clauses + 1) * (sizeof(struct __pyx_t_7ruleopt_11aux_classes_11aux_classes_ClauseStruct)))));
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":106
+    /* "ruleopt/aux_classes/aux_classes.pyx":127
  *             self.clauses = <ClauseStruct*>realloc(self.clauses, (self.n_clauses + 1) * sizeof(ClauseStruct))
  * 
  *             self.clauses[self.n_clauses].feature = feature             # <<<<<<<<<<<<<<
  *             self.clauses[self.n_clauses].ub = ub
  *             self.clauses[self.n_clauses].lb = lb
  */
     (__pyx_v_self->clauses[__pyx_v_self->n_clauses]).feature = __pyx_v_feature;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":107
+    /* "ruleopt/aux_classes/aux_classes.pyx":128
  * 
  *             self.clauses[self.n_clauses].feature = feature
  *             self.clauses[self.n_clauses].ub = ub             # <<<<<<<<<<<<<<
  *             self.clauses[self.n_clauses].lb = lb
  *             self.clauses[self.n_clauses].na = na
  */
     (__pyx_v_self->clauses[__pyx_v_self->n_clauses]).ub = __pyx_v_ub;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":108
+    /* "ruleopt/aux_classes/aux_classes.pyx":129
  *             self.clauses[self.n_clauses].feature = feature
  *             self.clauses[self.n_clauses].ub = ub
  *             self.clauses[self.n_clauses].lb = lb             # <<<<<<<<<<<<<<
  *             self.clauses[self.n_clauses].na = na
  * 
  */
     (__pyx_v_self->clauses[__pyx_v_self->n_clauses]).lb = __pyx_v_lb;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":109
+    /* "ruleopt/aux_classes/aux_classes.pyx":130
  *             self.clauses[self.n_clauses].ub = ub
  *             self.clauses[self.n_clauses].lb = lb
  *             self.clauses[self.n_clauses].na = na             # <<<<<<<<<<<<<<
  * 
  *             self.n_clauses += 1
  */
     (__pyx_v_self->clauses[__pyx_v_self->n_clauses]).na = __pyx_v_na;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":111
+    /* "ruleopt/aux_classes/aux_classes.pyx":132
  *             self.clauses[self.n_clauses].na = na
  * 
  *             self.n_clauses += 1             # <<<<<<<<<<<<<<
  * 
  *     cdef bint _check_rule_nogil(self, float[:] X) noexcept nogil:
  */
     __pyx_v_self->n_clauses = (__pyx_v_self->n_clauses + 1);
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":103
+    /* "ruleopt/aux_classes/aux_classes.pyx":124
  *                     break
  * 
  *         if check_exist == 0:             # <<<<<<<<<<<<<<
  *             self.clauses = <ClauseStruct*>realloc(self.clauses, (self.n_clauses + 1) * sizeof(ClauseStruct))
  * 
  */
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":77
- *             free(self.clauses)
+  /* "ruleopt/aux_classes/aux_classes.pyx":98
+ *         return feature, ub, lb, na
  * 
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na):             # <<<<<<<<<<<<<<
  *         """
  *         Adds a new clause to the rule or updates an existing clause for the given feature.
  */
 
   /* function exit code */
@@ -21423,24 +22050,24 @@
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_6add_clause, "\n        Adds a new clause to the rule or updates an existing clause for the given feature.\n\n        Parameters:\n        -----------\n        feature : int\n            The feature index to which the clause applies.\n        ub : double\n            The upper bound for the feature value.\n        lb : double\n            The lower bound for the feature value.\n        na : bint\n            A flag indicating whether NaN values should be considered as matching this clause.\n        ");
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause = {"add_clause", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_6add_clause};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause(PyObject *__pyx_v_self, 
+PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_10add_clause, "\n        Adds a new clause to the rule or updates an existing clause for the given feature.\n\n        Parameters:\n        -----------\n        feature : int\n            The feature index to which the clause applies.\n        ub : double\n            The upper bound for the feature value.\n        lb : double\n            The lower bound for the feature value.\n        na : bint\n            A flag indicating whether NaN values should be considered as matching this clause.\n        ");
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause = {"add_clause", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_10add_clause};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   int __pyx_v_feature;
@@ -21485,103 +22112,103 @@
       kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
       switch (__pyx_nargs) {
         case  0:
         if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_feature)) != 0)) {
           (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
           kw_args--;
         }
-        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
         else goto __pyx_L5_argtuple_error;
         CYTHON_FALLTHROUGH;
         case  1:
         if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_ub)) != 0)) {
           (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
           kw_args--;
         }
-        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
         else {
-          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 1); __PYX_ERR(0, 77, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 1); __PYX_ERR(0, 98, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  2:
         if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_lb)) != 0)) {
           (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
           kw_args--;
         }
-        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
         else {
-          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 2); __PYX_ERR(0, 77, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 2); __PYX_ERR(0, 98, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  3:
         if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_na)) != 0)) {
           (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
           kw_args--;
         }
-        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
         else {
-          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 3); __PYX_ERR(0, 77, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, 3); __PYX_ERR(0, 98, __pyx_L3_error)
         }
       }
       if (unlikely(kw_args > 0)) {
         const Py_ssize_t kwd_pos_args = __pyx_nargs;
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "add_clause") < 0)) __PYX_ERR(0, 77, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "add_clause") < 0)) __PYX_ERR(0, 98, __pyx_L3_error)
       }
     } else if (unlikely(__pyx_nargs != 4)) {
       goto __pyx_L5_argtuple_error;
     } else {
       values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
       values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
       values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
       values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
     }
-    __pyx_v_feature = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_feature == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
-    __pyx_v_ub = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_ub == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
-    __pyx_v_lb = __pyx_PyFloat_AsDouble(values[2]); if (unlikely((__pyx_v_lb == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
-    __pyx_v_na = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_na == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L3_error)
+    __pyx_v_feature = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_feature == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
+    __pyx_v_ub = __pyx_PyFloat_AsDouble(values[1]); if (unlikely((__pyx_v_ub == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
+    __pyx_v_lb = __pyx_PyFloat_AsDouble(values[2]); if (unlikely((__pyx_v_lb == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
+    __pyx_v_na = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_na == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L3_error)
   }
   goto __pyx_L6_skip;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 77, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("add_clause", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 98, __pyx_L3_error)
   __pyx_L6_skip:;
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L3_error:;
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.add_clause", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6add_clause(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature, __pyx_v_ub, __pyx_v_lb, __pyx_v_na);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10add_clause(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature, __pyx_v_ub, __pyx_v_lb, __pyx_v_na);
 
   /* function exit code */
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_6add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na) {
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10add_clause(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, int __pyx_v_feature, double __pyx_v_ub, double __pyx_v_lb, int __pyx_v_na) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("add_clause", 1);
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_add_clause(__pyx_v_self, __pyx_v_feature, __pyx_v_ub, __pyx_v_lb, __pyx_v_na, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 77, __pyx_L1_error)
+  __pyx_t_1 = __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_add_clause(__pyx_v_self, __pyx_v_feature, __pyx_v_ub, __pyx_v_lb, __pyx_v_na, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 98, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
   /* function exit code */
   __pyx_L1_error:;
@@ -21590,15 +22217,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "ruleopt/aux_classes/aux_classes.pyx":113
+/* "ruleopt/aux_classes/aux_classes.pyx":134
  *             self.n_clauses += 1
  * 
  *     cdef bint _check_rule_nogil(self, float[:] X) noexcept nogil:             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values,
  */
 
@@ -21606,179 +22233,179 @@
   int __pyx_v_i;
   int __pyx_r;
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_t_4;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":130
+  /* "ruleopt/aux_classes/aux_classes.pyx":151
  *         cdef int i
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):             # <<<<<<<<<<<<<<
  *                 if not self._check_clause_nogil(X, i):
  *                     return False
  */
   __pyx_t_1 = __pyx_v_self->n_clauses;
   __pyx_t_2 = __pyx_t_1;
   for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
     __pyx_v_i = __pyx_t_3;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":131
+    /* "ruleopt/aux_classes/aux_classes.pyx":152
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):
  *                 if not self._check_clause_nogil(X, i):             # <<<<<<<<<<<<<<
  *                     return False
  *         return True
  */
     __pyx_t_4 = (!((struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self->__pyx_vtab)->_check_clause_nogil(__pyx_v_self, __pyx_v_X, __pyx_v_i));
     if (__pyx_t_4) {
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":132
+      /* "ruleopt/aux_classes/aux_classes.pyx":153
  *             for i in range(self.n_clauses):
  *                 if not self._check_clause_nogil(X, i):
  *                     return False             # <<<<<<<<<<<<<<
  *         return True
  * 
  */
       __pyx_r = 0;
       goto __pyx_L0;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":131
+      /* "ruleopt/aux_classes/aux_classes.pyx":152
  *         with boundscheck(False):
  *             for i in range(self.n_clauses):
  *                 if not self._check_clause_nogil(X, i):             # <<<<<<<<<<<<<<
  *                     return False
  *         return True
  */
     }
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":133
+  /* "ruleopt/aux_classes/aux_classes.pyx":154
  *                 if not self._check_clause_nogil(X, i):
  *                     return False
  *         return True             # <<<<<<<<<<<<<<
  * 
  *     cdef bint _check_clause_nogil(self, float[:] X, int idx) noexcept nogil:
  */
   __pyx_r = 1;
   goto __pyx_L0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":113
+  /* "ruleopt/aux_classes/aux_classes.pyx":134
  *             self.n_clauses += 1
  * 
  *     cdef bint _check_rule_nogil(self, float[:] X) noexcept nogil:             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values,
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "ruleopt/aux_classes/aux_classes.pyx":135
+/* "ruleopt/aux_classes/aux_classes.pyx":156
  *         return True
  * 
  *     cdef bint _check_clause_nogil(self, float[:] X, int idx) noexcept nogil:             # <<<<<<<<<<<<<<
  *         """
  *         Checks if a specific clause of the rule applies to the given feature values,
  */
 
 static int __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__check_clause_nogil(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X, int __pyx_v_idx) {
   struct __pyx_t_7ruleopt_11aux_classes_11aux_classes_ClauseStruct __pyx_v_clause;
   float __pyx_v_val;
   int __pyx_r;
   Py_ssize_t __pyx_t_1;
   int __pyx_t_2;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":156
+  /* "ruleopt/aux_classes/aux_classes.pyx":177
  * 
  *         with boundscheck(False):
  *             clause = self.clauses[idx]             # <<<<<<<<<<<<<<
  *             val = X[clause.feature]
  * 
  */
   __pyx_v_clause = (__pyx_v_self->clauses[__pyx_v_idx]);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":157
+  /* "ruleopt/aux_classes/aux_classes.pyx":178
  *         with boundscheck(False):
  *             clause = self.clauses[idx]
  *             val = X[clause.feature]             # <<<<<<<<<<<<<<
  * 
  *         if val != val:  # Checking for NaN
  */
   __pyx_t_1 = __pyx_v_clause.feature;
   if (__pyx_t_1 < 0) __pyx_t_1 += __pyx_v_X.shape[0];
   __pyx_v_val = (*((float *) ( /* dim=0 */ (__pyx_v_X.data + __pyx_t_1 * __pyx_v_X.strides[0]) )));
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":159
+  /* "ruleopt/aux_classes/aux_classes.pyx":180
  *             val = X[clause.feature]
  * 
  *         if val != val:  # Checking for NaN             # <<<<<<<<<<<<<<
  *             return clause.na
  *         return clause.lb < val <= clause.ub
  */
   __pyx_t_2 = (__pyx_v_val != __pyx_v_val);
   if (__pyx_t_2) {
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":160
+    /* "ruleopt/aux_classes/aux_classes.pyx":181
  * 
  *         if val != val:  # Checking for NaN
  *             return clause.na             # <<<<<<<<<<<<<<
  *         return clause.lb < val <= clause.ub
  * 
  */
     __pyx_r = __pyx_v_clause.na;
     goto __pyx_L0;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":159
+    /* "ruleopt/aux_classes/aux_classes.pyx":180
  *             val = X[clause.feature]
  * 
  *         if val != val:  # Checking for NaN             # <<<<<<<<<<<<<<
  *             return clause.na
  *         return clause.lb < val <= clause.ub
  */
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":161
+  /* "ruleopt/aux_classes/aux_classes.pyx":182
  *         if val != val:  # Checking for NaN
  *             return clause.na
  *         return clause.lb < val <= clause.ub             # <<<<<<<<<<<<<<
  * 
  *     cpdef bint check_rule(self, float[:] X):
  */
   __pyx_t_2 = (__pyx_v_clause.lb < __pyx_v_val);
   if (__pyx_t_2) {
     __pyx_t_2 = (__pyx_v_val <= __pyx_v_clause.ub);
   }
   __pyx_r = __pyx_t_2;
   goto __pyx_L0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":135
+  /* "ruleopt/aux_classes/aux_classes.pyx":156
  *         return True
  * 
  *     cdef bint _check_clause_nogil(self, float[:] X, int idx) noexcept nogil:             # <<<<<<<<<<<<<<
  *         """
  *         Checks if a specific clause of the rule applies to the given feature values,
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "ruleopt/aux_classes/aux_classes.pyx":163
+/* "ruleopt/aux_classes/aux_classes.pyx":184
  *         return clause.lb < val <= clause.ub
  * 
  *     cpdef bint check_rule(self, float[:] X):             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values.
  */
 
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
 static int __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X, int __pyx_skip_dispatch) {
@@ -21800,19 +22427,19 @@
   /* Check if overridden in Python */
   else if (unlikely((Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0) || __Pyx_PyType_HasFeature(Py_TYPE(((PyObject *)__pyx_v_self)), (Py_TPFLAGS_IS_ABSTRACT | Py_TPFLAGS_HEAPTYPE)))) {
     #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
     static PY_UINT64_T __pyx_tp_dict_version = __PYX_DICT_VERSION_INIT, __pyx_obj_dict_version = __PYX_DICT_VERSION_INIT;
     if (unlikely(!__Pyx_object_dict_version_matches(((PyObject *)__pyx_v_self), __pyx_tp_dict_version, __pyx_obj_dict_version))) {
       PY_UINT64_T __pyx_typedict_guard = __Pyx_get_tp_dict_version(((PyObject *)__pyx_v_self));
       #endif
-      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_check_rule); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 163, __pyx_L1_error)
+      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_check_rule); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 184, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_1);
-      if (!__Pyx_IsSameCFunction(__pyx_t_1, (void*) __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule)) {
-        if (unlikely(!__pyx_v_X.memview)) { __Pyx_RaiseUnboundLocalError("X"); __PYX_ERR(0, 163, __pyx_L1_error) }
-        __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_X, 1, (PyObject *(*)(char *)) __pyx_memview_get_float, (int (*)(char *, PyObject *)) __pyx_memview_set_float, 0);; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 163, __pyx_L1_error)
+      if (!__Pyx_IsSameCFunction(__pyx_t_1, (void*) __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule)) {
+        if (unlikely(!__pyx_v_X.memview)) { __Pyx_RaiseUnboundLocalError("X"); __PYX_ERR(0, 184, __pyx_L1_error) }
+        __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_X, 1, (PyObject *(*)(char *)) __pyx_memview_get_float, (int (*)(char *, PyObject *)) __pyx_memview_set_float, 0);; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 184, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_INCREF(__pyx_t_1);
         __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
         __pyx_t_6 = 0;
         #if CYTHON_UNPACK_METHODS
         if (unlikely(PyMethod_Check(__pyx_t_4))) {
           __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
@@ -21826,19 +22453,19 @@
         }
         #endif
         {
           PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_3};
           __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+1-__pyx_t_6, 1+__pyx_t_6);
           __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
           __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 163, __pyx_L1_error)
+          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 184, __pyx_L1_error)
           __Pyx_GOTREF(__pyx_t_2);
           __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
         }
-        __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 163, __pyx_L1_error)
+        __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 184, __pyx_L1_error)
         __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
         __pyx_r = __pyx_t_7;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         goto __pyx_L0;
       }
       #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
       __pyx_tp_dict_version = __Pyx_get_tp_dict_version(((PyObject *)__pyx_v_self));
@@ -21849,25 +22476,25 @@
       #endif
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       #if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
     }
     #endif
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":177
+  /* "ruleopt/aux_classes/aux_classes.pyx":198
  *             True if the rule applies, False otherwise.
  *         """
  *         return self._check_rule_nogil(X)             # <<<<<<<<<<<<<<
  * 
  *     def to_text(self, feature_names=None):
  */
   __pyx_r = ((struct __pyx_vtabstruct_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self->__pyx_vtab)->_check_rule_nogil(__pyx_v_self, __pyx_v_X);
   goto __pyx_L0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":163
+  /* "ruleopt/aux_classes/aux_classes.pyx":184
  *         return clause.lb < val <= clause.ub
  * 
  *     cpdef bint check_rule(self, float[:] X):             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values.
  */
 
@@ -21882,24 +22509,24 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_8check_rule, "\n        Checks if the rule applies to the given feature values.\n\n        Parameters:\n        -----------\n        X : cnp.ndarray[float, ndim=1]\n            The array of feature values to check against the rule.\n\n        Returns:\n        --------\n        bint\n            True if the rule applies, False otherwise.\n        ");
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule = {"check_rule", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_8check_rule};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule(PyObject *__pyx_v_self, 
+PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_12check_rule, "\n        Checks if the rule applies to the given feature values.\n\n        Parameters:\n        -----------\n        X : cnp.ndarray[float, ndim=1]\n            The array of feature values to check against the rule.\n\n        Returns:\n        --------\n        bint\n            True if the rule applies, False otherwise.\n        ");
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule = {"check_rule", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_12check_rule};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   __Pyx_memviewslice __pyx_v_X = { 0, 0, { 0 }, { 0 }, { 0 } };
@@ -21935,72 +22562,72 @@
       kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
       switch (__pyx_nargs) {
         case  0:
         if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_X)) != 0)) {
           (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
           kw_args--;
         }
-        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 163, __pyx_L3_error)
+        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 184, __pyx_L3_error)
         else goto __pyx_L5_argtuple_error;
       }
       if (unlikely(kw_args > 0)) {
         const Py_ssize_t kwd_pos_args = __pyx_nargs;
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "check_rule") < 0)) __PYX_ERR(0, 163, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "check_rule") < 0)) __PYX_ERR(0, 184, __pyx_L3_error)
       }
     } else if (unlikely(__pyx_nargs != 1)) {
       goto __pyx_L5_argtuple_error;
     } else {
       values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
     }
-    __pyx_v_X = __Pyx_PyObject_to_MemoryviewSlice_ds_float(values[0], PyBUF_WRITABLE); if (unlikely(!__pyx_v_X.memview)) __PYX_ERR(0, 163, __pyx_L3_error)
+    __pyx_v_X = __Pyx_PyObject_to_MemoryviewSlice_ds_float(values[0], PyBUF_WRITABLE); if (unlikely(!__pyx_v_X.memview)) __PYX_ERR(0, 184, __pyx_L3_error)
   }
   goto __pyx_L6_skip;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("check_rule", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 163, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("check_rule", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 184, __pyx_L3_error)
   __pyx_L6_skip:;
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L3_error:;
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __PYX_XCLEAR_MEMVIEW(&__pyx_v_X, 1);
   __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.check_rule", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8check_rule(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_X);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12check_rule(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_X);
 
   /* function exit code */
   __PYX_XCLEAR_MEMVIEW(&__pyx_v_X, 1);
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_8check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X) {
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12check_rule(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, __Pyx_memviewslice __pyx_v_X) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("check_rule", 1);
   __Pyx_XDECREF(__pyx_r);
-  if (unlikely(!__pyx_v_X.memview)) { __Pyx_RaiseUnboundLocalError("X"); __PYX_ERR(0, 163, __pyx_L1_error) }
-  __pyx_t_1 = __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_check_rule(__pyx_v_self, __pyx_v_X, 1); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 163, __pyx_L1_error)
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 163, __pyx_L1_error)
+  if (unlikely(!__pyx_v_X.memview)) { __Pyx_RaiseUnboundLocalError("X"); __PYX_ERR(0, 184, __pyx_L1_error) }
+  __pyx_t_1 = __pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_check_rule(__pyx_v_self, __pyx_v_X, 1); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 184, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 184, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
   /* function exit code */
   __pyx_L1_error:;
@@ -22009,33 +22636,33 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "ruleopt/aux_classes/aux_classes.pyx":179
+/* "ruleopt/aux_classes/aux_classes.pyx":200
  *         return self._check_rule_nogil(X)
  * 
  *     def to_text(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a human-readable text representation, using optional
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text, "\n        Converts the rule to a human-readable text representation, using optional \n        feature names for clarity.\n\n        Parameters:\n        ----------\n        feature_names : list, optional\n            A list of feature names corresponding to feature indices. If None, f\n            eature indices are used.\n\n        Returns:\n        -------\n        str\n            A human-readable string representation of the rule.\n        ");
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text = {"to_text", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text(PyObject *__pyx_v_self, 
+PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text, "\n        Converts the rule to a human-readable text representation, using optional \n        feature names for clarity.\n\n        Parameters:\n        ----------\n        feature_names : list, optional\n            A list of feature names corresponding to feature indices. If None, f\n            eature indices are used.\n\n        Returns:\n        -------\n        str\n            A human-readable string representation of the rule.\n        ");
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text = {"to_text", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   PyObject *__pyx_v_feature_names = 0;
@@ -22071,61 +22698,61 @@
       }
       kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
       switch (__pyx_nargs) {
         case  0:
         if (kw_args > 0) {
           PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_feature_names);
           if (value) { values[0] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
-          else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 179, __pyx_L3_error)
+          else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 200, __pyx_L3_error)
         }
       }
       if (unlikely(kw_args > 0)) {
         const Py_ssize_t kwd_pos_args = __pyx_nargs;
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "to_text") < 0)) __PYX_ERR(0, 179, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "to_text") < 0)) __PYX_ERR(0, 200, __pyx_L3_error)
       }
     } else {
       switch (__pyx_nargs) {
         case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
         CYTHON_FALLTHROUGH;
         case  0: break;
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_feature_names = values[0];
   }
   goto __pyx_L6_skip;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("to_text", 0, 0, 1, __pyx_nargs); __PYX_ERR(0, 179, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("to_text", 0, 0, 1, __pyx_nargs); __PYX_ERR(0, 200, __pyx_L3_error)
   __pyx_L6_skip:;
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L3_error:;
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.to_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature_names);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature_names);
 
   /* function exit code */
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names) {
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names) {
   PyObject *__pyx_v_print_text = NULL;
   int __pyx_v_i;
   PyObject *__pyx_v_feature_label = NULL;
   PyObject *__pyx_v_na_string = NULL;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
@@ -22138,94 +22765,94 @@
   Py_UCS4 __pyx_t_8;
   PyObject *__pyx_t_9 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("to_text", 1);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":195
+  /* "ruleopt/aux_classes/aux_classes.pyx":216
  *             A human-readable string representation of the rule.
  *         """
  *         print_text = ""             # <<<<<<<<<<<<<<
  *         for i in range(self.n_clauses):
  *             feature_label = (f"x[{self.clauses[i].feature}]"
  */
   __Pyx_INCREF(__pyx_kp_u__15);
   __pyx_v_print_text = __pyx_kp_u__15;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":196
+  /* "ruleopt/aux_classes/aux_classes.pyx":217
  *         """
  *         print_text = ""
  *         for i in range(self.n_clauses):             # <<<<<<<<<<<<<<
  *             feature_label = (f"x[{self.clauses[i].feature}]"
  *                              if feature_names is None
  */
   __pyx_t_1 = __pyx_v_self->n_clauses;
   __pyx_t_2 = __pyx_t_1;
   for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
     __pyx_v_i = __pyx_t_3;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":198
+    /* "ruleopt/aux_classes/aux_classes.pyx":219
  *         for i in range(self.n_clauses):
  *             feature_label = (f"x[{self.clauses[i].feature}]"
  *                              if feature_names is None             # <<<<<<<<<<<<<<
  *                              else feature_names[self.clauses[i].feature])
  *             na_string = " or null" if self.clauses[i].na else " and not null"
  */
     __pyx_t_5 = (__pyx_v_feature_names == Py_None);
     if (__pyx_t_5) {
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":197
+      /* "ruleopt/aux_classes/aux_classes.pyx":218
  *         print_text = ""
  *         for i in range(self.n_clauses):
  *             feature_label = (f"x[{self.clauses[i].feature}]"             # <<<<<<<<<<<<<<
  *                              if feature_names is None
  *                              else feature_names[self.clauses[i].feature])
  */
-      __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 197, __pyx_L1_error)
+      __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 218, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_6);
       __pyx_t_7 = 0;
       __pyx_t_8 = 127;
       __Pyx_INCREF(__pyx_kp_u_x);
       __pyx_t_7 += 2;
       __Pyx_GIVEREF(__pyx_kp_u_x);
       PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_kp_u_x);
-      __pyx_t_9 = __Pyx_PyUnicode_From_int((__pyx_v_self->clauses[__pyx_v_i]).feature, 0, ' ', 'd'); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 197, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyUnicode_From_int((__pyx_v_self->clauses[__pyx_v_i]).feature, 0, ' ', 'd'); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 218, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_9);
       __Pyx_GIVEREF(__pyx_t_9);
       PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_9);
       __pyx_t_9 = 0;
       __Pyx_INCREF(__pyx_kp_u__16);
       __pyx_t_7 += 1;
       __Pyx_GIVEREF(__pyx_kp_u__16);
       PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_kp_u__16);
-      __pyx_t_9 = __Pyx_PyUnicode_Join(__pyx_t_6, 3, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 197, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyUnicode_Join(__pyx_t_6, 3, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 218, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       __pyx_t_4 = __pyx_t_9;
       __pyx_t_9 = 0;
     } else {
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":199
+      /* "ruleopt/aux_classes/aux_classes.pyx":220
  *             feature_label = (f"x[{self.clauses[i].feature}]"
  *                              if feature_names is None
  *                              else feature_names[self.clauses[i].feature])             # <<<<<<<<<<<<<<
  *             na_string = " or null" if self.clauses[i].na else " and not null"
  *             print_text += f"{self.clauses[i].lb:<9.2f} < {feature_label:<9} <= {self.clauses[i].ub:<9.2f}{na_string}\n"
  */
-      __pyx_t_9 = __Pyx_GetItemInt(__pyx_v_feature_names, (__pyx_v_self->clauses[__pyx_v_i]).feature, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 199, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_GetItemInt(__pyx_v_feature_names, (__pyx_v_self->clauses[__pyx_v_i]).feature, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 220, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __pyx_t_4 = __pyx_t_9;
       __pyx_t_9 = 0;
     }
     __Pyx_XDECREF_SET(__pyx_v_feature_label, __pyx_t_4);
     __pyx_t_4 = 0;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":200
+    /* "ruleopt/aux_classes/aux_classes.pyx":221
  *                              if feature_names is None
  *                              else feature_names[self.clauses[i].feature])
  *             na_string = " or null" if self.clauses[i].na else " and not null"             # <<<<<<<<<<<<<<
  *             print_text += f"{self.clauses[i].lb:<9.2f} < {feature_label:<9} <= {self.clauses[i].ub:<9.2f}{na_string}\n"
  *         return print_text.rstrip("\n")
  */
     if ((__pyx_v_self->clauses[__pyx_v_i]).na) {
@@ -22234,96 +22861,96 @@
     } else {
       __Pyx_INCREF(__pyx_kp_u_and_not_null);
       __pyx_t_4 = __pyx_kp_u_and_not_null;
     }
     __Pyx_XDECREF_SET(__pyx_v_na_string, ((PyObject*)__pyx_t_4));
     __pyx_t_4 = 0;
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":201
+    /* "ruleopt/aux_classes/aux_classes.pyx":222
  *                              else feature_names[self.clauses[i].feature])
  *             na_string = " or null" if self.clauses[i].na else " and not null"
  *             print_text += f"{self.clauses[i].lb:<9.2f} < {feature_label:<9} <= {self.clauses[i].ub:<9.2f}{na_string}\n"             # <<<<<<<<<<<<<<
  *         return print_text.rstrip("\n")
  * 
  */
-    __pyx_t_4 = PyTuple_New(7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_4 = PyTuple_New(7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __pyx_t_7 = 0;
     __pyx_t_8 = 127;
-    __pyx_t_9 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_v_i]).lb); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_9 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_v_i]).lb); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_9);
-    __pyx_t_6 = __Pyx_PyObject_Format(__pyx_t_9, __pyx_kp_u_9_2f); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_6 = __Pyx_PyObject_Format(__pyx_t_9, __pyx_kp_u_9_2f); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
     __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
     __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_8;
     __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
     __Pyx_GIVEREF(__pyx_t_6);
     PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6);
     __pyx_t_6 = 0;
     __Pyx_INCREF(__pyx_kp_u__17);
     __pyx_t_7 += 3;
     __Pyx_GIVEREF(__pyx_kp_u__17);
     PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_kp_u__17);
-    __pyx_t_6 = __Pyx_PyObject_Format(__pyx_v_feature_label, __pyx_kp_u_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_6 = __Pyx_PyObject_Format(__pyx_v_feature_label, __pyx_kp_u_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
     __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_8;
     __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
     __Pyx_GIVEREF(__pyx_t_6);
     PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_t_6);
     __pyx_t_6 = 0;
     __Pyx_INCREF(__pyx_kp_u__18);
     __pyx_t_7 += 4;
     __Pyx_GIVEREF(__pyx_kp_u__18);
     PyTuple_SET_ITEM(__pyx_t_4, 3, __pyx_kp_u__18);
-    __pyx_t_6 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_v_i]).ub); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_6 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_v_i]).ub); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
-    __pyx_t_9 = __Pyx_PyObject_Format(__pyx_t_6, __pyx_kp_u_9_2f); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyObject_Format(__pyx_t_6, __pyx_kp_u_9_2f); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_9);
     __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
     __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_9) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_9) : __pyx_t_8;
     __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_9);
     __Pyx_GIVEREF(__pyx_t_9);
     PyTuple_SET_ITEM(__pyx_t_4, 4, __pyx_t_9);
     __pyx_t_9 = 0;
-    __pyx_t_9 = __Pyx_PyUnicode_Unicode(__pyx_v_na_string); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyUnicode_Unicode(__pyx_v_na_string); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_9);
     __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_9) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_9) : __pyx_t_8;
     __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_9);
     __Pyx_GIVEREF(__pyx_t_9);
     PyTuple_SET_ITEM(__pyx_t_4, 5, __pyx_t_9);
     __pyx_t_9 = 0;
     __Pyx_INCREF(__pyx_kp_u__19);
     __pyx_t_7 += 1;
     __Pyx_GIVEREF(__pyx_kp_u__19);
     PyTuple_SET_ITEM(__pyx_t_4, 6, __pyx_kp_u__19);
-    __pyx_t_9 = __Pyx_PyUnicode_Join(__pyx_t_4, 7, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyUnicode_Join(__pyx_t_4, 7, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_9);
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-    __pyx_t_4 = __Pyx_PyUnicode_ConcatInPlace(__pyx_v_print_text, __pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 201, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyUnicode_ConcatInPlace(__pyx_v_print_text, __pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 222, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
     __Pyx_DECREF_SET(__pyx_v_print_text, ((PyObject*)__pyx_t_4));
     __pyx_t_4 = 0;
   }
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":202
+  /* "ruleopt/aux_classes/aux_classes.pyx":223
  *             na_string = " or null" if self.clauses[i].na else " and not null"
  *             print_text += f"{self.clauses[i].lb:<9.2f} < {feature_label:<9} <= {self.clauses[i].ub:<9.2f}{na_string}\n"
  *         return print_text.rstrip("\n")             # <<<<<<<<<<<<<<
  * 
  *     def to_dict(self, feature_names=None):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_4 = __Pyx_CallUnboundCMethod1(&__pyx_umethod_PyUnicode_Type_rstrip, __pyx_v_print_text, __pyx_kp_u__19); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 202, __pyx_L1_error)
+  __pyx_t_4 = __Pyx_CallUnboundCMethod1(&__pyx_umethod_PyUnicode_Type_rstrip, __pyx_v_print_text, __pyx_kp_u__19); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 223, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
   __pyx_r = __pyx_t_4;
   __pyx_t_4 = 0;
   goto __pyx_L0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":179
+  /* "ruleopt/aux_classes/aux_classes.pyx":200
  *         return self._check_rule_nogil(X)
  * 
  *     def to_text(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a human-readable text representation, using optional
  */
 
@@ -22339,33 +22966,33 @@
   __Pyx_XDECREF(__pyx_v_feature_label);
   __Pyx_XDECREF(__pyx_v_na_string);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "ruleopt/aux_classes/aux_classes.pyx":204
+/* "ruleopt/aux_classes/aux_classes.pyx":225
  *         return print_text.rstrip("\n")
  * 
  *     def to_dict(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a dictionary representation, using optional feature names for keys.
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict, "\n        Converts the rule to a dictionary representation, using optional feature names for keys.\n\n        Parameters:\n        ----------\n        feature_names : list, optional\n            A list of feature names corresponding to feature indices. If None, feature indices are used as keys.\n\n        Returns:\n        -------\n        dict\n            A dictionary representation of the rule, with feature names or indices as keys and clause details as values.\n        ");
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict = {"to_dict", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict(PyObject *__pyx_v_self, 
+PyDoc_STRVAR(__pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict, "\n        Converts the rule to a dictionary representation, using optional feature names for keys.\n\n        Parameters:\n        ----------\n        feature_names : list, optional\n            A list of feature names corresponding to feature indices. If None, feature indices are used as keys.\n\n        Returns:\n        -------\n        dict\n            A dictionary representation of the rule, with feature names or indices as keys and clause details as values.\n        ");
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict = {"to_dict", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   PyObject *__pyx_v_feature_names = 0;
@@ -22401,62 +23028,62 @@
       }
       kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
       switch (__pyx_nargs) {
         case  0:
         if (kw_args > 0) {
           PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_feature_names);
           if (value) { values[0] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
-          else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 204, __pyx_L3_error)
+          else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 225, __pyx_L3_error)
         }
       }
       if (unlikely(kw_args > 0)) {
         const Py_ssize_t kwd_pos_args = __pyx_nargs;
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "to_dict") < 0)) __PYX_ERR(0, 204, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "to_dict") < 0)) __PYX_ERR(0, 225, __pyx_L3_error)
       }
     } else {
       switch (__pyx_nargs) {
         case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
         CYTHON_FALLTHROUGH;
         case  0: break;
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_feature_names = values[0];
   }
   goto __pyx_L6_skip;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("to_dict", 0, 0, 1, __pyx_nargs); __PYX_ERR(0, 204, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("to_dict", 0, 0, 1, __pyx_nargs); __PYX_ERR(0, 225, __pyx_L3_error)
   __pyx_L6_skip:;
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L3_error:;
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.to_dict", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature_names);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v_feature_names);
 
   /* function exit code */
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names) {
-  int __pyx_7genexpr__pyx_v_i;
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_feature_names) {
+  int __pyx_8genexpr2__pyx_v_i;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_t_4;
   PyObject *__pyx_t_5 = NULL;
@@ -22464,88 +23091,88 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("to_dict", 1);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":218
+  /* "ruleopt/aux_classes/aux_classes.pyx":239
  *             A dictionary representation of the rule, with feature names or indices as keys and clause details as values.
  *         """
  *         return {             # <<<<<<<<<<<<<<
  *             (feature_names[self.clauses[i].feature] if feature_names else self.clauses[i].feature):
  *             {"lb": self.clauses[i].lb, "ub": self.clauses[i].ub, "na": self.clauses[i].na}
  */
   __Pyx_XDECREF(__pyx_r);
   { /* enter inner scope */
-    __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 218, __pyx_L1_error)
+    __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 239, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
 
-    /* "ruleopt/aux_classes/aux_classes.pyx":221
+    /* "ruleopt/aux_classes/aux_classes.pyx":242
  *             (feature_names[self.clauses[i].feature] if feature_names else self.clauses[i].feature):
  *             {"lb": self.clauses[i].lb, "ub": self.clauses[i].ub, "na": self.clauses[i].na}
  *             for i in range(self.n_clauses)             # <<<<<<<<<<<<<<
  *         }
  */
     __pyx_t_2 = __pyx_v_self->n_clauses;
     __pyx_t_3 = __pyx_t_2;
     for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
-      __pyx_7genexpr__pyx_v_i = __pyx_t_4;
+      __pyx_8genexpr2__pyx_v_i = __pyx_t_4;
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":219
+      /* "ruleopt/aux_classes/aux_classes.pyx":240
  *         """
  *         return {
  *             (feature_names[self.clauses[i].feature] if feature_names else self.clauses[i].feature):             # <<<<<<<<<<<<<<
  *             {"lb": self.clauses[i].lb, "ub": self.clauses[i].ub, "na": self.clauses[i].na}
  *             for i in range(self.n_clauses)
  */
-      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_v_feature_names); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 219, __pyx_L1_error)
+      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_v_feature_names); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 240, __pyx_L1_error)
       if (__pyx_t_6) {
-        __pyx_t_7 = __Pyx_GetItemInt(__pyx_v_feature_names, (__pyx_v_self->clauses[__pyx_7genexpr__pyx_v_i]).feature, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 219, __pyx_L1_error)
+        __pyx_t_7 = __Pyx_GetItemInt(__pyx_v_feature_names, (__pyx_v_self->clauses[__pyx_8genexpr2__pyx_v_i]).feature, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 240, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
         __pyx_t_5 = __pyx_t_7;
         __pyx_t_7 = 0;
       } else {
-        __pyx_t_7 = __Pyx_PyInt_From_int((__pyx_v_self->clauses[__pyx_7genexpr__pyx_v_i]).feature); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 219, __pyx_L1_error)
+        __pyx_t_7 = __Pyx_PyInt_From_int((__pyx_v_self->clauses[__pyx_8genexpr2__pyx_v_i]).feature); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 240, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
         __pyx_t_5 = __pyx_t_7;
         __pyx_t_7 = 0;
       }
 
-      /* "ruleopt/aux_classes/aux_classes.pyx":220
+      /* "ruleopt/aux_classes/aux_classes.pyx":241
  *         return {
  *             (feature_names[self.clauses[i].feature] if feature_names else self.clauses[i].feature):
  *             {"lb": self.clauses[i].lb, "ub": self.clauses[i].ub, "na": self.clauses[i].na}             # <<<<<<<<<<<<<<
  *             for i in range(self.n_clauses)
  *         }
  */
-      __pyx_t_7 = __Pyx_PyDict_NewPresized(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 220, __pyx_L1_error)
+      __pyx_t_7 = __Pyx_PyDict_NewPresized(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_7);
-      __pyx_t_8 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_7genexpr__pyx_v_i]).lb); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 220, __pyx_L1_error)
+      __pyx_t_8 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_8genexpr2__pyx_v_i]).lb); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_8);
-      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_lb, __pyx_t_8) < 0) __PYX_ERR(0, 220, __pyx_L1_error)
+      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_lb, __pyx_t_8) < 0) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __pyx_t_8 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_7genexpr__pyx_v_i]).ub); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 220, __pyx_L1_error)
+      __pyx_t_8 = PyFloat_FromDouble((__pyx_v_self->clauses[__pyx_8genexpr2__pyx_v_i]).ub); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_8);
-      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_ub, __pyx_t_8) < 0) __PYX_ERR(0, 220, __pyx_L1_error)
+      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_ub, __pyx_t_8) < 0) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __pyx_t_8 = __Pyx_PyBool_FromLong((__pyx_v_self->clauses[__pyx_7genexpr__pyx_v_i]).na); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 220, __pyx_L1_error)
+      __pyx_t_8 = __Pyx_PyBool_FromLong((__pyx_v_self->clauses[__pyx_8genexpr2__pyx_v_i]).na); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_8);
-      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_na, __pyx_t_8) < 0) __PYX_ERR(0, 220, __pyx_L1_error)
+      if (PyDict_SetItem(__pyx_t_7, __pyx_n_u_na, __pyx_t_8) < 0) __PYX_ERR(0, 241, __pyx_L1_error)
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      if (unlikely(PyDict_SetItem(__pyx_t_1, (PyObject*)__pyx_t_5, (PyObject*)__pyx_t_7))) __PYX_ERR(0, 219, __pyx_L1_error)
+      if (unlikely(PyDict_SetItem(__pyx_t_1, (PyObject*)__pyx_t_5, (PyObject*)__pyx_t_7))) __PYX_ERR(0, 240, __pyx_L1_error)
       __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
       __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
     }
   } /* exit inner scope */
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":204
+  /* "ruleopt/aux_classes/aux_classes.pyx":225
  *         return print_text.rstrip("\n")
  * 
  *     def to_dict(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a dictionary representation, using optional feature names for keys.
  */
 
@@ -22559,17 +23186,100 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
+/* "ruleopt/aux_classes/aux_classes.pxd":21
+ * cdef class Rule:
+ *     cdef ClauseStruct* clauses
+ *     cdef public int n_clauses             # <<<<<<<<<<<<<<
+ *     cdef public object label
+ *     cdef public object weight
+ */
+
+/* Python wrapper */
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_1__get__(PyObject *__pyx_v_self); /*proto*/
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_1__get__(PyObject *__pyx_v_self) {
+  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
+  PyObject *__pyx_r = 0;
+  __Pyx_RefNannyDeclarations
+  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
+  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses___get__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self));
+
+  /* function exit code */
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses___get__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self) {
+  PyObject *__pyx_r = NULL;
+  __Pyx_RefNannyDeclarations
+  PyObject *__pyx_t_1 = NULL;
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  __Pyx_RefNannySetupContext("__get__", 1);
+  __Pyx_XDECREF(__pyx_r);
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->n_clauses); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 21, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_1);
+  __pyx_r = __pyx_t_1;
+  __pyx_t_1 = 0;
+  goto __pyx_L0;
+
+  /* function exit code */
+  __pyx_L1_error:;
+  __Pyx_XDECREF(__pyx_t_1);
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.n_clauses.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = NULL;
+  __pyx_L0:;
+  __Pyx_XGIVEREF(__pyx_r);
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+/* Python wrapper */
+static int __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
+static int __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
+  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
+  int __pyx_r;
+  __Pyx_RefNannyDeclarations
+  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
+  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_2__set__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), ((PyObject *)__pyx_v_value));
+
+  /* function exit code */
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+static int __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_2__set__(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, PyObject *__pyx_v_value) {
+  int __pyx_r;
+  int __pyx_t_1;
+  int __pyx_lineno = 0;
+  const char *__pyx_filename = NULL;
+  int __pyx_clineno = 0;
+  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 21, __pyx_L1_error)
+  __pyx_v_self->n_clauses = __pyx_t_1;
+
+  /* function exit code */
+  __pyx_r = 0;
+  goto __pyx_L0;
+  __pyx_L1_error:;
+  __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.n_clauses.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = -1;
+  __pyx_L0:;
+  return __pyx_r;
+}
+
 /* "ruleopt/aux_classes/aux_classes.pxd":22
  *     cdef ClauseStruct* clauses
- *     cdef int n_clauses
+ *     cdef public int n_clauses
  *     cdef public object label             # <<<<<<<<<<<<<<
  *     cdef public object weight
  *     cdef public object sdist
  */
 
 /* Python wrapper */
 static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5label_1__get__(PyObject *__pyx_v_self); /*proto*/
@@ -22661,15 +23371,15 @@
   /* function exit code */
   __pyx_r = 0;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
 /* "ruleopt/aux_classes/aux_classes.pxd":23
- *     cdef int n_clauses
+ *     cdef public int n_clauses
  *     cdef public object label
  *     cdef public object weight             # <<<<<<<<<<<<<<
  *     cdef public object sdist
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na)
  */
 
 /* Python wrapper */
@@ -22766,15 +23476,15 @@
 }
 
 /* "ruleopt/aux_classes/aux_classes.pxd":24
  *     cdef public object label
  *     cdef public object weight
  *     cdef public object sdist             # <<<<<<<<<<<<<<
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na)
- *     cdef bint _check_rule_nogil(self, DTYPE_t[:] X) noexcept nogil
+ *     cpdef tuple _get_clause(self, int index)
  */
 
 /* Python wrapper */
 static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist_1__get__(PyObject *__pyx_v_self); /*proto*/
 static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist_1__get__(PyObject *__pyx_v_self) {
   CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
   PyObject *__pyx_r = 0;
@@ -22869,23 +23579,23 @@
 /* "(tree fragment)":1
  * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__ = {"__reduce_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__(PyObject *__pyx_v_self, 
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__ = {"__reduce_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   #if !CYTHON_METH_FASTCALL
@@ -22902,22 +23612,22 @@
   __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
   #endif
   #endif
   __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
   if (unlikely(__pyx_nargs > 0)) {
     __Pyx_RaiseArgtupleInvalid("__reduce_cython__", 1, 0, 0, __pyx_nargs); return NULL;}
   if (unlikely(__pyx_kwds) && __Pyx_NumKwargs_FASTCALL(__pyx_kwds) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__reduce_cython__", 0))) return NULL;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14__reduce_cython__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self));
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_18__reduce_cython__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self));
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_14__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self) {
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_18__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__reduce_cython__", 1);
 
@@ -22949,23 +23659,23 @@
  * def __reduce_cython__(self):
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__(PyObject *__pyx_v_self, 
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ); /*proto*/
-static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__ = {"__setstate_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};
-static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__(PyObject *__pyx_v_self, 
+static PyMethodDef __pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__ = {"__setstate_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0};
+static PyObject *__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__(PyObject *__pyx_v_self, 
 #if CYTHON_METH_FASTCALL
 PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
 #else
 PyObject *__pyx_args, PyObject *__pyx_kwds
 #endif
 ) {
   CYTHON_UNUSED PyObject *__pyx_v___pyx_state = 0;
@@ -23031,28 +23741,28 @@
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_AddTraceback("ruleopt.aux_classes.aux_classes.Rule.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16__setstate_cython__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v___pyx_state);
+  __pyx_r = __pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_20__setstate_cython__(((struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *)__pyx_v_self), __pyx_v___pyx_state);
 
   /* function exit code */
   {
     Py_ssize_t __pyx_temp;
     for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
       __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
     }
   }
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_16__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state) {
+static PyObject *__pyx_pf_7ruleopt_11aux_classes_11aux_classes_4Rule_20__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__setstate_cython__", 1);
 
@@ -23872,14 +24582,51 @@
   Py_XDECREF(tmp);
   tmp = ((PyObject*)p->sdist);
   p->sdist = Py_None; Py_INCREF(Py_None);
   Py_XDECREF(tmp);
   return 0;
 }
 
+static PyObject *__pyx_tp_richcompare_7ruleopt_11aux_classes_11aux_classes_Rule(PyObject *o1, PyObject *o2, int op) {
+  switch (op) {
+    case Py_EQ: {
+      return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7__eq__(o1, o2);
+    }
+    case Py_NE: {
+      PyObject *ret;
+      ret = __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_7__eq__(o1, o2);
+      if (likely(ret && ret != Py_NotImplemented)) {
+        int b = __Pyx_PyObject_IsTrue(ret);
+        Py_DECREF(ret);
+        if (unlikely(b < 0)) return NULL;
+        ret = (b) ? Py_False : Py_True;
+        Py_INCREF(ret);
+      }
+      return ret;
+    }
+    default: {
+      return __Pyx_NewRef(Py_NotImplemented);
+    }
+  }
+}
+
+static PyObject *__pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_n_clauses(PyObject *o, CYTHON_UNUSED void *x) {
+  return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_1__get__(o);
+}
+
+static int __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_n_clauses(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
+  if (v) {
+    return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_9n_clauses_3__set__(o, v);
+  }
+  else {
+    PyErr_SetString(PyExc_NotImplementedError, "__del__");
+    return -1;
+  }
+}
+
 static PyObject *__pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_label(PyObject *o, CYTHON_UNUSED void *x) {
   return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5label_1__get__(o);
 }
 
 static int __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_label(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
   if (v) {
     return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5label_3__set__(o, v);
@@ -23912,34 +24659,36 @@
   }
   else {
     return __pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_5sdist_5__del__(o);
   }
 }
 
 static PyMethodDef __pyx_methods_7ruleopt_11aux_classes_11aux_classes_Rule[] = {
-  {"to_text", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_10to_text},
-  {"to_dict", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_12to_dict},
-  {"__reduce_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0},
-  {"__setstate_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0},
+  {"to_text", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_14to_text},
+  {"to_dict", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_7ruleopt_11aux_classes_11aux_classes_4Rule_16to_dict},
+  {"__reduce_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0},
+  {"__setstate_cython__", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, 0},
   {0, 0, 0, 0}
 };
 
 static struct PyGetSetDef __pyx_getsets_7ruleopt_11aux_classes_11aux_classes_Rule[] = {
+  {(char *)"n_clauses", __pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_n_clauses, __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_n_clauses, (char *)0, 0},
   {(char *)"label", __pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_label, __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_label, (char *)0, 0},
   {(char *)"weight", __pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_weight, __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_weight, (char *)0, 0},
   {(char *)"sdist", __pyx_getprop_7ruleopt_11aux_classes_11aux_classes_4Rule_sdist, __pyx_setprop_7ruleopt_11aux_classes_11aux_classes_4Rule_sdist, (char *)0, 0},
   {0, 0, 0, 0, 0}
 };
 #if CYTHON_USE_TYPE_SPECS
 static PyType_Slot __pyx_type_7ruleopt_11aux_classes_11aux_classes_Rule_slots[] = {
   {Py_tp_dealloc, (void *)__pyx_tp_dealloc_7ruleopt_11aux_classes_11aux_classes_Rule},
   {Py_sq_length, (void *)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_3__len__},
   {Py_mp_length, (void *)__pyx_pw_7ruleopt_11aux_classes_11aux_classes_4Rule_3__len__},
   {Py_tp_traverse, (void *)__pyx_tp_traverse_7ruleopt_11aux_classes_11aux_classes_Rule},
   {Py_tp_clear, (void *)__pyx_tp_clear_7ruleopt_11aux_classes_11aux_classes_Rule},
+  {Py_tp_richcompare, (void *)__pyx_tp_richcompare_7ruleopt_11aux_classes_11aux_classes_Rule},
   {Py_tp_methods, (void *)__pyx_methods_7ruleopt_11aux_classes_11aux_classes_Rule},
   {Py_tp_getset, (void *)__pyx_getsets_7ruleopt_11aux_classes_11aux_classes_Rule},
   {Py_tp_new, (void *)__pyx_tp_new_7ruleopt_11aux_classes_11aux_classes_Rule},
   {0, 0},
 };
 static PyType_Spec __pyx_type_7ruleopt_11aux_classes_11aux_classes_Rule_spec = {
   "ruleopt.aux_classes.aux_classes.Rule",
@@ -23999,15 +24748,15 @@
   0, /*tp_getattro*/
   0, /*tp_setattro*/
   0, /*tp_as_buffer*/
   Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
   0, /*tp_doc*/
   __pyx_tp_traverse_7ruleopt_11aux_classes_11aux_classes_Rule, /*tp_traverse*/
   __pyx_tp_clear_7ruleopt_11aux_classes_11aux_classes_Rule, /*tp_clear*/
-  0, /*tp_richcompare*/
+  __pyx_tp_richcompare_7ruleopt_11aux_classes_11aux_classes_Rule, /*tp_richcompare*/
   0, /*tp_weaklistoffset*/
   0, /*tp_iter*/
   0, /*tp_iternext*/
   __pyx_methods_7ruleopt_11aux_classes_11aux_classes_Rule, /*tp_methods*/
   0, /*tp_members*/
   __pyx_getsets_7ruleopt_11aux_classes_11aux_classes_Rule, /*tp_getset*/
   0, /*tp_base*/
@@ -25047,14 +25796,15 @@
     {&__pyx_kp_u_None, __pyx_k_None, sizeof(__pyx_k_None), 0, 1, 0, 0},
     {&__pyx_n_b_O, __pyx_k_O, sizeof(__pyx_k_O), 0, 0, 0, 1},
     {&__pyx_kp_u_Out_of_bounds_on_buffer_access_a, __pyx_k_Out_of_bounds_on_buffer_access_a, sizeof(__pyx_k_Out_of_bounds_on_buffer_access_a), 0, 1, 0, 0},
     {&__pyx_n_s_PickleError, __pyx_k_PickleError, sizeof(__pyx_k_PickleError), 0, 0, 1, 1},
     {&__pyx_n_s_Rule, __pyx_k_Rule, sizeof(__pyx_k_Rule), 0, 0, 1, 1},
     {&__pyx_n_s_Rule___reduce_cython, __pyx_k_Rule___reduce_cython, sizeof(__pyx_k_Rule___reduce_cython), 0, 0, 1, 1},
     {&__pyx_n_s_Rule___setstate_cython, __pyx_k_Rule___setstate_cython, sizeof(__pyx_k_Rule___setstate_cython), 0, 0, 1, 1},
+    {&__pyx_n_s_Rule__get_clause, __pyx_k_Rule__get_clause, sizeof(__pyx_k_Rule__get_clause), 0, 0, 1, 1},
     {&__pyx_n_s_Rule_add_clause, __pyx_k_Rule_add_clause, sizeof(__pyx_k_Rule_add_clause), 0, 0, 1, 1},
     {&__pyx_n_s_Rule_check_rule, __pyx_k_Rule_check_rule, sizeof(__pyx_k_Rule_check_rule), 0, 0, 1, 1},
     {&__pyx_n_s_Rule_to_dict, __pyx_k_Rule_to_dict, sizeof(__pyx_k_Rule_to_dict), 0, 0, 1, 1},
     {&__pyx_n_s_Rule_to_text, __pyx_k_Rule_to_text, sizeof(__pyx_k_Rule_to_text), 0, 0, 1, 1},
     {&__pyx_n_s_Sequence, __pyx_k_Sequence, sizeof(__pyx_k_Sequence), 0, 0, 1, 1},
     {&__pyx_kp_s_Step_may_not_be_zero_axis_d, __pyx_k_Step_may_not_be_zero_axis_d, sizeof(__pyx_k_Step_may_not_be_zero_axis_d), 0, 0, 1, 0},
     {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
@@ -25065,15 +25815,15 @@
     {&__pyx_kp_u__15, __pyx_k__15, sizeof(__pyx_k__15), 0, 1, 0, 0},
     {&__pyx_kp_u__16, __pyx_k__16, sizeof(__pyx_k__16), 0, 1, 0, 0},
     {&__pyx_kp_u__17, __pyx_k__17, sizeof(__pyx_k__17), 0, 1, 0, 0},
     {&__pyx_kp_u__18, __pyx_k__18, sizeof(__pyx_k__18), 0, 1, 0, 0},
     {&__pyx_kp_u__19, __pyx_k__19, sizeof(__pyx_k__19), 0, 1, 0, 0},
     {&__pyx_kp_u__2, __pyx_k__2, sizeof(__pyx_k__2), 0, 1, 0, 0},
     {&__pyx_n_s__3, __pyx_k__3, sizeof(__pyx_k__3), 0, 0, 1, 1},
-    {&__pyx_n_s__50, __pyx_k__50, sizeof(__pyx_k__50), 0, 0, 1, 1},
+    {&__pyx_n_s__52, __pyx_k__52, sizeof(__pyx_k__52), 0, 0, 1, 1},
     {&__pyx_kp_u__6, __pyx_k__6, sizeof(__pyx_k__6), 0, 1, 0, 0},
     {&__pyx_kp_u__7, __pyx_k__7, sizeof(__pyx_k__7), 0, 1, 0, 0},
     {&__pyx_n_s_abc, __pyx_k_abc, sizeof(__pyx_k_abc), 0, 0, 1, 1},
     {&__pyx_n_s_add_clause, __pyx_k_add_clause, sizeof(__pyx_k_add_clause), 0, 0, 1, 1},
     {&__pyx_n_s_allocate_buffer, __pyx_k_allocate_buffer, sizeof(__pyx_k_allocate_buffer), 0, 0, 1, 1},
     {&__pyx_kp_u_and, __pyx_k_and, sizeof(__pyx_k_and), 0, 1, 0, 0},
     {&__pyx_kp_u_and_not_null, __pyx_k_and_not_null, sizeof(__pyx_k_and_not_null), 0, 1, 0, 0},
@@ -25108,14 +25858,15 @@
     {&__pyx_n_s_feature_names, __pyx_k_feature_names, sizeof(__pyx_k_feature_names), 0, 0, 1, 1},
     {&__pyx_n_s_flags, __pyx_k_flags, sizeof(__pyx_k_flags), 0, 0, 1, 1},
     {&__pyx_n_s_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 0, 1, 1},
     {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
     {&__pyx_n_s_fortran, __pyx_k_fortran, sizeof(__pyx_k_fortran), 0, 0, 1, 1},
     {&__pyx_n_u_fortran, __pyx_k_fortran, sizeof(__pyx_k_fortran), 0, 1, 0, 1},
     {&__pyx_kp_u_gc, __pyx_k_gc, sizeof(__pyx_k_gc), 0, 1, 0, 0},
+    {&__pyx_n_s_get_clause, __pyx_k_get_clause, sizeof(__pyx_k_get_clause), 0, 0, 1, 1},
     {&__pyx_n_s_getstate, __pyx_k_getstate, sizeof(__pyx_k_getstate), 0, 0, 1, 1},
     {&__pyx_kp_u_got, __pyx_k_got, sizeof(__pyx_k_got), 0, 1, 0, 0},
     {&__pyx_kp_u_got_differing_extents_in_dimensi, __pyx_k_got_differing_extents_in_dimensi, sizeof(__pyx_k_got_differing_extents_in_dimensi), 0, 1, 0, 0},
     {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
     {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
     {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
     {&__pyx_n_s_index, __pyx_k_index, sizeof(__pyx_k_index), 0, 0, 1, 1},
@@ -25126,14 +25877,15 @@
     {&__pyx_n_s_itemsize, __pyx_k_itemsize, sizeof(__pyx_k_itemsize), 0, 0, 1, 1},
     {&__pyx_kp_s_itemsize_0_for_cython_array, __pyx_k_itemsize_0_for_cython_array, sizeof(__pyx_k_itemsize_0_for_cython_array), 0, 0, 1, 0},
     {&__pyx_n_s_lb, __pyx_k_lb, sizeof(__pyx_k_lb), 0, 0, 1, 1},
     {&__pyx_n_u_lb, __pyx_k_lb, sizeof(__pyx_k_lb), 0, 1, 0, 1},
     {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
     {&__pyx_n_s_memview, __pyx_k_memview, sizeof(__pyx_k_memview), 0, 0, 1, 1},
     {&__pyx_n_s_mode, __pyx_k_mode, sizeof(__pyx_k_mode), 0, 0, 1, 1},
+    {&__pyx_n_s_n_clauses, __pyx_k_n_clauses, sizeof(__pyx_k_n_clauses), 0, 0, 1, 1},
     {&__pyx_n_s_na, __pyx_k_na, sizeof(__pyx_k_na), 0, 0, 1, 1},
     {&__pyx_n_u_na, __pyx_k_na, sizeof(__pyx_k_na), 0, 1, 0, 1},
     {&__pyx_n_s_na_string, __pyx_k_na_string, sizeof(__pyx_k_na_string), 0, 0, 1, 1},
     {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
     {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
     {&__pyx_n_s_ndim, __pyx_k_ndim, sizeof(__pyx_k_ndim), 0, 0, 1, 1},
     {&__pyx_n_s_new, __pyx_k_new, sizeof(__pyx_k_new), 0, 0, 1, 1},
@@ -25195,15 +25947,15 @@
     {&__pyx_n_s_yvals, __pyx_k_yvals, sizeof(__pyx_k_yvals), 0, 0, 1, 1},
     {0, 0, 0, 0, 0, 0, 0}
   };
   return __Pyx_InitStrings(__pyx_string_tab);
 }
 /* #### Code section: cached_builtins ### */
 static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
-  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 96, __pyx_L1_error)
+  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 84, __pyx_L1_error)
   __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(1, 2, __pyx_L1_error)
   __pyx_builtin___import__ = __Pyx_GetBuiltinName(__pyx_n_s_import); if (!__pyx_builtin___import__) __PYX_ERR(1, 100, __pyx_L1_error)
   __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(1, 141, __pyx_L1_error)
   __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(1, 156, __pyx_L1_error)
   __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(1, 159, __pyx_L1_error)
   __pyx_builtin_AssertionError = __Pyx_GetBuiltinName(__pyx_n_s_AssertionError); if (!__pyx_builtin_AssertionError) __PYX_ERR(1, 373, __pyx_L1_error)
   __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(1, 408, __pyx_L1_error)
@@ -25252,26 +26004,26 @@
  *         from pickle import PickleError as __pyx_PickleError
  *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x82a3537, 0x6ae9995, 0xb068931) = (name))" % __pyx_checksum
  */
   __pyx_tuple__8 = PyTuple_Pack(3, __pyx_int_136983863, __pyx_int_112105877, __pyx_int_184977713); if (unlikely(!__pyx_tuple__8)) __PYX_ERR(1, 4, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__8);
   __Pyx_GIVEREF(__pyx_tuple__8);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":984
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":984
  *         __pyx_import_array()
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_umath() except -1:
  */
   __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(2, 984, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__9);
   __Pyx_GIVEREF(__pyx_tuple__9);
 
-  /* "C:/Users/runneradmin/AppData/Local/Temp/pip-build-env-f656rhlf/overlay/Lib/site-packages/numpy/__init__.cython-30.pxd":990
+  /* "../../../../../private/var/folders/62/nb0pn_857qd74kdkfyhcct0c0000gn/T/pip-build-env-m2m19inm/overlay/lib/python3.9/site-packages/numpy/__init__.cython-30.pxd":990
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_ufunc() except -1:
  */
   __pyx_tuple__10 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(2, 990, __pyx_L1_error)
@@ -25419,86 +26171,98 @@
  *     __pyx_unpickle_Coefficients__set_state(self, __pyx_state)
  */
   __pyx_tuple__36 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_pyx_state); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(1, 16, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__36);
   __Pyx_GIVEREF(__pyx_tuple__36);
   __pyx_codeobj__37 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__36, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_setstate_cython, 16, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__37)) __PYX_ERR(1, 16, __pyx_L1_error)
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":77
- *             free(self.clauses)
+  /* "ruleopt/aux_classes/aux_classes.pyx":90
+ * 
+ * 
+ *     cpdef tuple _get_clause(self, int index):             # <<<<<<<<<<<<<<
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub
+ */
+  __pyx_tuple__38 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_index); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 90, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__38);
+  __Pyx_GIVEREF(__pyx_tuple__38);
+  __pyx_codeobj__39 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__38, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_get_clause, 90, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__39)) __PYX_ERR(0, 90, __pyx_L1_error)
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":98
+ *         return feature, ub, lb, na
  * 
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na):             # <<<<<<<<<<<<<<
  *         """
  *         Adds a new clause to the rule or updates an existing clause for the given feature.
  */
-  __pyx_tuple__38 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_feature, __pyx_n_s_ub, __pyx_n_s_lb, __pyx_n_s_na); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 77, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__38);
-  __Pyx_GIVEREF(__pyx_tuple__38);
-  __pyx_codeobj__39 = (PyObject*)__Pyx_PyCode_New(5, 0, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__38, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_add_clause, 77, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__39)) __PYX_ERR(0, 77, __pyx_L1_error)
+  __pyx_tuple__40 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_feature, __pyx_n_s_ub, __pyx_n_s_lb, __pyx_n_s_na); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(0, 98, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__40);
+  __Pyx_GIVEREF(__pyx_tuple__40);
+  __pyx_codeobj__41 = (PyObject*)__Pyx_PyCode_New(5, 0, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__40, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_add_clause, 98, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__41)) __PYX_ERR(0, 98, __pyx_L1_error)
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":163
+  /* "ruleopt/aux_classes/aux_classes.pyx":184
  *         return clause.lb < val <= clause.ub
  * 
  *     cpdef bint check_rule(self, float[:] X):             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values.
  */
-  __pyx_tuple__40 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_X); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(0, 163, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__40);
-  __Pyx_GIVEREF(__pyx_tuple__40);
-  __pyx_codeobj__41 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__40, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_check_rule, 163, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__41)) __PYX_ERR(0, 163, __pyx_L1_error)
+  __pyx_tuple__42 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_X); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(0, 184, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__42);
+  __Pyx_GIVEREF(__pyx_tuple__42);
+  __pyx_codeobj__43 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__42, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_check_rule, 184, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__43)) __PYX_ERR(0, 184, __pyx_L1_error)
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":179
+  /* "ruleopt/aux_classes/aux_classes.pyx":200
  *         return self._check_rule_nogil(X)
  * 
  *     def to_text(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a human-readable text representation, using optional
  */
-  __pyx_tuple__42 = PyTuple_Pack(6, __pyx_n_s_self, __pyx_n_s_feature_names, __pyx_n_s_print_text, __pyx_n_s_i, __pyx_n_s_feature_label, __pyx_n_s_na_string); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(0, 179, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__42);
-  __Pyx_GIVEREF(__pyx_tuple__42);
-  __pyx_codeobj__43 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__42, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_to_text, 179, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__43)) __PYX_ERR(0, 179, __pyx_L1_error)
-  __pyx_tuple__44 = PyTuple_Pack(1, Py_None); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(0, 179, __pyx_L1_error)
+  __pyx_tuple__44 = PyTuple_Pack(6, __pyx_n_s_self, __pyx_n_s_feature_names, __pyx_n_s_print_text, __pyx_n_s_i, __pyx_n_s_feature_label, __pyx_n_s_na_string); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(0, 200, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__44);
   __Pyx_GIVEREF(__pyx_tuple__44);
+  __pyx_codeobj__45 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__44, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_to_text, 200, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__45)) __PYX_ERR(0, 200, __pyx_L1_error)
+  __pyx_tuple__46 = PyTuple_Pack(1, Py_None); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(0, 200, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__46);
+  __Pyx_GIVEREF(__pyx_tuple__46);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":204
+  /* "ruleopt/aux_classes/aux_classes.pyx":225
  *         return print_text.rstrip("\n")
  * 
  *     def to_dict(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a dictionary representation, using optional feature names for keys.
  */
-  __pyx_tuple__45 = PyTuple_Pack(3, __pyx_n_s_self, __pyx_n_s_feature_names, __pyx_n_s_i); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(0, 204, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__45);
-  __Pyx_GIVEREF(__pyx_tuple__45);
-  __pyx_codeobj__46 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__45, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_to_dict, 204, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__46)) __PYX_ERR(0, 204, __pyx_L1_error)
+  __pyx_tuple__47 = PyTuple_Pack(3, __pyx_n_s_self, __pyx_n_s_feature_names, __pyx_n_s_i); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(0, 225, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__47);
+  __Pyx_GIVEREF(__pyx_tuple__47);
+  __pyx_codeobj__48 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__47, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_ruleopt_aux_classes_aux_classes, __pyx_n_s_to_dict, 225, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__48)) __PYX_ERR(0, 225, __pyx_L1_error)
 
   /* "(tree fragment)":1
  * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):
  */
-  __pyx_codeobj__47 = (PyObject*)__Pyx_PyCode_New(1, 0, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__32, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_reduce_cython, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__47)) __PYX_ERR(1, 1, __pyx_L1_error)
+  __pyx_codeobj__49 = (PyObject*)__Pyx_PyCode_New(1, 0, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__32, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_reduce_cython, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__49)) __PYX_ERR(1, 1, __pyx_L1_error)
 
   /* "(tree fragment)":3
  * def __reduce_cython__(self):
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  */
-  __pyx_codeobj__48 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__36, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_setstate_cython, 3, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__48)) __PYX_ERR(1, 3, __pyx_L1_error)
+  __pyx_codeobj__50 = (PyObject*)__Pyx_PyCode_New(2, 0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__36, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_setstate_cython, 3, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__50)) __PYX_ERR(1, 3, __pyx_L1_error)
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_Coefficients(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
-  __pyx_codeobj__49 = (PyObject*)__Pyx_PyCode_New(3, 0, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__30, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle_Coefficients, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__49)) __PYX_ERR(1, 1, __pyx_L1_error)
+  __pyx_codeobj__51 = (PyObject*)__Pyx_PyCode_New(3, 0, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__30, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle_Coefficients, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__51)) __PYX_ERR(1, 1, __pyx_L1_error)
   __Pyx_RefNannyFinishContext();
   return 0;
   __pyx_L1_error:;
   __Pyx_RefNannyFinishContext();
   return -1;
 }
 /* #### Code section: init_constants ### */
@@ -25602,14 +26366,15 @@
   #endif
   if (PyObject_SetAttr(__pyx_m, __pyx_n_s_Coefficients, (PyObject *) __pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Coefficients) < 0) __PYX_ERR(0, 7, __pyx_L1_error)
   #if !CYTHON_COMPILING_IN_LIMITED_API
   if (__Pyx_setup_reduce((PyObject *) __pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Coefficients) < 0) __PYX_ERR(0, 7, __pyx_L1_error)
   #endif
   __pyx_vtabptr_7ruleopt_11aux_classes_11aux_classes_Rule = &__pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule;
   __pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule.add_clause = (PyObject *(*)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, int, double, double, int, int __pyx_skip_dispatch))__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_add_clause;
+  __pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule._get_clause = (PyObject *(*)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, int, int __pyx_skip_dispatch))__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__get_clause;
   __pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule._check_rule_nogil = (int (*)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice))__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__check_rule_nogil;
   __pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule._check_clause_nogil = (int (*)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice, int))__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule__check_clause_nogil;
   __pyx_vtable_7ruleopt_11aux_classes_11aux_classes_Rule.check_rule = (int (*)(struct __pyx_obj_7ruleopt_11aux_classes_11aux_classes_Rule *, __Pyx_memviewslice, int __pyx_skip_dispatch))__pyx_f_7ruleopt_11aux_classes_11aux_classes_4Rule_check_rule;
   #if CYTHON_USE_TYPE_SPECS
   __pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule = (PyTypeObject *) __Pyx_PyType_FromModuleAndSpec(__pyx_m, &__pyx_type_7ruleopt_11aux_classes_11aux_classes_Rule_spec, NULL); if (unlikely(!__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule)) __PYX_ERR(0, 45, __pyx_L1_error)
   if (__Pyx_fix_up_extension_type_from_spec(&__pyx_type_7ruleopt_11aux_classes_11aux_classes_Rule_spec, __pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule) < 0) __PYX_ERR(0, 45, __pyx_L1_error)
   #else
@@ -26833,95 +27598,108 @@
  */
   __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_12Coefficients_7__setstate_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Coefficients___setstate_cython, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__37)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 16, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Coefficients, __pyx_n_s_setstate_cython, __pyx_t_5) < 0) __PYX_ERR(1, 16, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Coefficients);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":77
- *             free(self.clauses)
+  /* "ruleopt/aux_classes/aux_classes.pyx":90
+ * 
+ * 
+ *     cpdef tuple _get_clause(self, int index):             # <<<<<<<<<<<<<<
+ *         cdef int feature = self.clauses[index].feature
+ *         cdef double ub = self.clauses[index].ub
+ */
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_9_get_clause, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule__get_clause, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__39)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 90, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_5);
+  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_get_clause, __pyx_t_5) < 0) __PYX_ERR(0, 90, __pyx_L1_error)
+  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
+  PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule);
+
+  /* "ruleopt/aux_classes/aux_classes.pyx":98
+ *         return feature, ub, lb, na
  * 
  *     cpdef add_clause(self, int feature, double ub, double lb, bint na):             # <<<<<<<<<<<<<<
  *         """
  *         Adds a new clause to the rule or updates an existing clause for the given feature.
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_7add_clause, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_add_clause, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__39)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 77, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_11add_clause, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_add_clause, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__41)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 98, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
-  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_add_clause, __pyx_t_5) < 0) __PYX_ERR(0, 77, __pyx_L1_error)
+  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_add_clause, __pyx_t_5) < 0) __PYX_ERR(0, 98, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":163
+  /* "ruleopt/aux_classes/aux_classes.pyx":184
  *         return clause.lb < val <= clause.ub
  * 
  *     cpdef bint check_rule(self, float[:] X):             # <<<<<<<<<<<<<<
  *         """
  *         Checks if the rule applies to the given feature values.
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_9check_rule, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_check_rule, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__41)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 163, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_13check_rule, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_check_rule, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__43)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 184, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
-  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_check_rule, __pyx_t_5) < 0) __PYX_ERR(0, 163, __pyx_L1_error)
+  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_check_rule, __pyx_t_5) < 0) __PYX_ERR(0, 184, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":179
+  /* "ruleopt/aux_classes/aux_classes.pyx":200
  *         return self._check_rule_nogil(X)
  * 
  *     def to_text(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a human-readable text representation, using optional
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_11to_text, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_to_text, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__43)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 179, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_15to_text, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_to_text, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__45)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 200, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
-  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_5, __pyx_tuple__44);
-  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_to_text, __pyx_t_5) < 0) __PYX_ERR(0, 179, __pyx_L1_error)
+  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_5, __pyx_tuple__46);
+  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_to_text, __pyx_t_5) < 0) __PYX_ERR(0, 200, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule);
 
-  /* "ruleopt/aux_classes/aux_classes.pyx":204
+  /* "ruleopt/aux_classes/aux_classes.pyx":225
  *         return print_text.rstrip("\n")
  * 
  *     def to_dict(self, feature_names=None):             # <<<<<<<<<<<<<<
  *         """
  *         Converts the rule to a dictionary representation, using optional feature names for keys.
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_13to_dict, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_to_dict, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__46)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 204, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_17to_dict, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule_to_dict, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__48)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 225, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
-  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_5, __pyx_tuple__44);
-  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_to_dict, __pyx_t_5) < 0) __PYX_ERR(0, 204, __pyx_L1_error)
+  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_5, __pyx_tuple__46);
+  if (__Pyx_SetItemOnTypeDict((PyObject *)__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule, __pyx_n_s_to_dict, __pyx_t_5) < 0) __PYX_ERR(0, 225, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   PyType_Modified(__pyx_ptype_7ruleopt_11aux_classes_11aux_classes_Rule);
 
   /* "(tree fragment)":1
  * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_15__reduce_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule___reduce_cython, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__47)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_19__reduce_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule___reduce_cython, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__49)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_reduce_cython, __pyx_t_5) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
 
   /* "(tree fragment)":3
  * def __reduce_cython__(self):
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
  *     raise TypeError, "no default __reduce__ due to non-trivial __cinit__"
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_17__setstate_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule___setstate_cython, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__48)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 3, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_4Rule_21__setstate_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_Rule___setstate_cython, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__50)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 3, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_setstate_cython, __pyx_t_5) < 0) __PYX_ERR(1, 3, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_Coefficients(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
-  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_1__pyx_unpickle_Coefficients, 0, __pyx_n_s_pyx_unpickle_Coefficients, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__49)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_CyFunction_New(&__pyx_mdef_7ruleopt_11aux_classes_11aux_classes_1__pyx_unpickle_Coefficients, 0, __pyx_n_s_pyx_unpickle_Coefficients, NULL, __pyx_n_s_ruleopt_aux_classes_aux_classes_2, __pyx_d, ((PyObject *)__pyx_codeobj__51)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_pyx_unpickle_Coefficients, __pyx_t_5) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
 
   /* "ruleopt/aux_classes/aux_classes.pyx":1
  * from libc.stdlib cimport free, realloc             # <<<<<<<<<<<<<<
  * from cython cimport boundscheck
@@ -34589,15 +35367,15 @@
 __Pyx_PyType_GetName(PyTypeObject* tp)
 {
     PyObject *name = __Pyx_PyObject_GetAttrStr((PyObject *)tp,
                                                __pyx_n_s_name_2);
     if (unlikely(name == NULL) || unlikely(!PyUnicode_Check(name))) {
         PyErr_Clear();
         Py_XDECREF(name);
-        name = __Pyx_NewRef(__pyx_n_s__50);
+        name = __Pyx_NewRef(__pyx_n_s__52);
     }
     return name;
 }
 #endif
 
 /* CheckBinaryVersion */
   static unsigned long __Pyx_get_runtime_version(void) {
```

## ruleopt/estimator/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-from .sklearn_.rug import (RUGClassifier)
-from .sklearn_.rux import (RUXClassifier)
-from .xgboost_ import (RUXXGBClassifier)
-from .lightgbm_ import (RUXLGBMClassifier)
-
-__all__ = [
-    "RUGClassifier",
-    "RUXClassifier",
-    "RUXLGBMClassifier",
+from .sklearn_.rug import (RUGClassifier)
+from .sklearn_.rux import (RUXClassifier)
+from .xgboost_ import (RUXXGBClassifier)
+from .lightgbm_ import (RUXLGBMClassifier)
+
+__all__ = [
+    "RUGClassifier",
+    "RUXClassifier",
+    "RUXLGBMClassifier",
     "RUXXGBClassifier"]
```

## ruleopt/estimator/base.py

 * *Ordering differences only*

```diff
@@ -1,702 +1,702 @@
-from __future__ import annotations
-import warnings
-from typing import Union, Dict
-from abc import abstractmethod
-import numpy as np
-from numpy.typing import ArrayLike
-from sklearn.base import BaseEstimator, ClassifierMixin
-from sklearn.utils.class_weight import compute_sample_weight
-
-from ..aux_classes import Coefficients, Rule
-from ..rule_cost import RuleCost
-from ..utils import check_inputs
-from ..solver.base import OptimizationSolver
-
-
-class _RUGBASE(BaseEstimator, ClassifierMixin):
-    """
-    The foundational class for all estimators in the ruleopt library. `_RUGBASE` provides
-    the core framework that every model in ruleopt builds upon.
-
-    Parameters
-    ----------
-    solver : OptimizationSolver
-        An instance of a derived class inherits from the 'Optimization Solver' base class.
-        The solver is responsible for optimizing the rule set based on the cost function
-        and constraints.
-
-    rule_cost : RuleCost or int
-        Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-        or a fixed cost
-
-    class_weight: dict, "balanced" or None
-        A dictionary mapping class labels to their respective weights, the string "balanced"
-        to automatically adjust weights inversely proportional to class frequencies,
-        or None for no weights. Used to adjust the model in favor of certain classes.
-
-    threshold : float
-        The minimum weight threshold for including a rule in the final model
-
-    random_state : int or None
-        Seed for the random number generator to ensure reproducible results.
-        Defaults to None.
-    """
-
-    def __init__(
-        self,
-        solver: OptimizationSolver,
-        rule_cost: Union[RuleCost, int],
-        class_weight: Dict[int, float],
-        threshold: float,
-        random_state: Union[None, int],
-    ):
-
-        self._validate_rug_parameters(
-            threshold=threshold,
-            random_state=random_state,
-            rule_cost=rule_cost,
-            solver=solver,
-            class_weight=class_weight,
-        )
-        self.threshold = float(threshold)
-        self.rule_cost = rule_cost
-        self.solver = solver
-        self.random_state = random_state
-        self.class_weight = class_weight
-
-        # Additional initializations
-        self._rng = np.random.default_rng(
-            random_state if random_state is not None else None
-        )
-        self.decision_trees_ = {}
-        self.decision_rules_ = {}
-        self.rule_info_ = {}
-        self.coefficients_ = Coefficients()
-
-        self._is_fitted: bool = False
-        self.majority_class_: int = None
-        self.majority_probability_: float = None
-        self.k_: float = None
-        self.classes_: np.array = None
-        self.rule_columns_: np.array = None
-
-    def _cleanup(self) -> None:
-        """
-        Clean up the model by resetting all of its attributes.
-        """
-        # Resetting all dictionaries
-        self.decision_trees_ = {}
-        self.decision_rules_ = {}
-        self.rule_info_ = {}
-
-        # Cleaning up coefficients
-        self.coefficients_.cleanup()
-
-        # Resetting the random number generator
-        self._rng = np.random.default_rng(self.random_state)
-
-    @abstractmethod
-    def _get_rule(self, *arg, **kwargs) -> Rule: ...
-
-    @abstractmethod
-    def _get_matrix(self, *arg, **kwargs) -> None: ...
-
-    def _get_class_infos(self, y: np.ndarray) -> None:
-        """
-        Computes and stores information about the classes in the dataset.
-
-        This method calculates the majority class, its probability, the total number
-        of unique classes, and stores an array of unique class labels.
-
-        Parameters
-        ----------
-        y : np.ndarray
-            The target values, expected to be a 1D numpy array of class labels.
-
-        Sets Attributes
-        ---------------
-        majority_class_ : int
-            The class label with the highest frequency in `y`.
-        majority_probability_ : float
-            The proportion of samples in `y` belonging to the majority class,
-            calculated as the count of the majority class divided by the total number of samples.
-        k_ : float
-            The total number of unique classes in `y`.
-        classes_ : np.array
-            An array of the unique class labels present in the dataset.
-        """
-        classes, class_counts = np.unique(y, return_counts=True)
-
-        self.majority_class_ = classes[np.argmax(class_counts)]
-        self.majority_probability_ = class_counts / np.sum(class_counts)
-
-        self.k_ = classes.shape[0]
-        self.classes_ = classes
-
-    def _preprocess(self, y: np.ndarray) -> np.ndarray:
-        """
-        Transforms the target values into a vector. If the target
-        class is k and there are K classes, then all components but
-        the kth are set to -1/(K-1) and the kth component is set to 1. 
-
-        Parameters
-        ----------
-        y : np.ndarray
-            The target values as a 1D numpy array of class labels.
-
-        Returns
-        -------
-        np.ndarray
-            The preprocessed target values in a one-hot-encoded format, adjusted for the model's
-            optimization process.
-        """
-
-        # Convert the labels into kth unit vector
-        vec_y = np.eye(self.k_)[y]
-
-        # Replace 0s with -1/(K-1)
-        vec_y[vec_y == 0] = -1 / (self.k_ - 1)
-
-        return vec_y
-
-    def _get_rule_cost(
-        self, temp_rule: Rule, covers: np.ndarray, counts: np.ndarray, y: np.ndarray
-    ) -> float:
-        """
-        Calculates the cost of a rule.
-
-        Depending on the `rule_cost` attribute, this method either calls a custom cost
-        function defined in a `RuleCost` instance or returns a fixed cost for the rule.
-
-        Parameters
-        ----------
-        temp_rule : Rule
-            The rule for which the cost is being calculated.
-        covers : np.ndarray
-            An array indicating whether each instance in the dataset is covered by the rule.
-        counts : np.ndarray
-            An array indicating the count of instances covered by the rule, segmented by class.
-        y : np.ndarray
-            The target array, containing the actual class labels of the instances.
-
-        Returns
-        -------
-        float
-            The calculated cost of the rule.
-        """
-
-        if isinstance(self.rule_cost, RuleCost):
-            return self.rule_cost(
-                temp_rule=temp_rule, covers=covers, counts=counts, y=y
-            )
-        elif isinstance(self.rule_cost, int):
-            return self.rule_cost
-        else:
-            raise TypeError(
-                f"Unsupported type for `rule_cost`: {type(self.rule_cost)}.",
-                "Expected a RuleCost instance or an int.",
-            )
-
-    def _fill_rules(self, weights: np.ndarray) -> None:
-        """
-        Selects and stores rules based on their weights and a predefined threshold.
-
-        Parameters
-        ----------
-        weights : np.ndarray
-            An array containing the weights of each rule.
-
-        Modifies
-        --------
-        rule_columns_ : np.ndarray
-            Updated to include indices of the selected rules, ordered by their weight.
-        decision_rules_ : Dict[int, Rule]
-            Populated with the selected and ordered rules, keyed by their new indices.
-        """
-        # Scale the weights
-        max_weight = np.max(weights)
-        if max_weight != 1 and max_weight > 1.0e-6:
-            weights = np.divide(weights, max_weight)
-
-        # Select columns where weights are above the threshold
-        selected_columns = np.where(weights > self.threshold)[0]
-
-        # Order the selected columns by their weights
-        weight_order = np.argsort(-weights[selected_columns])
-        ordered_columns = selected_columns[weight_order]
-
-        # Assign the ordered columns to the class attribute
-        self.rule_columns_ = ordered_columns
-
-        # Iterate over the columns and fill the rules dictionary
-        for i, col in enumerate(ordered_columns):
-            treeno, leafno, label, sdist = self.rule_info_[col]
-            fit_tree = self.decision_trees_[treeno]
-            rule = self._get_rule(fit_tree, leafno)
-            rule.label = label
-            rule.weight = weights[col]
-            rule.sdist = sdist
-            self.decision_rules_[i] = rule
-
-    def _predict_base(
-        self,
-        x: np.ndarray,
-        indices: list = None,
-        threshold: float = 0,
-        *,
-        predict_info=False,
-    ) -> np.ndarray:
-        """
-        Calculates the base class weights for each instance based on selected rules.
-        Optionally returns additional prediction info.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            The feature matrix for the instances to predict.
-        indices : list, optional
-            Specific indices of rules to use for prediction. If None, all rules
-            are used.
-        threshold : float, default=0
-            The threshold for selecting rules based on their weights.
-        predict_info : bool, default=False
-            If True, returns additional information about the prediction process
-            including indices of samples with missed values, number of rules
-            applied per sample, and average rule length per sample. Otherwise,
-            returns only the array of raw class weights.
-
-        Returns
-        -------
-        np.ndarray
-            An array of raw class weights for each instance, used as the basis for final
-            prediction.
-            If predict_info is True, also returns arrays containing indices of samples
-            with missed values, number of rules applied per sample, and average rule
-            length per sample.
-        """
-
-        # Check if the model has been fitted
-        if indices is None:
-            indices = []
-        if not self.decision_trees_:
-            raise ValueError("You need to fit the RUG model first")
-
-        # If no specific indices are provided, use all rule indices
-        if len(indices) == 0:
-            indices = list(self.decision_rules_.keys())
-
-        # If provided indices exceed the available rules, return a warning
-        elif np.max(indices) > len(self.decision_rules_):
-            warnings.warn(f"\n There are only {len(self.decision_rules_)} rules")
-            return None
-
-        rule_lengths = np.zeros(x.shape[0], dtype=np.intp)
-        sum_class_weights_arr = np.empty(shape=(x.shape[0], self.k_), dtype=np.float64)
-
-        # Initialize arrays to track missing values and rule lengths per sample
-        missed_values_index_ = np.empty((0,), dtype=np.intp)
-        rules_per_sample_ = np.zeros(x.shape[0], dtype=np.intp)
-        rule_length_per_sample_ = np.zeros(x.shape[0], dtype=np.float64)
-
-        # Iterate over each sample in the feature matrix x
-        for sindx, x0 in enumerate(x):
-            # Initialize an array to hold class weights for this sample
-            sum_class_weights = np.zeros(self.k_, dtype=np.float64)
-            rule_lengths[sindx] = 0
-
-            # Iterate over each rule and apply it to the sample
-            for indx, rule in self.decision_rules_.items():
-                # Only apply the rule if its index is in the specified indices,
-                # it applies to the sample, and its weight is above the threshold
-                if indx in indices and rule.check_rule(x0) and rule.weight >= threshold:
-                    # Add the weight of the rule to the weight for its class
-                    sum_class_weights[rule.label] += rule.weight
-                    # Increment the count of rules applied to this sample
-                    rules_per_sample_[sindx] += 1
-                    # Add the length of the rule to the total rule length for this sample
-                    rule_lengths[sindx] += len(rule)
-
-            # If any rules were applied to this sample, calculate the average rule length
-            if rule_lengths[sindx] > 0:
-                rule_length_per_sample_[sindx] = (
-                    rule_lengths[sindx] / rules_per_sample_[sindx]
-                )
-            else:
-                # If no rules were applied to this sample, add it to the missed values index
-                missed_values_index_ = np.concatenate((missed_values_index_, [sindx]))
-
-            # Add the class weights for this sample to the array of class weights
-            sum_class_weights_arr[sindx, :] = sum_class_weights
-
-        # Return the array of class weights
-        if predict_info:
-            warnings.warn(
-                "Enabling 'predict_info' will return additional prediction "
-                "details, including indices of samples with missed values, "
-                "number of rules applied per sample, and average rule length "
-                "per sample. While this information is useful for in-depth "
-                "analysis, it may increase computational overhead and complexity "
-                "of result interpretation. Use this feature judiciously."
-            )
-            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
-
-        else:
-            return sum_class_weights_arr
-
-    def predict(
-        self,
-        x: ArrayLike,
-        indices: list | None = None,
-        threshold: float = 0.0,
-        *,
-        predict_info: bool = False,
-    ) -> np.ndarray:
-        """
-        Predicts class labels for the given data, optionally returning
-        additional prediction info.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        indices : list or None, default=None
-            Specific indices of rules to use for prediction. If None,
-            all rules are used.
-        threshold : float, default=0
-            The threshold for selecting rules based on their weights.
-        predict_info : bool, default=False
-            If True, returns additional information about the prediction
-            process including indices of samples with missed values, number
-            of rules applied per sample, and average rule length per sample.
-            Otherwise, returns only the predicted class labels.
-
-        Returns
-        -------
-        np.ndarray
-            An array of predicted class labels for each instance in `x`.
-            If predict_info is True, also returns arrays containing indices
-            of samples with missed values, number of rules applied per sample,
-            and average rule length per sample.
-        """
-
-        if indices is None:
-            indices = []
-
-        x = check_inputs(x)
-
-        if predict_info:
-            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
-                self._predict_base(x, indices, threshold, predict_info=predict_info)
-            )
-            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
-
-        else:
-            sum_class_weights_arr = self._predict_base(
-                x, indices, threshold, predict_info=predict_info
-            )
-
-        return_prediction = np.empty(shape=(x.shape[0],), dtype=np.intp)
-
-        # Convert the class weights into class predictions
-        for sindx, sum_class_weights in enumerate(sum_class_weights_arr):
-            # If the sum of the class weights is 0, predict the majority class
-            if np.sum(sum_class_weights) <= 10e-6:
-                return_prediction[sindx] = self.majority_class_
-            else:
-                # Otherwise, predict the class with the highest weight
-                return_prediction[sindx] = np.argmax(sum_class_weights)
-
-        # Return the predicted classes
-        return return_prediction
-
-    def predict_proba(
-        self,
-        x: ArrayLike,
-        indices: list | None = None,
-        threshold: float = 0.0,
-        *,
-        predict_info: bool = False,
-    ):
-        """
-        Predicts class probabilities for the given data, optionally
-        returning additional prediction info.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        indices : list or None, default=None
-            Specific indices of rules to use for calculating probabilities.
-            If None, all rules are used.
-        threshold : float, default=0
-            The threshold for selecting rules based on their weights.
-        predict_info : bool, default=False
-            If True, returns additional information about the prediction process
-            including indices of samples with missed values, number of rules applied
-            per sample, and average rule length per sample. Otherwise, returns only
-            the probabilities of each class for each sample.
-
-        Returns
-        -------
-        np.ndarray
-            An array where each row corresponds to a sample in `x` and each column
-            to a class, containing the probability of each class for each sample.
-            If predict_info is True, also returns arrays containing indices of samples
-            with missed values, number of rules applied per sample, and average rule
-            length per sample.
-        """
-
-        if indices is None:
-            indices = []
-
-        x = check_inputs(x)
-
-        if predict_info:
-            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
-                self._predict_base(x, indices, threshold, predict_info=predict_info)
-            )
-            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
-
-        else:
-            sum_class_weights_arr = self._predict_base(
-                x, indices, threshold, predict_info=predict_info
-            )
-
-        return_prediction = np.empty(shape=(x.shape[0], self.k_), dtype=np.float64)
-
-        # Convert the class weights into class probabilities
-        for sindx, sum_class_weights in enumerate(sum_class_weights_arr):
-            total_weight = np.sum(sum_class_weights)
-            if total_weight <= 10e-6:
-                # If the sum of the class weights is 0, predict the majority class probabilities
-                return_prediction[sindx, :] = self.majority_probability_
-            else:
-                # Otherwise, divide the class weights by the total weight
-                # to get the class probabilities
-                return_prediction[sindx, :] = np.divide(sum_class_weights, total_weight)
-
-        # Return the class probabilities
-        return return_prediction
-
-    def _get_sample_wight(self, sample_weight, class_weight, y):
-        """
-        Calculates the final sample weights based on initial sample weights, class weights and
-        target values.
-
-        Parameters
-        ----------
-        sample_weight : array-like, shape (n_samples,) or None
-            Initial weights of samples. If None, all samples are assumed to have weight one.
-        class_weight : dict, "balanced" or None
-            Weights associated with classes in the form {class_label: weight}. Can be "balanced"
-            to automatically adjust weights inversely proportional to class frequencies in the input data
-            or None for equal weights.
-        y : array-like, shape (n_samples,)
-            Array of target values (class labels).
-
-        Returns
-        -------
-        final_sample_weights : array-like, shape (n_samples,) or None
-            The computed array of weights for each sample in the dataset. Returns None if all computed
-            weights are equal to one, indicating no weighting is necessary.
-        """
-        if class_weight is None and sample_weight is None:
-            return None
-
-        if sample_weight is not None:
-            if (
-                not isinstance(sample_weight, np.ndarray)
-                or sample_weight.shape != y.shape
-            ):
-                raise ValueError(
-                    "sample_weight must be a numpy array of the same shape as y."
-                )
-
-        final_sample_weights = np.ones_like(y, dtype=np.float64)
-
-        if class_weight is not None:
-            if isinstance(class_weight, dict):
-                if len(class_weight.keys()) != np.unique(y).size:
-                    raise ValueError(
-                        "The class_weight dictionary must have a key for each unique value in y."
-                    )
-
-            final_sample_weights *= compute_sample_weight(class_weight, y)
-        if sample_weight is not None:
-            final_sample_weights *= sample_weight
-
-        if np.min(final_sample_weights) != 1:
-            warnings.warn(
-                "Minimum sample weight automatically scaled to 1 for consistency."
-            )
-            final_sample_weights /= np.min(final_sample_weights)
-
-        return final_sample_weights
-
-    def _validate_rug_parameters(
-        self,
-        threshold: float,
-        solver: OptimizationSolver,
-        class_weight: Dict[int:float],
-        random_state: int | None,
-        rule_cost,
-    ):
-        if not isinstance(threshold, (float, int)) or threshold < 0:
-            raise TypeError("threshold must be a non-negative float or integer.")
-
-        if not isinstance(solver, (OptimizationSolver)):
-            raise TypeError("solver should be inherited from OptimizationSolver.")
-
-        if not (isinstance(random_state, int) or random_state is None):
-            raise TypeError("random_state must be an integer or None.")
-
-        if not isinstance(rule_cost, (int, RuleCost)):
-            raise TypeError("rule_cost must be an instance of RuleCost or an integer.")
-
-        if isinstance(rule_cost, int) and rule_cost < 0:
-            raise ValueError("If rule_cost is an integer, it must be non-negative.")
-
-        if not (
-            isinstance(class_weight, dict)
-            and all(
-                isinstance(k, int) and isinstance(v, float)
-                for k, v in class_weight.items()
-            )
-            or class_weight in ["balanced", None]
-        ):
-            raise TypeError(
-                "class_weight must be a dictionary with integer keys and float values, 'balanced', or None."
-            )
-
-    @property
-    def is_fitted(self):
-        """
-        Indicates whether the model is fitted.
-
-        Returns
-        -------
-        bool
-            True if the model is fitted, False otherwise.
-        """
-
-        return self._is_fitted
-
-    @property
-    def decision_rules(self):
-        """
-        Returns the rules extracted from the decision trees, after optimization.
-
-        Returns
-        -------
-        Dict[int, Rule]
-            A dictionary where keys are rule indices and values are Rule objects.
-        """
-
-        return self.decision_rules_
-
-    @property
-    def decision_trees(self):
-        """
-        Returns dictionary that stores the decision tree models.
-
-        Returns
-        -------
-        Dict[int, Any]
-            A dictionary containing decision tree models, with identifiers as keys
-            and decision
-            tree instances as values.
-        """
-        return self.decision_trees_
-
-    @property
-    def rule_info(self):
-        """
-        Returns information about each rule.
-
-        Returns
-        -------
-        Dict[int, Tuple[int, int, int, np.ndarray]]
-            A dictionary with rule indices as keys and tuples containing information about
-            each rule as values. The tuple structure is (rule_id, feature_index, threshold,
-            values_array).
-        """
-
-        return self.rule_info_
-
-    @property
-    def coefficients(self):
-        """
-        Stores coefficients associated with the rules during optimization.
-
-        Returns
-        -------
-        Coefficients
-            An object or array-like structure storing coefficients related to each rule.
-        """
-
-        return self.coefficients_
-
-    @property
-    def majority_class(self):
-        """
-        Returns the class label of the majority class in the dataset.
-
-        Returns
-        -------
-        int
-            The label of the majority class.
-        """
-
-        return self.majority_class_
-
-    @property
-    def majority_probability(self):
-        """
-        Returns the probability of the majority class in the dataset.
-
-        Returns
-        -------
-        float
-            The probability of encountering the majority class in the dataset.
-        """
-
-        return self.majority_probability_
-
-    @property
-    def k(self):
-        """
-        Returns the total number of unique classes in the dataset.
-
-        Returns
-        -------
-        float
-            The total number of unique classes.
-        """
-
-        return self.k_
-
-    @property
-    def classes(self):
-        """
-        Returns unique class labels in the dataset.
-
-        Returns
-        -------
-        np.ndarray
-            An array containing the unique class labels of the dataset.
-        """
-
-        return self.classes_
-
-    @property
-    def rule_columns(self):
-        """
-        Returns indices of rules selected as part of the model.
-
-        Returns
-        -------
-        np.ndarray
-            An array of indices corresponding to the rules included in the model.
-        """
-
-        return self.rule_columns_
+from __future__ import annotations
+import warnings
+from typing import Union, Dict
+from abc import abstractmethod
+import numpy as np
+from numpy.typing import ArrayLike
+from sklearn.base import BaseEstimator, ClassifierMixin
+from sklearn.utils.class_weight import compute_sample_weight
+
+from ..aux_classes import Coefficients, Rule
+from ..rule_cost import RuleCost
+from ..utils import check_inputs
+from ..solver.base import OptimizationSolver
+
+
+class _RUGBASE(BaseEstimator, ClassifierMixin):
+    """
+    The foundational class for all estimators in the ruleopt library. `_RUGBASE` provides
+    the core framework that every model in ruleopt builds upon.
+
+    Parameters
+    ----------
+    solver : OptimizationSolver
+        An instance of a derived class inherits from the 'Optimization Solver' base class.
+        The solver is responsible for optimizing the rule set based on the cost function
+        and constraints.
+
+    rule_cost : RuleCost or int
+        Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+        or a fixed cost
+
+    class_weight: dict, "balanced" or None
+        A dictionary mapping class labels to their respective weights, the string "balanced"
+        to automatically adjust weights inversely proportional to class frequencies,
+        or None for no weights. Used to adjust the model in favor of certain classes.
+
+    threshold : float
+        The minimum weight threshold for including a rule in the final model
+
+    random_state : int or None
+        Seed for the random number generator to ensure reproducible results.
+        Defaults to None.
+    """
+
+    def __init__(
+        self,
+        solver: OptimizationSolver,
+        rule_cost: Union[RuleCost, int],
+        class_weight: Dict[int, float],
+        threshold: float,
+        random_state: Union[None, int],
+    ):
+
+        self._validate_rug_parameters(
+            threshold=threshold,
+            random_state=random_state,
+            rule_cost=rule_cost,
+            solver=solver,
+            class_weight=class_weight,
+        )
+        self.threshold = float(threshold)
+        self.rule_cost = rule_cost
+        self.solver = solver
+        self.random_state = random_state
+        self.class_weight = class_weight
+
+        # Additional initializations
+        self._rng = np.random.default_rng(
+            random_state if random_state is not None else None
+        )
+        self.decision_trees_ = {}
+        self.decision_rules_ = {}
+        self.rule_info_ = {}
+        self.coefficients_ = Coefficients()
+
+        self._is_fitted: bool = False
+        self.majority_class_: int = None
+        self.majority_probability_: float = None
+        self.k_: float = None
+        self.classes_: np.array = None
+        self.rule_columns_: np.array = None
+
+    def _cleanup(self) -> None:
+        """
+        Clean up the model by resetting all of its attributes.
+        """
+        # Resetting all dictionaries
+        self.decision_trees_ = {}
+        self.decision_rules_ = {}
+        self.rule_info_ = {}
+
+        # Cleaning up coefficients
+        self.coefficients_.cleanup()
+
+        # Resetting the random number generator
+        self._rng = np.random.default_rng(self.random_state)
+
+    @abstractmethod
+    def _get_rule(self, *arg, **kwargs) -> Rule: ...
+
+    @abstractmethod
+    def _get_matrix(self, *arg, **kwargs) -> None: ...
+
+    def _get_class_infos(self, y: np.ndarray) -> None:
+        """
+        Computes and stores information about the classes in the dataset.
+
+        This method calculates the majority class, its probability, the total number
+        of unique classes, and stores an array of unique class labels.
+
+        Parameters
+        ----------
+        y : np.ndarray
+            The target values, expected to be a 1D numpy array of class labels.
+
+        Sets Attributes
+        ---------------
+        majority_class_ : int
+            The class label with the highest frequency in `y`.
+        majority_probability_ : float
+            The proportion of samples in `y` belonging to the majority class,
+            calculated as the count of the majority class divided by the total number of samples.
+        k_ : float
+            The total number of unique classes in `y`.
+        classes_ : np.array
+            An array of the unique class labels present in the dataset.
+        """
+        classes, class_counts = np.unique(y, return_counts=True)
+
+        self.majority_class_ = classes[np.argmax(class_counts)]
+        self.majority_probability_ = class_counts / np.sum(class_counts)
+
+        self.k_ = classes.shape[0]
+        self.classes_ = classes
+
+    def _preprocess(self, y: np.ndarray) -> np.ndarray:
+        """
+        Transforms the target values into a vector. If the target
+        class is k and there are K classes, then all components but
+        the kth are set to -1/(K-1) and the kth component is set to 1. 
+
+        Parameters
+        ----------
+        y : np.ndarray
+            The target values as a 1D numpy array of class labels.
+
+        Returns
+        -------
+        np.ndarray
+            The preprocessed target values in a one-hot-encoded format, adjusted for the model's
+            optimization process.
+        """
+
+        # Convert the labels into kth unit vector
+        vec_y = np.eye(self.k_)[y]
+
+        # Replace 0s with -1/(K-1)
+        vec_y[vec_y == 0] = -1 / (self.k_ - 1)
+
+        return vec_y
+
+    def _get_rule_cost(
+        self, temp_rule: Rule, covers: np.ndarray, counts: np.ndarray, y: np.ndarray
+    ) -> float:
+        """
+        Calculates the cost of a rule.
+
+        Depending on the `rule_cost` attribute, this method either calls a custom cost
+        function defined in a `RuleCost` instance or returns a fixed cost for the rule.
+
+        Parameters
+        ----------
+        temp_rule : Rule
+            The rule for which the cost is being calculated.
+        covers : np.ndarray
+            An array indicating whether each instance in the dataset is covered by the rule.
+        counts : np.ndarray
+            An array indicating the count of instances covered by the rule, segmented by class.
+        y : np.ndarray
+            The target array, containing the actual class labels of the instances.
+
+        Returns
+        -------
+        float
+            The calculated cost of the rule.
+        """
+
+        if isinstance(self.rule_cost, RuleCost):
+            return self.rule_cost(
+                temp_rule=temp_rule, covers=covers, counts=counts, y=y
+            )
+        elif isinstance(self.rule_cost, int):
+            return self.rule_cost
+        else:
+            raise TypeError(
+                f"Unsupported type for `rule_cost`: {type(self.rule_cost)}.",
+                "Expected a RuleCost instance or an int.",
+            )
+
+    def _fill_rules(self, weights: np.ndarray) -> None:
+        """
+        Selects and stores rules based on their weights and a predefined threshold.
+
+        Parameters
+        ----------
+        weights : np.ndarray
+            An array containing the weights of each rule.
+
+        Modifies
+        --------
+        rule_columns_ : np.ndarray
+            Updated to include indices of the selected rules, ordered by their weight.
+        decision_rules_ : Dict[int, Rule]
+            Populated with the selected and ordered rules, keyed by their new indices.
+        """
+        # Scale the weights
+        max_weight = np.max(weights)
+        if max_weight != 1 and max_weight > 1.0e-6:
+            weights = np.divide(weights, max_weight)
+
+        # Select columns where weights are above the threshold
+        selected_columns = np.where(weights > self.threshold)[0]
+
+        # Order the selected columns by their weights
+        weight_order = np.argsort(-weights[selected_columns])
+        ordered_columns = selected_columns[weight_order]
+
+        # Assign the ordered columns to the class attribute
+        self.rule_columns_ = ordered_columns
+
+        # Iterate over the columns and fill the rules dictionary
+        for i, col in enumerate(ordered_columns):
+            treeno, leafno, label, sdist = self.rule_info_[col]
+            fit_tree = self.decision_trees_[treeno]
+            rule = self._get_rule(fit_tree, leafno)
+            rule.label = label
+            rule.weight = weights[col]
+            rule.sdist = sdist
+            self.decision_rules_[i] = rule
+
+    def _predict_base(
+        self,
+        x: np.ndarray,
+        indices: list = None,
+        threshold: float = 0,
+        *,
+        predict_info=False,
+    ) -> np.ndarray:
+        """
+        Calculates the base class weights for each instance based on selected rules.
+        Optionally returns additional prediction info.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            The feature matrix for the instances to predict.
+        indices : list, optional
+            Specific indices of rules to use for prediction. If None, all rules
+            are used.
+        threshold : float, default=0
+            The threshold for selecting rules based on their weights.
+        predict_info : bool, default=False
+            If True, returns additional information about the prediction process
+            including indices of samples with missed values, number of rules
+            applied per sample, and average rule length per sample. Otherwise,
+            returns only the array of raw class weights.
+
+        Returns
+        -------
+        np.ndarray
+            An array of raw class weights for each instance, used as the basis for final
+            prediction.
+            If predict_info is True, also returns arrays containing indices of samples
+            with missed values, number of rules applied per sample, and average rule
+            length per sample.
+        """
+
+        # Check if the model has been fitted
+        if indices is None:
+            indices = []
+        if not self.decision_trees_:
+            raise ValueError("You need to fit the RUG model first")
+
+        # If no specific indices are provided, use all rule indices
+        if len(indices) == 0:
+            indices = list(self.decision_rules_.keys())
+
+        # If provided indices exceed the available rules, return a warning
+        elif np.max(indices) > len(self.decision_rules_):
+            warnings.warn(f"\n There are only {len(self.decision_rules_)} rules")
+            return None
+
+        rule_lengths = np.zeros(x.shape[0], dtype=np.intp)
+        sum_class_weights_arr = np.empty(shape=(x.shape[0], self.k_), dtype=np.float64)
+
+        # Initialize arrays to track missing values and rule lengths per sample
+        missed_values_index_ = np.empty((0,), dtype=np.intp)
+        rules_per_sample_ = np.zeros(x.shape[0], dtype=np.intp)
+        rule_length_per_sample_ = np.zeros(x.shape[0], dtype=np.float64)
+
+        # Iterate over each sample in the feature matrix x
+        for sindx, x0 in enumerate(x):
+            # Initialize an array to hold class weights for this sample
+            sum_class_weights = np.zeros(self.k_, dtype=np.float64)
+            rule_lengths[sindx] = 0
+
+            # Iterate over each rule and apply it to the sample
+            for indx, rule in self.decision_rules_.items():
+                # Only apply the rule if its index is in the specified indices,
+                # it applies to the sample, and its weight is above the threshold
+                if indx in indices and rule.check_rule(x0) and rule.weight >= threshold:
+                    # Add the weight of the rule to the weight for its class
+                    sum_class_weights[rule.label] += rule.weight
+                    # Increment the count of rules applied to this sample
+                    rules_per_sample_[sindx] += 1
+                    # Add the length of the rule to the total rule length for this sample
+                    rule_lengths[sindx] += len(rule)
+
+            # If any rules were applied to this sample, calculate the average rule length
+            if rule_lengths[sindx] > 0:
+                rule_length_per_sample_[sindx] = (
+                    rule_lengths[sindx] / rules_per_sample_[sindx]
+                )
+            else:
+                # If no rules were applied to this sample, add it to the missed values index
+                missed_values_index_ = np.concatenate((missed_values_index_, [sindx]))
+
+            # Add the class weights for this sample to the array of class weights
+            sum_class_weights_arr[sindx, :] = sum_class_weights
+
+        # Return the array of class weights
+        if predict_info:
+            warnings.warn(
+                "Enabling 'predict_info' will return additional prediction "
+                "details, including indices of samples with missed values, "
+                "number of rules applied per sample, and average rule length "
+                "per sample. While this information is useful for in-depth "
+                "analysis, it may increase computational overhead and complexity "
+                "of result interpretation. Use this feature judiciously."
+            )
+            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
+
+        else:
+            return sum_class_weights_arr
+
+    def predict(
+        self,
+        x: ArrayLike,
+        indices: list | None = None,
+        threshold: float = 0.0,
+        *,
+        predict_info: bool = False,
+    ) -> np.ndarray:
+        """
+        Predicts class labels for the given data, optionally returning
+        additional prediction info.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        indices : list or None, default=None
+            Specific indices of rules to use for prediction. If None,
+            all rules are used.
+        threshold : float, default=0
+            The threshold for selecting rules based on their weights.
+        predict_info : bool, default=False
+            If True, returns additional information about the prediction
+            process including indices of samples with missed values, number
+            of rules applied per sample, and average rule length per sample.
+            Otherwise, returns only the predicted class labels.
+
+        Returns
+        -------
+        np.ndarray
+            An array of predicted class labels for each instance in `x`.
+            If predict_info is True, also returns arrays containing indices
+            of samples with missed values, number of rules applied per sample,
+            and average rule length per sample.
+        """
+
+        if indices is None:
+            indices = []
+
+        x = check_inputs(x)
+
+        if predict_info:
+            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
+                self._predict_base(x, indices, threshold, predict_info=predict_info)
+            )
+            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
+
+        else:
+            sum_class_weights_arr = self._predict_base(
+                x, indices, threshold, predict_info=predict_info
+            )
+
+        return_prediction = np.empty(shape=(x.shape[0],), dtype=np.intp)
+
+        # Convert the class weights into class predictions
+        for sindx, sum_class_weights in enumerate(sum_class_weights_arr):
+            # If the sum of the class weights is 0, predict the majority class
+            if np.sum(sum_class_weights) <= 10e-6:
+                return_prediction[sindx] = self.majority_class_
+            else:
+                # Otherwise, predict the class with the highest weight
+                return_prediction[sindx] = np.argmax(sum_class_weights)
+
+        # Return the predicted classes
+        return return_prediction
+
+    def predict_proba(
+        self,
+        x: ArrayLike,
+        indices: list | None = None,
+        threshold: float = 0.0,
+        *,
+        predict_info: bool = False,
+    ):
+        """
+        Predicts class probabilities for the given data, optionally
+        returning additional prediction info.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        indices : list or None, default=None
+            Specific indices of rules to use for calculating probabilities.
+            If None, all rules are used.
+        threshold : float, default=0
+            The threshold for selecting rules based on their weights.
+        predict_info : bool, default=False
+            If True, returns additional information about the prediction process
+            including indices of samples with missed values, number of rules applied
+            per sample, and average rule length per sample. Otherwise, returns only
+            the probabilities of each class for each sample.
+
+        Returns
+        -------
+        np.ndarray
+            An array where each row corresponds to a sample in `x` and each column
+            to a class, containing the probability of each class for each sample.
+            If predict_info is True, also returns arrays containing indices of samples
+            with missed values, number of rules applied per sample, and average rule
+            length per sample.
+        """
+
+        if indices is None:
+            indices = []
+
+        x = check_inputs(x)
+
+        if predict_info:
+            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
+                self._predict_base(x, indices, threshold, predict_info=predict_info)
+            )
+            return missed_values_index_, rules_per_sample_, rule_length_per_sample_
+
+        else:
+            sum_class_weights_arr = self._predict_base(
+                x, indices, threshold, predict_info=predict_info
+            )
+
+        return_prediction = np.empty(shape=(x.shape[0], self.k_), dtype=np.float64)
+
+        # Convert the class weights into class probabilities
+        for sindx, sum_class_weights in enumerate(sum_class_weights_arr):
+            total_weight = np.sum(sum_class_weights)
+            if total_weight <= 10e-6:
+                # If the sum of the class weights is 0, predict the majority class probabilities
+                return_prediction[sindx, :] = self.majority_probability_
+            else:
+                # Otherwise, divide the class weights by the total weight
+                # to get the class probabilities
+                return_prediction[sindx, :] = np.divide(sum_class_weights, total_weight)
+
+        # Return the class probabilities
+        return return_prediction
+
+    def _get_sample_wight(self, sample_weight, class_weight, y):
+        """
+        Calculates the final sample weights based on initial sample weights, class weights and
+        target values.
+
+        Parameters
+        ----------
+        sample_weight : array-like, shape (n_samples,) or None
+            Initial weights of samples. If None, all samples are assumed to have weight one.
+        class_weight : dict, "balanced" or None
+            Weights associated with classes in the form {class_label: weight}. Can be "balanced"
+            to automatically adjust weights inversely proportional to class frequencies in the input data
+            or None for equal weights.
+        y : array-like, shape (n_samples,)
+            Array of target values (class labels).
+
+        Returns
+        -------
+        final_sample_weights : array-like, shape (n_samples,) or None
+            The computed array of weights for each sample in the dataset. Returns None if all computed
+            weights are equal to one, indicating no weighting is necessary.
+        """
+        if class_weight is None and sample_weight is None:
+            return None
+
+        if sample_weight is not None:
+            if (
+                not isinstance(sample_weight, np.ndarray)
+                or sample_weight.shape != y.shape
+            ):
+                raise ValueError(
+                    "sample_weight must be a numpy array of the same shape as y."
+                )
+
+        final_sample_weights = np.ones_like(y, dtype=np.float64)
+
+        if class_weight is not None:
+            if isinstance(class_weight, dict):
+                if len(class_weight.keys()) != np.unique(y).size:
+                    raise ValueError(
+                        "The class_weight dictionary must have a key for each unique value in y."
+                    )
+
+            final_sample_weights *= compute_sample_weight(class_weight, y)
+        if sample_weight is not None:
+            final_sample_weights *= sample_weight
+
+        if np.min(final_sample_weights) != 1:
+            warnings.warn(
+                "Minimum sample weight automatically scaled to 1 for consistency."
+            )
+            final_sample_weights /= np.min(final_sample_weights)
+
+        return final_sample_weights
+
+    def _validate_rug_parameters(
+        self,
+        threshold: float,
+        solver: OptimizationSolver,
+        class_weight: Dict[int:float],
+        random_state: int | None,
+        rule_cost,
+    ):
+        if not isinstance(threshold, (float, int)) or threshold < 0:
+            raise TypeError("threshold must be a non-negative float or integer.")
+
+        if not isinstance(solver, (OptimizationSolver)):
+            raise TypeError("solver should be inherited from OptimizationSolver.")
+
+        if not (isinstance(random_state, int) or random_state is None):
+            raise TypeError("random_state must be an integer or None.")
+
+        if not isinstance(rule_cost, (int, RuleCost)):
+            raise TypeError("rule_cost must be an instance of RuleCost or an integer.")
+
+        if isinstance(rule_cost, int) and rule_cost < 0:
+            raise ValueError("If rule_cost is an integer, it must be non-negative.")
+
+        if not (
+            isinstance(class_weight, dict)
+            and all(
+                isinstance(k, int) and isinstance(v, float)
+                for k, v in class_weight.items()
+            )
+            or class_weight in ["balanced", None]
+        ):
+            raise TypeError(
+                "class_weight must be a dictionary with integer keys and float values, 'balanced', or None."
+            )
+
+    @property
+    def is_fitted(self):
+        """
+        Indicates whether the model is fitted.
+
+        Returns
+        -------
+        bool
+            True if the model is fitted, False otherwise.
+        """
+
+        return self._is_fitted
+
+    @property
+    def decision_rules(self):
+        """
+        Returns the rules extracted from the decision trees, after optimization.
+
+        Returns
+        -------
+        Dict[int, Rule]
+            A dictionary where keys are rule indices and values are Rule objects.
+        """
+
+        return self.decision_rules_
+
+    @property
+    def decision_trees(self):
+        """
+        Returns dictionary that stores the decision tree models.
+
+        Returns
+        -------
+        Dict[int, Any]
+            A dictionary containing decision tree models, with identifiers as keys
+            and decision
+            tree instances as values.
+        """
+        return self.decision_trees_
+
+    @property
+    def rule_info(self):
+        """
+        Returns information about each rule.
+
+        Returns
+        -------
+        Dict[int, Tuple[int, int, int, np.ndarray]]
+            A dictionary with rule indices as keys and tuples containing information about
+            each rule as values. The tuple structure is (rule_id, feature_index, threshold,
+            values_array).
+        """
+
+        return self.rule_info_
+
+    @property
+    def coefficients(self):
+        """
+        Stores coefficients associated with the rules during optimization.
+
+        Returns
+        -------
+        Coefficients
+            An object or array-like structure storing coefficients related to each rule.
+        """
+
+        return self.coefficients_
+
+    @property
+    def majority_class(self):
+        """
+        Returns the class label of the majority class in the dataset.
+
+        Returns
+        -------
+        int
+            The label of the majority class.
+        """
+
+        return self.majority_class_
+
+    @property
+    def majority_probability(self):
+        """
+        Returns the probability of the majority class in the dataset.
+
+        Returns
+        -------
+        float
+            The probability of encountering the majority class in the dataset.
+        """
+
+        return self.majority_probability_
+
+    @property
+    def k(self):
+        """
+        Returns the total number of unique classes in the dataset.
+
+        Returns
+        -------
+        float
+            The total number of unique classes.
+        """
+
+        return self.k_
+
+    @property
+    def classes(self):
+        """
+        Returns unique class labels in the dataset.
+
+        Returns
+        -------
+        np.ndarray
+            An array containing the unique class labels of the dataset.
+        """
+
+        return self.classes_
+
+    @property
+    def rule_columns(self):
+        """
+        Returns indices of rules selected as part of the model.
+
+        Returns
+        -------
+        np.ndarray
+            An array of indices corresponding to the rules included in the model.
+        """
+
+        return self.rule_columns_
```

## ruleopt/estimator/lightgbm_.py

 * *Ordering differences only*

```diff
@@ -1,327 +1,327 @@
-from __future__ import annotations
-import numpy as np
-from numpy.typing import ArrayLike
-
-from .base import _RUGBASE
-from ..aux_classes import Rule
-from ..rule_cost import Gini
-from ..utils import check_module_available, check_inputs
-
-LIGHTGBM_AVAILABLE = check_module_available("lightgbm")
-
-
-class RUXLGBMClassifier(_RUGBASE):
-    """
-    A classifier that extracts and optimizes decision rules from a trained
-    LightGBM ensemble model to create a compact and interpretable model.
-    This process involves translating the ensemble's trees into a set of rules and
-    using optimization to balance model accuracy and interpretability. The complexity
-    of the resulting rule-based model is  controlled through a penalty parameter.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not LIGHTGBM_AVAILABLE:
-            raise ImportError(
-                "LightGBM is required for this class but is not installed.",
-                "Please install it with 'pip install lightgbm'",
-            )
-        instance = super(RUXLGBMClassifier, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        trained_ensemble,
-        solver,
-        *,
-        rule_cost=Gini(),
-        class_weight: dict | str | None = None,
-        threshold: float = 1.0e-6,
-        random_state: int | None = None,
-    ):
-        """
-        Parameters
-        ----------
-        trained_ensemble : lightgbm.LGBMClassifier or lightgbm.Booster
-            The trained LightGBM ensemble model from which the rules will be extracted.
-
-        solver : OptimizationSolver
-            An instance of a derived class inherits from the 'Optimization Solver' base class.
-            The solver is responsible for optimizing the rule set based on the cost function
-            and constraints.
-
-        rule_cost : RuleCost or int, default=Gini()
-            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-            or a fixed cost
-
-        class_weight: dict, "balanced" or None, default=None
-            A dictionary mapping class labels to their respective weights, the string "balanced"
-            to automatically adjust weights inversely proportional to class frequencies,
-            or None for no weights. Used to adjust the model in favor of certain classes.
-
-        threshold : float, default=1.0e-6
-            The minimum weight threshold for including a rule in the final model.
-
-        random_state : int or None, default=None
-            Seed for the random number generator to ensure reproducible results.
-            Defaults to None.
-        """
-        ### LAZY INIT
-        from lightgbm import Booster
-
-        if not isinstance(trained_ensemble, Booster):
-            if hasattr(trained_ensemble, "booster_"):
-                if not isinstance(trained_ensemble.booster_, Booster):
-                    raise TypeError("trained_ensemble is not an instance of LightGBM.")
-                else:
-                    self.trained_ensemble = trained_ensemble.booster_
-            else:
-                raise TypeError("trained_ensemble is not an instance of LightGBM")
-        else:
-            self.trained_ensemble = trained_ensemble
-
-        super().__init__(
-            threshold=threshold,
-            random_state=random_state,
-            rule_cost=rule_cost,
-            solver=solver,
-            class_weight=class_weight,
-        )
-
-    def _find_leaf_index(self, fit_tree: dict, leaf_index: int, path=None) -> list:
-        """
-        Recursively finds the path from the root to the specified leaf node in a LightGBM tree.
-
-        Parameters
-        ----------
-        fit_tree : dict
-            The tree dictionary from a LightGBM model.
-        leaf_index : int
-            The target leaf node's ID.
-        path : list, optional
-            The path taken to reach the current node, used in recursive calls. Defaults to None.
-
-        Returns
-        -------
-        list
-            The path from the root to the leaf node, represented as a list of node IDs.
-        """
-        if path is None:
-            path = []
-        if isinstance(fit_tree, dict):
-            # If the current fit_tree is the leaf node we're looking for
-            if "leaf_index" in fit_tree and fit_tree["leaf_index"] == leaf_index:
-                return path
-            # Recursively look in the items of the fit_tree
-            for key, value in fit_tree.items():
-                result = self._find_leaf_index(value, leaf_index, path + [key])
-                if result:
-                    return result
-
-    def _get_rule(self, fit_tree: dict, nodeid: int) -> Rule:
-        """
-        Constructs a rule corresponding to the path leading to a specific leaf node in
-        a LightGBM tree.
-
-        Parameters
-        ----------
-        fit_tree : dict
-            The tree structure extracted from a LightGBM model, typically in JSON format.
-        nodeid : int
-            The unique identifier of the leaf node for which to construct the rule.
-
-        Returns
-        -------
-        Rule
-            An object representing the decision rule leading to the specified leaf node.
-        """
-        # Get the path to the leaf node
-        leaf_path = self._find_leaf_index(fit_tree, nodeid)
-
-        # Initialize the rule
-        return_rule = Rule()
-
-        # child variable is used to track the last traversed node
-        child = None
-
-        # While there are still nodes in the path to the leaf node
-        while leaf_path:
-            fit_tree_ = fit_tree.copy()
-            for path in leaf_path:
-                fit_tree_ = fit_tree_[path]
-
-            # If the current node is a split node, add a clause to the rule
-            if "split_feature" in fit_tree_.keys():
-                # Check which child node we're coming from
-                is_left = child == "left_child"
-                # Get the threshold for the split
-                threshold = fit_tree_["threshold"]
-                # Get the default path in case of missing values
-                missing = (is_left and fit_tree_["default_left"]) or (
-                    child == "right_child" and not fit_tree_["default_left"]
-                )
-
-                feature = fit_tree_["split_feature"]
-                ub = threshold if is_left else np.inf
-                lb = -np.inf if is_left else threshold
-                na = missing
-
-                return_rule.add_clause(feature, ub, lb, na)
-
-            # Move to the next node in the path
-            child = leaf_path.pop()
-
-        return return_rule
-
-    def _get_matrix(
-        self,
-        y: np.ndarray,
-        vec_y: np.ndarray,
-        fit_tree: dict,
-        treeno: int,
-        y_rules: np.ndarray,
-    ):
-        """
-        Populates the matrices for the optimization problem based on a single LightGBM tree.
-
-        Parameters
-        ----------
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector, suitable for the optimization problem.
-        fit_tree : dict
-            A single decision tree's structure from LightGBM, in dictionary form.
-        treeno : int
-            The index of the current tree within the ensemble.
-        y_rules : np.ndarray
-            The array of leaf indices for each sample in the training data, determined by
-            the current tree.
-        """
-        # If the coefficients matrix is empty, start from the first column
-        if self.coefficients_.cols.shape[0] == 0:
-            col = 0
-        else:
-            # Otherwise, start from the next available column
-            col = np.max(self.coefficients_.cols) + 1
-
-        # Get the leaf node for each sample in x
-        y_rules = y_rules[:, treeno]
-
-        # Iterate over unique leaf nodes
-        for leafno in np.unique(y_rules):
-            # Get the samples in the leaf
-            covers = np.where(y_rules == leafno)[0]
-            leaf_y_vals = y[covers]  # y values of the samples in the leaf
-
-            # Get unique labels in the leaf and their counts
-            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
-
-            # Identify the majority class in the leaf
-            label = unique_labels[np.argmax(counts)]
-
-            # Create a vector for this label
-            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
-            label_vector[label] = 1
-
-            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
-            fill_ahat = np.dot(vec_y[covers, :], label_vector)
-
-            # Update the coefficients matrix with the new information
-            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
-            self.coefficients_.cols = np.concatenate(
-                (self.coefficients_.cols, [col] * covers.shape[0])
-            )
-            self.coefficients_.yvals = np.concatenate(
-                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
-            )
-
-            cost = self._get_rule_cost(
-                temp_rule=self._get_rule(fit_tree, leafno),
-                covers=covers,
-                counts=counts,
-                y=y,
-            )
-
-            # Append the cost to the costs in the coefficients matrix
-            self.coefficients_.costs = np.concatenate(
-                (self.coefficients_.costs, [cost])
-            )
-
-            # Calculate the distribution of the samples in the leaf across the classess
-            sdist = counts
-            self.rule_info_[col] = (treeno, leafno, label, sdist)
-            col += 1
-
-    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray):
-        """
-        Generates the coefficient matrices for the optimization problem from all
-        trees in the LightGBM ensemble.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            The feature matrix of the training data.
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector.
-        """
-        y_rules = self.trained_ensemble.predict(x, pred_leaf=True).astype(np.intp)
-        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
-            self._get_matrix(y, vec_y, fit_tree, treeno, y_rules)
-
-    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
-        """
-        Fits the RUXLGBMClassifier to the training data, optimizing the
-        extracted rules for a balance between accuracy and interpretability.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
-            The target values (class labels) as integers
-        sample_weight : array-like of shape (n_samples,), default=None
-            Sample weights. If None, then samples are equally weighted.
-
-        Returns
-        -------
-        RUXLGBMClassifier
-            The fitted model, ready for making predictions.
-        """
-
-        x, y = check_inputs(x, y)
-
-        # If the model has been fitted before, clean it up
-        if self.coefficients_.cols.shape[0] != 0:
-            self._cleanup()
-
-        # Fills the fitted decision trees.
-        tree_infos = self.trained_ensemble.dump_model()["tree_info"]
-        for treeno, fit_tree in enumerate(tree_infos):
-            self.decision_trees_[treeno] = fit_tree
-
-        # Extract and set properties of the target variable
-        self._get_class_infos(y)
-
-        # Preprocess the target values
-        vec_y = self._preprocess(y)
-
-        # Calculate the coefficients and other parameters for the optimization problem
-        self._get_matrices(x=x, y=y, vec_y=vec_y)
-
-        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
-
-        # Solve the optimization problem again with the new rules
-        ws, *_ = self.solver(
-            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
-        )
-
-        # Fill the decision rules based on the weights obtained from the optimization problem
-        self._fill_rules(ws)
-
-        # Mark the model as fitted
-        self._is_fitted = True
-
-        # Return the fitted model
-        return self
+from __future__ import annotations
+import numpy as np
+from numpy.typing import ArrayLike
+
+from .base import _RUGBASE
+from ..aux_classes import Rule
+from ..rule_cost import Gini
+from ..utils import check_module_available, check_inputs
+
+LIGHTGBM_AVAILABLE = check_module_available("lightgbm")
+
+
+class RUXLGBMClassifier(_RUGBASE):
+    """
+    A classifier that extracts and optimizes decision rules from a trained
+    LightGBM ensemble model to create a compact and interpretable model.
+    This process involves translating the ensemble's trees into a set of rules and
+    using optimization to balance model accuracy and interpretability. The complexity
+    of the resulting rule-based model is  controlled through a penalty parameter.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not LIGHTGBM_AVAILABLE:
+            raise ImportError(
+                "LightGBM is required for this class but is not installed.",
+                "Please install it with 'pip install lightgbm'",
+            )
+        instance = super(RUXLGBMClassifier, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        trained_ensemble,
+        solver,
+        *,
+        rule_cost=Gini(),
+        class_weight: dict | str | None = None,
+        threshold: float = 1.0e-6,
+        random_state: int | None = None,
+    ):
+        """
+        Parameters
+        ----------
+        trained_ensemble : lightgbm.LGBMClassifier or lightgbm.Booster
+            The trained LightGBM ensemble model from which the rules will be extracted.
+
+        solver : OptimizationSolver
+            An instance of a derived class inherits from the 'Optimization Solver' base class.
+            The solver is responsible for optimizing the rule set based on the cost function
+            and constraints.
+
+        rule_cost : RuleCost or int, default=Gini()
+            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+            or a fixed cost
+
+        class_weight: dict, "balanced" or None, default=None
+            A dictionary mapping class labels to their respective weights, the string "balanced"
+            to automatically adjust weights inversely proportional to class frequencies,
+            or None for no weights. Used to adjust the model in favor of certain classes.
+
+        threshold : float, default=1.0e-6
+            The minimum weight threshold for including a rule in the final model.
+
+        random_state : int or None, default=None
+            Seed for the random number generator to ensure reproducible results.
+            Defaults to None.
+        """
+        ### LAZY INIT
+        from lightgbm import Booster
+
+        if not isinstance(trained_ensemble, Booster):
+            if hasattr(trained_ensemble, "booster_"):
+                if not isinstance(trained_ensemble.booster_, Booster):
+                    raise TypeError("trained_ensemble is not an instance of LightGBM.")
+                else:
+                    self.trained_ensemble = trained_ensemble.booster_
+            else:
+                raise TypeError("trained_ensemble is not an instance of LightGBM")
+        else:
+            self.trained_ensemble = trained_ensemble
+
+        super().__init__(
+            threshold=threshold,
+            random_state=random_state,
+            rule_cost=rule_cost,
+            solver=solver,
+            class_weight=class_weight,
+        )
+
+    def _find_leaf_index(self, fit_tree: dict, leaf_index: int, path=None) -> list:
+        """
+        Recursively finds the path from the root to the specified leaf node in a LightGBM tree.
+
+        Parameters
+        ----------
+        fit_tree : dict
+            The tree dictionary from a LightGBM model.
+        leaf_index : int
+            The target leaf node's ID.
+        path : list, optional
+            The path taken to reach the current node, used in recursive calls. Defaults to None.
+
+        Returns
+        -------
+        list
+            The path from the root to the leaf node, represented as a list of node IDs.
+        """
+        if path is None:
+            path = []
+        if isinstance(fit_tree, dict):
+            # If the current fit_tree is the leaf node we're looking for
+            if "leaf_index" in fit_tree and fit_tree["leaf_index"] == leaf_index:
+                return path
+            # Recursively look in the items of the fit_tree
+            for key, value in fit_tree.items():
+                result = self._find_leaf_index(value, leaf_index, path + [key])
+                if result:
+                    return result
+
+    def _get_rule(self, fit_tree: dict, nodeid: int) -> Rule:
+        """
+        Constructs a rule corresponding to the path leading to a specific leaf node in
+        a LightGBM tree.
+
+        Parameters
+        ----------
+        fit_tree : dict
+            The tree structure extracted from a LightGBM model, typically in JSON format.
+        nodeid : int
+            The unique identifier of the leaf node for which to construct the rule.
+
+        Returns
+        -------
+        Rule
+            An object representing the decision rule leading to the specified leaf node.
+        """
+        # Get the path to the leaf node
+        leaf_path = self._find_leaf_index(fit_tree, nodeid)
+
+        # Initialize the rule
+        return_rule = Rule()
+
+        # child variable is used to track the last traversed node
+        child = None
+
+        # While there are still nodes in the path to the leaf node
+        while leaf_path:
+            fit_tree_ = fit_tree.copy()
+            for path in leaf_path:
+                fit_tree_ = fit_tree_[path]
+
+            # If the current node is a split node, add a clause to the rule
+            if "split_feature" in fit_tree_.keys():
+                # Check which child node we're coming from
+                is_left = child == "left_child"
+                # Get the threshold for the split
+                threshold = fit_tree_["threshold"]
+                # Get the default path in case of missing values
+                missing = (is_left and fit_tree_["default_left"]) or (
+                    child == "right_child" and not fit_tree_["default_left"]
+                )
+
+                feature = fit_tree_["split_feature"]
+                ub = threshold if is_left else np.inf
+                lb = -np.inf if is_left else threshold
+                na = missing
+
+                return_rule.add_clause(feature, ub, lb, na)
+
+            # Move to the next node in the path
+            child = leaf_path.pop()
+
+        return return_rule
+
+    def _get_matrix(
+        self,
+        y: np.ndarray,
+        vec_y: np.ndarray,
+        fit_tree: dict,
+        treeno: int,
+        y_rules: np.ndarray,
+    ):
+        """
+        Populates the matrices for the optimization problem based on a single LightGBM tree.
+
+        Parameters
+        ----------
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector, suitable for the optimization problem.
+        fit_tree : dict
+            A single decision tree's structure from LightGBM, in dictionary form.
+        treeno : int
+            The index of the current tree within the ensemble.
+        y_rules : np.ndarray
+            The array of leaf indices for each sample in the training data, determined by
+            the current tree.
+        """
+        # If the coefficients matrix is empty, start from the first column
+        if self.coefficients_.cols.shape[0] == 0:
+            col = 0
+        else:
+            # Otherwise, start from the next available column
+            col = np.max(self.coefficients_.cols) + 1
+
+        # Get the leaf node for each sample in x
+        y_rules = y_rules[:, treeno]
+
+        # Iterate over unique leaf nodes
+        for leafno in np.unique(y_rules):
+            # Get the samples in the leaf
+            covers = np.where(y_rules == leafno)[0]
+            leaf_y_vals = y[covers]  # y values of the samples in the leaf
+
+            # Get unique labels in the leaf and their counts
+            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
+
+            # Identify the majority class in the leaf
+            label = unique_labels[np.argmax(counts)]
+
+            # Create a vector for this label
+            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
+            label_vector[label] = 1
+
+            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
+            fill_ahat = np.dot(vec_y[covers, :], label_vector)
+
+            # Update the coefficients matrix with the new information
+            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
+            self.coefficients_.cols = np.concatenate(
+                (self.coefficients_.cols, [col] * covers.shape[0])
+            )
+            self.coefficients_.yvals = np.concatenate(
+                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
+            )
+
+            cost = self._get_rule_cost(
+                temp_rule=self._get_rule(fit_tree, leafno),
+                covers=covers,
+                counts=counts,
+                y=y,
+            )
+
+            # Append the cost to the costs in the coefficients matrix
+            self.coefficients_.costs = np.concatenate(
+                (self.coefficients_.costs, [cost])
+            )
+
+            # Calculate the distribution of the samples in the leaf across the classess
+            sdist = counts
+            self.rule_info_[col] = (treeno, leafno, label, sdist)
+            col += 1
+
+    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray):
+        """
+        Generates the coefficient matrices for the optimization problem from all
+        trees in the LightGBM ensemble.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            The feature matrix of the training data.
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector.
+        """
+        y_rules = self.trained_ensemble.predict(x, pred_leaf=True).astype(np.intp)
+        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
+            self._get_matrix(y, vec_y, fit_tree, treeno, y_rules)
+
+    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
+        """
+        Fits the RUXLGBMClassifier to the training data, optimizing the
+        extracted rules for a balance between accuracy and interpretability.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
+            The target values (class labels) as integers
+        sample_weight : array-like of shape (n_samples,), default=None
+            Sample weights. If None, then samples are equally weighted.
+
+        Returns
+        -------
+        RUXLGBMClassifier
+            The fitted model, ready for making predictions.
+        """
+
+        x, y = check_inputs(x, y)
+
+        # If the model has been fitted before, clean it up
+        if self.coefficients_.cols.shape[0] != 0:
+            self._cleanup()
+
+        # Fills the fitted decision trees.
+        tree_infos = self.trained_ensemble.dump_model()["tree_info"]
+        for treeno, fit_tree in enumerate(tree_infos):
+            self.decision_trees_[treeno] = fit_tree
+
+        # Extract and set properties of the target variable
+        self._get_class_infos(y)
+
+        # Preprocess the target values
+        vec_y = self._preprocess(y)
+
+        # Calculate the coefficients and other parameters for the optimization problem
+        self._get_matrices(x=x, y=y, vec_y=vec_y)
+
+        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
+
+        # Solve the optimization problem again with the new rules
+        ws, *_ = self.solver(
+            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
+        )
+
+        # Fill the decision rules based on the weights obtained from the optimization problem
+        self._fill_rules(ws)
+
+        # Mark the model as fitted
+        self._is_fitted = True
+
+        # Return the fitted model
+        return self
```

## ruleopt/estimator/xgboost_.py

 * *Ordering differences only*

```diff
@@ -1,306 +1,306 @@
-from __future__ import annotations
-import re
-import numpy as np
-import pandas as pd
-from numpy.typing import ArrayLike
-
-from .base import _RUGBASE
-from ..aux_classes import Rule
-from ..rule_cost import Gini
-from ..utils import check_module_available, check_inputs
-
-
-XGBOOST_AVAILABLE = check_module_available("xgboost")
-
-
-class RUXXGBClassifier(_RUGBASE):
-    """
-    A classifier that extracts and optimizes decision rules from a trained
-    XGBoost ensemble model to create a compact and interpretable model.
-    This process involves translating the ensemble's trees into a set of rules and
-    using optimization to balance model accuracy and interpretability. The complexity
-    of the resulting rule-based model is  controlled through a penalty parameter.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not XGBOOST_AVAILABLE:
-            raise ImportError(
-                "XGBoost is required for this class but is not installed.",
-                "Please install it with 'pip install xgboost'",
-            )
-        instance = super(RUXXGBClassifier, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        trained_ensemble,
-        solver,
-        *,
-        rule_cost=Gini(),
-        class_weight: dict | str | None = None,
-        threshold: float = 1.0e-6,
-        random_state: int | None = None,
-    ):
-        """
-        Parameters
-        ----------
-        trained_ensemble : xgboost.XGBClassifier
-            The trained XGBoost ensemble model from which rules will be extracted.
-            The model should already be trained on the dataset.
-
-        solver : OptimizationSolver
-            An instance of a derived class inherits from the 'Optimization Solver' base class.
-            The solver is responsible for optimizing the rule set based on the cost function
-            and constraints.
-
-        rule_cost : RuleCost or int, default=Gini()
-            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-            or a fixed cost
-
-        class_weight: dict, "balanced" or None, default=None
-            A dictionary mapping class labels to their respective weights, the string "balanced"
-            to automatically adjust weights inversely proportional to class frequencies,
-            or None for no weights. Used to adjust the model in favor of certain classes.
-
-        threshold : float, default=1.0e-6
-            The minimum weight threshold for including a rule in the final model
-
-        random_state : int or None, default=None
-            Seed for the random number generator to ensure reproducible results.
-            Defaults to None.
-        """
-        ### LAZY IMPORT
-        from xgboost import Booster
-
-        if not isinstance(trained_ensemble, Booster):
-            if hasattr(trained_ensemble, "get_booster"):
-                if not isinstance(trained_ensemble.get_booster(), Booster):
-                    raise TypeError(
-                        "trained_ensemble is not an instance of XGBClassifier."
-                    )
-                else:
-                    self.trained_ensemble = trained_ensemble
-            else:
-                raise TypeError("trained_ensemble is not an instance of XGBoost")
-        else:
-            raise TypeError(
-                "XGBoost Booster instance not supported yet. Use XGBClassifier."
-            )
-
-        super().__init__(
-            threshold=threshold,
-            random_state=random_state,
-            rule_cost=rule_cost,
-            solver=solver,
-            class_weight=class_weight,
-        )
-
-    def _get_rule(self, fit_tree: pd.DataFrame, leaf_index: int) -> Rule:
-        """
-        Extracts a decision rule leading to a specified leaf node from an XGBoost tree.
-
-        Parameters
-        ----------
-        fit_tree : pd.DataFrame
-            The decision trees represented as a DataFrame extracted from the trained XGBoost model.
-        leaf_index : int
-            The ID of the leaf node for which to construct the decision rule.
-
-        Returns
-        -------
-        Rule
-            An object representing the decision rule leading to the specified leaf node,
-            composed of clauses that define the decision path.
-        """
-        # Initialize the rule
-        return_rule = Rule()
-
-        if fit_tree.shape[0] <= 1:
-            return return_rule
-
-        while True:
-            # Find the parent node of the current leaf
-            parent = fit_tree.loc[
-                np.any(fit_tree.loc[:, ["Yes", "No"]] == leaf_index, axis=1), "Node"
-            ].values[0]
-
-            # Extract information about the decision at the parent node
-            feature = int(fit_tree.loc[fit_tree.Node == parent, "Feature"].values[0])
-
-            threshold = fit_tree.loc[fit_tree.Node == parent, "Split"].values[0]
-            is_left = (
-                fit_tree.loc[fit_tree.Node == parent, "Yes"].values[0] == leaf_index
-            )
-            missing = (
-                fit_tree.loc[fit_tree.Node == parent, "Missing"].values[0] == leaf_index
-            )
-
-            ub = threshold if is_left else np.inf
-            lb = -np.inf if is_left else threshold
-            na = missing
-
-            return_rule.add_clause(feature, ub, lb, na)
-
-            # If we reached the root of the tree, break the loop
-            if parent == 0:
-                break
-
-            # Move up the tree
-            leaf_index = parent
-
-        return return_rule
-
-    def _get_matrix(
-        self,
-        y: np.ndarray,
-        vec_y: np.ndarray,
-        fit_tree: pd.DataFrame,
-        treeno: int,
-        y_rules: np.ndarray,
-    ):
-        """
-        Populates the matrices for the optimization problem based on a single XGBoost tree.
-
-        Parameters
-        ----------
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector, suitable for the optimization problem.
-        fit_tree : pd.DataFrame
-            A single decision tree's structure from XGBoost, represented as a DataFrame.
-        treeno : int
-            The index of the current tree within the ensemble.
-        y_rules : np.ndarray
-            The array of leaf indices for each sample in the training data, determined
-            by the current tree.
-        """
-        # If the coefficients matrix is empty, start from the first column
-        if self.coefficients_.cols.shape[0] == 0:
-            col = 0
-        else:
-            # Otherwise, start from the next available column
-            col = np.max(self.coefficients_.cols) + 1
-
-        # Get the leaf node for each sample in x
-        y_rules = y_rules[:, treeno]
-
-        # Iterate over unique leaf nodes
-        for leafno in np.unique(y_rules):
-            # Get the samples in the leaf
-            covers = np.where(y_rules == leafno)[0]
-            leaf_y_vals = y[covers]  # y values of the samples in the leaf
-
-            # Get unique labels in the leaf and their counts
-            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
-
-            # Identify the majority class in the leaf
-            label = unique_labels[np.argmax(counts)]
-
-            # Create a vector for this label
-            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
-            label_vector[label] = 1
-
-            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
-            fill_ahat = np.dot(vec_y[covers, :], label_vector)
-
-            # Update the coefficients matrix with the new information
-            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
-            self.coefficients_.cols = np.concatenate(
-                (self.coefficients_.cols, [col] * covers.shape[0])
-            )
-            self.coefficients_.yvals = np.concatenate(
-                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
-            )
-
-            cost = self._get_rule_cost(
-                temp_rule=self._get_rule(fit_tree, leafno),
-                covers=covers,
-                counts=counts,
-                y=y,
-            )
-
-            # Append the cost to the costs in the coefficients matrix
-            self.coefficients_.costs = np.concatenate(
-                (self.coefficients_.costs, [cost])
-            )
-
-            # Calculate the distribution of the samples in the leaf across the classes
-            sdist = counts
-            self.rule_info_[col] = (treeno, leafno, label, sdist)
-            col += 1
-
-    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray):
-        """
-        Generates the coefficient matrices for the optimization problem from
-        all trees in the XGBoost ensemble.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            The feature matrix of the training data.
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector.
-        """
-        y_rules = self.trained_ensemble.apply(x).astype(np.intp)
-        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
-            self._get_matrix(y, vec_y, fit_tree, treeno, y_rules)
-
-    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
-        """
-        Fits the RUXXGBClassifier to the training data, optimizing
-        the extracted rules for a balance between accuracy and interpretability.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
-            The target values (class labels) as integers
-        sample_weight : array-like of shape (n_samples,), default=None
-            Sample weights. If None, then samples are equally weighted.
-
-        Returns
-        -------
-        RUXXGBClassifier
-            The fitted model, ready for making predictions.
-        """
-        x, y = check_inputs(x, y)
-
-        # If the model has been fitted before, clean it up
-        if self.coefficients_.cols.shape[0] != 0:
-            self._cleanup()
-
-        # Fills the fitted decision trees.
-        out = self.trained_ensemble.get_booster().trees_to_dataframe()
-        pattern = re.compile(r"-(\d+)")
-        columns = ["Yes", "No", "Missing"]
-        out[columns] = out[columns].map(
-            lambda x: (
-                int(pattern.search(x).group(1))
-                if pd.notna(x) and pattern.search(x)
-                else None
-            )
-        )
-        out.Feature = out.Feature.str.lstrip("f")
-        self.decision_trees_ = {
-            treeno: out.loc[out.Tree == treeno] for treeno in out.Tree.unique()
-        }
-
-        self._get_class_infos(y)
-        vec_y = self._preprocess(y)
-
-        self._get_matrices(x=x, y=y, vec_y=vec_y)
-
-        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
-
-        ws, *_ = self.solver(
-            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
-        )
-
-        self._fill_rules(ws)
-        self._is_fitted = True
-
-        return self
+from __future__ import annotations
+import re
+import numpy as np
+import pandas as pd
+from numpy.typing import ArrayLike
+
+from .base import _RUGBASE
+from ..aux_classes import Rule
+from ..rule_cost import Gini
+from ..utils import check_module_available, check_inputs
+
+
+XGBOOST_AVAILABLE = check_module_available("xgboost")
+
+
+class RUXXGBClassifier(_RUGBASE):
+    """
+    A classifier that extracts and optimizes decision rules from a trained
+    XGBoost ensemble model to create a compact and interpretable model.
+    This process involves translating the ensemble's trees into a set of rules and
+    using optimization to balance model accuracy and interpretability. The complexity
+    of the resulting rule-based model is  controlled through a penalty parameter.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not XGBOOST_AVAILABLE:
+            raise ImportError(
+                "XGBoost is required for this class but is not installed.",
+                "Please install it with 'pip install xgboost'",
+            )
+        instance = super(RUXXGBClassifier, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        trained_ensemble,
+        solver,
+        *,
+        rule_cost=Gini(),
+        class_weight: dict | str | None = None,
+        threshold: float = 1.0e-6,
+        random_state: int | None = None,
+    ):
+        """
+        Parameters
+        ----------
+        trained_ensemble : xgboost.XGBClassifier
+            The trained XGBoost ensemble model from which rules will be extracted.
+            The model should already be trained on the dataset.
+
+        solver : OptimizationSolver
+            An instance of a derived class inherits from the 'Optimization Solver' base class.
+            The solver is responsible for optimizing the rule set based on the cost function
+            and constraints.
+
+        rule_cost : RuleCost or int, default=Gini()
+            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+            or a fixed cost
+
+        class_weight: dict, "balanced" or None, default=None
+            A dictionary mapping class labels to their respective weights, the string "balanced"
+            to automatically adjust weights inversely proportional to class frequencies,
+            or None for no weights. Used to adjust the model in favor of certain classes.
+
+        threshold : float, default=1.0e-6
+            The minimum weight threshold for including a rule in the final model
+
+        random_state : int or None, default=None
+            Seed for the random number generator to ensure reproducible results.
+            Defaults to None.
+        """
+        ### LAZY IMPORT
+        from xgboost import Booster
+
+        if not isinstance(trained_ensemble, Booster):
+            if hasattr(trained_ensemble, "get_booster"):
+                if not isinstance(trained_ensemble.get_booster(), Booster):
+                    raise TypeError(
+                        "trained_ensemble is not an instance of XGBClassifier."
+                    )
+                else:
+                    self.trained_ensemble = trained_ensemble
+            else:
+                raise TypeError("trained_ensemble is not an instance of XGBoost")
+        else:
+            raise TypeError(
+                "XGBoost Booster instance not supported yet. Use XGBClassifier."
+            )
+
+        super().__init__(
+            threshold=threshold,
+            random_state=random_state,
+            rule_cost=rule_cost,
+            solver=solver,
+            class_weight=class_weight,
+        )
+
+    def _get_rule(self, fit_tree: pd.DataFrame, leaf_index: int) -> Rule:
+        """
+        Extracts a decision rule leading to a specified leaf node from an XGBoost tree.
+
+        Parameters
+        ----------
+        fit_tree : pd.DataFrame
+            The decision trees represented as a DataFrame extracted from the trained XGBoost model.
+        leaf_index : int
+            The ID of the leaf node for which to construct the decision rule.
+
+        Returns
+        -------
+        Rule
+            An object representing the decision rule leading to the specified leaf node,
+            composed of clauses that define the decision path.
+        """
+        # Initialize the rule
+        return_rule = Rule()
+
+        if fit_tree.shape[0] <= 1:
+            return return_rule
+
+        while True:
+            # Find the parent node of the current leaf
+            parent = fit_tree.loc[
+                np.any(fit_tree.loc[:, ["Yes", "No"]] == leaf_index, axis=1), "Node"
+            ].values[0]
+
+            # Extract information about the decision at the parent node
+            feature = int(fit_tree.loc[fit_tree.Node == parent, "Feature"].values[0])
+
+            threshold = fit_tree.loc[fit_tree.Node == parent, "Split"].values[0]
+            is_left = (
+                fit_tree.loc[fit_tree.Node == parent, "Yes"].values[0] == leaf_index
+            )
+            missing = (
+                fit_tree.loc[fit_tree.Node == parent, "Missing"].values[0] == leaf_index
+            )
+
+            ub = threshold if is_left else np.inf
+            lb = -np.inf if is_left else threshold
+            na = missing
+
+            return_rule.add_clause(feature, ub, lb, na)
+
+            # If we reached the root of the tree, break the loop
+            if parent == 0:
+                break
+
+            # Move up the tree
+            leaf_index = parent
+
+        return return_rule
+
+    def _get_matrix(
+        self,
+        y: np.ndarray,
+        vec_y: np.ndarray,
+        fit_tree: pd.DataFrame,
+        treeno: int,
+        y_rules: np.ndarray,
+    ):
+        """
+        Populates the matrices for the optimization problem based on a single XGBoost tree.
+
+        Parameters
+        ----------
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector, suitable for the optimization problem.
+        fit_tree : pd.DataFrame
+            A single decision tree's structure from XGBoost, represented as a DataFrame.
+        treeno : int
+            The index of the current tree within the ensemble.
+        y_rules : np.ndarray
+            The array of leaf indices for each sample in the training data, determined
+            by the current tree.
+        """
+        # If the coefficients matrix is empty, start from the first column
+        if self.coefficients_.cols.shape[0] == 0:
+            col = 0
+        else:
+            # Otherwise, start from the next available column
+            col = np.max(self.coefficients_.cols) + 1
+
+        # Get the leaf node for each sample in x
+        y_rules = y_rules[:, treeno]
+
+        # Iterate over unique leaf nodes
+        for leafno in np.unique(y_rules):
+            # Get the samples in the leaf
+            covers = np.where(y_rules == leafno)[0]
+            leaf_y_vals = y[covers]  # y values of the samples in the leaf
+
+            # Get unique labels in the leaf and their counts
+            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
+
+            # Identify the majority class in the leaf
+            label = unique_labels[np.argmax(counts)]
+
+            # Create a vector for this label
+            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
+            label_vector[label] = 1
+
+            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
+            fill_ahat = np.dot(vec_y[covers, :], label_vector)
+
+            # Update the coefficients matrix with the new information
+            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
+            self.coefficients_.cols = np.concatenate(
+                (self.coefficients_.cols, [col] * covers.shape[0])
+            )
+            self.coefficients_.yvals = np.concatenate(
+                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
+            )
+
+            cost = self._get_rule_cost(
+                temp_rule=self._get_rule(fit_tree, leafno),
+                covers=covers,
+                counts=counts,
+                y=y,
+            )
+
+            # Append the cost to the costs in the coefficients matrix
+            self.coefficients_.costs = np.concatenate(
+                (self.coefficients_.costs, [cost])
+            )
+
+            # Calculate the distribution of the samples in the leaf across the classes
+            sdist = counts
+            self.rule_info_[col] = (treeno, leafno, label, sdist)
+            col += 1
+
+    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray):
+        """
+        Generates the coefficient matrices for the optimization problem from
+        all trees in the XGBoost ensemble.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            The feature matrix of the training data.
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector.
+        """
+        y_rules = self.trained_ensemble.apply(x).astype(np.intp)
+        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
+            self._get_matrix(y, vec_y, fit_tree, treeno, y_rules)
+
+    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
+        """
+        Fits the RUXXGBClassifier to the training data, optimizing
+        the extracted rules for a balance between accuracy and interpretability.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
+            The target values (class labels) as integers
+        sample_weight : array-like of shape (n_samples,), default=None
+            Sample weights. If None, then samples are equally weighted.
+
+        Returns
+        -------
+        RUXXGBClassifier
+            The fitted model, ready for making predictions.
+        """
+        x, y = check_inputs(x, y)
+
+        # If the model has been fitted before, clean it up
+        if self.coefficients_.cols.shape[0] != 0:
+            self._cleanup()
+
+        # Fills the fitted decision trees.
+        out = self.trained_ensemble.get_booster().trees_to_dataframe()
+        pattern = re.compile(r"-(\d+)")
+        columns = ["Yes", "No", "Missing"]
+        out[columns] = out[columns].map(
+            lambda x: (
+                int(pattern.search(x).group(1))
+                if pd.notna(x) and pattern.search(x)
+                else None
+            )
+        )
+        out.Feature = out.Feature.str.lstrip("f")
+        self.decision_trees_ = {
+            treeno: out.loc[out.Tree == treeno] for treeno in out.Tree.unique()
+        }
+
+        self._get_class_infos(y)
+        vec_y = self._preprocess(y)
+
+        self._get_matrices(x=x, y=y, vec_y=vec_y)
+
+        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
+
+        ws, *_ = self.solver(
+            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
+        )
+
+        self._fill_rules(ws)
+        self._is_fitted = True
+
+        return self
```

## ruleopt/estimator/sklearn_/__init__.py

 * *Ordering differences only*

```diff
@@ -1,7 +1,7 @@
-from .rug import RUGClassifier
-from .rux import RUXClassifier
-
-__all__ = [
-    "RUGClassifier",
-    "RUXClassifier",
-]
+from .rug import RUGClassifier
+from .rux import RUXClassifier
+
+__all__ = [
+    "RUGClassifier",
+    "RUXClassifier",
+]
```

## ruleopt/estimator/sklearn_/base_sklearn.py

 * *Ordering differences only*

```diff
@@ -1,192 +1,192 @@
-from typing import Union, Dict
-from sklearn.tree import DecisionTreeClassifier
-import numpy as np
-from ..base import _RUGBASE
-from ...aux_classes import Rule
-from ...rule_cost import RuleCost
-from ...solver.base import OptimizationSolver
-
-
-class _RUGSKLEARN(_RUGBASE):
-    """
-    The base class specialized for use with scikit-learn.
-
-    This subclass implements the rule extraction process specifically for decision trees
-    trained using scikit-learn.
-    """
-
-    def __init__(
-        self,
-        solver,
-        rule_cost,
-        class_weight,
-        threshold,
-        random_state,
-    ):
-        """
-        Parameters
-        ----------
-        solver : OptimizationSolver
-            An instance of a derived class inherits from the 'Optimization Solver' base class.
-            The solver is responsible for optimizing the rule set based on the cost function
-            and constraints.
-
-        rule_cost : RuleCost or int
-            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-            or a fixed cost
-
-        class_weight: dict, "balanced" or None
-            A dictionary mapping class labels to their respective weights, the string "balanced"
-            to automatically adjust weights inversely proportional to class frequencies,
-            or None for no weights. Used to adjust the model in favor of certain classes.
-
-        threshold : floa
-            The minimum weight threshold for including a rule in the final model
-
-        random_state : int or None
-            Seed for the random number generator to ensure reproducible results.
-            Defaults to None.
-        """
-        super().__init__(
-            threshold=threshold,
-            random_state=random_state,
-            rule_cost=rule_cost,
-            solver=solver,
-            class_weight=class_weight,
-        )
-
-    def _get_rule(self, fit_tree: DecisionTreeClassifier, nodeid: int) -> Rule:
-        """
-        Constructs a rule from a given node in a decision tree.
-
-        Parameters
-        ----------
-        fit_tree : DecisionTreeClassifier
-            The fitted decision tree from which to extract the rule.
-        nodeid : int
-            The ID of the node from which the rule is to be extracted.
-
-        Returns
-        -------
-        Rule
-            An object representing the extracted rule.
-        """
-
-        # Initializing the rule to be returned
-        return_rule = Rule()
-
-        # If the first feature of the tree is -2, the rule is empty
-        if fit_tree.tree_.feature[0] == -2:
-            return Rule()
-
-        # Extracting information from the tree
-        tree = fit_tree.tree_
-        left = tree.children_left
-        right = tree.children_right
-        threshold = tree.threshold
-        missing_left = tree.missing_go_to_left
-
-        # Building dictionaries to hold node information
-        node_info = {
-            node_id: (parent, True, bool(missing_left[parent]))
-            for parent, node_id in enumerate(left)
-        }
-        node_info.update(
-            {
-                node_id: (parent, False, not bool(missing_left[parent]))
-                for parent, node_id in enumerate(right)
-            }
-        )
-
-        # Traversing up the tree to build the rule
-        while nodeid != 0:
-            parent, is_left, missing = node_info[nodeid]
-
-            feature = tree.feature[parent]
-            ub = threshold[parent] if is_left else np.inf
-            lb = -np.inf if is_left else threshold[parent]
-            na = missing
-
-            return_rule.add_clause(feature, ub, lb, na)
-            nodeid = parent
-
-        return return_rule
-
-    def _get_matrix(
-        self,
-        x: np.ndarray,
-        y: np.ndarray,
-        vec_y: np.ndarray,
-        fit_tree: DecisionTreeClassifier,
-        treeno: int,
-    ) -> None:
-        """
-        Generates matrices for optimization based on a decision tree and training data.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            The feature matrix of the training data.
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector, adjusted for optimization.
-        fit_tree : DecisionTreeClassifier
-            A fitted decision tree model from which to extract rules.
-        treeno : int
-            An identifier for the decision tree within an ensemble.
-        """
-        # If the coefficients matrix is empty, start from the first column
-        if self.coefficients_.cols.shape[0] == 0:
-            col = 0
-        else:
-            # Otherwise, start from the next available column
-            col = np.max(self.coefficients_.cols) + 1
-
-        # Get the leaf node for each sample in x
-        y_rules = fit_tree.apply(x)
-
-        # Iterate over unique leaf nodes
-        for leafno in np.unique(y_rules):
-            # Get the samples in the leaf
-            covers = np.where(y_rules == leafno)[0]
-            leaf_y_vals = y[covers]  # y values of the samples in the leaf
-
-            # Get unique labels in the leaf and their counts
-            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
-
-            # Identify the majority class in the leaf
-            label = unique_labels[np.argmax(counts)]
-
-            # Create a vector for this label
-            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
-            label_vector[label] = 1
-
-            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
-            fill_ahat = np.dot(vec_y[covers, :], label_vector)
-
-            # Update the coefficients matrix with the new information
-            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
-            self.coefficients_.cols = np.concatenate(
-                (self.coefficients_.cols, [col] * covers.shape[0])
-            )
-            self.coefficients_.yvals = np.concatenate(
-                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
-            )
-
-            cost = self._get_rule_cost(
-                temp_rule=self._get_rule(fit_tree, leafno),
-                covers=covers,
-                counts=counts,
-                y=y,
-            )
-
-            # Append the cost to the costs in the coefficients matrix
-            self.coefficients_.costs = np.concatenate(
-                (self.coefficients_.costs, [cost])
-            )
-
-            # Calculate the distribution of the samples in the leaf across the classes
-            sdist = counts
-            self.rule_info_[col] = (treeno, leafno, label, sdist)
-            col += 1
+from typing import Union, Dict
+from sklearn.tree import DecisionTreeClassifier
+import numpy as np
+from ..base import _RUGBASE
+from ...aux_classes import Rule
+from ...rule_cost import RuleCost
+from ...solver.base import OptimizationSolver
+
+
+class _RUGSKLEARN(_RUGBASE):
+    """
+    The base class specialized for use with scikit-learn.
+
+    This subclass implements the rule extraction process specifically for decision trees
+    trained using scikit-learn.
+    """
+
+    def __init__(
+        self,
+        solver,
+        rule_cost,
+        class_weight,
+        threshold,
+        random_state,
+    ):
+        """
+        Parameters
+        ----------
+        solver : OptimizationSolver
+            An instance of a derived class inherits from the 'Optimization Solver' base class.
+            The solver is responsible for optimizing the rule set based on the cost function
+            and constraints.
+
+        rule_cost : RuleCost or int
+            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+            or a fixed cost
+
+        class_weight: dict, "balanced" or None
+            A dictionary mapping class labels to their respective weights, the string "balanced"
+            to automatically adjust weights inversely proportional to class frequencies,
+            or None for no weights. Used to adjust the model in favor of certain classes.
+
+        threshold : floa
+            The minimum weight threshold for including a rule in the final model
+
+        random_state : int or None
+            Seed for the random number generator to ensure reproducible results.
+            Defaults to None.
+        """
+        super().__init__(
+            threshold=threshold,
+            random_state=random_state,
+            rule_cost=rule_cost,
+            solver=solver,
+            class_weight=class_weight,
+        )
+
+    def _get_rule(self, fit_tree: DecisionTreeClassifier, nodeid: int) -> Rule:
+        """
+        Constructs a rule from a given node in a decision tree.
+
+        Parameters
+        ----------
+        fit_tree : DecisionTreeClassifier
+            The fitted decision tree from which to extract the rule.
+        nodeid : int
+            The ID of the node from which the rule is to be extracted.
+
+        Returns
+        -------
+        Rule
+            An object representing the extracted rule.
+        """
+
+        # Initializing the rule to be returned
+        return_rule = Rule()
+
+        # If the first feature of the tree is -2, the rule is empty
+        if fit_tree.tree_.feature[0] == -2:
+            return Rule()
+
+        # Extracting information from the tree
+        tree = fit_tree.tree_
+        left = tree.children_left
+        right = tree.children_right
+        threshold = tree.threshold
+        missing_left = tree.missing_go_to_left
+
+        # Building dictionaries to hold node information
+        node_info = {
+            node_id: (parent, True, bool(missing_left[parent]))
+            for parent, node_id in enumerate(left)
+        }
+        node_info.update(
+            {
+                node_id: (parent, False, not bool(missing_left[parent]))
+                for parent, node_id in enumerate(right)
+            }
+        )
+
+        # Traversing up the tree to build the rule
+        while nodeid != 0:
+            parent, is_left, missing = node_info[nodeid]
+
+            feature = tree.feature[parent]
+            ub = threshold[parent] if is_left else np.inf
+            lb = -np.inf if is_left else threshold[parent]
+            na = missing
+
+            return_rule.add_clause(feature, ub, lb, na)
+            nodeid = parent
+
+        return return_rule
+
+    def _get_matrix(
+        self,
+        x: np.ndarray,
+        y: np.ndarray,
+        vec_y: np.ndarray,
+        fit_tree: DecisionTreeClassifier,
+        treeno: int,
+    ) -> None:
+        """
+        Generates matrices for optimization based on a decision tree and training data.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            The feature matrix of the training data.
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector, adjusted for optimization.
+        fit_tree : DecisionTreeClassifier
+            A fitted decision tree model from which to extract rules.
+        treeno : int
+            An identifier for the decision tree within an ensemble.
+        """
+        # If the coefficients matrix is empty, start from the first column
+        if self.coefficients_.cols.shape[0] == 0:
+            col = 0
+        else:
+            # Otherwise, start from the next available column
+            col = np.max(self.coefficients_.cols) + 1
+
+        # Get the leaf node for each sample in x
+        y_rules = fit_tree.apply(x)
+
+        # Iterate over unique leaf nodes
+        for leafno in np.unique(y_rules):
+            # Get the samples in the leaf
+            covers = np.where(y_rules == leafno)[0]
+            leaf_y_vals = y[covers]  # y values of the samples in the leaf
+
+            # Get unique labels in the leaf and their counts
+            unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
+
+            # Identify the majority class in the leaf
+            label = unique_labels[np.argmax(counts)]
+
+            # Create a vector for this label
+            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
+            label_vector[label] = 1
+
+            # Calculate fill_ahat, which will be used to update yvals in the coefficients matrix
+            fill_ahat = np.dot(vec_y[covers, :], label_vector)
+
+            # Update the coefficients matrix with the new information
+            self.coefficients_.rows = np.concatenate((self.coefficients_.rows, covers))
+            self.coefficients_.cols = np.concatenate(
+                (self.coefficients_.cols, [col] * covers.shape[0])
+            )
+            self.coefficients_.yvals = np.concatenate(
+                (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
+            )
+
+            cost = self._get_rule_cost(
+                temp_rule=self._get_rule(fit_tree, leafno),
+                covers=covers,
+                counts=counts,
+                y=y,
+            )
+
+            # Append the cost to the costs in the coefficients matrix
+            self.coefficients_.costs = np.concatenate(
+                (self.coefficients_.costs, [cost])
+            )
+
+            # Calculate the distribution of the samples in the leaf across the classes
+            sdist = counts
+            self.rule_info_[col] = (treeno, leafno, label, sdist)
+            col += 1
```

## ruleopt/estimator/sklearn_/rug.py

 * *Ordering differences only*

```diff
@@ -1,548 +1,548 @@
-from __future__ import annotations
-import warnings
-
-import numpy as np
-from numpy.typing import ArrayLike
-from sklearn.tree import DecisionTreeClassifier
-
-from .base_sklearn import _RUGSKLEARN
-from ...rule_cost import Gini
-from ...utils import check_inputs
-
-
-class RUGClassifier(_RUGSKLEARN):
-    """
-    Rule Generation algorithm for multi-class classification. This algorithm aims at
-    producing a compact and interpretable model by employing optimization-bsed rule learning.
-    """
-
-    def __init__(
-        self,
-        solver,
-        *,
-        rule_cost=Gini(),
-        max_rmp_calls=20,
-        threshold: float = 1.0e-6,
-        random_state: int | None = None,
-        class_weight: dict | str | None = None,
-        criterion: str = "gini",
-        splitter: str = "best",
-        max_depth: int | None = None,
-        min_samples_split: int = 2,
-        min_samples_leaf: int = 1,
-        min_weight_fraction_leaf: float = 0.0,
-        max_features: int | float | str = None,
-        max_leaf_nodes: int | None = None,
-        min_impurity_decrease: float = 0.0,
-        ccp_alpha: float = 0.0,
-        monotonic_cst: ArrayLike | None = None,
-    ):
-        """
-        Parameters
-        ----------
-        solver : OptimizationSolver
-            An instance of a derived class inherits from the 'Optimization Solver' base class.
-            The solver is responsible for optimizing the rule set based on the cost function
-            and constraints.
-            
-        rule_cost : RuleCost or int, default=Gini()
-            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-            or a fixed cost
-
-        max_rmp_calls : int, default=20
-            Maximum number of Restricted Master Problem (RMP) iterations allowed during fitting.
-            
-        class_weight: dict, "balanced" or None, default=None
-            A dictionary mapping class labels to their respective weights, the string "balanced"
-            to automatically adjust weights inversely proportional to class frequencies,
-            or None for no weights. Used to adjust the model in favor of certain classes.
-            
-        threshold : float, default=1.0e-6
-            The minimum weight threshold for including a rule in the final model.
-            
-        random_state : int or None, default=None
-            Seed for the random number generator to ensure reproducible results.
-            Defaults to None.
-            
-        criterion : {"gini", "entropy", "log_loss"}, default="gini"
-            The function to measure the quality of a split. Supported criteria are
-            "gini" for the Gini impurity and "log_loss" and "entropy" both for the
-            Shannon information gain, see :ref:`tree_mathematical_formulation`.
-
-        splitter : {"best", "random"}, default="best"
-            The strategy used to choose the split at each node. Supported
-            strategies are "best" to choose the best split and "random" to choose
-            the best random split.
-
-        max_depth : int, default=None
-            The maximum depth of the tree. If None, then nodes are expanded until
-            all leaves are pure or until all leaves contain less than
-            min_samples_split samples.
-
-        min_samples_split : int or float, default=2
-            The minimum number of samples required to split an internal node:
-
-        min_samples_leaf : int or float, default=1
-            The minimum number of samples required to be at a leaf node.
-            A split point at any depth will only be considered if it leaves at
-            least ``min_samples_leaf`` training samples in each of the left and
-            right branches.  This may have the effect of smoothing the model,
-            especially in regression.
-
-        min_weight_fraction_leaf : float, default=0.0
-            The minimum weighted fraction of the sum total of weights (of all
-            the input samples) required to be at a leaf node. Samples have
-            equal weight when sample_weight is not provided.
-
-        max_features : int, float or {"sqrt", "log2"}, default=None
-            The number of features to consider when looking for the best split:
-
-        max_leaf_nodes : int, default=None
-            Grow a tree with ``max_leaf_nodes`` in best-first fashion.
-            Best nodes are defined as relative reduction in impurity.
-            If None then unlimited number of leaf nodes.
-
-        min_impurity_decrease : float, default=0.0
-            A node will be split if this split induces a decrease of the impurity
-            greater than or equal to this value.
-
-        ccp_alpha : non-negative float, default=0.0
-            Complexity parameter used for Minimal Cost-Complexity Pruning. The
-            subtree with the largest cost complexity that is smaller than
-            ``ccp_alpha`` will be chosen. By default, no pruning is performed.
-
-        monotonic_cst : array-like of int of shape (n_features), default=None
-            Indicates the monotonicity constraint to enforce on each feature.
-            - 1: monotonic increase
-            - 0: no constraint
-            - -1: monotonic decrease
-        """
-
-        if hasattr(solver, "max_rule"):
-            if getattr(solver, "max_rule") is not None:
-                warnings.warn(
-                    "The 'max_rule' attribute is available only for RUX classifiers. "
-                    "It has been automatically set to 'None' for the current solver."
-                )
-                solver.max_rule = None
-
-        self._validate_parameters(
-            max_rmp_calls,
-            class_weight,
-            criterion,
-            splitter,
-            max_depth,
-            min_samples_split,
-            min_samples_leaf,
-            min_weight_fraction_leaf,
-            max_features,
-            max_leaf_nodes,
-            min_impurity_decrease,
-            ccp_alpha,
-            monotonic_cst,
-        )
-
-        super().__init__(
-            threshold=threshold,
-            random_state=random_state,
-            solver=solver,
-            rule_cost=rule_cost,
-            class_weight=class_weight,
-        )
-
-        self.max_rmp_calls = int(max_rmp_calls)
-
-        self.criterion = criterion
-        self.splitter = splitter
-        self.max_depth = max_depth
-        self.min_samples_split = min_samples_split
-        self.min_samples_leaf = min_samples_leaf
-        self.min_weight_fraction_leaf = min_weight_fraction_leaf
-        self.max_features = max_features
-        self.max_leaf_nodes = max_leaf_nodes
-        self.min_impurity_decrease = min_impurity_decrease
-        self.ccp_alpha = ccp_alpha
-        self.monotonic_cst = monotonic_cst
-
-    def _pspdt(
-        self,
-        x: np.ndarray,
-        y: np.ndarray,
-        vec_y: np.ndarray,
-        fit_tree: DecisionTreeClassifier,
-        treeno: int,
-        betas: np.ndarray,
-    ) -> bool:
-        """
-        Pricing SubProblem for Decision Trees (PSPDT) in the rule generation process.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            Feature matrix of the training data.
-        y : np.ndarray
-            Target vector of the training data.
-        vec_y : np.ndarray
-            Preprocessed target vector, adjusted for optimization.
-        fit_tree : DecisionTreeClassifier
-            Fitted decision tree for rule extraction.
-        treeno : int
-            Identifier for the current tree in the iterative process.
-        betas : np.ndarray
-            Dual variables or sample weights from the latest master problem solution.
-
-        Returns
-        -------
-        bool
-            Indicates whether a new rule that improves the objective function was found.
-        """
-        no_improvement = True
-
-        n, col = x.shape[0], np.max(self.coefficients_.cols) + 1
-
-        # Apply the decision tree to the feature matrix
-        y_rules = fit_tree.apply(x)
-
-        for leafno in np.unique(y_rules):
-            # Get the samples that fall into this leaf
-            covers = np.where(y_rules == leafno)[0]
-            leaf_y_vals = y[covers]  # y values of the samples in the leaf
-
-            # Get the unique labels in the leaf and their counts
-            unique_labels = np.arange(self.k_, dtype=np.intp)
-            counts = np.zeros(self.k_, dtype=np.intp)
-            unique_labels_, counts_ = np.unique(leaf_y_vals, return_counts=True)
-            for i, j in enumerate(unique_labels_):
-                unique_labels[j] = unique_labels_[i]
-                counts[j] = counts_[i]
-
-            # Identify the majority class in the leaf
-            label = unique_labels_[np.argmax(counts_)]  # majority class in the leaf
-
-            # Create a vector for this label
-            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
-            label_vector[label] = 1
-
-            # Calculate the y values for the optimization problem
-            fill_ahat = np.dot(vec_y[covers, :], label_vector)
-
-            # Prepare to check the reduced cost
-            aijhat = np.zeros(n)
-            aijhat[covers] = fill_ahat
-
-            cost = self._get_rule_cost(
-                temp_rule=self._get_rule(fit_tree, leafno),
-                covers=covers,
-                counts=counts,
-                y=y,
-            )
-
-            # Calculate the reduced cost
-            red_cost = np.dot(
-                np.multiply(((self.k_ - 1.0) / self.k_), aijhat), betas
-            ) - (cost * self.solver.penalty)
-
-            # If the reduced cost is positive, update the coefficients
-            if red_cost > 0:  # only columns with proper reduced costs are added
-                covers_fill = np.full((covers.shape[0],), fill_ahat, dtype=np.intp)
-                covers_col = np.full((covers.shape[0],), col, dtype=np.intp)
-                self.coefficients_.rows = np.concatenate(
-                    (self.coefficients_.rows, covers)
-                )
-                self.coefficients_.cols = np.concatenate(
-                    (self.coefficients_.cols, covers_col)
-                )
-                self.coefficients_.yvals = np.concatenate(
-                    (self.coefficients_.yvals, covers_fill)
-                )
-                self.coefficients_.costs = np.concatenate(
-                    (self.coefficients_.costs, [cost])
-                )
-
-                # Calculate the distribution of the samples in the leaf across the classes
-                sdist = np.zeros(self.k_, dtype=np.intp)
-                sdist[unique_labels] = counts
-                self.rule_info_[col] = (treeno, leafno, label, sdist)
-                col += 1
-                no_improvement = False
-
-        # Return whether there was any improvement
-        return no_improvement
-
-    def _fit_decision_tree(
-        self, x: np.ndarray, y: np.ndarray, sample_weight: np.ndarray
-    ) -> DecisionTreeClassifier:
-        """
-        Fits a decision tree to the data, taking into account sample weights.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            Feature matrix of the training data.
-        y : np.ndarray
-            Target vector of the training data.
-        sample_weight : np.ndarray
-            Array of weights for the samples.
-
-        Returns
-        -------
-        DecisionTreeClassifier
-            A decision tree classifier fitted to the weighted data.
-        """
-        dt = DecisionTreeClassifier(
-            random_state=self._rng.integers(np.iinfo(np.int16).max),
-            criterion=self.criterion,
-            splitter=self.splitter,
-            class_weight=self.class_weight,
-            max_depth=self.max_depth,
-            min_samples_split=self.min_samples_split,
-            min_samples_leaf=self.min_samples_leaf,
-            min_weight_fraction_leaf=self.min_weight_fraction_leaf,
-            max_features=self.max_features,
-            max_leaf_nodes=self.max_leaf_nodes,
-            min_impurity_decrease=self.min_impurity_decrease,
-            ccp_alpha=self.ccp_alpha,
-            monotonic_cst=self.monotonic_cst,
-        )
-
-        if sample_weight is not None:
-            dt.class_weight = None
-
-        # Fit the decision tree to the data
-        return dt.fit(x, y, sample_weight=sample_weight)
-
-    def _fill_ahat(
-        self,
-        x: np.ndarray,
-        y: np.ndarray,
-        vec_y: np.ndarray,
-        fit_tree_: DecisionTreeClassifier = None,
-        treeno_: int = None,
-    ):
-        """
-        Updates the optimization problem's coefficients based on the rules from a decision tree.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            Feature matrix of the training data.
-        y : np.ndarray
-            Target vector of the training data.
-        vec_y : np.ndarray
-            Preprocessed target vector, adjusted for optimization.
-        fit_tree : DecisionTreeClassifier, optional
-            A decision tree from which to extract rules.
-        treeno : int, optional
-            Identifier for the decision tree within a sequence of generated trees.
-        """
-        # Initialize coefficients for the next batch.
-        self.coefficients_.cleanup()
-
-        # If there are existing rules, process them to fill the coefficient matrix
-        if len(self.rule_info_) > 0:
-            for col, (treeno, leafno, label, _) in self.rule_info_.items():
-                # Retrieve the decision tree corresponding to the current rule
-                fit_tree = self.decision_trees_[treeno]
-
-                # Apply the decision tree to the feature matrix to get the leaf indices
-                # for each sample
-                y_rules = fit_tree.apply(x)
-
-                # Identify the samples that fall into the current leaf
-                covers = np.where(y_rules == leafno)[0]
-                leaf_y_vals = y[covers]
-
-                # Compute the unique labels in the leaf and their counts
-                unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
-
-                # Determine the majority class label in the leaf
-                label = unique_labels[np.argmax(counts)]
-
-                # Create a vector representation of this label
-                label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
-                label_vector[label] = 1
-
-                fill_ahat = np.dot(vec_y[covers, :], label_vector)
-
-                self.coefficients_.rows = np.concatenate(
-                    (self.coefficients_.rows, covers)
-                )
-                self.coefficients_.cols = np.concatenate(
-                    (self.coefficients_.cols, [col] * covers.shape[0])
-                )
-                self.coefficients_.yvals = np.concatenate(
-                    (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
-                )
-
-                cost = self._get_rule_cost(
-                    temp_rule=self._get_rule(fit_tree, leafno),
-                    covers=covers,
-                    counts=counts,
-                    y=y,
-                )
-
-                self.coefficients_.costs = np.concatenate(
-                    (self.coefficients_.costs, [cost])
-                )
-
-        # If a specific decision tree is provided, update the coefficient matrix based on this tree
-        if fit_tree_:
-            self._get_matrix(x, y, vec_y, fit_tree_, treeno_)
-
-    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
-        """
-        Fits the RUGClassifier model to the training data using a rule generation approach.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
-            The target values (class labels) as integers
-        sample_weight : array-like of shape (n_samples,), default=None
-            Sample weights. If None, then samples are equally weighted.
-
-        Returns
-        -------
-        RUGClassifier
-            The fitted model, ready for making predictions.
-        """
-        x, y = check_inputs(x, y)
-        if self._is_fitted:
-            self._cleanup()
-
-        treeno = 0
-        fit_tree = self._fit_decision_tree(x, y, sample_weight=None)
-        self.decision_trees_[treeno] = fit_tree
-
-        self._get_class_infos(y)
-        vec_y = self._preprocess(y)
-        self._get_matrix(x, y, vec_y, fit_tree, treeno)
-
-        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
-
-        ws, betas = self.solver(
-            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
-        )
-
-        # Rule generation
-        for _ in range(self.max_rmp_calls):
-            if np.all(betas == 0):
-                break
-
-            treeno += 1
-            fit_tree = self._fit_decision_tree(x, y, sample_weight=betas)
-            self.decision_trees_[treeno] = fit_tree
-
-            no_improvement = self._pspdt(x, y, vec_y, fit_tree, treeno, betas)
-
-            if no_improvement:
-                break
-
-            ws, betas = self.solver(
-                coefficients=self.coefficients_,
-                k=self.k_,
-                ws0=ws.copy(),
-                sample_weight=sample_weight,
-            )
-
-        self._fill_rules(ws)
-        self._is_fitted = True
-
-        return self
-
-    def _validate_parameters(
-        self,
-        max_rmp_calls,
-        class_weight,
-        criterion,
-        splitter,
-        max_depth,
-        min_samples_split,
-        min_samples_leaf,
-        min_weight_fraction_leaf,
-        max_features,
-        max_leaf_nodes,
-        min_impurity_decrease,
-        ccp_alpha,
-        monotonic_cst,
-    ):
-        # max_rmp_calls check
-        if not isinstance(max_rmp_calls, (float, int)):
-            raise TypeError("max_rmp_calls must be an integer.")
-
-        if max_rmp_calls < 0:
-            raise ValueError("max_rmp_calls must be a non-negative integer.")
-
-        # class_weight check
-        if not isinstance(class_weight, (dict, str, type(None))) or (
-            isinstance(class_weight, str) and class_weight != "balanced"
-        ):
-            raise ValueError("class_weight must be a dictionary, 'balanced', or None.")
-
-        # criterion check
-        if criterion not in {"gini", "entropy", "log_loss"}:
-            raise ValueError(
-                "criterion must be one of 'gini', 'entropy', or 'log_loss'."
-            )
-
-        # splitter check
-        if splitter not in {"best", "random"}:
-            raise ValueError("splitter must be 'best' or 'random'.")
-
-        # max_depth check
-        if max_depth is not None and not isinstance(max_depth, int):
-            raise TypeError("max_depth must be an integer or None.")
-        if isinstance(max_depth, int) and max_depth < 1:
-            raise ValueError("max_depth must be greater than 0.")
-
-        # min_samples_split check
-        if not isinstance(min_samples_split, (int, float)) or min_samples_split < 2:
-            raise ValueError(
-                "min_samples_split must be an integer or float greater than or equal to 2."
-            )
-
-        # min_samples_leaf check
-        if not isinstance(min_samples_leaf, (int, float)) or min_samples_leaf < 1:
-            raise ValueError(
-                "min_samples_leaf must be an integer or float greater than or equal to 1."
-            )
-
-        # min_weight_fraction_leaf check
-        if not isinstance(min_weight_fraction_leaf, float) or not (
-            0.0 <= min_weight_fraction_leaf <= 1.0
-        ):
-            raise ValueError(
-                "min_weight_fraction_leaf must be a float between 0.0 and 1.0."
-            )
-
-        # max_features check
-        if (
-            max_features is not None
-            and not isinstance(max_features, (int, float, str))
-            or (isinstance(max_features, str) and max_features not in {"sqrt", "log2"})
-        ):
-            raise ValueError(
-                "max_features must be an integer, float, 'sqrt', 'log2', or None."
-            )
-
-        # max_leaf_nodes check
-        if max_leaf_nodes is not None and (
-            not isinstance(max_leaf_nodes, int) or max_leaf_nodes < 1
-        ):
-            raise ValueError("max_leaf_nodes must be a positive integer or None.")
-
-        # min_impurity_decrease check
-        if not isinstance(min_impurity_decrease, float) or min_impurity_decrease < 0.0:
-            raise ValueError("min_impurity_decrease must be a non-negative float.")
-
-        # ccp_alpha check
-        if not isinstance(ccp_alpha, float) or ccp_alpha < 0.0:
-            raise ValueError("ccp_alpha must be a non-negative float.")
-
-        # monotonic_cst check
-        if monotonic_cst is not None and (
-            not isinstance(monotonic_cst, (list, tuple))
-            or not all(isinstance(item, int) for item in monotonic_cst)
-        ):
-            raise ValueError("monotonic_cst must be an array-like of integers or None.")
+from __future__ import annotations
+import warnings
+
+import numpy as np
+from numpy.typing import ArrayLike
+from sklearn.tree import DecisionTreeClassifier
+
+from .base_sklearn import _RUGSKLEARN
+from ...rule_cost import Gini
+from ...utils import check_inputs
+
+
+class RUGClassifier(_RUGSKLEARN):
+    """
+    Rule Generation algorithm for multi-class classification. This algorithm aims at
+    producing a compact and interpretable model by employing optimization-bsed rule learning.
+    """
+
+    def __init__(
+        self,
+        solver,
+        *,
+        rule_cost=Gini(),
+        max_rmp_calls=20,
+        threshold: float = 1.0e-6,
+        random_state: int | None = None,
+        class_weight: dict | str | None = None,
+        criterion: str = "gini",
+        splitter: str = "best",
+        max_depth: int | None = None,
+        min_samples_split: int = 2,
+        min_samples_leaf: int = 1,
+        min_weight_fraction_leaf: float = 0.0,
+        max_features: int | float | str = None,
+        max_leaf_nodes: int | None = None,
+        min_impurity_decrease: float = 0.0,
+        ccp_alpha: float = 0.0,
+        monotonic_cst: ArrayLike | None = None,
+    ):
+        """
+        Parameters
+        ----------
+        solver : OptimizationSolver
+            An instance of a derived class inherits from the 'Optimization Solver' base class.
+            The solver is responsible for optimizing the rule set based on the cost function
+            and constraints.
+            
+        rule_cost : RuleCost or int, default=Gini()
+            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+            or a fixed cost
+
+        max_rmp_calls : int, default=20
+            Maximum number of Restricted Master Problem (RMP) iterations allowed during fitting.
+            
+        class_weight: dict, "balanced" or None, default=None
+            A dictionary mapping class labels to their respective weights, the string "balanced"
+            to automatically adjust weights inversely proportional to class frequencies,
+            or None for no weights. Used to adjust the model in favor of certain classes.
+            
+        threshold : float, default=1.0e-6
+            The minimum weight threshold for including a rule in the final model.
+            
+        random_state : int or None, default=None
+            Seed for the random number generator to ensure reproducible results.
+            Defaults to None.
+            
+        criterion : {"gini", "entropy", "log_loss"}, default="gini"
+            The function to measure the quality of a split. Supported criteria are
+            "gini" for the Gini impurity and "log_loss" and "entropy" both for the
+            Shannon information gain, see :ref:`tree_mathematical_formulation`.
+
+        splitter : {"best", "random"}, default="best"
+            The strategy used to choose the split at each node. Supported
+            strategies are "best" to choose the best split and "random" to choose
+            the best random split.
+
+        max_depth : int, default=None
+            The maximum depth of the tree. If None, then nodes are expanded until
+            all leaves are pure or until all leaves contain less than
+            min_samples_split samples.
+
+        min_samples_split : int or float, default=2
+            The minimum number of samples required to split an internal node:
+
+        min_samples_leaf : int or float, default=1
+            The minimum number of samples required to be at a leaf node.
+            A split point at any depth will only be considered if it leaves at
+            least ``min_samples_leaf`` training samples in each of the left and
+            right branches.  This may have the effect of smoothing the model,
+            especially in regression.
+
+        min_weight_fraction_leaf : float, default=0.0
+            The minimum weighted fraction of the sum total of weights (of all
+            the input samples) required to be at a leaf node. Samples have
+            equal weight when sample_weight is not provided.
+
+        max_features : int, float or {"sqrt", "log2"}, default=None
+            The number of features to consider when looking for the best split:
+
+        max_leaf_nodes : int, default=None
+            Grow a tree with ``max_leaf_nodes`` in best-first fashion.
+            Best nodes are defined as relative reduction in impurity.
+            If None then unlimited number of leaf nodes.
+
+        min_impurity_decrease : float, default=0.0
+            A node will be split if this split induces a decrease of the impurity
+            greater than or equal to this value.
+
+        ccp_alpha : non-negative float, default=0.0
+            Complexity parameter used for Minimal Cost-Complexity Pruning. The
+            subtree with the largest cost complexity that is smaller than
+            ``ccp_alpha`` will be chosen. By default, no pruning is performed.
+
+        monotonic_cst : array-like of int of shape (n_features), default=None
+            Indicates the monotonicity constraint to enforce on each feature.
+            - 1: monotonic increase
+            - 0: no constraint
+            - -1: monotonic decrease
+        """
+
+        if hasattr(solver, "max_rule"):
+            if getattr(solver, "max_rule") is not None:
+                warnings.warn(
+                    "The 'max_rule' attribute is available only for RUX classifiers. "
+                    "It has been automatically set to 'None' for the current solver."
+                )
+                solver.max_rule = None
+
+        self._validate_parameters(
+            max_rmp_calls,
+            class_weight,
+            criterion,
+            splitter,
+            max_depth,
+            min_samples_split,
+            min_samples_leaf,
+            min_weight_fraction_leaf,
+            max_features,
+            max_leaf_nodes,
+            min_impurity_decrease,
+            ccp_alpha,
+            monotonic_cst,
+        )
+
+        super().__init__(
+            threshold=threshold,
+            random_state=random_state,
+            solver=solver,
+            rule_cost=rule_cost,
+            class_weight=class_weight,
+        )
+
+        self.max_rmp_calls = int(max_rmp_calls)
+
+        self.criterion = criterion
+        self.splitter = splitter
+        self.max_depth = max_depth
+        self.min_samples_split = min_samples_split
+        self.min_samples_leaf = min_samples_leaf
+        self.min_weight_fraction_leaf = min_weight_fraction_leaf
+        self.max_features = max_features
+        self.max_leaf_nodes = max_leaf_nodes
+        self.min_impurity_decrease = min_impurity_decrease
+        self.ccp_alpha = ccp_alpha
+        self.monotonic_cst = monotonic_cst
+
+    def _pspdt(
+        self,
+        x: np.ndarray,
+        y: np.ndarray,
+        vec_y: np.ndarray,
+        fit_tree: DecisionTreeClassifier,
+        treeno: int,
+        betas: np.ndarray,
+    ) -> bool:
+        """
+        Pricing SubProblem for Decision Trees (PSPDT) in the rule generation process.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            Feature matrix of the training data.
+        y : np.ndarray
+            Target vector of the training data.
+        vec_y : np.ndarray
+            Preprocessed target vector, adjusted for optimization.
+        fit_tree : DecisionTreeClassifier
+            Fitted decision tree for rule extraction.
+        treeno : int
+            Identifier for the current tree in the iterative process.
+        betas : np.ndarray
+            Dual variables or sample weights from the latest master problem solution.
+
+        Returns
+        -------
+        bool
+            Indicates whether a new rule that improves the objective function was found.
+        """
+        no_improvement = True
+
+        n, col = x.shape[0], np.max(self.coefficients_.cols) + 1
+
+        # Apply the decision tree to the feature matrix
+        y_rules = fit_tree.apply(x)
+
+        for leafno in np.unique(y_rules):
+            # Get the samples that fall into this leaf
+            covers = np.where(y_rules == leafno)[0]
+            leaf_y_vals = y[covers]  # y values of the samples in the leaf
+
+            # Get the unique labels in the leaf and their counts
+            unique_labels = np.arange(self.k_, dtype=np.intp)
+            counts = np.zeros(self.k_, dtype=np.intp)
+            unique_labels_, counts_ = np.unique(leaf_y_vals, return_counts=True)
+            for i, j in enumerate(unique_labels_):
+                unique_labels[j] = unique_labels_[i]
+                counts[j] = counts_[i]
+
+            # Identify the majority class in the leaf
+            label = unique_labels_[np.argmax(counts_)]  # majority class in the leaf
+
+            # Create a vector for this label
+            label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
+            label_vector[label] = 1
+
+            # Calculate the y values for the optimization problem
+            fill_ahat = np.dot(vec_y[covers, :], label_vector)
+
+            # Prepare to check the reduced cost
+            aijhat = np.zeros(n)
+            aijhat[covers] = fill_ahat
+
+            cost = self._get_rule_cost(
+                temp_rule=self._get_rule(fit_tree, leafno),
+                covers=covers,
+                counts=counts,
+                y=y,
+            )
+
+            # Calculate the reduced cost
+            red_cost = np.dot(
+                np.multiply(((self.k_ - 1.0) / self.k_), aijhat), betas
+            ) - (cost * self.solver.penalty)
+
+            # If the reduced cost is positive, update the coefficients
+            if red_cost > 0:  # only columns with proper reduced costs are added
+                covers_fill = np.full((covers.shape[0],), fill_ahat, dtype=np.intp)
+                covers_col = np.full((covers.shape[0],), col, dtype=np.intp)
+                self.coefficients_.rows = np.concatenate(
+                    (self.coefficients_.rows, covers)
+                )
+                self.coefficients_.cols = np.concatenate(
+                    (self.coefficients_.cols, covers_col)
+                )
+                self.coefficients_.yvals = np.concatenate(
+                    (self.coefficients_.yvals, covers_fill)
+                )
+                self.coefficients_.costs = np.concatenate(
+                    (self.coefficients_.costs, [cost])
+                )
+
+                # Calculate the distribution of the samples in the leaf across the classes
+                sdist = np.zeros(self.k_, dtype=np.intp)
+                sdist[unique_labels] = counts
+                self.rule_info_[col] = (treeno, leafno, label, sdist)
+                col += 1
+                no_improvement = False
+
+        # Return whether there was any improvement
+        return no_improvement
+
+    def _fit_decision_tree(
+        self, x: np.ndarray, y: np.ndarray, sample_weight: np.ndarray
+    ) -> DecisionTreeClassifier:
+        """
+        Fits a decision tree to the data, taking into account sample weights.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            Feature matrix of the training data.
+        y : np.ndarray
+            Target vector of the training data.
+        sample_weight : np.ndarray
+            Array of weights for the samples.
+
+        Returns
+        -------
+        DecisionTreeClassifier
+            A decision tree classifier fitted to the weighted data.
+        """
+        dt = DecisionTreeClassifier(
+            random_state=self._rng.integers(np.iinfo(np.int16).max),
+            criterion=self.criterion,
+            splitter=self.splitter,
+            class_weight=self.class_weight,
+            max_depth=self.max_depth,
+            min_samples_split=self.min_samples_split,
+            min_samples_leaf=self.min_samples_leaf,
+            min_weight_fraction_leaf=self.min_weight_fraction_leaf,
+            max_features=self.max_features,
+            max_leaf_nodes=self.max_leaf_nodes,
+            min_impurity_decrease=self.min_impurity_decrease,
+            ccp_alpha=self.ccp_alpha,
+            monotonic_cst=self.monotonic_cst,
+        )
+
+        if sample_weight is not None:
+            dt.class_weight = None
+
+        # Fit the decision tree to the data
+        return dt.fit(x, y, sample_weight=sample_weight)
+
+    def _fill_ahat(
+        self,
+        x: np.ndarray,
+        y: np.ndarray,
+        vec_y: np.ndarray,
+        fit_tree_: DecisionTreeClassifier = None,
+        treeno_: int = None,
+    ):
+        """
+        Updates the optimization problem's coefficients based on the rules from a decision tree.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            Feature matrix of the training data.
+        y : np.ndarray
+            Target vector of the training data.
+        vec_y : np.ndarray
+            Preprocessed target vector, adjusted for optimization.
+        fit_tree : DecisionTreeClassifier, optional
+            A decision tree from which to extract rules.
+        treeno : int, optional
+            Identifier for the decision tree within a sequence of generated trees.
+        """
+        # Initialize coefficients for the next batch.
+        self.coefficients_.cleanup()
+
+        # If there are existing rules, process them to fill the coefficient matrix
+        if len(self.rule_info_) > 0:
+            for col, (treeno, leafno, label, _) in self.rule_info_.items():
+                # Retrieve the decision tree corresponding to the current rule
+                fit_tree = self.decision_trees_[treeno]
+
+                # Apply the decision tree to the feature matrix to get the leaf indices
+                # for each sample
+                y_rules = fit_tree.apply(x)
+
+                # Identify the samples that fall into the current leaf
+                covers = np.where(y_rules == leafno)[0]
+                leaf_y_vals = y[covers]
+
+                # Compute the unique labels in the leaf and their counts
+                unique_labels, counts = np.unique(leaf_y_vals, return_counts=True)
+
+                # Determine the majority class label in the leaf
+                label = unique_labels[np.argmax(counts)]
+
+                # Create a vector representation of this label
+                label_vector = np.full((self.k_,), -1 / (self.k_ - 1))
+                label_vector[label] = 1
+
+                fill_ahat = np.dot(vec_y[covers, :], label_vector)
+
+                self.coefficients_.rows = np.concatenate(
+                    (self.coefficients_.rows, covers)
+                )
+                self.coefficients_.cols = np.concatenate(
+                    (self.coefficients_.cols, [col] * covers.shape[0])
+                )
+                self.coefficients_.yvals = np.concatenate(
+                    (self.coefficients_.yvals, np.full(covers.shape[0], fill_ahat))
+                )
+
+                cost = self._get_rule_cost(
+                    temp_rule=self._get_rule(fit_tree, leafno),
+                    covers=covers,
+                    counts=counts,
+                    y=y,
+                )
+
+                self.coefficients_.costs = np.concatenate(
+                    (self.coefficients_.costs, [cost])
+                )
+
+        # If a specific decision tree is provided, update the coefficient matrix based on this tree
+        if fit_tree_:
+            self._get_matrix(x, y, vec_y, fit_tree_, treeno_)
+
+    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
+        """
+        Fits the RUGClassifier model to the training data using a rule generation approach.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
+            The target values (class labels) as integers
+        sample_weight : array-like of shape (n_samples,), default=None
+            Sample weights. If None, then samples are equally weighted.
+
+        Returns
+        -------
+        RUGClassifier
+            The fitted model, ready for making predictions.
+        """
+        x, y = check_inputs(x, y)
+        if self._is_fitted:
+            self._cleanup()
+
+        treeno = 0
+        fit_tree = self._fit_decision_tree(x, y, sample_weight=None)
+        self.decision_trees_[treeno] = fit_tree
+
+        self._get_class_infos(y)
+        vec_y = self._preprocess(y)
+        self._get_matrix(x, y, vec_y, fit_tree, treeno)
+
+        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
+
+        ws, betas = self.solver(
+            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
+        )
+
+        # Rule generation
+        for _ in range(self.max_rmp_calls):
+            if np.all(betas == 0):
+                break
+
+            treeno += 1
+            fit_tree = self._fit_decision_tree(x, y, sample_weight=betas)
+            self.decision_trees_[treeno] = fit_tree
+
+            no_improvement = self._pspdt(x, y, vec_y, fit_tree, treeno, betas)
+
+            if no_improvement:
+                break
+
+            ws, betas = self.solver(
+                coefficients=self.coefficients_,
+                k=self.k_,
+                ws0=ws.copy(),
+                sample_weight=sample_weight,
+            )
+
+        self._fill_rules(ws)
+        self._is_fitted = True
+
+        return self
+
+    def _validate_parameters(
+        self,
+        max_rmp_calls,
+        class_weight,
+        criterion,
+        splitter,
+        max_depth,
+        min_samples_split,
+        min_samples_leaf,
+        min_weight_fraction_leaf,
+        max_features,
+        max_leaf_nodes,
+        min_impurity_decrease,
+        ccp_alpha,
+        monotonic_cst,
+    ):
+        # max_rmp_calls check
+        if not isinstance(max_rmp_calls, (float, int)):
+            raise TypeError("max_rmp_calls must be an integer.")
+
+        if max_rmp_calls < 0:
+            raise ValueError("max_rmp_calls must be a non-negative integer.")
+
+        # class_weight check
+        if not isinstance(class_weight, (dict, str, type(None))) or (
+            isinstance(class_weight, str) and class_weight != "balanced"
+        ):
+            raise ValueError("class_weight must be a dictionary, 'balanced', or None.")
+
+        # criterion check
+        if criterion not in {"gini", "entropy", "log_loss"}:
+            raise ValueError(
+                "criterion must be one of 'gini', 'entropy', or 'log_loss'."
+            )
+
+        # splitter check
+        if splitter not in {"best", "random"}:
+            raise ValueError("splitter must be 'best' or 'random'.")
+
+        # max_depth check
+        if max_depth is not None and not isinstance(max_depth, int):
+            raise TypeError("max_depth must be an integer or None.")
+        if isinstance(max_depth, int) and max_depth < 1:
+            raise ValueError("max_depth must be greater than 0.")
+
+        # min_samples_split check
+        if not isinstance(min_samples_split, (int, float)) or min_samples_split < 2:
+            raise ValueError(
+                "min_samples_split must be an integer or float greater than or equal to 2."
+            )
+
+        # min_samples_leaf check
+        if not isinstance(min_samples_leaf, (int, float)) or min_samples_leaf < 1:
+            raise ValueError(
+                "min_samples_leaf must be an integer or float greater than or equal to 1."
+            )
+
+        # min_weight_fraction_leaf check
+        if not isinstance(min_weight_fraction_leaf, float) or not (
+            0.0 <= min_weight_fraction_leaf <= 1.0
+        ):
+            raise ValueError(
+                "min_weight_fraction_leaf must be a float between 0.0 and 1.0."
+            )
+
+        # max_features check
+        if (
+            max_features is not None
+            and not isinstance(max_features, (int, float, str))
+            or (isinstance(max_features, str) and max_features not in {"sqrt", "log2"})
+        ):
+            raise ValueError(
+                "max_features must be an integer, float, 'sqrt', 'log2', or None."
+            )
+
+        # max_leaf_nodes check
+        if max_leaf_nodes is not None and (
+            not isinstance(max_leaf_nodes, int) or max_leaf_nodes < 1
+        ):
+            raise ValueError("max_leaf_nodes must be a positive integer or None.")
+
+        # min_impurity_decrease check
+        if not isinstance(min_impurity_decrease, float) or min_impurity_decrease < 0.0:
+            raise ValueError("min_impurity_decrease must be a non-negative float.")
+
+        # ccp_alpha check
+        if not isinstance(ccp_alpha, float) or ccp_alpha < 0.0:
+            raise ValueError("ccp_alpha must be a non-negative float.")
+
+        # monotonic_cst check
+        if monotonic_cst is not None and (
+            not isinstance(monotonic_cst, (list, tuple))
+            or not all(isinstance(item, int) for item in monotonic_cst)
+        ):
+            raise ValueError("monotonic_cst must be an array-like of integers or None.")
```

## ruleopt/estimator/sklearn_/rux.py

 * *Ordering differences only*

```diff
@@ -1,149 +1,149 @@
-from __future__ import annotations
-
-import numpy as np
-from sklearn.ensemble._forest import ForestClassifier
-from sklearn.ensemble import GradientBoostingClassifier
-from numpy.typing import ArrayLike
-
-from .base_sklearn import _RUGSKLEARN
-from ...rule_cost import Gini
-from ...utils import check_inputs
-
-
-class RUXClassifier(_RUGSKLEARN):
-    """
-    RUXClassifier aims to build a compact and interpretable model
-    by employing rule-based learning extracted from a trained scikit-learn
-    ensemble model (such as Gradient Boosting or Random Forest). It allows
-    a user to trade off between the complexity of the model (number of rules)
-    and the accuracy of the model.
-    """
-
-    def __init__(
-        self,
-        trained_ensemble,
-        solver,
-        *,
-        rule_cost=Gini(),
-        class_weight: dict | str | None = None,
-        threshold: float = 1.0e-6,
-        random_state: int | None = None,
-    ):
-        """
-        Parameters
-        ----------
-        trained_ensemble : sklearn.ensemble object
-            The trained scikit-learn ensemble model from which the rules will be
-            extracted.
-
-        solver : OptimizationSolver
-            An instance of a derived class inherits from the 'Optimization Solver' base class.
-            The solver is responsible for optimizing the rule set based on the cost function
-            and constraints.
-
-        rule_cost : RuleCost or int, default=Gini()
-            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
-            or a fixed cost
-
-        class_weight: dict, "balanced" or None, default=None
-            A dictionary mapping class labels to their respective weights, the string "balanced"
-            to automatically adjust weights inversely proportional to class frequencies,
-            or None for no weights. Used to adjust the model in favor of certain classes.
-
-        threshold : float, default=1.0e-6
-            The minimum weight threshold for including a rule in the final model
-
-        random_state : int or None, default=None
-            Seed for the random number generator to ensure reproducible results.
-            Defaults to None.
-        """
-        if not (
-            isinstance(trained_ensemble, (GradientBoostingClassifier, ForestClassifier))
-        ):
-            raise TypeError(
-                "trained_ensemble must be an instance of ",
-                "sklearn.ensemble.GradientBoostingClassifier, ",
-                "sklearn.ensemble.RandomForestClassifier, ",
-                "or sklearn.ensemble.ExtraTreesClassifier.",
-            )
-
-        self.trained_ensemble = trained_ensemble
-        super().__init__(
-            threshold=threshold,
-            random_state=random_state,
-            rule_cost=rule_cost,
-            solver=solver,
-            class_weight=class_weight,
-        )
-
-    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray) -> None:
-        """
-        Prepares the optimization problem matrices based on the ensemble of decision trees.
-
-        Parameters
-        ----------
-        x : np.ndarray
-            The feature matrix of the training data.
-        y : np.ndarray
-            The target vector of the training data.
-        vec_y : np.ndarray
-            The preprocessed target vector, adjusted for optimization.
-        """
-        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
-            self._get_matrix(x, y, vec_y, fit_tree, treeno)
-
-    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
-        """
-        Fits the RUXClassifier to the training data.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
-            The target values (class labels) as integers
-        sample_weight : array-like of shape (n_samples,), default=None
-            Sample weights. If None, then samples are equally weighted.
-
-        Returns
-        -------
-        RUXClassifier
-            The fitted model, ready for making predictions.
-        """
-        x, y = check_inputs(x, y)
-
-        # If the model has been fitted before, clean it up
-        if self.coefficients_.cols.shape[0] != 0:
-            self._cleanup()
-
-        # Fills the fitted decision trees.
-        tree_infos = self.trained_ensemble.estimators_
-        for treeno, fit_tree in enumerate(tree_infos):
-            self.decision_trees_[treeno] = (
-                fit_tree[0] if isinstance(fit_tree, np.ndarray) else fit_tree
-            )
-
-        # Extract and set properties of the target variable
-        self._get_class_infos(y)
-
-        # Preprocess the target values
-        vec_y = self._preprocess(y)
-
-        # Calculate the coefficients and other parameters for the optimization problem
-        self._get_matrices(x, y, vec_y)
-
-        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
-
-        # Solve the optimization problem again with the new rules
-        ws, *_ = self.solver(
-            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
-        )
-
-        # Fill the decision rules based on the weights obtained from the optimization problem
-        self._fill_rules(ws)
-
-        # Mark the model as fitted
-        self._is_fitted = True
-
-        # Return the fitted model
-        return self
+from __future__ import annotations
+
+import numpy as np
+from sklearn.ensemble._forest import ForestClassifier
+from sklearn.ensemble import GradientBoostingClassifier
+from numpy.typing import ArrayLike
+
+from .base_sklearn import _RUGSKLEARN
+from ...rule_cost import Gini
+from ...utils import check_inputs
+
+
+class RUXClassifier(_RUGSKLEARN):
+    """
+    RUXClassifier aims to build a compact and interpretable model
+    by employing rule-based learning extracted from a trained scikit-learn
+    ensemble model (such as Gradient Boosting or Random Forest). It allows
+    a user to trade off between the complexity of the model (number of rules)
+    and the accuracy of the model.
+    """
+
+    def __init__(
+        self,
+        trained_ensemble,
+        solver,
+        *,
+        rule_cost=Gini(),
+        class_weight: dict | str | None = None,
+        threshold: float = 1.0e-6,
+        random_state: int | None = None,
+    ):
+        """
+        Parameters
+        ----------
+        trained_ensemble : sklearn.ensemble object
+            The trained scikit-learn ensemble model from which the rules will be
+            extracted.
+
+        solver : OptimizationSolver
+            An instance of a derived class inherits from the 'Optimization Solver' base class.
+            The solver is responsible for optimizing the rule set based on the cost function
+            and constraints.
+
+        rule_cost : RuleCost or int, default=Gini()
+            Defines the cost of rules, either as a specific calculation method (RuleCost instance)
+            or a fixed cost
+
+        class_weight: dict, "balanced" or None, default=None
+            A dictionary mapping class labels to their respective weights, the string "balanced"
+            to automatically adjust weights inversely proportional to class frequencies,
+            or None for no weights. Used to adjust the model in favor of certain classes.
+
+        threshold : float, default=1.0e-6
+            The minimum weight threshold for including a rule in the final model
+
+        random_state : int or None, default=None
+            Seed for the random number generator to ensure reproducible results.
+            Defaults to None.
+        """
+        if not (
+            isinstance(trained_ensemble, (GradientBoostingClassifier, ForestClassifier))
+        ):
+            raise TypeError(
+                "trained_ensemble must be an instance of ",
+                "sklearn.ensemble.GradientBoostingClassifier, ",
+                "sklearn.ensemble.RandomForestClassifier, ",
+                "or sklearn.ensemble.ExtraTreesClassifier.",
+            )
+
+        self.trained_ensemble = trained_ensemble
+        super().__init__(
+            threshold=threshold,
+            random_state=random_state,
+            rule_cost=rule_cost,
+            solver=solver,
+            class_weight=class_weight,
+        )
+
+    def _get_matrices(self, x: np.ndarray, y: np.ndarray, vec_y: np.ndarray) -> None:
+        """
+        Prepares the optimization problem matrices based on the ensemble of decision trees.
+
+        Parameters
+        ----------
+        x : np.ndarray
+            The feature matrix of the training data.
+        y : np.ndarray
+            The target vector of the training data.
+        vec_y : np.ndarray
+            The preprocessed target vector, adjusted for optimization.
+        """
+        for treeno, fit_tree in enumerate(self.decision_trees_.values()):
+            self._get_matrix(x, y, vec_y, fit_tree, treeno)
+
+    def fit(self, x: ArrayLike, y: ArrayLike, sample_weight: ArrayLike | None = None):
+        """
+        Fits the RUXClassifier to the training data.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+        y : array-like of shape (n_samples,) or (n_samples, n_outputs)
+            The target values (class labels) as integers
+        sample_weight : array-like of shape (n_samples,), default=None
+            Sample weights. If None, then samples are equally weighted.
+
+        Returns
+        -------
+        RUXClassifier
+            The fitted model, ready for making predictions.
+        """
+        x, y = check_inputs(x, y)
+
+        # If the model has been fitted before, clean it up
+        if self.coefficients_.cols.shape[0] != 0:
+            self._cleanup()
+
+        # Fills the fitted decision trees.
+        tree_infos = self.trained_ensemble.estimators_
+        for treeno, fit_tree in enumerate(tree_infos):
+            self.decision_trees_[treeno] = (
+                fit_tree[0] if isinstance(fit_tree, np.ndarray) else fit_tree
+            )
+
+        # Extract and set properties of the target variable
+        self._get_class_infos(y)
+
+        # Preprocess the target values
+        vec_y = self._preprocess(y)
+
+        # Calculate the coefficients and other parameters for the optimization problem
+        self._get_matrices(x, y, vec_y)
+
+        sample_weight = self._get_sample_wight(sample_weight, self.class_weight, y)
+
+        # Solve the optimization problem again with the new rules
+        ws, *_ = self.solver(
+            coefficients=self.coefficients_, k=self.k_, sample_weight=sample_weight
+        )
+
+        # Fill the decision rules based on the weights obtained from the optimization problem
+        self._fill_rules(ws)
+
+        # Mark the model as fitted
+        self._is_fitted = True
+
+        # Return the fitted model
+        return self
```

## ruleopt/explainer/__init__.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-from .explainer import (Explainer )
-
-__all__ = [
+from .explainer import (Explainer )
+
+__all__ = [
     "Explainer"]
```

## ruleopt/explainer/explainer.py

```diff
@@ -1,243 +1,243 @@
-from __future__ import annotations
-import warnings
-import numpy as np
-from sklearn.utils import check_array
-from sklearn.utils.validation import check_is_fitted
-from ..estimator.base import _RUGBASE
-
-from numpy.typing import ArrayLike
-
-
-class Explainer:
-    """
-    Initializes the Explainer with a given estimator. The estimator must be fitted and
-    of a type that inherits from _RUGBASE, such as RUGClassifier, RUXClassifier,
-    RUXLGBMClassifier, or RUXXGBClassifier.
-    """
-
-    def __init__(self, estimator: _RUGBASE) -> None:
-        """
-        Parameters
-        ----------
-        estimator : ruleopt.estimator instance
-            A fitted estimator of a type that inherits from _RUGBASE.
-        """
-        if not isinstance(estimator, _RUGBASE):
-            raise TypeError(
-                "Estimator should be an instance of a class inheriting from _RUGBASE, ",
-                f"not {type(estimator)}",
-            )
-
-        check_is_fitted(estimator, attributes=["_is_fitted"])
-
-        self.estimator = estimator
-
-    def retrieve_rule_details(
-        self,
-        feature_names: list | None = None,
-        indices: list | None = None,
-        info: bool = True,
-    ) -> dict:
-        """
-        Retrieves and optionally prints detailed information about the specified rules.
-        If indices are provided, information for those specific rules is returned.
-        Otherwise, information for all rules is returned.
-
-        Parameters
-        ----------
-        feature_names : list or None, default=None
-            List of feature names for more readable rule descriptions. If None, indices are used.
-
-        indices :list or None, default=None
-            Indices of the rules to retrieve. If None, retrieves all rules.
-
-        info : bool, default=True
-            If True, prints the rules' details in a human-readable format.
-
-        Returns
-        -------
-        dict
-            A dictionary mapping each rule index to its details, including label, weight,
-            rule description, and statistical distribution. If a rule has no conditions,
-            it sets the majority class.
-        """
-        rules = self.estimator.decision_rules_
-        if indices is not None:
-            # Validate indices
-            max_index = max(rules.keys())
-            indices = [i for i in indices if i <= max_index]
-            if len(indices) < len(set(indices)):
-                warnings.warn("Some specified indices are out of range.")
-        else:
-            indices = list(rules.keys())
-
-        return_dict = {}
-        for indx in indices:
-            rule = rules.get(indx, None)
-            if rule is None:
-                continue  # Skip if rule does not exist, alternative to raising an error
-            rule_details = {
-                "label": rule.label,
-                "weight": rule.weight,
-                "rule": (
-                    rule.to_dict(feature_names)
-                    if rule
-                    else "No Rule: Set Majority Class"
-                ),
-                "sdist": rule.sdist,
-            }
-            return_dict[indx] = rule_details
-            if info:
-                self._display_rule_info(indx, rule, feature_names)
-
-        return return_dict
-
-    def find_applicable_rules_for_samples(
-        self,
-        x: ArrayLike,
-        threshold: float = 0.0,
-        feature_names: list | None = None,
-        info: bool = True,
-    ) -> list:
-        """
-        Identifies which rules apply to each instance in the provided input data
-        based on a given threshold.Optionally, prints detailed information about
-        each rule that applies to the instances.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-
-        threshold : float, default=0.0
-            Minimum rule weight threshold for considering a rule as covering an instance.
-
-        feature_names : list or None, default=None
-            List of feature names for more readable rule descriptions. If None, indices are used.
-
-        info : bool, default=True
-            If True, prints the details of the applicable rules for each instance.
-
-        Returns
-        -------
-        List[List[int]]
-            A list of lists, where each inner list contains the indices of rules that cover
-            the corresponding instance in `x`.
-        """
-        x = check_array(np.asarray(x, dtype=np.float32), force_all_finite="allow-nan")
-        x_to_rule_list = []
-        for i, x0 in enumerate(x):
-            if info:
-                print(f"Rules for instance {i}")
-            rule_list = []
-
-            for rule_id, rule in self.estimator.decision_rules_.items():
-                if rule.check_rule(x0) and rule.weight >= threshold:
-                    rule_list.append(rule_id)
-
-                    if info:
-                        self._display_rule_info(rule_id, rule, feature_names)
-
-            x_to_rule_list.append(rule_list)
-
-        return x_to_rule_list
-
-    def _display_rule_info(self, indx, rule, feature_names=None) -> None:
-        """
-        Prints the details of a specified rule in a human-readable format. This
-        method is designed for internal use to support other public methods that
-        may require detailed rule information to be printed.
-
-        Parameters
-        ----------
-        indx : int
-            Index of the rule being printed.
-
-        rule : Rule object
-            The rule whose details are to be printed.
-
-        feature_names : Optional[List[str]], default=None
-            List of feature names for more readable rule descriptions. If None,
-            feature indices are used.
-        """
-        print(f"RULE {indx}:")
-        rule_description = (
-            rule.to_text(feature_names) if feature_names else rule.to_text()
-        )
-        print(rule_description)
-        print(f"Class: {rule.label}")
-        print(f"Scaled rule weight: {rule.weight:.4f}\n")
-
-    def summarize_rule_metrics(self, info: bool = True) -> dict:
-        """
-        Calculates and optionally prints the total number of rules and the average
-        rule length within the model.
-
-        Parameters
-        ----------
-        info : bool, default=True
-            If True, prints the summary information.
-
-        Returns
-        -------
-        dict
-            A dictionary containing 'num_of_rules' (the total number of rules) and
-            'avg_rule_length' (the average length of the rules).
-        """
-        num_of_rules = len(self.estimator.decision_rules_)
-        avg_rule_length = np.mean(
-            [len(rule) for rule in self.estimator.decision_rules_.values()]
-        )
-
-        if info:
-            print(f"Total number of rules: {num_of_rules}")
-            print(f"Average rule length: {avg_rule_length:.2f}")
-
-        return {"num_of_rules": num_of_rules, "avg_rule_length": avg_rule_length}
-
-    def evaluate_rule_coverage_metrics(self, x: ArrayLike, info: bool = True) -> dict:
-        """
-        Calculates metrics including the number of instances not covered by any
-        rule ('num_of_missed'), the average number of rules per sample
-        ('avg_num_rules_per_sample'), and the average rule length per sample
-        ('avg_rule_length_per_sample'). Optionally, prints this information.
-
-        Parameters
-        ----------
-        x : array-like of shape (n_samples, n_features)
-            The training input samples. Internally, it will be converted to dtype=np.float32.
-
-        info : bool, default=True
-            If True, prints the calculated metrics.
-
-        Returns
-        -------
-        dict
-            A dictionary with calculated metrics: 'num_of_missed', 'avg_num_rules_per_sample',
-            and 'avg_rule_length_per_sample'.
-        """
-
-        with warnings.catch_warnings():
-            warnings.simplefilter("ignore")
-            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
-                self.estimator.predict(x, predict_info=True)
-            )
-
-        results = {
-            "num_of_missed": len(missed_values_index_),
-            "avg_num_rules_per_sample": np.mean(rules_per_sample_),
-            "avg_rule_length_per_sample": np.mean(rule_length_per_sample_),
-        }
-
-        if info:
-            print(
-                f"Number of instances not covered by any rule: {results['num_of_missed']}"
-            )
-            print(
-                f"Average number of rules per sample: {results['avg_num_rules_per_sample']:.2f}"
-            )
-            print(
-                f"Average length of rules per sample: {results['avg_rule_length_per_sample']:.2f}"
-            )
-
-        return results
+from __future__ import annotations
+import warnings
+import numpy as np
+from sklearn.utils import check_array
+from sklearn.utils.validation import check_is_fitted
+from ..estimator.base import _RUGBASE
+
+from numpy.typing import ArrayLike
+
+
+class Explainer:
+    """
+    Initializes the Explainer with a given estimator. The estimator must be fitted and
+    of a type that inherits from _RUGBASE, such as RUGClassifier, RUXClassifier,
+    RUXLGBMClassifier, or RUXXGBClassifier.
+    """
+
+    def __init__(self, estimator: _RUGBASE) -> None:
+        """
+        Parameters
+        ----------
+        estimator : ruleopt.estimator instance
+            A fitted estimator of a type that inherits from _RUGBASE.
+        """
+        if not isinstance(estimator, _RUGBASE):
+            raise TypeError(
+                "Estimator should be an instance of a class inheriting from _RUGBASE, ",
+                f"not {type(estimator)}",
+            )
+
+        check_is_fitted(estimator, attributes=["_is_fitted"])
+
+        self.estimator = estimator
+
+    def retrieve_rule_details(
+        self,
+        feature_names: list | None = None,
+        indices: list | None = None,
+        info: bool = True,
+    ) -> dict:
+        """
+        Retrieves and optionally prints detailed information about the specified rules.
+        If indices are provided, information for those specific rules is returned.
+        Otherwise, information for all rules is returned.
+
+        Parameters
+        ----------
+        feature_names : list or None, default=None
+            List of feature names for more readable rule descriptions. If None, indices are used.
+
+        indices :list or None, default=None
+            Indices of the rules to retrieve. If None, retrieves all rules.
+
+        info : bool, default=True
+            If True, prints the rules' details in a human-readable format.
+
+        Returns
+        -------
+        dict
+            A dictionary mapping each rule index to its details, including label, weight,
+            rule description, and statistical distribution. If a rule has no conditions,
+            it sets the majority class.
+        """
+        rules = self.estimator.decision_rules_
+        if indices is not None:
+            # Validate indices
+            max_index = max(rules.keys())
+            indices = [i for i in indices if i <= max_index]
+            if len(indices) < len(set(indices)):
+                warnings.warn("Some specified indices are out of range.")
+        else:
+            indices = list(rules.keys())
+
+        return_dict = {}
+        for indx in indices:
+            rule = rules.get(indx, None)
+            if rule is None:
+                continue  # Skip if rule does not exist, alternative to raising an error
+            rule_details = {
+                "label": int(rule.label),
+                "weight": float(rule.weight),
+                "rule": (
+                    rule.to_dict(feature_names)
+                    if rule
+                    else "No Rule: Set Majority Class"
+                ),
+                "sdist": rule.sdist.tolist(),
+            }
+            return_dict[indx] = rule_details
+            if info:
+                self._display_rule_info(indx, rule, feature_names)
+
+        return return_dict
+
+    def find_applicable_rules_for_samples(
+        self,
+        x: ArrayLike,
+        threshold: float = 0.0,
+        feature_names: list | None = None,
+        info: bool = True,
+    ) -> list:
+        """
+        Identifies which rules apply to each instance in the provided input data
+        based on a given threshold.Optionally, prints detailed information about
+        each rule that applies to the instances.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+
+        threshold : float, default=0.0
+            Minimum rule weight threshold for considering a rule as covering an instance.
+
+        feature_names : list or None, default=None
+            List of feature names for more readable rule descriptions. If None, indices are used.
+
+        info : bool, default=True
+            If True, prints the details of the applicable rules for each instance.
+
+        Returns
+        -------
+        List[List[int]]
+            A list of lists, where each inner list contains the indices of rules that cover
+            the corresponding instance in `x`.
+        """
+        x = check_array(np.asarray(x, dtype=np.float32), force_all_finite="allow-nan")
+        x_to_rule_list = []
+        for i, x0 in enumerate(x):
+            if info:
+                print(f"Rules for instance {i}")
+            rule_list = []
+
+            for rule_id, rule in self.estimator.decision_rules_.items():
+                if rule.check_rule(x0) and rule.weight >= threshold:
+                    rule_list.append(rule_id)
+
+                    if info:
+                        self._display_rule_info(rule_id, rule, feature_names)
+
+            x_to_rule_list.append(rule_list)
+
+        return x_to_rule_list
+
+    def _display_rule_info(self, indx, rule, feature_names=None) -> None:
+        """
+        Prints the details of a specified rule in a human-readable format. This
+        method is designed for internal use to support other public methods that
+        may require detailed rule information to be printed.
+
+        Parameters
+        ----------
+        indx : int
+            Index of the rule being printed.
+
+        rule : Rule object
+            The rule whose details are to be printed.
+
+        feature_names : Optional[List[str]], default=None
+            List of feature names for more readable rule descriptions. If None,
+            feature indices are used.
+        """
+        print(f"RULE {indx}:")
+        rule_description = (
+            rule.to_text(feature_names) if feature_names else rule.to_text()
+        )
+        print(rule_description)
+        print(f"Class: {rule.label}")
+        print(f"Scaled rule weight: {rule.weight:.4f}\n")
+
+    def summarize_rule_metrics(self, info: bool = True) -> dict:
+        """
+        Calculates and optionally prints the total number of rules and the average
+        rule length within the model.
+
+        Parameters
+        ----------
+        info : bool, default=True
+            If True, prints the summary information.
+
+        Returns
+        -------
+        dict
+            A dictionary containing 'num_of_rules' (the total number of rules) and
+            'avg_rule_length' (the average length of the rules).
+        """
+        num_of_rules = len(self.estimator.decision_rules_)
+        avg_rule_length = np.mean(
+            [len(rule) for rule in self.estimator.decision_rules_.values()]
+        )
+
+        if info:
+            print(f"Total number of rules: {num_of_rules}")
+            print(f"Average rule length: {avg_rule_length:.2f}")
+
+        return {"num_of_rules": num_of_rules, "avg_rule_length": avg_rule_length}
+
+    def evaluate_rule_coverage_metrics(self, x: ArrayLike, info: bool = True) -> dict:
+        """
+        Calculates metrics including the number of instances not covered by any
+        rule ('num_of_missed'), the average number of rules per sample
+        ('avg_num_rules_per_sample'), and the average rule length per sample
+        ('avg_rule_length_per_sample'). Optionally, prints this information.
+
+        Parameters
+        ----------
+        x : array-like of shape (n_samples, n_features)
+            The training input samples. Internally, it will be converted to dtype=np.float32.
+
+        info : bool, default=True
+            If True, prints the calculated metrics.
+
+        Returns
+        -------
+        dict
+            A dictionary with calculated metrics: 'num_of_missed', 'avg_num_rules_per_sample',
+            and 'avg_rule_length_per_sample'.
+        """
+
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            missed_values_index_, rules_per_sample_, rule_length_per_sample_ = (
+                self.estimator.predict(x, predict_info=True)
+            )
+
+        results = {
+            "num_of_missed": len(missed_values_index_),
+            "avg_num_rules_per_sample": np.mean(rules_per_sample_),
+            "avg_rule_length_per_sample": np.mean(rule_length_per_sample_),
+        }
+
+        if info:
+            print(
+                f"Number of instances not covered by any rule: {results['num_of_missed']}"
+            )
+            print(
+                f"Average number of rules per sample: {results['avg_num_rules_per_sample']:.2f}"
+            )
+            print(
+                f"Average length of rules per sample: {results['avg_rule_length_per_sample']:.2f}"
+            )
+
+        return results
```

## ruleopt/rule_cost/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-from .rule_cost import Length, Gini, Mixed, MixedSigmoid, RuleCost
-
-__all__ = ["Length", "Gini", "Mixed", "MixedSigmoid", "RuleCost"]
+from .rule_cost import Length, Gini, Mixed, MixedSigmoid, RuleCost
+
+__all__ = ["Length", "Gini", "Mixed", "MixedSigmoid", "RuleCost"]
```

## ruleopt/rule_cost/rule_cost.py

 * *Ordering differences only*

```diff
@@ -1,173 +1,173 @@
-from abc import abstractmethod, ABC
-import numpy as np
-from ..aux_classes import Rule
-
-
-class RuleCost(ABC):
-    """
-    Abstract base class representing the cost associated with a rule or a set of rules.
-
-    This class is designed to be subclassed by specific cost calculation implementations.
-    Each subclass should provide a specific cost calculation strategy by overriding the
-    `__call__` method. The `__call__` method allows instances of the subclass to be used
-    as if they were functions, directly invoking the cost calculation.
-    """
-
-    @abstractmethod
-    def __call__(self):
-        """
-        Abstract method to be implemented by subclasses to calculate and return the cost.
-
-        This method should take relevant parameters as input (e.g., the rule or set of
-        rules being evaluated) and return a numerical value representing the cost. The
-        exact implementation details and parameters are to be defined in the subclass.
-
-        Returns
-        -------
-        cost : float
-            The calculated cost of the rule or set of rules. This is a numerical value
-            indicating the cost or penalty associated with the rule(s) based on the
-            specific calculation strategy implemented in the subclass.
-        """
-
-
-class Length(RuleCost):
-    """
-    Calculate the cost of a rule based on its length.
-    """
-
-    def __call__(self, temp_rule: Rule, *args, **kwargs) -> int:
-        """
-        Calculate and return the cost of the rule.
-
-        Parameters
-        ----------
-        temp_rule : Rule
-            The rule to calculate the cost for.
-
-        Returns
-        -------
-        int
-            The cost of the rule, defined as its length.
-        """
-        cost = len(temp_rule)
-        return cost
-
-
-class Gini(RuleCost):
-    """
-    Calculate the Gini cost of a split.
-    """
-
-    def __call__(self, counts: np.ndarray, *args, **kwargs) -> float:
-        """
-        Calculate and return the Gini cost for a node.
-
-        Parameters
-        ----------
-        counts : np.ndarray
-            An array containing the counts of each class in a node.
-
-        Returns
-        -------
-        float
-            The Gini cost for the node.
-        """
-        probs = np.divide(counts, np.sum(counts))
-        cost = 1 - np.sum(np.square(probs))
-        return cost
-
-
-class Mixed(RuleCost):
-    """
-    Calculate the mixed cost, combining class separation and data selection terms with
-    a weighting parameter.
-    """
-
-    def __init__(self, w: float = 0.7) -> None:
-        """
-        Initialize the mixed cost calculation with a weighting parameter.
-
-        Parameters
-        ----------
-        w : float, optional, default=0.7
-            Weighting parameter to balance class separation and data selection terms.
-        """
-        self.w = w
-
-    def __call__(self, covers: np.ndarray, y: np.ndarray, *args, **kwargs) -> float:
-        """
-        Calculate and return the mixed cost for a rule.
-
-        Parameters
-        ----------
-        covers : np.ndarray
-            Array of cover sizes for the classes.
-
-        y : np.ndarray
-            The target array.
-
-        Returns
-        -------
-        float
-            The mixed cost for the rule.
-        """
-        class_separation_term = 1 - (1 - (np.min(covers) / covers.shape[0]))
-        data_selection_term = 1 - (covers.shape[0] / y.shape[0])
-        cost = self.w * class_separation_term + (1 - self.w) * data_selection_term
-        return cost
-
-
-class MixedSigmoid(RuleCost):
-    """
-    Calculate the mixed cost with a sigmoid adjustment based on weighting and alpha
-    parameters.
-    """
-
-    def __init__(self, w: float = 0.7, alpha: float = 10) -> None:
-        """
-        Initialize the sigmoid-adjusted mixed cost calculation with weighting and
-        alpha parameters.
-
-        Parameters
-        ----------
-        w : float, optional, default=0.7
-            Weighting parameter to balance class separation and data selection terms.
-
-        alpha : float, optional, default=10
-            Scaling parameter to adjust the steepness of the sigmoid function.
-        """
-        self.w = w
-        self.alpha = alpha
-
-    def __call__(self, covers: np.ndarray, y: np.ndarray, *args, **kwargs) -> float:
-        """
-        Calculate and return the sigmoid-adjusted mixed cost for a rule.
-
-        Parameters
-        ----------
-        covers : np.ndarray
-            Array of cover sizes for the classes.
-
-        y : np.ndarray
-            The target array.
-
-        Returns
-        -------
-        float
-            The sigmoid-adjusted mixed cost for the rule.
-        """
-        class_separation_term = 1 - (1 - (np.min(covers) / covers.shape[0]))
-        data_selection_term = 1 - (covers.shape[0] / y.shape[0])
-        cost = 1 / (
-            1
-            + np.exp(
-                -self.alpha
-                * (
-                    self.w * class_separation_term
-                    + (1 - self.w) * data_selection_term
-                    - 0.5
-                )
-            )
-        )
-        return cost
+from abc import abstractmethod, ABC
+import numpy as np
+from ..aux_classes import Rule
+
+
+class RuleCost(ABC):
+    """
+    Abstract base class representing the cost associated with a rule or a set of rules.
+
+    This class is designed to be subclassed by specific cost calculation implementations.
+    Each subclass should provide a specific cost calculation strategy by overriding the
+    `__call__` method. The `__call__` method allows instances of the subclass to be used
+    as if they were functions, directly invoking the cost calculation.
+    """
+
+    @abstractmethod
+    def __call__(self):
+        """
+        Abstract method to be implemented by subclasses to calculate and return the cost.
+
+        This method should take relevant parameters as input (e.g., the rule or set of
+        rules being evaluated) and return a numerical value representing the cost. The
+        exact implementation details and parameters are to be defined in the subclass.
+
+        Returns
+        -------
+        cost : float
+            The calculated cost of the rule or set of rules. This is a numerical value
+            indicating the cost or penalty associated with the rule(s) based on the
+            specific calculation strategy implemented in the subclass.
+        """
+
+
+class Length(RuleCost):
+    """
+    Calculate the cost of a rule based on its length.
+    """
+
+    def __call__(self, temp_rule: Rule, *args, **kwargs) -> int:
+        """
+        Calculate and return the cost of the rule.
+
+        Parameters
+        ----------
+        temp_rule : Rule
+            The rule to calculate the cost for.
+
+        Returns
+        -------
+        int
+            The cost of the rule, defined as its length.
+        """
+        cost = len(temp_rule)
+        return cost
+
+
+class Gini(RuleCost):
+    """
+    Calculate the Gini cost of a split.
+    """
+
+    def __call__(self, counts: np.ndarray, *args, **kwargs) -> float:
+        """
+        Calculate and return the Gini cost for a node.
+
+        Parameters
+        ----------
+        counts : np.ndarray
+            An array containing the counts of each class in a node.
+
+        Returns
+        -------
+        float
+            The Gini cost for the node.
+        """
+        probs = np.divide(counts, np.sum(counts))
+        cost = 1 - np.sum(np.square(probs))
+        return cost
+
+
+class Mixed(RuleCost):
+    """
+    Calculate the mixed cost, combining class separation and data selection terms with
+    a weighting parameter.
+    """
+
+    def __init__(self, w: float = 0.7) -> None:
+        """
+        Initialize the mixed cost calculation with a weighting parameter.
+
+        Parameters
+        ----------
+        w : float, optional, default=0.7
+            Weighting parameter to balance class separation and data selection terms.
+        """
+        self.w = w
+
+    def __call__(self, covers: np.ndarray, y: np.ndarray, *args, **kwargs) -> float:
+        """
+        Calculate and return the mixed cost for a rule.
+
+        Parameters
+        ----------
+        covers : np.ndarray
+            Array of cover sizes for the classes.
+
+        y : np.ndarray
+            The target array.
+
+        Returns
+        -------
+        float
+            The mixed cost for the rule.
+        """
+        class_separation_term = 1 - (1 - (np.min(covers) / covers.shape[0]))
+        data_selection_term = 1 - (covers.shape[0] / y.shape[0])
+        cost = self.w * class_separation_term + (1 - self.w) * data_selection_term
+        return cost
+
+
+class MixedSigmoid(RuleCost):
+    """
+    Calculate the mixed cost with a sigmoid adjustment based on weighting and alpha
+    parameters.
+    """
+
+    def __init__(self, w: float = 0.7, alpha: float = 10) -> None:
+        """
+        Initialize the sigmoid-adjusted mixed cost calculation with weighting and
+        alpha parameters.
+
+        Parameters
+        ----------
+        w : float, optional, default=0.7
+            Weighting parameter to balance class separation and data selection terms.
+
+        alpha : float, optional, default=10
+            Scaling parameter to adjust the steepness of the sigmoid function.
+        """
+        self.w = w
+        self.alpha = alpha
+
+    def __call__(self, covers: np.ndarray, y: np.ndarray, *args, **kwargs) -> float:
+        """
+        Calculate and return the sigmoid-adjusted mixed cost for a rule.
+
+        Parameters
+        ----------
+        covers : np.ndarray
+            Array of cover sizes for the classes.
+
+        y : np.ndarray
+            The target array.
+
+        Returns
+        -------
+        float
+            The sigmoid-adjusted mixed cost for the rule.
+        """
+        class_separation_term = 1 - (1 - (np.min(covers) / covers.shape[0]))
+        data_selection_term = 1 - (covers.shape[0] / y.shape[0])
+        cost = 1 / (
+            1
+            + np.exp(
+                -self.alpha
+                * (
+                    self.w * class_separation_term
+                    + (1 - self.w) * data_selection_term
+                    - 0.5
+                )
+            )
+        )
+        return cost
```

## ruleopt/solver/__init__.py

 * *Ordering differences only*

```diff
@@ -1,7 +1,7 @@
-from .unc_solver import UNCSolver
-from .ortools_solver import ORToolsSolver
-from .base import OptimizationSolver
-from .gurobi_solver import GurobiSolver
-from .cplex_solver import CPLEXSolver
-
-__all__ = ["UNCSolver", "ORToolsSolver", "GurobiSolver", "CPLEXSolver", "OptimizationSolver"]
+from .unc_solver import UNCSolver
+from .ortools_solver import ORToolsSolver
+from .base import OptimizationSolver
+from .gurobi_solver import GurobiSolver
+from .cplex_solver import CPLEXSolver
+
+__all__ = ["UNCSolver", "ORToolsSolver", "GurobiSolver", "CPLEXSolver", "OptimizationSolver"]
```

## ruleopt/solver/base.py

 * *Ordering differences only*

```diff
@@ -1,84 +1,84 @@
-from abc import ABC, abstractmethod
-from typing import Any
-import warnings
-
-
-class OptimizationSolver(ABC):
-    """
-    This abstract base class defines the interface for a generic solver.
-    Implementations of this class must provide the `__call__` method, 
-    allowing the solver to be invoked as if it were a function.
-    """
-
-    def __init__(self) -> None:
-        super().__init__()
-        if not hasattr(self, "penalty"):
-            raise AttributeError("Subclasses must define 'penalty'")
-        if not hasattr(self, "use_sparse"):
-            raise AttributeError("Subclasses must define 'use_sparse'")
-
-    @abstractmethod
-    def __call__(self, *args: Any, **kwds: Any) -> Any:
-        """
-        Executes the solver using the provided arguments and keyword arguments.
-
-        Parameters:
-            *args (Any): Positional arguments required for solving the problem.
-            **kwds (Any): Keyword arguments required for solving the problem.
-
-        Returns:
-            Any: The result of the solving process.
-        """
-        pass
-
-    def _check_params(self):
-        if not isinstance(self.penalty, (float, int)) or self.penalty <= 0:
-            raise TypeError("penalty must be a positive float.")
-
-        if not isinstance(self.use_sparse, bool):
-            raise TypeError(f"use_sparse must be True or False.")
-
-        if hasattr(self, "solver_type"):
-            valid_solvers = [
-                "CLP",
-                "GLOP",
-                "GUROBI_LP",
-                "CPLEX_LP",
-                "XPRESS_LP",
-                "GLPK_LP",
-                "HiGHS",
-            ]
-            if (
-                not isinstance(self.solver_type, str)
-                or self.solver_type not in valid_solvers
-            ):
-                raise ValueError(f"solver_type must be one of {valid_solvers}.")
-
-        if hasattr(self, "lr"):
-            if not isinstance(self.lr, (float, int)) or self.lr <= 0:
-                raise TypeError("lr must be a positive float.")
-
-        if hasattr(self, "weight_decay"):
-            if not isinstance(self.weight_decay, (int, float)) or self.weight_decay < 0:
-                raise TypeError("weight_decay must be a non-negative float.")
-
-        if hasattr(self, "max_rule"):
-            if self.max_rule is not None and (
-                not isinstance(self.max_rule, int) or self.max_rule <= 0
-            ):
-                raise TypeError("max_rule must be a positive integer or None.")
-
-        if hasattr(self, "patience"):
-            if not isinstance(self.patience, int) or self.patience <= 0:
-                raise TypeError("patience must be a positive integer.")
-
-        if hasattr(self, "device"):
-            valid_devices = ["cuda", "cpu"]
-            if not isinstance(self.device, str) or self.device not in valid_devices:
-                raise ValueError(f"solver_type must be one of {valid_devices}.")
-
-        if self.use_sparse:
-            warnings.warn(
-                "A sparse data format is being used. If your dataset is not sufficiently "
-                "large, using a sparse format could lead to performance issues.",
-            )
+from abc import ABC, abstractmethod
+from typing import Any
+import warnings
+
+
+class OptimizationSolver(ABC):
+    """
+    This abstract base class defines the interface for a generic solver.
+    Implementations of this class must provide the `__call__` method, 
+    allowing the solver to be invoked as if it were a function.
+    """
+
+    def __init__(self) -> None:
+        super().__init__()
+        if not hasattr(self, "penalty"):
+            raise AttributeError("Subclasses must define 'penalty'")
+        if not hasattr(self, "use_sparse"):
+            raise AttributeError("Subclasses must define 'use_sparse'")
+
+    @abstractmethod
+    def __call__(self, *args: Any, **kwds: Any) -> Any:
+        """
+        Executes the solver using the provided arguments and keyword arguments.
+
+        Parameters:
+            *args (Any): Positional arguments required for solving the problem.
+            **kwds (Any): Keyword arguments required for solving the problem.
+
+        Returns:
+            Any: The result of the solving process.
+        """
+        pass
+
+    def _check_params(self):
+        if not isinstance(self.penalty, (float, int)) or self.penalty <= 0:
+            raise TypeError("penalty must be a positive float.")
+
+        if not isinstance(self.use_sparse, bool):
+            raise TypeError(f"use_sparse must be True or False.")
+
+        if hasattr(self, "solver_type"):
+            valid_solvers = [
+                "CLP",
+                "GLOP",
+                "GUROBI_LP",
+                "CPLEX_LP",
+                "XPRESS_LP",
+                "GLPK_LP",
+                "HiGHS",
+            ]
+            if (
+                not isinstance(self.solver_type, str)
+                or self.solver_type not in valid_solvers
+            ):
+                raise ValueError(f"solver_type must be one of {valid_solvers}.")
+
+        if hasattr(self, "lr"):
+            if not isinstance(self.lr, (float, int)) or self.lr <= 0:
+                raise TypeError("lr must be a positive float.")
+
+        if hasattr(self, "weight_decay"):
+            if not isinstance(self.weight_decay, (int, float)) or self.weight_decay < 0:
+                raise TypeError("weight_decay must be a non-negative float.")
+
+        if hasattr(self, "max_rule"):
+            if self.max_rule is not None and (
+                not isinstance(self.max_rule, int) or self.max_rule <= 0
+            ):
+                raise TypeError("max_rule must be a positive integer or None.")
+
+        if hasattr(self, "patience"):
+            if not isinstance(self.patience, int) or self.patience <= 0:
+                raise TypeError("patience must be a positive integer.")
+
+        if hasattr(self, "device"):
+            valid_devices = ["cuda", "cpu"]
+            if not isinstance(self.device, str) or self.device not in valid_devices:
+                raise ValueError(f"solver_type must be one of {valid_devices}.")
+
+        if self.use_sparse:
+            warnings.warn(
+                "A sparse data format is being used. If your dataset is not sufficiently "
+                "large, using a sparse format could lead to performance issues.",
+            )
```

## ruleopt/solver/cplex_solver.py

```diff
@@ -1,127 +1,129 @@
-from typing import Tuple
-import numpy as np
-from scipy.sparse import csr_matrix
-from ..utils import check_module_available
-from .base import OptimizationSolver
-
-CPLEX_AVAILABLE = check_module_available("docplex")
-
-
-class CPLEXSolver(OptimizationSolver):
-    """
-    A solver wrapper function for linear optimization using the proprietary CPLEX optimizer.
-
-    The solver supports both dense and sparse matrix representations.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not CPLEX_AVAILABLE:
-            raise ImportError(
-                "CPLEX is required for this class but is not installed.",
-                "Please install it with 'pip install docplex cplex'",
-            )
-        instance = super(CPLEXSolver, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        penalty: float = 2.0,
-        use_sparse: bool = False,
-    ) -> None:
-        """
-        Parameters
-        ----------
-        penalty : float, default=2.0
-            Penalty parameter for the cost in the objective function.
-        use_sparse : bool, default=False
-            Determines whether to use a sparse matrix representation for the optimization
-            problem. Using sparse matrices can significantly reduce memory usage and improve
-            performance for large-scale problems with many zeros in the data.
-        """
-        self.penalty = penalty
-        self.use_sparse = use_sparse
-        super().__init__()
-        super()._check_params()
-
-    def __call__(
-        self,
-        coefficients,
-        k: int,
-        sample_weight,
-        ws0: np.ndarray = None,
-        *args,
-        **kwargs
-    ) -> Tuple[np.ndarray, np.ndarray]:
-        """
-        Parameters
-        ----------
-        coefficients : object
-            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
-            and costs associated with each rule ('costs').
-        k : float
-            A scaling factor for the coefficients.
-        ws0 : array-like, optional
-            Initial weights for the optimization process. If provided, should have the same
-            length as the number of rules. Otherwise, weights are initialized to ones.
-
-        Returns
-        -------
-        ws : numpy.ndarray
-            The optimal weights for each rule.
-        betas : numpy.ndarray
-            The optimal dual solution.
-        """
-        ### LAZY IMPORT
-        from docplex.mp.model import Model
-
-        a_hat = csr_matrix(
-            (
-                coefficients.yvals,
-                (coefficients.rows, coefficients.cols),
-            ),
-            dtype=np.float64,
-        ) * ((k - 1.0) / k)
-
-        if not self.use_sparse:
-            a_hat = a_hat.toarray()
-
-        costs = np.array(coefficients.costs, copy=False)
-
-        n, m = a_hat.shape
-        # Primal Model
-        modprimal = Model("RUXG Primal")
-
-        # Variables
-        vs = modprimal.continuous_var_list(n, name="vs")
-        ws = modprimal.continuous_var_list(m, name="ws")
-
-        # Set initial values
-        initial_values = []
-
-        if ws0 is not None:
-            initial_values += [(ws[i], ws0[i]) for i in range(len(ws0))]
-
-        # Assign initial solution
-        modprimal.start = initial_values
-
-        # Objective
-        modprimal.minimize(
-            modprimal.sum(vs)
-            if sample_weight is None
-            else modprimal.sum(vs * sample_weight)
-            + modprimal.scal_prod(ws, costs * self.penalty)
-        )
-        # Constraints
-        for i in range(n):
-            modprimal.add_constraint(
-                modprimal.sum(a_hat[i, j] * ws[j] for j in range(m)) + vs[i] >= 1.0
-            )
-
-        modprimal.solve()
-
-        betas = np.array(
-            [c.dual_value for c in modprimal.iter_constraints()], dtype=np.float64
-        )
-        ws = np.array([v.solution_value for v in ws], dtype=np.float64)
-
-        return ws, betas
+from typing import Tuple
+import numpy as np
+from scipy.sparse import csr_matrix
+from ..utils import check_module_available
+from .base import OptimizationSolver
+
+CPLEX_AVAILABLE = check_module_available("docplex")
+
+
+class CPLEXSolver(OptimizationSolver):
+    """
+    A solver wrapper function for linear optimization using the proprietary CPLEX optimizer.
+
+    The solver supports both dense and sparse matrix representations.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not CPLEX_AVAILABLE:
+            raise ImportError(
+                "CPLEX is required for this class but is not installed.",
+                "Please install it with 'pip install docplex cplex'",
+            )
+        instance = super(CPLEXSolver, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        penalty: float = 2.0,
+        use_sparse: bool = False,
+    ) -> None:
+        """
+        Parameters
+        ----------
+        penalty : float, default=2.0
+            Penalty parameter for the cost in the objective function.
+        use_sparse : bool, default=False
+            Determines whether to use a sparse matrix representation for the optimization
+            problem. Using sparse matrices can significantly reduce memory usage and improve
+            performance for large-scale problems with many zeros in the data.
+        """
+        self.penalty = penalty
+        self.use_sparse = use_sparse
+        super().__init__()
+        super()._check_params()
+
+    def __call__(
+        self,
+        coefficients,
+        k: int,
+        sample_weight,
+        ws0: np.ndarray = None,
+        *args,
+        **kwargs,
+    ) -> Tuple[np.ndarray, np.ndarray]:
+        """
+        Parameters
+        ----------
+        coefficients : object
+            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
+            and costs associated with each rule ('costs').
+        k : float
+            A scaling factor for the coefficients.
+        ws0 : array-like, optional
+            Initial weights for the optimization process. If provided, should have the same
+            length as the number of rules. Otherwise, weights are initialized to ones.
+
+        Returns
+        -------
+        ws : numpy.ndarray
+            The optimal weights for each rule.
+        betas : numpy.ndarray
+            The optimal dual solution.
+        """
+        ### LAZY IMPORT
+        from docplex.mp.model import Model
+
+        a_hat = csr_matrix(
+            (
+                coefficients.yvals,
+                (coefficients.rows, coefficients.cols),
+            ),
+            dtype=np.float64,
+        ) * ((k - 1.0) / k)
+
+        if not self.use_sparse:
+            a_hat = a_hat.toarray()
+
+        costs = np.array(coefficients.costs, copy=False)
+
+        n, m = a_hat.shape
+        # Primal Model
+        modprimal = Model("RUXG Primal")
+
+        # Variables
+        vs = modprimal.continuous_var_list(n, name="vs")
+        ws = modprimal.continuous_var_list(m, name="ws")
+
+        # Set initial values
+        initial_values = []
+
+        if ws0 is not None:
+            initial_values += [(ws[i], ws0[i]) for i in range(len(ws0))]
+
+        # Assign initial solution
+        modprimal.start = initial_values
+
+        # Objective
+        modprimal.minimize(
+            (
+                modprimal.sum(vs)
+                if sample_weight is None
+                else modprimal.sum(vs * sample_weight)
+            )
+            + modprimal.scal_prod(ws, costs * self.penalty)
+        )
+        # Constraints
+        for i in range(n):
+            modprimal.add_constraint(
+                modprimal.sum(a_hat[i, j] * ws[j] for j in range(m)) + vs[i] >= 1.0
+            )
+
+        modprimal.solve()
+
+        betas = np.array(
+            [c.dual_value for c in modprimal.iter_constraints()], dtype=np.float64
+        )
+        ws = np.array([v.solution_value for v in ws], dtype=np.float64)
+
+        return ws, betas
```

## ruleopt/solver/gurobi_solver.py

```diff
@@ -1,120 +1,119 @@
-from typing import Tuple
-import numpy as np
-from scipy.sparse import csr_matrix
-from ..utils import check_module_available
-from .base import OptimizationSolver
-
-GUROBI_AVAILABLE = check_module_available("gurobipy")
-
-
-class GurobiSolver(OptimizationSolver):
-    """
-    A solver wrapper function for linear optimization using the proprietary Gurobi optimizer.
-
-    The solver supports both dense and sparse matrix representations.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not GUROBI_AVAILABLE:
-            raise ImportError(
-                "Gurobi is required for this class but is not installed.",
-                "Please install it with 'pip install gurobipy'",
-            )
-        instance = super(GurobiSolver, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        penalty: float = 2.0,
-        use_sparse: bool = False,
-    ) -> None:
-        """
-        Parameters
-        ----------
-        penalty : float, default=2.0
-            Penalty parameter for the cost in the objective function.
-
-        use_sparse : bool, default=False
-            Determines whether to use a sparse matrix representation for the optimization
-            problem. Using sparse matrices can significantly reduce memory usage and improve
-            performance for large-scale problems with many zeros in the data.
-        """
-        self.penalty = penalty
-        self.use_sparse = use_sparse
-        super().__init__()
-        super()._check_params()
-
-    def __call__(
-        self,
-        coefficients,
-        k: int,
-        sample_weight,
-        ws0: np.ndarray = None,
-        *args,
-        **kwargs,
-    ) -> Tuple[np.ndarray, np.ndarray]:
-        """
-        Parameters
-        ----------
-        coefficients : object
-            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
-            and costs associated with each rule ('costs').
-        k : float
-            A scaling factor for the coefficients.
-        ws0 : array-like, optional
-            Initial weights for the optimization process. If provided, should have the same
-            length as the number of rules. Otherwise, weights are initialized to ones.
-
-        Returns
-        -------
-        ws : numpy.ndarray
-            The optimized weights for each rule after the optimization process.
-        betas : numpy.ndarray
-            The betas values indicating constraint violations for the optimized solution.
-        """
-        ### LAZY IMPORT
-        from gurobipy import Model, GRB
-
-        a_hat = csr_matrix(
-            (
-                coefficients.yvals,
-                (coefficients.rows, coefficients.cols),
-            ),
-            dtype=np.float64,
-        ) * ((k - 1.0) / k)
-
-        if not self.use_sparse:
-            a_hat = a_hat.toarray()
-
-        costs = np.array(coefficients.costs, copy=False)
-
-        n, m = a_hat.shape
-
-        modprimal = Model("RUG Primal")
-        modprimal.setParam("OutputFlag", False)
-        # Variables
-        vs = modprimal.addMVar(shape=int(n), name="vs")
-        ws = modprimal.addMVar(shape=int(m), name="ws")
-
-        if ws0 is not None:
-            tempws = np.zeros(m)
-            tempws[: len(ws0)] = ws0
-            ws.setAttr("Start", tempws)
-            modprimal.update()
-        # Objective
-        modprimal.setObjective(
-            (
-                np.ones(n) @ vs
-                if sample_weight is None
-                else sample_weight @ vs + (costs * self.penalty) @ ws
-            ),
-            GRB.MINIMIZE,
-        )
-        # Constraints
-        modprimal.addConstr(a_hat @ ws + vs >= 1.0, name="a_hat Constraints")
-
-        modprimal.optimize()
-
-        betas = np.array(modprimal.getAttr(GRB.Attr.Pi)[:n])
-
-        return ws.X, betas
+from typing import Tuple
+import numpy as np
+from scipy.sparse import csr_matrix
+from ..utils import check_module_available
+from .base import OptimizationSolver
+
+GUROBI_AVAILABLE = check_module_available("gurobipy")
+
+
+class GurobiSolver(OptimizationSolver):
+    """
+    A solver wrapper function for linear optimization using the proprietary Gurobi optimizer.
+
+    The solver supports both dense and sparse matrix representations.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not GUROBI_AVAILABLE:
+            raise ImportError(
+                "Gurobi is required for this class but is not installed.",
+                "Please install it with 'pip install gurobipy'",
+            )
+        instance = super(GurobiSolver, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        penalty: float = 2.0,
+        use_sparse: bool = False,
+    ) -> None:
+        """
+        Parameters
+        ----------
+        penalty : float, default=2.0
+            Penalty parameter for the cost in the objective function.
+
+        use_sparse : bool, default=False
+            Determines whether to use a sparse matrix representation for the optimization
+            problem. Using sparse matrices can significantly reduce memory usage and improve
+            performance for large-scale problems with many zeros in the data.
+        """
+        self.penalty = penalty
+        self.use_sparse = use_sparse
+        super().__init__()
+        super()._check_params()
+
+    def __call__(
+        self,
+        coefficients,
+        k: int,
+        sample_weight,
+        ws0: np.ndarray = None,
+        *args,
+        **kwargs,
+    ) -> Tuple[np.ndarray, np.ndarray]:
+        """
+        Parameters
+        ----------
+        coefficients : object
+            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
+            and costs associated with each rule ('costs').
+        k : float
+            A scaling factor for the coefficients.
+        ws0 : array-like, optional
+            Initial weights for the optimization process. If provided, should have the same
+            length as the number of rules. Otherwise, weights are initialized to ones.
+
+        Returns
+        -------
+        ws : numpy.ndarray
+            The optimized weights for each rule after the optimization process.
+        betas : numpy.ndarray
+            The betas values indicating constraint violations for the optimized solution.
+        """
+        ### LAZY IMPORT
+        from gurobipy import Model, GRB
+
+        a_hat = csr_matrix(
+            (
+                coefficients.yvals,
+                (coefficients.rows, coefficients.cols),
+            ),
+            dtype=np.float64,
+        ) * ((k - 1.0) / k)
+
+        if not self.use_sparse:
+            a_hat = a_hat.toarray()
+
+        costs = np.array(coefficients.costs, copy=False)
+
+        n, m = a_hat.shape
+
+        modprimal = Model("RUG Primal")
+        modprimal.setParam("OutputFlag", False)
+        # Variables
+        vs = modprimal.addMVar(shape=int(n), name="vs")
+        ws = modprimal.addMVar(shape=int(m), name="ws")
+
+        if ws0 is not None:
+            tempws = np.zeros(m)
+            tempws[: len(ws0)] = ws0
+            ws.setAttr("Start", tempws)
+            modprimal.update()
+        # Objective
+        modprimal.setObjective(
+            (
+                (np.ones(n) @ vs if sample_weight is None else sample_weight @ vs)
+                + (costs * self.penalty) @ ws
+            ),
+            GRB.MINIMIZE,
+        )
+        # Constraints
+        modprimal.addConstr(a_hat @ ws + vs >= 1.0, name="a_hat Constraints")
+
+        modprimal.optimize()
+
+        betas = np.array(modprimal.getAttr(GRB.Attr.Pi)[:n])
+
+        return ws.X, betas
```

## ruleopt/solver/ortools_solver.py

```diff
@@ -1,144 +1,145 @@
-from typing import Any
-from scipy.sparse import csr_matrix
-import numpy as np
-from ..utils import check_module_available
-from .base import OptimizationSolver
-
-
-ORTOOLS_AVAILABLE = check_module_available("ortools")
-
-
-class ORToolsSolver(OptimizationSolver):
-    """
-    A solver for linear optimization problems using the Google OR-Tools linear solver.
-
-    This solver can handle large-scale linear programming problems by interfacing with
-    various backend solvers such as CLP, GLOP, and proprietary solvers like Gurobi and CPLEX.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not ORTOOLS_AVAILABLE:
-            raise ImportError(
-                "OR-Tools is required for this class but is not installed.",
-                "Please install it with 'pip install ortools'",
-            )
-        instance = super(ORToolsSolver, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        penalty: float = 2.0,
-        solver_type: str = "GLOP",
-        use_sparse: bool = False,
-    ) -> None:
-        """
-        Parameters
-        ----------
-        penalty : float, default=2.0
-            Penalty parameter for the cost in the objective function.
-
-        solver_type : {"CLP", "GLOP", "GUROBI_LP", "CPLEX_LP", "XPRESS_LP", "GLPK_LP", "HiGHS"}, default="GLOP"
-            The type of Linear Programming solver to use.
-
-        use_sparse : bool, default=False
-            Determines whether to use a sparse matrix representation for the optimization
-            problem. Using sparse matrices can significantly reduce memory usage and improve
-            performance for large-scale problems with many zeros in the data.
-        """
-        self.solver_type = solver_type
-        self.penalty = penalty
-        self.use_sparse = use_sparse
-        super().__init__()
-        super()._check_params()
-
-    def __call__(self, coefficients, k, sample_weight, *args, **kwargs) -> Any:
-        """
-        Solves a linear optimization problem with the given coefficients and penalty.
-
-        Parameters
-        ----------
-        coefficients : object
-            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
-            and costs associated with each rule ('costs').
-        k : float
-            A scaling factor for the coefficients.
-
-        Returns
-        -------
-        ws : numpy.ndarray
-            The optimized weights for each rule after the optimization process.
-        betas : numpy.ndarray
-            The betas values indicating constraint violations for the optimized solution.
-
-        Raises
-        ------
-        ValueError
-            If the specified solver type is not supported or not linked correctly.
-        """
-        ### LAZY IMPORT
-        from ortools.linear_solver.pywraplp import Solver
-
-        a_hat = csr_matrix(
-            (
-                coefficients.yvals,
-                (coefficients.rows, coefficients.cols),
-            ),
-            dtype=np.float64,
-        ) * ((k - 1.0) / k)
-
-        if not self.use_sparse:
-            a_hat = a_hat.toarray()
-
-        n, m = a_hat.shape
-
-        solver = Solver.CreateSolver(self.solver_type)
-
-        if solver is None:
-            raise ValueError(
-                f"Support for {self.solver_type} not linked in, or the license ",
-                "was not found.",
-            )
-
-        # Variables
-        vs = [solver.NumVar(0, solver.infinity(), f"vs[{i}]") for i in range(n)]
-        ws = [solver.NumVar(0, solver.infinity(), f"ws[{i}]") for i in range(m)]
-
-        # Objective
-        objective_terms = (
-            [vs[i] for i in range(n)]
-            if sample_weight is None
-            else [vs[i] * sample_weight[i] for i in range(n)]
-            + [self.penalty * coefficients.costs[i] * ws[i] for i in range(m)]
-        )
-        solver.Minimize(solver.Sum(objective_terms))
-
-        # Constraints and storing them for dual value access
-        constraints = []
-        for i in range(n):
-            constraint = solver.Add(
-                solver.Sum([a_hat[i, j] * ws[j] for j in range(m)]) + vs[i] >= 1
-            )
-            constraints.append(constraint)
-
-        solver.Solve()
-
-        ws = np.array([ws[j].solution_value() for j in range(m)])
-        betas = np.array([constraint.dual_value() for constraint in constraints])
-
-        return ws, betas
-
-    def _validate_parameters(self, solver_type, penalty_parameter):
-        valid_solvers = [
-            "CLP",
-            "GLOP",
-            "GUROBI_LP",
-            "CPLEX_LP",
-            "XPRESS_LP",
-            "GLPK_LP",
-            "HiGHS",
-        ]
-        if not isinstance(solver_type, str) or solver_type not in valid_solvers:
-            raise ValueError(f"solver_type must be one of {valid_solvers}.")
-
-        if not isinstance(penalty_parameter, (float, int)) or penalty_parameter <= 0:
-            raise ValueError("penalty_parameter must be a positive float or integer.")
+from typing import Any
+from scipy.sparse import csr_matrix
+import numpy as np
+from ..utils import check_module_available
+from .base import OptimizationSolver
+
+
+ORTOOLS_AVAILABLE = check_module_available("ortools")
+
+
+class ORToolsSolver(OptimizationSolver):
+    """
+    A solver for linear optimization problems using the Google OR-Tools linear solver.
+
+    This solver can handle large-scale linear programming problems by interfacing with
+    various backend solvers such as CLP, GLOP, and proprietary solvers like Gurobi and CPLEX.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not ORTOOLS_AVAILABLE:
+            raise ImportError(
+                "OR-Tools is required for this class but is not installed.",
+                "Please install it with 'pip install ortools'",
+            )
+        instance = super(ORToolsSolver, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        penalty: float = 2.0,
+        solver_type: str = "GLOP",
+        use_sparse: bool = False,
+    ) -> None:
+        """
+        Parameters
+        ----------
+        penalty : float, default=2.0
+            Penalty parameter for the cost in the objective function.
+
+        solver_type : {"CLP", "GLOP", "GUROBI_LP", "CPLEX_LP", "XPRESS_LP", "GLPK_LP", "HiGHS"}, default="GLOP"
+            The type of Linear Programming solver to use.
+
+        use_sparse : bool, default=False
+            Determines whether to use a sparse matrix representation for the optimization
+            problem. Using sparse matrices can significantly reduce memory usage and improve
+            performance for large-scale problems with many zeros in the data.
+        """
+        self.solver_type = solver_type
+        self.penalty = penalty
+        self.use_sparse = use_sparse
+        super().__init__()
+        super()._check_params()
+
+    def __call__(self, coefficients, k, sample_weight, *args, **kwargs) -> Any:
+        """
+        Solves a linear optimization problem with the given coefficients and penalty.
+
+        Parameters
+        ----------
+        coefficients : object
+            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
+            and costs associated with each rule ('costs').
+        k : float
+            A scaling factor for the coefficients.
+
+        Returns
+        -------
+        ws : numpy.ndarray
+            The optimized weights for each rule after the optimization process.
+        betas : numpy.ndarray
+            The betas values indicating constraint violations for the optimized solution.
+
+        Raises
+        ------
+        ValueError
+            If the specified solver type is not supported or not linked correctly.
+        """
+        ### LAZY IMPORT
+        from ortools.linear_solver.pywraplp import Solver
+
+        a_hat = csr_matrix(
+            (
+                coefficients.yvals,
+                (coefficients.rows, coefficients.cols),
+            ),
+            dtype=np.float64,
+        ) * ((k - 1.0) / k)
+
+        if not self.use_sparse:
+            a_hat = a_hat.toarray()
+
+        n, m = a_hat.shape
+
+        costs = np.array(coefficients.costs, dtype=np.float32)
+
+        solver = Solver.CreateSolver(self.solver_type)
+
+        if solver is None:
+            raise ValueError(
+                f"Support for {self.solver_type} not linked in, or the license ",
+                "was not found.",
+            )
+
+        # Variables
+        vs = [solver.NumVar(0, solver.infinity(), f"vs[{i}]") for i in range(n)]
+        ws = [solver.NumVar(0, solver.infinity(), f"ws[{i}]") for i in range(m)]
+
+        # Objective
+        objective_terms = (
+            [vs[i] for i in range(n)]
+            if sample_weight is None
+            else [vs[i] * sample_weight[i] for i in range(n)]
+        ) + [self.penalty * costs[i] * ws[i] for i in range(m)]
+        solver.Minimize(solver.Sum(objective_terms))
+
+        # Constraints and storing them for dual value access
+        constraints = []
+        for i in range(n):
+            constraint = solver.Add(
+                solver.Sum([a_hat[i, j] * ws[j] for j in range(m)]) + vs[i] >= 1
+            )
+            constraints.append(constraint)
+
+        solver.Solve()
+
+        ws = np.array([ws[j].solution_value() for j in range(m)])
+        betas = np.array([constraint.dual_value() for constraint in constraints])
+
+        return ws, betas
+
+    def _validate_parameters(self, solver_type, penalty_parameter):
+        valid_solvers = [
+            "CLP",
+            "GLOP",
+            "GUROBI_LP",
+            "CPLEX_LP",
+            "XPRESS_LP",
+            "GLPK_LP",
+            "HiGHS",
+        ]
+        if not isinstance(solver_type, str) or solver_type not in valid_solvers:
+            raise ValueError(f"solver_type must be one of {valid_solvers}.")
+
+        if not isinstance(penalty_parameter, (float, int)) or penalty_parameter <= 0:
+            raise ValueError("penalty_parameter must be a positive float or integer.")
```

## ruleopt/solver/unc_solver.py

```diff
@@ -1,259 +1,269 @@
-import numpy as np
-from scipy.sparse import csr_matrix
-from ..utils import check_module_available
-from .base import OptimizationSolver
-
-TORCH_AVAILABLE = check_module_available("torch")
-
-
-class _TorchSolverManager:
-    _torch_solver_class = None
-
-    @staticmethod
-    def _initialize_torch_solver():
-
-        from torch import ones, topk, relu, zeros_like, sum, matmul
-        from torch.nn import Module, Parameter
-
-        class _TorchSolver(Module):
-            """
-            A solver module for using PyTorch.
-
-            This module is designed to solve optimization problems with a specific structure,
-            leveraging the PyTorch framework for gradient-based optimization.
-
-            Attributes:
-                max_rule (int): The maximum number of rules to be selected.
-                ws (torch.nn.Parameter): Weights associated with each rule.
-                gates (torch.nn.Parameter): Gate parameters to control rule selection.
-                vs (torch.nn.Parameter): Slack variables for handling constraints.
-                penalty (float): Penalty parameter for the objective function.
-                a_hat (torch.Tensor): Coefficient matrix after processing.
-                costs (torch.Tensor): Cost associated with each rule.
-            """
-
-            def __init__(self, m, penalty, costs, k, max_rule=None, sample_weight=None):
-                """
-                Initializes the Solver with given parameters and coefficients.
-
-                Parameters:
-                    m (int): Number of rules.
-                    penalty (float): Penalty parameter for the cost in the objective function.
-                    coefficients (object): An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
-                                            and costs associated with each rule ('costs').
-                    k (float): A scaling factor for the coefficients.
-                    max_rule (int): The maximum number of rules to be selected.
-                """
-                super().__init__()
-                self.max_rule = max_rule if max_rule is not None else float("inf")
-
-                self.ws = Parameter(ones(m, requires_grad=True))
-
-                self.sample_weight = sample_weight
-
-                self.penalty = penalty
-
-                self.costs = costs
-
-                self.k = k
-
-                self.m = m
-
-            def forward(self, a_hat):
-                """
-                Defines the forward pass for the optimization problem.
-
-                Performs the selection of rules based on the weighted gates, calculates the
-                objective function, and applies penalties for constraint violations.
-
-                Returns:
-                    torch.Tensor: The total loss comprising the objective function and penalties for constraint violations.
-                """
-                if self.max_rule < self.m:
-                    _, indices = topk(self.ws, self.max_rule, sorted=False)
-                    selected_weights = zeros_like(self.ws)
-                    selected_weights.index_fill_(0, indices, 1)
-                    ws = relu(self.ws) * selected_weights
-                else:
-                    ws = relu(self.ws)
-
-                objective_ws = self.penalty * sum(self.costs * ws)
-
-                betas = ((self.k - 1.0) / self.k) * relu(
-                    1 - matmul(a_hat, ws.unsqueeze(-1)).squeeze()
-                )
-
-                if self.sample_weight is not None:
-                    betas = betas * self.sample_weight
-
-                betas_penalty = sum(betas)
-
-                total_loss = objective_ws + betas_penalty
-
-                inspection_values = {
-                    "betas": betas,
-                    "ws": ws,
-                }
-
-                return total_loss, inspection_values
-
-        return _TorchSolver
-
-    @classmethod
-    def get_torch_solver(cls, *args, **kwargs):
-        if cls._torch_solver_class is None:
-            cls._torch_solver_class = cls._initialize_torch_solver()
-        return cls._torch_solver_class(*args, **kwargs)
-
-
-class UNCSolver(OptimizationSolver):
-    """
-    A gradient descent solver for optimization problems, leveraging PyTorch for gradient-based optimization.
-
-    This solver iteratively updates parameters to minimize an objective function, applying penalties
-    for constraint violations. It utilizes a gradient descent approach with early stopping based on
-    a patience parameter to prevent overfitting.
-    """
-
-    def __new__(cls, *args, **kwargs):
-        if not TORCH_AVAILABLE:
-            raise ImportError(
-                "PyTorch is required for this class but is not installed.",
-                "Please install it with 'pip install pytorch'",
-            )
-        instance = super(UNCSolver, cls).__new__(cls)
-        return instance
-
-    def __init__(
-        self,
-        penalty: float = 2.0,
-        lr: float = 0.01,
-        weight_decay: float = 0.1,
-        max_rule: int | None = None,
-        patience: int = 100,
-        device: str = "cpu",
-        use_sparse: bool = False,
-    ) -> None:
-        """
-        Parameters
-        ----------
-        penalty : float, default=2.0
-            Penalty parameter for the cost in the objective function.
-        lr : float, default=0.01
-            Learning rate for the Adam optimizer.
-        weight_decay : float, default=0.01
-            Weight decay (L2 penalty) for the optimizer.
-        max_rule : int or None, default=None
-            Maximum number of rules to be selected. If None, no limit is applied.
-        patience : int, default=100
-            Number of iterations to wait for an improvement before stopping the optimization.
-        device : {"cuda", "cpu"}, default="cpu"
-            The device on which to perform computations.
-        use_sparse : bool, default=False
-            Determines whether to use a sparse matrix representation for the optimization
-            problem. Using sparse matrices can significantly reduce memory usage and improve
-            performance for large-scale problems with many zeros in the data.
-        """
-        self.penalty = penalty
-        self.lr = lr
-        self.weight_decay = weight_decay
-        self.max_rule = max_rule
-        self.patience = patience
-        self.device = device
-        self.use_sparse = use_sparse
-        super().__init__()
-        super()._check_params()
-
-    def __call__(self, coefficients, k, sample_weight=None, *args, **kwargs):
-        """
-        Executes the heuristic optimization process on given problem coefficients.
-
-        Parameters
-        ----------
-        coefficients : object
-            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
-            and costs associated with each rule ('costs').
-
-        k : float
-            A scaling factor for the coefficients.
-
-        Returns
-        -------
-        ws : numpy.ndarray
-            The optimized weights for each rule after the optimization process.
-        betas : numpy.ndarray
-            The betas values indicating constraint violations for the optimized solution.
-        """
-        ### LAZY IMPORT
-        from torch import tensor, sparse_csr_tensor, from_numpy, float32
-        from torch.optim import Adam
-        from torch.optim.lr_scheduler import ReduceLROnPlateau
-
-        a_hat = csr_matrix(
-            (
-                coefficients.yvals,
-                (coefficients.rows, coefficients.cols),
-            ),
-            dtype=np.float64,
-        ) * ((k - 1.0) / k)
-
-        if not self.use_sparse:
-            a_hat = tensor(a_hat.toarray(), dtype=float32, device=self.device)
-
-        else:
-            a_hat = sparse_csr_tensor(
-                from_numpy(a_hat.indptr),
-                from_numpy(a_hat.indices),
-                from_numpy(a_hat.data),
-                dtype=float32,
-                device=self.device,
-            )
-
-        if sample_weight is not None:
-            sample_weight = tensor(sample_weight, dtype=float32)
-
-        costs = tensor(coefficients.costs, dtype=float32, device=self.device)
-
-        m = a_hat.shape[1]
-
-        solver = _TorchSolverManager.get_torch_solver(
-            m=m,
-            k=k,
-            penalty=self.penalty,
-            costs=costs,
-            max_rule=self.max_rule,
-            sample_weight=sample_weight,
-        ).to(self.device)
-
-        optimizer = Adam(
-            solver.parameters(), lr=self.lr, weight_decay=self.weight_decay
-        )
-        scheduler = ReduceLROnPlateau(
-            optimizer, "min", factor=0.1, patience=self.patience // 4
-        )
-
-        best_loss = float("inf")
-        counter = 0
-
-        ws = None
-        betas = None
-
-        while True:
-            optimizer.zero_grad()
-            loss, inspection_values = solver(a_hat)
-            loss.backward()
-            optimizer.step()
-
-            scheduler.step(loss)
-
-            if loss.item() < best_loss:
-                best_loss = loss.item()
-                ws = inspection_values.get("ws").detach().cpu().numpy()
-                betas = inspection_values.get("betas").detach().cpu().numpy()
-                counter = 0
-            else:
-                counter += 1
-                if counter > self.patience:
-                    break
-
-        return ws, np.where(betas <= 1.0e-4, 0, betas)
+import numpy as np
+from scipy.sparse import csr_matrix
+from ..utils import check_module_available
+from .base import OptimizationSolver
+
+TORCH_AVAILABLE = check_module_available("torch")
+
+
+class _TorchSolverManager:
+    _torch_solver_class = None
+
+    @staticmethod
+    def _initialize_solver():
+        from torch import ones, topk, relu, zeros_like, sum, matmul, clip
+        from torch.nn import Module, Parameter
+
+        class _TorchSolver(Module):
+            """
+            A solver module for using PyTorch.
+
+            This module is designed to solve optimization problems with a specific structure,
+            leveraging the PyTorch framework for gradient-based optimization.
+
+            Attributes:
+                max_rule (int): The maximum number of rules to be selected.
+                ws (torch.nn.Parameter): Weights associated with each rule.
+                gates (torch.nn.Parameter): Gate parameters to control rule selection.
+                vs (torch.nn.Parameter): Slack variables for handling constraints.
+                penalty (float): Penalty parameter for the objective function.
+                a_hat (torch.Tensor): Coefficient matrix after processing.
+                costs (torch.Tensor): Cost associated with each rule.
+            """
+
+            def __init__(
+                self, m, n, penalty, costs, k, max_rule=None, sample_weight=None
+            ):
+                """
+                Initializes the Solver with given parameters and coefficients.
+
+                Parameters:
+                    m (int): Number of rules.
+                    penalty (float): Penalty parameter for the cost in the objective function.
+                    coefficients (object): An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
+                                            and costs associated with each rule ('costs').
+                    k (float): A scaling factor for the coefficients.
+                    max_rule (int): The maximum number of rules to be selected.
+                """
+                super().__init__()
+                self.max_rule = max_rule if max_rule is not None else float("inf")
+
+                self.ws = Parameter(ones(m, requires_grad=True) * 0.5)
+
+                self.betas = Parameter(ones(n, requires_grad=True) * 0.5)
+
+                self.sample_weight = sample_weight
+
+                self.penalty = penalty
+
+                self.costs = costs
+
+                self.k = k
+
+                self.m = m
+
+            def forward(self, a_hat):
+                """
+                Defines the forward pass for the optimization problem.
+
+                Performs the selection of rules based on the weighted gates, calculates the
+                objective function, and applies penalties for constraint violations.
+
+                Returns:
+                    torch.Tensor: The total loss comprising the objective function and penalties for constraint violations.
+                """
+                if self.max_rule < self.m:
+                    _, indices = topk(self.ws, self.max_rule, sorted=False)
+                    selected_weights = zeros_like(self.ws)
+                    selected_weights.index_fill_(0, indices, 1)
+                    ws = relu(self.ws) * selected_weights
+                else:
+                    ws = relu(self.ws)
+
+                betas = clip(self.betas, min=0, max=1)
+
+                vs = relu(1 - matmul(a_hat, ws.unsqueeze(-1)).squeeze())
+
+                if self.sample_weight is not None:
+                    vs = vs * self.sample_weight
+
+                primal_objective = self.penalty * sum(self.costs * ws) + sum(vs)
+
+                dual_constraint_violation = relu(
+                    matmul(a_hat.t(), betas.unsqueeze(-1)).squeeze()
+                    - self.costs * self.penalty
+                )
+
+                dual_objective = sum(betas)
+
+                total_loss = (
+                    primal_objective
+                    - dual_objective
+                    - sum((betas - 0.5).pow(2))
+                    + (primal_objective - dual_objective).pow(2)
+                    + sum(dual_constraint_violation) * 10
+                )
+
+                return total_loss
+
+        return _TorchSolver
+
+    @classmethod
+    def get_solver(cls, *args, **kwargs):
+        if cls._torch_solver_class is None:
+            cls._torch_solver_class = cls._initialize_solver()
+        return cls._torch_solver_class(*args, **kwargs)
+
+
+class UNCSolver(OptimizationSolver):
+    """
+    A gradient descent solver for optimization problems, leveraging PyTorch for gradient-based optimization.
+
+    This solver iteratively updates parameters to minimize an objective function, applying penalties
+    for constraint violations. It utilizes a gradient descent approach with early stopping based on
+    a patience parameter to prevent overfitting.
+    """
+
+    def __new__(cls, *args, **kwargs):
+        if not TORCH_AVAILABLE:
+            raise ImportError(
+                "PyTorch is required for this class but is not installed.",
+                "Please install it with 'pip install torch'",
+            )
+        instance = super(UNCSolver, cls).__new__(cls)
+        return instance
+
+    def __init__(
+        self,
+        penalty: float = 2.0,
+        lr: float = 0.01,
+        weight_decay: float = 0.1,
+        max_rule: int | None = None,
+        patience: int = 100,
+        device: str = "cpu",
+        use_sparse: bool = False,
+    ) -> None:
+        """
+        Parameters
+        ----------
+        penalty : float, default=2.0
+            Penalty parameter for the cost in the objective function.
+        lr : float, default=0.01
+            Learning rate for the Adam optimizer.
+        weight_decay : float, default=0.01
+            Weight decay (L2 penalty) for the optimizer.
+        max_rule : int or None, default=None
+            Maximum number of rules to be selected. If None, no limit is applied.
+        patience : int, default=100
+            Number of iterations to wait for an improvement before stopping the optimization.
+        device : {"cuda", "cpu"}, default="cpu"
+            The device on which to perform computations.
+        use_sparse : bool, default=False
+            Determines whether to use a sparse matrix representation for the optimization
+            problem. Using sparse matrices can significantly reduce memory usage and improve
+            performance for large-scale problems with many zeros in the data.
+        """
+        self.penalty = penalty
+        self.lr = lr
+        self.weight_decay = weight_decay
+        self.max_rule = max_rule
+        self.patience = patience
+        self.device = device
+        self.use_sparse = use_sparse
+        super().__init__()
+        super()._check_params()
+
+    def __call__(self, coefficients, k, sample_weight=None, *args, **kwargs):
+        """
+        Executes the heuristic optimization process on given problem coefficients.
+
+        Parameters
+        ----------
+        coefficients : object
+            An object containing the sparse matrix coefficients ('yvals', 'rows', 'cols'),
+            and costs associated with each rule ('costs').
+
+        k : float
+            A scaling factor for the coefficients.
+
+        Returns
+        -------
+        ws : numpy.ndarray
+            The optimized weights for each rule after the optimization process.
+        vs : numpy.ndarray
+            The vs values indicating constraint violations for the optimized solution.
+        """
+        ### LAZY IMPORT
+        from torch import tensor, sparse_csr_tensor, from_numpy, float32, clip
+        from torch.optim import Adam
+        from torch.optim.lr_scheduler import ReduceLROnPlateau
+
+        a_hat = csr_matrix(
+            (
+                coefficients.yvals,
+                (coefficients.rows, coefficients.cols),
+            ),
+            dtype=np.float64,
+        ) * ((k - 1.0) / k)
+
+        if not self.use_sparse:
+            a_hat = tensor(a_hat.toarray(), dtype=float32, device=self.device)
+
+        else:
+            a_hat = sparse_csr_tensor(
+                from_numpy(a_hat.indptr),
+                from_numpy(a_hat.indices),
+                from_numpy(a_hat.data),
+                dtype=float32,
+                device=self.device,
+            )
+
+        if sample_weight is not None:
+            sample_weight = tensor(sample_weight, dtype=float32)
+
+        costs = tensor(coefficients.costs, dtype=float32, device=self.device)
+
+        n, m = a_hat.shape
+
+        solver = _TorchSolverManager.get_solver(
+            m=m,
+            n=n,
+            k=k,
+            penalty=self.penalty,
+            costs=costs,
+            max_rule=self.max_rule,
+            sample_weight=sample_weight,
+        ).to(self.device)
+
+        optimizer = Adam(
+            solver.parameters(), lr=self.lr, weight_decay=self.weight_decay
+        )
+        scheduler = ReduceLROnPlateau(
+            optimizer, "min", factor=0.9, patience=self.patience // 5
+        )
+
+        best_loss = float("inf")
+        counter = 0
+
+        while True:
+            optimizer.zero_grad()
+            loss = solver(a_hat)
+            loss.backward()
+            optimizer.step()
+
+            scheduler.step(loss)
+
+            if loss.item() < best_loss:
+                best_loss = loss.item()
+                ws = solver.ws.clone()
+                betas = solver.betas.clone()
+                counter = 0
+            else:
+                counter += 1
+                if counter > self.patience:
+                    break
+
+        return (
+            clip(ws, min=0).detach().cpu().numpy(),
+            clip(betas, min=0, max=1).detach().cpu().numpy(),
+        )
```

## ruleopt/utils/__init__.py

 * *Ordering differences only*

```diff
@@ -1,5 +1,5 @@
-from .utils import (check_inputs, check_module_available)
-
-__all__ = [
-    "check_inputs",
+from .utils import (check_inputs, check_module_available)
+
+__all__ = [
+    "check_inputs",
     "check_module_available"]
```

## ruleopt/utils/utils.py

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-from typing import Tuple
-from sklearn.utils import check_array
-import numpy as np
-import importlib.util
-    
-def check_inputs(x, y = None) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Validates and preprocesses input data for the model.
-
-    Parameters
-    ----------
-    x : array-like of shape (n_samples, n_features)
-        The training input samples. Internally, it will be converted to dtype=np.float32.
-    y : array-like of shape (n_samples,) or (n_samples, n_outputs)
-        The target values (class labels) as integers
-
-    Returns
-    -------
-    Tuple[np.ndarray, np.ndarray]
-        The validated and preprocessed input matrix `x` and target vector `y`.
-    """
-    x = check_array(np.asarray(x, dtype=np.float32), force_all_finite="allow-nan")
-    if y is not None:
-        y = check_array(np.asarray(y, dtype=np.intp), ensure_2d=False)
-        return x, y
-    return x
-
-
-def check_module_available(module_name):
-    """
-    Checks module is installed.
-    """
-    spec = importlib.util.find_spec(module_name)
+from typing import Tuple
+from sklearn.utils import check_array
+import numpy as np
+import importlib.util
+    
+def check_inputs(x, y = None) -> Tuple[np.ndarray, np.ndarray]:
+    """
+    Validates and preprocesses input data for the model.
+
+    Parameters
+    ----------
+    x : array-like of shape (n_samples, n_features)
+        The training input samples. Internally, it will be converted to dtype=np.float32.
+    y : array-like of shape (n_samples,) or (n_samples, n_outputs)
+        The target values (class labels) as integers
+
+    Returns
+    -------
+    Tuple[np.ndarray, np.ndarray]
+        The validated and preprocessed input matrix `x` and target vector `y`.
+    """
+    x = check_array(np.asarray(x, dtype=np.float32), force_all_finite="allow-nan")
+    if y is not None:
+        y = check_array(np.asarray(y, dtype=np.intp), ensure_2d=False)
+        return x, y
+    return x
+
+
+def check_module_available(module_name):
+    """
+    Checks module is installed.
+    """
+    spec = importlib.util.find_spec(module_name)
     return spec is not None
```

## Comparing `ruleopt-0.1.2.dist-info/LICENSE` & `ruleopt-0.1.3.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-MIT License
-
-Copyright (c) 2024
-
-Ilker Birbil, Nursen Aydin, Ozgür Martin, Samet Copur
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2024
+
+Ilker Birbil, Nursen Aydin, Ozgür Martin, Samet Copur
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

## Comparing `ruleopt-0.1.2.dist-info/METADATA` & `ruleopt-0.1.3.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,94 +1,93 @@
-Metadata-Version: 2.1
-Name: ruleopt
-Version: 0.1.2
-Summary: Optimization Based Rule Learning for Classification
-Author: Nursen Aydin
-Author-email: Ilker Birbil <sibirbil@gmail.com>, Ozgür Martin <ozgurmartin@gmail.com>, Samet Copur <sametcopur@yahoo.com>
-License: MIT License
-Project-URL: Documentation, https://ruleopt.readthedocs.io/
-Project-URL: Repository, https://github.com/sametcopur/ruleopt
-Project-URL: Tracker, https://github.com/sametcopur/ruleopt/issues
-Keywords: python,data-science,machine-learning,linear-programming,machine-learning-library,explainable-ai
-Classifier: Programming Language :: Python :: 3
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Operating System :: OS Independent
-Requires-Python: >=3.9
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: scikit-learn >=1.4.1
-Requires-Dist: numpy >=1.26.4
-Requires-Dist: pandas >=2.2.1
-Requires-Dist: scipy >=1.11.4
-
-# RuleOpt: Optimization-Based Rule Learning for Classification
-
-RuleOpt is a rule-based machine learning algorithm designed for classification problems. Focusing on scalability and interpretability, RuleOpt utilizes optimization algorithms for rule generation and extraction. An earlier version of this work is available in [our manuscript](https://arxiv.org/abs/2104.10751).
-
- The Python library `ruleopt` is capable to extract rules from ensemble models, and it also implements a novel rule generation scheme. The library ensures compatibility with existing machine learning pipelines, and it is especially efficient for tackling large-scale problems.
-
-Here are a few highlights of `ruleopt`:
-
-- **Efficient Rule Generation and Extraction**: Leverages linear programming and gradient descent for scalable rule generation (standalone machine learning method) and rule extraction from trained random forest and boosting models.
-- **Interpretability**: Prioritizes model transparency by assigning costs to rules in order to achieve a desirable balance with accuracy.
-- **Integration with Machine Learning Libraries**: Facilitates smooth integration with well-known Python libraries `scikit-learn`, `LightGBM`, and `XGBoost`, and existing machine learning pipelines.
-- **Extensive Solver Support**: Supports a wide array of solvers, including _Gurobi_, _CPLEX_, _GLPK_, and a `PyTorch`-based _UNCSolver_ designed to scale the algorithm.
-
-### Installation 
-To install `ruleopt`, clone this repository and use pip to install the package:
-
-```bash
-pip install ruleopt
-```
-### Usage
-
-To use `ruleopt`, you need to initialize the `ruleopt` class with your specific parameters and fit it to your data. Here's a basic example:
-
-
-```python
-from sklearn.model_selection import train_test_split
-from sklearn.datasets import load_iris
-
-from ruleopt import RUGClassifier
-from ruleopt.rule_cost import Gini
-from ruleopt.solver import UNCSolver
-
-# Set a random state for reproducibility
-random_state = 42
-
-# Load the Iris dataset
-X, y = load_iris(return_X_y=True)
-
-# Split the dataset into training and testing sets
-X_train, X_test, y_train, y_test = train_test_split(
-    X, y, test_size=0.2, random_state=random_state
-)
-
-# Define tree parameters
-tree_parameters = {"max_depth": 3, "class_weight": "balanced"}
-
-solver = UNCSolver()
-rule_cost = Gini()
-
-# Initialize the RUGClassifier with specific parameters
-rug = RUGClassifier(
-    solver=solver,
-    random_state=random_state,
-    max_rmp_calls=20,
-    rule_cost=rule_cost
-    **tree_parameters,
-)
-
-# Fit the RUGClassifier to the training data
-rug.fit(X_train, y_train)
-
-# Predict the labels of the testing set
-y_pred = rug.predict(X_test)
-```
-### Documentation
-For more detailed information about the API and advanced usage, please refer to the full  [documentation](https://ruleopt.readthedocs.io/en/latest/).
-
-### Contributing
-Contributions are welcome! If you'd like to improve `ruleopt` or suggest new features, feel free to fork the repository and submit a pull request.
-
-### License
-`ruleopt` is released under the MIT License. See the LICENSE file for more details.
+Metadata-Version: 2.1
+Name: ruleopt
+Version: 0.1.3
+Summary: Optimization Based Rule Learning for Classification
+Author-email: Ilker Birbil <sibirbil@gmail.com>, Nursen Aydin <nursenaydin@gmail.com>, Ozgür Martin <ozgurmartin@gmail.com>, Samet Copur <sametcopur@yahoo.com>
+License: MIT License
+Project-URL: Documentation, https://ruleopt.readthedocs.io/
+Project-URL: Repository, https://github.com/sametcopur/ruleopt
+Project-URL: Tracker, https://github.com/sametcopur/ruleopt/issues
+Keywords: python,data-science,machine-learning,linear-programming,machine-learning-library,explainable-ai
+Classifier: Programming Language :: Python :: 3
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: OS Independent
+Requires-Python: >=3.9
+Description-Content-Type: text/markdown
+License-File: LICENSE
+Requires-Dist: scikit-learn >=1.4.1
+Requires-Dist: numpy >=1.26.4
+Requires-Dist: pandas >=2.2.1
+Requires-Dist: scipy >=1.11.4
+
+# RuleOpt: Optimization-Based Rule Learning for Classification
+
+RuleOpt is a rule-based machine learning algorithm designed for classification problems. Focusing on scalability and interpretability, RuleOpt utilizes optimization algorithms for rule generation and extraction. An earlier version of this work is available in [our manuscript](https://arxiv.org/abs/2104.10751).
+
+ The Python library `ruleopt` is capable to extract rules from ensemble models, and it also implements a novel rule generation scheme. The library ensures compatibility with existing machine learning pipelines, and it is especially efficient for tackling large-scale problems.
+
+Here are a few highlights of `ruleopt`:
+
+- **Efficient Rule Generation and Extraction**: Leverages linear programming and gradient descent for scalable rule generation (standalone machine learning method) and rule extraction from trained random forest and boosting models.
+- **Interpretability**: Prioritizes model transparency by assigning costs to rules in order to achieve a desirable balance with accuracy.
+- **Integration with Machine Learning Libraries**: Facilitates smooth integration with well-known Python libraries `scikit-learn`, `LightGBM`, and `XGBoost`, and existing machine learning pipelines.
+- **Extensive Solver Support**: Supports a wide array of solvers, including _Gurobi_, _CPLEX_, _GLPK_, and a `PyTorch`-based _UNCSolver_ designed to scale the algorithm.
+
+### Installation 
+To install `ruleopt`, clone this repository and use pip to install the package:
+
+```bash
+pip install ruleopt
+```
+### Usage
+
+To use `ruleopt`, you need to initialize the `ruleopt` class with your specific parameters and fit it to your data. Here's a basic example:
+
+
+```python
+from sklearn.model_selection import train_test_split
+from sklearn.datasets import load_iris
+
+from ruleopt import RUGClassifier
+from ruleopt.rule_cost import Gini
+from ruleopt.solver import UNCSolver
+
+# Set a random state for reproducibility
+random_state = 42
+
+# Load the Iris dataset
+X, y = load_iris(return_X_y=True)
+
+# Split the dataset into training and testing sets
+X_train, X_test, y_train, y_test = train_test_split(
+    X, y, test_size=0.2, random_state=random_state
+)
+
+# Define tree parameters
+tree_parameters = {"max_depth": 3, "class_weight": "balanced"}
+
+solver = UNCSolver()
+rule_cost = Gini()
+
+# Initialize the RUGClassifier with specific parameters
+rug = RUGClassifier(
+    solver=solver,
+    random_state=random_state,
+    max_rmp_calls=20,
+    rule_cost=rule_cost,
+    **tree_parameters,
+)
+
+# Fit the RUGClassifier to the training data
+rug.fit(X_train, y_train)
+
+# Predict the labels of the testing set
+y_pred = rug.predict(X_test)
+```
+### Documentation
+For more detailed information about the API and advanced usage, please refer to the full  [documentation](https://ruleopt.readthedocs.io/en/latest/).
+
+### Contributing
+Contributions are welcome! If you'd like to improve `ruleopt` or suggest new features, feel free to fork the repository and submit a pull request.
+
+### License
+`ruleopt` is released under the MIT License. See the LICENSE file for more details.
```

## Comparing `ruleopt-0.1.2.dist-info/RECORD` & `ruleopt-0.1.3.dist-info/RECORD`

 * *Files 26% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-ruleopt/__init__.py,sha256=4IfJMKA1Ej57JEvfEktQXc0zMXgkqpmWSMDKOe7cfyE,257
-ruleopt/aux_classes/__init__.py,sha256=UGkt4gSK-CxEorj-BOxOVGu36HvPbUfYN5OeZSy2vp4,96
-ruleopt/aux_classes/aux_classes.c,sha256=THsoeSSjobN21UPS2MJlJyt-rnsa9xgnGaqMe5jazOY,1367569
-ruleopt/aux_classes/aux_classes.cp39-win_amd64.pyd,sha256=i8vgnqAfB-mYySeFyQnz-giv2QEqZoTNd5hyzUWmA3s,206848
-ruleopt/estimator/__init__.py,sha256=8SIFO2ba0bwOdMUxQjdnwHlbsj_OhnZ0cGipMq8XMV0,280
-ruleopt/estimator/base.py,sha256=X7YYnTJgf9EUpG0YfH4u4i20-Zh_lovzjtpzXXOELOs,26086
-ruleopt/estimator/lightgbm_.py,sha256=xlF0ylat2NgKg3QL4488YFrfALTTgWDGDBCxzlUewpc,12714
-ruleopt/estimator/xgboost_.py,sha256=9L9ormW460jLWcr37P8R33_TGifPLQcCMsVExGk3NbM,11558
-ruleopt/estimator/sklearn_/__init__.py,sha256=vpPehVjHJuFZgWiq2vuI6WADan_84Vqnw2CcmAYXYQQ,126
-ruleopt/estimator/sklearn_/base_sklearn.py,sha256=I16mb0j61TGgpxO2D0TWjJnqbwO7Pqtw_2M-_H4RWPU,6845
-ruleopt/estimator/sklearn_/rug.py,sha256=vdymlcTZDDBSCZB59NEGLmzWwf7QyvBjrzjO9bYaG-w,21519
-ruleopt/estimator/sklearn_/rux.py,sha256=H4bmlGaX_3GkDyM1voYlAy_o1AkJwvMhVVlSMR9Sc78,5662
-ruleopt/explainer/__init__.py,sha256=vYoSUVEeHYFWLjrwXyBSVdu7lhU9nK1KWGyEwidMgvQ,68
-ruleopt/explainer/explainer.py,sha256=xoS60Y4WDv46YXIsyLZiq6Memf0sDlOcn4YjwrBdmJw,8993
-ruleopt/rule_cost/__init__.py,sha256=RyyBoe-0dHNHd_LMMYnEiCotnqQAJgRPhI9PHizvN7g,137
-ruleopt/rule_cost/rule_cost.py,sha256=oRMArJEWRVOyyAY2olNV3NLZ2uBgAQoiywtgOu7Ckgs,5252
-ruleopt/solver/__init__.py,sha256=2Ggey48NybpjTnmsXk11S3UHdgplsn8PojuOYatw3eY,293
-ruleopt/solver/base.py,sha256=uVF4n8D_skgQAfa_Dfcm_DJ1PiYFyvI-1AlOxJjBUkU,3233
-ruleopt/solver/cplex_solver.py,sha256=7D0WAeLyM6L7GJ9mcrb58IncxjPLqoombSCi6jNuaTE,4043
-ruleopt/solver/gurobi_solver.py,sha256=t5JyfNX5ul9Wv4Mq2wUCvpfgyMMs5EuaGp6jzmow6p0,3890
-ruleopt/solver/ortools_solver.py,sha256=9_rS5IYrop_Nl1FADEAeVhhbYGR-GatO831Nk0tR6_c,5080
-ruleopt/solver/unc_solver.py,sha256=QMjtyilS3Vcyzv9J_1gkx00ks5WN2cwUm2pyh7IVgBE,9596
-ruleopt/utils/__init__.py,sha256=Nu-b2q1FCwPPlzMCKOHS1GHDpDXtEqXsywvd4W21m2M,124
-ruleopt/utils/utils.py,sha256=h5QypOLcP01jNq3te8p7TZmQ1QEwpbcLQ_GBjKGf83s,1086
-ruleopt-0.1.2.dist-info/LICENSE,sha256=92AcbQTTnaW3MHsF7V5rVL_3m2vpSdZLi5uzGGid4-o,1135
-ruleopt-0.1.2.dist-info/METADATA,sha256=J_xsLqcZwKTbCjO6IOnuivTNaSvrFzfdfVsPlNni4Y8,4136
-ruleopt-0.1.2.dist-info/WHEEL,sha256=Z6c-bE0pUM47a70GvqO_SvH_XXU0lm62gEAKtoNJ08A,100
-ruleopt-0.1.2.dist-info/top_level.txt,sha256=5eXJDNaihq5rZdf1uSl9UMqGI050yX27S4inqYQMGSA,8
-ruleopt-0.1.2.dist-info/RECORD,,
+ruleopt/__init__.py,sha256=o8AuVrs9jVmDhaQwkVxxw5LJ90cNfXetouaQ2ELc9iw,247
+ruleopt/estimator/__init__.py,sha256=84Fg0ed4aOcTTKXOKx9HGjfrXAud-PuSurZieMmbNCw,271
+ruleopt/estimator/lightgbm_.py,sha256=5BqHMAmzPCg4d-lItpGXCMdvr_ArDPgmD5WTTC7KlDU,12387
+ruleopt/estimator/xgboost_.py,sha256=NHTzX7hLSqOMRwtOGq1FmUPWBre8BVMGRlWHTo7iVLY,11252
+ruleopt/estimator/base.py,sha256=e-5dHYxDcZvdbn3TYrCit5bEX6xgbrU6W_n0TMIEZww,25384
+ruleopt/estimator/sklearn_/base_sklearn.py,sha256=ghZFcsGV5Oo4VUWdaVLsDom-YBjPF8--GgXNCunywFs,6653
+ruleopt/estimator/sklearn_/rux.py,sha256=aWI-iaiq0rinQ-qIMooknyo5FMODM8EXA6ZcU4db194,5513
+ruleopt/estimator/sklearn_/__init__.py,sha256=3hCiryClpNFIMGTkiTotqQoPjMk8A81o1dV3sjuA2Io,119
+ruleopt/estimator/sklearn_/rug.py,sha256=GuWpabat2s7nFKTW5ivez2MHm5MmZq0LAzfxrpwlbTo,20971
+ruleopt/utils/__init__.py,sha256=fH5j0D0cpNx1APzpF3DLHrjfoD_B3xm6bWFm--_vJGM,120
+ruleopt/utils/utils.py,sha256=i27-ZnwKw9fXlCoUOeIwdf6c1NGzoRGLjbDEb1LtzM8,1053
+ruleopt/solver/unc_solver.py,sha256=Gst6LqmJ2mJer4Lk8b5iG0_1Olc19OAXbRNPegDoz2s,9684
+ruleopt/solver/ortools_solver.py,sha256=tuLKRjXkWfbYaG8NSy3Tf4kJqhAAqso6wv6rfW3U3lE,4975
+ruleopt/solver/__init__.py,sha256=vDPoPasoLN8mrMAK9XqxA8o2hhujz17AyOBjSBLcLEk,286
+ruleopt/solver/gurobi_solver.py,sha256=8goOKnpwfdgpbhPsbYWfjxTjuzYhQq8KQJv9RBVNuIg,3756
+ruleopt/solver/cplex_solver.py,sha256=sosqL-EErtb8n67enF4qF1G-vV_NljbT4WckLgsIBU4,3957
+ruleopt/solver/base.py,sha256=eifT6BI4Tur6vD1TSzxaAW3wNVaTjbAih78g7odUv6Y,3149
+ruleopt/rule_cost/rule_cost.py,sha256=z8hTXNgWCDLfsfTY43Totuh06rab9z7gjpvsRvGUdLY,5079
+ruleopt/rule_cost/__init__.py,sha256=umUIFMfNXmHTCdj819rVeO-daVXGGXQSpJAGAZhBVJo,134
+ruleopt/explainer/explainer.py,sha256=UilDlCWeHBREwZR25-cRtpwKXlF-7rcK8YvFkCcGZH4,8771
+ruleopt/explainer/__init__.py,sha256=Qj8LYBiKERpljG1l85lDYaSTZCn9ZRCu3cAadAr2fF4,65
+ruleopt/aux_classes/__init__.py,sha256=N-EmTWYG51YSOZJ4Lw7fq2hJNyzBp9eirffgV7CBRUw,91
+ruleopt/aux_classes/aux_classes.cpython-39-darwin.so,sha256=-prFk71KO8P3bO5kE8XZcMPqQgEjSlkmsE_kRtD_tXk,265440
+ruleopt/aux_classes/aux_classes.c,sha256=YdPR1VmtjD0PENv-fcufjzqbd5W5BvYjqSfSw47YOjk,1406238
+ruleopt-0.1.3.dist-info/RECORD,,
+ruleopt-0.1.3.dist-info/LICENSE,sha256=xYWPUH6qfAqTDo8XQnQIi0n2OKjJkXO6cS7B1qwABVc,1112
+ruleopt-0.1.3.dist-info/WHEEL,sha256=t3aNIuHimB-eyeerOmc50nLML0b4_R6yjydcdcJkGHg,108
+ruleopt-0.1.3.dist-info/top_level.txt,sha256=5eXJDNaihq5rZdf1uSl9UMqGI050yX27S4inqYQMGSA,8
+ruleopt-0.1.3.dist-info/METADATA,sha256=WNf94ku0Y2ZKVMEtqtnzFEuCS56aFGRrgjdKu67W1kw,4060
```

