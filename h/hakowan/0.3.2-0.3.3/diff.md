# Comparing `tmp/hakowan-0.3.2-py3-none-any.whl.zip` & `tmp/hakowan-0.3.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,80 +1,80 @@
-Zip file size: 501643 bytes, number of entries: 78
--rw-r--r--  2.0 unx      396 b- defN 24-Jan-25 04:49 hakowan/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Jan-25 04:49 hakowan/py.typed
--rw-r--r--  2.0 unx       27 b- defN 24-Jan-25 04:49 hakowan/common/__init__.py
--rw-r--r--  2.0 unx     1965 b- defN 24-Jan-25 04:49 hakowan/common/color.py
--rw-r--r--  2.0 unx      265 b- defN 24-Jan-25 04:49 hakowan/common/default.py
--rw-r--r--  2.0 unx      135 b- defN 24-Jan-25 04:49 hakowan/common/envmaps.py
--rw-r--r--  2.0 unx      131 b- defN 24-Jan-25 04:49 hakowan/common/exception.py
--rw-r--r--  2.0 unx      117 b- defN 24-Jan-25 04:49 hakowan/common/logger.py
--rw-r--r--  2.0 unx     6543 b- defN 24-Jan-25 04:49 hakowan/common/named_colors.py
--rw-r--r--  2.0 unx      548 b- defN 24-Jan-25 04:49 hakowan/common/to_color.py
--rw-r--r--  2.0 unx        0 b- defN 24-Jan-25 04:49 hakowan/common/colormap/__init__.py
--rw-r--r--  2.0 unx     2614 b- defN 24-Jan-25 04:49 hakowan/common/colormap/colorbrewer2.py
--rw-r--r--  2.0 unx     1235 b- defN 24-Jan-25 04:49 hakowan/common/colormap/colormap.py
--rw-r--r--  2.0 unx    19025 b- defN 24-Jan-25 04:49 hakowan/common/colormap/coolwarm.py
--rw-r--r--  2.0 unx    11519 b- defN 24-Jan-25 04:49 hakowan/common/colormap/inferno.py
--rw-r--r--  2.0 unx    11515 b- defN 24-Jan-25 04:49 hakowan/common/colormap/magma.py
--rw-r--r--  2.0 unx      575 b- defN 24-Jan-25 04:49 hakowan/common/colormap/named_colormaps.py
--rw-r--r--  2.0 unx    11517 b- defN 24-Jan-25 04:49 hakowan/common/colormap/plasma.py
--rw-r--r--  2.0 unx    10794 b- defN 24-Jan-25 04:49 hakowan/common/colormap/turbo.py
--rw-r--r--  2.0 unx    11519 b- defN 24-Jan-25 04:49 hakowan/common/colormap/viridis.py
--rw-r--r--  2.0 unx      106 b- defN 24-Jan-25 04:49 hakowan/compiler/__init__.py
--rw-r--r--  2.0 unx    10577 b- defN 24-Jan-25 04:49 hakowan/compiler/attribute.py
--rw-r--r--  2.0 unx     7476 b- defN 24-Jan-25 04:49 hakowan/compiler/channel.py
--rw-r--r--  2.0 unx     4033 b- defN 24-Jan-25 04:49 hakowan/compiler/color.py
--rw-r--r--  2.0 unx     2548 b- defN 24-Jan-25 04:49 hakowan/compiler/compile.py
--rw-r--r--  2.0 unx     2030 b- defN 24-Jan-25 04:49 hakowan/compiler/scene.py
--rw-r--r--  2.0 unx     8763 b- defN 24-Jan-25 04:49 hakowan/compiler/texture.py
--rw-r--r--  2.0 unx    11755 b- defN 24-Jan-25 04:49 hakowan/compiler/transform.py
--rw-r--r--  2.0 unx      478 b- defN 24-Jan-25 04:49 hakowan/compiler/utils.py
--rw-r--r--  2.0 unx     9039 b- defN 24-Jan-25 04:49 hakowan/compiler/view.py
--rw-r--r--  2.0 unx      292 b- defN 24-Jan-25 04:49 hakowan/envmaps/README.md
--rw-r--r--  2.0 unx   426040 b- defN 24-Jan-25 04:49 hakowan/envmaps/museum.exr
--rw-r--r--  2.0 unx        0 b- defN 24-Jan-25 04:49 hakowan/grammar/__init__.py
--rw-r--r--  2.0 unx      104 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/__init__.py
--rw-r--r--  2.0 unx     3152 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/channel.py
--rw-r--r--  2.0 unx      476 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/curvestyle.py
--rw-r--r--  2.0 unx      250 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/material/__init__.py
--rw-r--r--  2.0 unx     3882 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/material/material.py
--rw-r--r--  2.0 unx      366 b- defN 24-Jan-25 04:49 hakowan/grammar/channel/material/medium.py
--rw-r--r--  2.0 unx       48 b- defN 24-Jan-25 04:49 hakowan/grammar/dataframe/__init__.py
--rw-r--r--  2.0 unx     1279 b- defN 24-Jan-25 04:49 hakowan/grammar/dataframe/dataframe.py
--rw-r--r--  2.0 unx       25 b- defN 24-Jan-25 04:49 hakowan/grammar/layer/__init__.py
--rw-r--r--  2.0 unx     9467 b- defN 24-Jan-25 04:49 hakowan/grammar/layer/layer.py
--rw-r--r--  2.0 unx      416 b- defN 24-Jan-25 04:49 hakowan/grammar/layer/layer_spec.py
--rw-r--r--  2.0 unx       46 b- defN 24-Jan-25 04:49 hakowan/grammar/mark/__init__.py
--rw-r--r--  2.0 unx      375 b- defN 24-Jan-25 04:49 hakowan/grammar/mark/mark.py
--rw-r--r--  2.0 unx      158 b- defN 24-Jan-25 04:49 hakowan/grammar/scale/__init__.py
--rw-r--r--  2.0 unx     1301 b- defN 24-Jan-25 04:49 hakowan/grammar/scale/attribute.py
--rw-r--r--  2.0 unx      285 b- defN 24-Jan-25 04:49 hakowan/grammar/scale/offset.py
--rw-r--r--  2.0 unx     2887 b- defN 24-Jan-25 04:49 hakowan/grammar/scale/scale.py
--rw-r--r--  2.0 unx       23 b- defN 24-Jan-25 04:49 hakowan/grammar/texture/__init__.py
--rw-r--r--  2.0 unx     3188 b- defN 24-Jan-25 04:49 hakowan/grammar/texture/texture.py
--rw-r--r--  2.0 unx       25 b- defN 24-Jan-25 04:49 hakowan/grammar/transform/__init__.py
--rw-r--r--  2.0 unx     3719 b- defN 24-Jan-25 04:49 hakowan/grammar/transform/transform.py
--rw-r--r--  2.0 unx      361 b- defN 24-Jan-25 04:49 hakowan/render/__init__.py
--rw-r--r--  2.0 unx     9953 b- defN 24-Jan-25 04:49 hakowan/render/bsdf.py
--rw-r--r--  2.0 unx      200 b- defN 24-Jan-25 04:49 hakowan/render/color.py
--rw-r--r--  2.0 unx     1344 b- defN 24-Jan-25 04:49 hakowan/render/emitter.py
--rw-r--r--  2.0 unx      623 b- defN 24-Jan-25 04:49 hakowan/render/film.py
--rw-r--r--  2.0 unx     1798 b- defN 24-Jan-25 04:49 hakowan/render/integrator.py
--rw-r--r--  2.0 unx      950 b- defN 24-Jan-25 04:49 hakowan/render/medium.py
--rw-r--r--  2.0 unx     3921 b- defN 24-Jan-25 04:49 hakowan/render/render.py
--rw-r--r--  2.0 unx      587 b- defN 24-Jan-25 04:49 hakowan/render/sampler.py
--rw-r--r--  2.0 unx     1057 b- defN 24-Jan-25 04:49 hakowan/render/sensor.py
--rw-r--r--  2.0 unx    14185 b- defN 24-Jan-25 04:49 hakowan/render/shape.py
--rw-r--r--  2.0 unx      593 b- defN 24-Jan-25 04:49 hakowan/render/spectrum.py
--rw-r--r--  2.0 unx     4662 b- defN 24-Jan-25 04:49 hakowan/render/texture.py
--rw-r--r--  2.0 unx      137 b- defN 24-Jan-25 04:49 hakowan/setup/__init__.py
--rw-r--r--  2.0 unx     3410 b- defN 24-Jan-25 04:49 hakowan/setup/config.py
--rw-r--r--  2.0 unx     1096 b- defN 24-Jan-25 04:49 hakowan/setup/emitter.py
--rw-r--r--  2.0 unx     1144 b- defN 24-Jan-25 04:49 hakowan/setup/film.py
--rw-r--r--  2.0 unx     3123 b- defN 24-Jan-25 04:49 hakowan/setup/integrator.py
--rw-r--r--  2.0 unx     1009 b- defN 24-Jan-25 04:49 hakowan/setup/sampler.py
--rw-r--r--  2.0 unx     1441 b- defN 24-Jan-25 04:49 hakowan/setup/sensor.py
--rw-r--r--  2.0 unx    11335 b- defN 24-Jan-25 04:49 hakowan-0.3.2.dist-info/LICENSE
--rw-r--r--  2.0 unx       81 b- defN 16-Jan-01 00:00 hakowan-0.3.2.dist-info/WHEEL
--rw-r--r--  2.0 unx     1476 b- defN 16-Jan-01 00:00 hakowan-0.3.2.dist-info/METADATA
--rw-r--r--  2.0 unx     6639 b- defN 16-Jan-01 00:00 hakowan-0.3.2.dist-info/RECORD
-78 files, 676174 bytes uncompressed, 491127 bytes compressed:  27.4%
+Zip file size: 502415 bytes, number of entries: 78
+-rw-r--r--  2.0 unx      546 b- defN 24-Apr-06 19:38 hakowan/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-06 19:38 hakowan/py.typed
+-rw-r--r--  2.0 unx       27 b- defN 24-Apr-06 19:38 hakowan/common/__init__.py
+-rw-r--r--  2.0 unx     1965 b- defN 24-Apr-06 19:38 hakowan/common/color.py
+-rw-r--r--  2.0 unx      265 b- defN 24-Apr-06 19:38 hakowan/common/default.py
+-rw-r--r--  2.0 unx      135 b- defN 24-Apr-06 19:38 hakowan/common/envmaps.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-06 19:38 hakowan/common/exception.py
+-rw-r--r--  2.0 unx      117 b- defN 24-Apr-06 19:38 hakowan/common/logger.py
+-rw-r--r--  2.0 unx     6543 b- defN 24-Apr-06 19:38 hakowan/common/named_colors.py
+-rw-r--r--  2.0 unx      691 b- defN 24-Apr-06 19:38 hakowan/common/to_color.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-06 19:38 hakowan/common/colormap/__init__.py
+-rw-r--r--  2.0 unx     2614 b- defN 24-Apr-06 19:38 hakowan/common/colormap/colorbrewer2.py
+-rw-r--r--  2.0 unx     1235 b- defN 24-Apr-06 19:38 hakowan/common/colormap/colormap.py
+-rw-r--r--  2.0 unx    19025 b- defN 24-Apr-06 19:38 hakowan/common/colormap/coolwarm.py
+-rw-r--r--  2.0 unx    11519 b- defN 24-Apr-06 19:38 hakowan/common/colormap/inferno.py
+-rw-r--r--  2.0 unx    11515 b- defN 24-Apr-06 19:38 hakowan/common/colormap/magma.py
+-rw-r--r--  2.0 unx      575 b- defN 24-Apr-06 19:38 hakowan/common/colormap/named_colormaps.py
+-rw-r--r--  2.0 unx    11517 b- defN 24-Apr-06 19:38 hakowan/common/colormap/plasma.py
+-rw-r--r--  2.0 unx    10794 b- defN 24-Apr-06 19:38 hakowan/common/colormap/turbo.py
+-rw-r--r--  2.0 unx    11519 b- defN 24-Apr-06 19:38 hakowan/common/colormap/viridis.py
+-rw-r--r--  2.0 unx      106 b- defN 24-Apr-06 19:38 hakowan/compiler/__init__.py
+-rw-r--r--  2.0 unx    10577 b- defN 24-Apr-06 19:38 hakowan/compiler/attribute.py
+-rw-r--r--  2.0 unx     7476 b- defN 24-Apr-06 19:38 hakowan/compiler/channel.py
+-rw-r--r--  2.0 unx     4044 b- defN 24-Apr-06 19:38 hakowan/compiler/color.py
+-rw-r--r--  2.0 unx     2548 b- defN 24-Apr-06 19:38 hakowan/compiler/compile.py
+-rw-r--r--  2.0 unx     2030 b- defN 24-Apr-06 19:38 hakowan/compiler/scene.py
+-rw-r--r--  2.0 unx     8690 b- defN 24-Apr-06 19:38 hakowan/compiler/texture.py
+-rw-r--r--  2.0 unx    11916 b- defN 24-Apr-06 19:38 hakowan/compiler/transform.py
+-rw-r--r--  2.0 unx      478 b- defN 24-Apr-06 19:38 hakowan/compiler/utils.py
+-rw-r--r--  2.0 unx     9320 b- defN 24-Apr-06 19:38 hakowan/compiler/view.py
+-rw-r--r--  2.0 unx      292 b- defN 24-Apr-06 19:38 hakowan/envmaps/README.md
+-rw-r--r--  2.0 unx   426040 b- defN 24-Apr-06 19:38 hakowan/envmaps/museum.exr
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-06 19:38 hakowan/grammar/__init__.py
+-rw-r--r--  2.0 unx      104 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/__init__.py
+-rw-r--r--  2.0 unx     3152 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/channel.py
+-rw-r--r--  2.0 unx      476 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/curvestyle.py
+-rw-r--r--  2.0 unx      250 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/material/__init__.py
+-rw-r--r--  2.0 unx     3766 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/material/material.py
+-rw-r--r--  2.0 unx      366 b- defN 24-Apr-06 19:38 hakowan/grammar/channel/material/medium.py
+-rw-r--r--  2.0 unx       48 b- defN 24-Apr-06 19:38 hakowan/grammar/dataframe/__init__.py
+-rw-r--r--  2.0 unx     1279 b- defN 24-Apr-06 19:38 hakowan/grammar/dataframe/dataframe.py
+-rw-r--r--  2.0 unx       25 b- defN 24-Apr-06 19:38 hakowan/grammar/layer/__init__.py
+-rw-r--r--  2.0 unx    13160 b- defN 24-Apr-06 19:38 hakowan/grammar/layer/layer.py
+-rw-r--r--  2.0 unx      416 b- defN 24-Apr-06 19:38 hakowan/grammar/layer/layer_spec.py
+-rw-r--r--  2.0 unx       46 b- defN 24-Apr-06 19:38 hakowan/grammar/mark/__init__.py
+-rw-r--r--  2.0 unx      375 b- defN 24-Apr-06 19:38 hakowan/grammar/mark/mark.py
+-rw-r--r--  2.0 unx      158 b- defN 24-Apr-06 19:38 hakowan/grammar/scale/__init__.py
+-rw-r--r--  2.0 unx     1301 b- defN 24-Apr-06 19:38 hakowan/grammar/scale/attribute.py
+-rw-r--r--  2.0 unx      285 b- defN 24-Apr-06 19:38 hakowan/grammar/scale/offset.py
+-rw-r--r--  2.0 unx     2887 b- defN 24-Apr-06 19:38 hakowan/grammar/scale/scale.py
+-rw-r--r--  2.0 unx       23 b- defN 24-Apr-06 19:38 hakowan/grammar/texture/__init__.py
+-rw-r--r--  2.0 unx     3154 b- defN 24-Apr-06 19:38 hakowan/grammar/texture/texture.py
+-rw-r--r--  2.0 unx       25 b- defN 24-Apr-06 19:38 hakowan/grammar/transform/__init__.py
+-rw-r--r--  2.0 unx     3737 b- defN 24-Apr-06 19:38 hakowan/grammar/transform/transform.py
+-rw-r--r--  2.0 unx      361 b- defN 24-Apr-06 19:38 hakowan/render/__init__.py
+-rw-r--r--  2.0 unx     9953 b- defN 24-Apr-06 19:38 hakowan/render/bsdf.py
+-rw-r--r--  2.0 unx      200 b- defN 24-Apr-06 19:38 hakowan/render/color.py
+-rw-r--r--  2.0 unx     1344 b- defN 24-Apr-06 19:38 hakowan/render/emitter.py
+-rw-r--r--  2.0 unx      623 b- defN 24-Apr-06 19:38 hakowan/render/film.py
+-rw-r--r--  2.0 unx     1798 b- defN 24-Apr-06 19:38 hakowan/render/integrator.py
+-rw-r--r--  2.0 unx      950 b- defN 24-Apr-06 19:38 hakowan/render/medium.py
+-rw-r--r--  2.0 unx     4133 b- defN 24-Apr-06 19:38 hakowan/render/render.py
+-rw-r--r--  2.0 unx      587 b- defN 24-Apr-06 19:38 hakowan/render/sampler.py
+-rw-r--r--  2.0 unx     1057 b- defN 24-Apr-06 19:38 hakowan/render/sensor.py
+-rw-r--r--  2.0 unx    14360 b- defN 24-Apr-06 19:38 hakowan/render/shape.py
+-rw-r--r--  2.0 unx      593 b- defN 24-Apr-06 19:38 hakowan/render/spectrum.py
+-rw-r--r--  2.0 unx     4662 b- defN 24-Apr-06 19:38 hakowan/render/texture.py
+-rw-r--r--  2.0 unx      137 b- defN 24-Apr-06 19:38 hakowan/setup/__init__.py
+-rw-r--r--  2.0 unx     3410 b- defN 24-Apr-06 19:38 hakowan/setup/config.py
+-rw-r--r--  2.0 unx     1096 b- defN 24-Apr-06 19:38 hakowan/setup/emitter.py
+-rw-r--r--  2.0 unx     1144 b- defN 24-Apr-06 19:38 hakowan/setup/film.py
+-rw-r--r--  2.0 unx     3123 b- defN 24-Apr-06 19:38 hakowan/setup/integrator.py
+-rw-r--r--  2.0 unx     1009 b- defN 24-Apr-06 19:38 hakowan/setup/sampler.py
+-rw-r--r--  2.0 unx     1441 b- defN 24-Apr-06 19:38 hakowan/setup/sensor.py
+-rw-r--r--  2.0 unx    11335 b- defN 24-Apr-06 19:37 hakowan-0.3.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx       81 b- defN 16-Jan-01 00:00 hakowan-0.3.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx     1266 b- defN 16-Jan-01 00:00 hakowan-0.3.3.dist-info/METADATA
+-rw-r--r--  2.0 unx     6640 b- defN 16-Jan-01 00:00 hakowan-0.3.3.dist-info/RECORD
+78 files, 680586 bytes uncompressed, 491899 bytes compressed:  27.7%
```

## zipnote {}

```diff
@@ -216,20 +216,20 @@
 
 Filename: hakowan/setup/sampler.py
 Comment: 
 
 Filename: hakowan/setup/sensor.py
 Comment: 
 
-Filename: hakowan-0.3.2.dist-info/LICENSE
+Filename: hakowan-0.3.3.dist-info/LICENSE
 Comment: 
 
-Filename: hakowan-0.3.2.dist-info/WHEEL
+Filename: hakowan-0.3.3.dist-info/WHEEL
 Comment: 
 
-Filename: hakowan-0.3.2.dist-info/METADATA
+Filename: hakowan-0.3.3.dist-info/METADATA
 Comment: 
 
-Filename: hakowan-0.3.2.dist-info/RECORD
+Filename: hakowan-0.3.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## hakowan/__init__.py

```diff
@@ -1,12 +1,15 @@
 """ Hakowan: A 3D data visualization grammer """
 
-__version__ = "0.3.2"
+__version__ = "0.3.3"
 
 from .common import logger
 from .setup import Config as config
 from .grammar import dataframe, mark, channel, scale, texture, transform
 from .grammar.layer import Layer as layer
 from .grammar.scale import Attribute as attribute
 from .grammar.channel import material
 from .compiler import compile
 from .render import render
+
+__all__ = ["logger", "config", "dataframe", "mark", "channel", "scale",
+           "texture", "transform", "layer", "material", "compile", "render"]
```

## hakowan/common/to_color.py

```diff
@@ -7,11 +7,15 @@
         case float() | int():
             return Color(float(data), float(data), float(data))
         case str():
             if data.startswith("#"):
                 return Color.from_hex(data)
             elif data.lower() in css_colors:
                 return css_colors[data.lower()]
+            else:
+                raise ValueError(f"Unknown color name: {data}")
         case (r, g, b):
             return Color(r, g, b)
+        case (r, g, b, a):
+            return Color(r, g, b)
         case _:
             raise ValueError(f"Cannot convert {data} to color")
```

## hakowan/compiler/color.py

```diff
@@ -34,48 +34,48 @@
     assert mesh.has_attribute(attr_name)
 
     def attr_to_color(colormap: Callable, categories: bool = False):
         nonlocal mesh
         nonlocal attr_name
         nonlocal tex
 
-        num_categories = 0
+        unique_values: list[float] = []
 
         def get_color(value: float):
             if not categories:
                 return colormap(value).data
             else:
-                assert num_categories > 0
+                assert len(unique_values) > 0
                 assert isinstance(colormap, ColorMap)
                 num_colors = colormap.num_colors()
                 return colormap(
-                    np.round(value * (num_categories - 1)) % num_colors / (num_colors - 1)
+                    unique_values.index(value) % num_colors / (num_colors - 1)
                 ).data
 
         if mesh.is_attribute_indexed(attr_name):
             attr = mesh.indexed_attribute(attr_name)
             value_attr = attr.values
             index_attr = attr.indices
             if categories:
-                num_categories = len(np.unique(value_attr.data))
+                unique_values = np.unique(value_attr.data).tolist()
 
             color_data = np.array([get_color(x) for x in value_attr.data])
             color_attr_name = unique_name(mesh, "vertex_color")
 
             mesh.create_attribute(
                 color_attr_name,
                 element=attr.element_type,
                 usage=lagrange.AttributeUsage.Color,
                 initial_values=color_data,
                 initial_indices=index_attr.data.copy(),
             )
         else:
             attr = mesh.attribute(attr_name)
             if categories:
-                num_categories = len(np.unique(attr.data))
+                unique_values = np.unique(attr.data).tolist()
             color_data = np.array([get_color(x) for x in attr.data])
 
             if attr.element_type == lagrange.AttributeElement.Facet:
                 color_attr_name = unique_name(mesh, "face_color")
             else:
                 color_attr_name = unique_name(mesh, "vertex_color")
```

## hakowan/compiler/texture.py

```diff
@@ -49,24 +49,26 @@
             while s._child is not None:
                 s = s._child
             s._child = clip_scale
         else:
             tex.data.scale = clip_scale
 
     if tex.colormap != "identity":
-        # Add a normalize scale as the first scale to the attribute if no scale is provided.
-        if tex.data.scale is None:
-            domain_min, domain_max = tex.domain if tex.domain is not None else (None, None)
-            range_min, range_max = tex.range if tex.range is not None else (0, 1)
-            normalize_scale = Normalize(
-                range_min=range_min,
-                range_max=range_max,
-                domain_min=domain_min,
-                domain_max=domain_max,
-            )
+        range_min, range_max = tex.range if tex.range is not None else (0, 1)
+        normalize_scale = Normalize(
+            range_min=range_min,
+            range_max=range_max,
+        )
+        if tex.data.scale is not None:
+            assert isinstance(tex.data.scale, Scale)
+            s = tex.data.scale
+            while s._child is not None:
+                s = s._child
+            s._child = normalize_scale
+        else:
             tex.data.scale = normalize_scale
 
     # Compute scaled attribute
     compute_scaled_attribute(df, tex.data)
 
     return [tex.data]
```

## hakowan/compiler/transform.py

```diff
@@ -76,15 +76,15 @@
                 raise NotImplementedError(
                     f"Filter transform does not support curve mark yet."
                 )
         case _:
             raise RuntimeError(f"Unsupported element type: {attr.element_type}!")
 
 
-def _appply_uv_mesh_transform(view: View, transform: UVMesh):
+def _apply_uv_mesh_transform(view: View, transform: UVMesh):
     """Extract the UV mesh from the original mesh."""
     df = view.data_frame
     assert df is not None
     assert transform is not None
     mesh = df.mesh
     if mesh.num_vertices == 0:
         return
@@ -159,16 +159,28 @@
     mesh = df.mesh
 
     if np.shape(transform.matrix) == (4, 4):
         matrix = np.array(transform.matrix, order="F", dtype=np.float64)
     elif np.shape(transform.matrix) == (3, 3):
         matrix = np.eye(4, dtype=np.float64)
         matrix[:3, :3] = np.array(transform.matrix, order="F", dtype=np.float64)
+    else:
+        raise RuntimeError(
+            f"Invalid affine transformation matrix with shape {np.shape(transform.matrix)}."
+        )
     lagrange.transform_mesh(mesh, matrix)
 
+    # Transform ROI box if it exists.
+    if df.roi_box is not None:
+        df.roi_box = np.array(df.roi_box, dtype=np.float64)
+        M = np.array(transform.matrix)[:3, :3]
+        df.roi_box = (M @ df.roi_box.T).T
+        if M.shape == (4, 4):
+            df.roi_box += M[:3, 3].T
+
     # BBox must be updated after affine transform.
     logger.debug("Updating view bbox due to affine transform.")
     view.initialize_bbox()
 
 
 def _apply_compute_transform(view: View, transform: Compute):
     df = view.data_frame
@@ -194,25 +206,23 @@
         mesh.create_attribute(
             transform.z,
             element=lagrange.AttributeElement.Vertex,
             usage=lagrange.AttributeUsage.Scalar,
             initial_values=mesh.vertices[:, 2].copy(),
         )
     if transform.normal is not None:
-        normal_opt = lagrange.NormalOptions()
-        normal_opt.output_attribute_name = transform.normal
-        lagrange.compute_normal(mesh, options=normal_opt)
+        lagrange.compute_normal(mesh, output_attribute_name=transform.normal)
     if transform.vertex_normal is not None:
-        vertex_normal_opt = lagrange.VertexNormalOptions()
-        vertex_normal_opt.output_attribute_name = transform.vertex_normal
-        lagrange.compute_vertex_normal(mesh, options=vertex_normal_opt)
+        lagrange.compute_vertex_normal(
+            mesh, output_attribute_name=transform.vertex_normal
+        )
     if transform.facet_normal is not None:
-        facet_normal_opt = lagrange.FacetNormalOptions()
-        facet_normal_opt.output_attribute_name = transform.facet_normal
-        lagrange.compute_facet_normal(mesh, options=facet_normal_opt)
+        lagrange.compute_facet_normal(
+            mesh, output_attribute_name=transform.facet_normal
+        )
     if transform.component is not None:
         lagrange.compute_components(mesh, output_attribute_name=transform.component)
 
 
 def _apply_explode_transform(view: View, transform: Explode):
     df = view.data_frame
     assert df is not None
@@ -279,21 +289,23 @@
     """Apply a chain of transforms specified by view.transform to view.data_frame.
     Transforms are applied in the order specified by the chain.
     """
 
     def _apply(t: Transform | None):
         if t is None:
             return
+        _apply(t._child)
+
         match (t):
             case Filter():
                 assert view.data_frame is not None
                 _apply_filter_transform(view, t)
             case UVMesh():
                 assert view.data_frame is not None
-                _appply_uv_mesh_transform(view, t)
+                _apply_uv_mesh_transform(view, t)
             case Affine():
                 assert view.data_frame is not None
                 _apply_affine_transform(view, t)
             case Compute():
                 assert view.data_frame is not None
                 _apply_compute_transform(view, t)
             case Explode():
@@ -301,10 +313,8 @@
                 _apply_explode_transform(view, t)
             case Norm():
                 assert view.data_frame is not None
                 _apply_norm_transform(view, t)
             case _:
                 raise NotImplementedError(f"Unsupported transform: {type(t)}!")
 
-        _apply(t._child)
-
     _apply(view.transform)
```

## hakowan/compiler/view.py

```diff
@@ -63,46 +63,54 @@
         ]
         active_attribute_names += [
             attr._internal_color_field
             for attr in self._active_attributes
             if attr._internal_color_field is not None
         ]
 
+        # If input mesh contains normal and normal channel is not set,
+        # we will keep the input normal.
+        normal_attr_names = [
+            mesh.get_attribute_name(attr_id)
+            for attr_id in mesh.get_matching_attribute_ids(
+                usage=lagrange.AttributeUsage.Normal
+            )
+        ]
+        if (
+            len(normal_attr_names) > 0
+            and len(set(normal_attr_names) & set(active_attribute_names)) == 0
+        ):
+            logger.debug(f"Adding input normal attribute '{normal_attr_names[0]}'")
+            active_attribute_names.append(normal_attr_names[0])
+
         # Drop all non-active attributes
         for attr_id in mesh.get_matching_attribute_ids():
             attr_name = mesh.get_attribute_name(attr_id)
             if attr_name not in active_attribute_names and not attr_name.startswith(
                 "_hakowan"
             ):
                 mesh.delete_attribute(attr_name)
 
         # Convert all corner attributes to indexed attributes
-        for attr in self._active_attributes:
-            attr_name = attr._internal_name
-            assert attr_name is not None
+        for attr_name in active_attribute_names:
             if mesh.is_attribute_indexed(attr_name):
                 continue
 
             mesh_attr = mesh.attribute(attr_name)
             if mesh_attr.element_type == lagrange.AttributeElement.Corner:
                 attr_id = lagrange.map_attribute_in_place(
                     mesh, attr_name, lagrange.AttributeElement.Indexed
                 )
                 lagrange.weld_indexed_attribute(mesh, attr_id)
 
         # Gather all indexed attributes
         indexed_attr_names = []
-        for attr in self._active_attributes:
-            attr_name = attr._internal_name
+        for attr_name in active_attribute_names:
             if mesh.is_attribute_indexed(attr_name):
                 indexed_attr_names.append(attr_name)
-            if attr._internal_color_field is not None and mesh.is_attribute_indexed(
-                attr._internal_color_field
-            ):
-                indexed_attr_names.append(attr._internal_color_field)
 
         # Unify all active index buffers.
         if len(indexed_attr_names) > 0:
             unified_mesh = lagrange.unify_index_buffer(mesh, indexed_attr_names)
         else:
             unified_mesh = mesh
```

## hakowan/grammar/channel/material/material.py

```diff
@@ -8,20 +8,17 @@
 
 @dataclass(kw_only=True, slots=True)
 class Material(Channel):
     """Material base class.
 
     Attributes:
         two_sided: Whether to render both sides of the surface (default: False).
-        bump_map: Bump map texture (default: None).
     """
 
     two_sided: bool = False
-    bump_map: Texture | None = None
-    bump_scale: float = 1.0
 
 
 @dataclass(slots=True)
 class Diffuse(Material):
     """Diffuse material.
 
     Attributes:
```

## hakowan/grammar/layer/layer.py

```diff
@@ -1,18 +1,31 @@
 from .layer_spec import LayerSpec
 from ..dataframe import DataFrame, DataFrameLike
 from ..mark import Mark
 from ..channel import Channel, Position, Normal, Size, VectorField, BumpMap
-from ..channel.material import Material
+from ..channel.material import (
+    Material,
+    Diffuse,
+    Conductor,
+    RoughConductor,
+    Plastic,
+    RoughPlastic,
+    Principled,
+    ThinPrincipled,
+    Dielectric,
+    ThinDielectric,
+    RoughDielectric,
+    Hair,
+)
 from ..transform import Transform, Affine
 from ..scale import Attribute
 
 from dataclasses import dataclass, field
 from pathlib import Path
-from typing import Optional, Self, Sequence
+from typing import Optional, Sequence
 import lagrange
 import numpy as np
 import numpy.typing as npt
 
 
 @dataclass(kw_only=True, slots=True)
 class Layer:
@@ -53,15 +66,15 @@
         if mark is not None:
             self.mark(mark, in_place=True)
         if transform is not None:
             self.transform(transform, in_place=True)
         if channels is not None:
             self._spec.channels = channels
 
-    def __add__(self, other: Self) -> "Layer":
+    def __add__(self, other: "Layer") -> "Layer":
         """Combine two layers into a composite layer.
 
         Args:
             other (Layer): The other layer to be combined with.
 
         Returns:
             (Layer): The composite layer.
@@ -107,27 +120,37 @@
                 l._spec.data = data
                 if roi_box is not None:
                     l._spec.data.roi_box = roi_box
             case _:
                 raise TypeError(f"Unsupported data type: {type(data)}!")
         return l
 
-    def mark(self, mark: Mark, *, in_place: bool = False) -> "Layer":
+    def mark(self, mark: Mark | str, *, in_place: bool = False) -> "Layer":
         """Overwrite the mark component of this layer.
 
         Args:
-            mark (Mark): The new mark component.
+            mark (Mark | str): The new mark component.
             in_place (bool, optional): Whether to modify the current layer in place or create new
                 layer. Defaults to False (i.e. create a new layer).
 
         Returns:
             result (Layer): The layer object with mark component overwritten.
         """
         l = self.__get_working_layer(in_place)
-        l._spec.mark = mark
+        match (mark):
+            case Mark():
+                l._spec.mark = mark
+            case "point" | "Point" | "POINT":
+                l._spec.mark = Mark.Point
+            case "curve" | "Curve" | "CURVE":
+                l._spec.mark = Mark.Curve
+            case "surface" | "Surface" | "SURFACE":
+                l._spec.mark = Mark.Surface
+            case _:
+                raise ValueError(f"Unsupported mark type: {mark}!")
         return l
 
     def channel(
         self,
         *,
         position: Position | str | None = None,
         normal: Normal | str | None = None,
@@ -183,14 +206,55 @@
             l._spec.channels.append(convert(vector_field, VectorField))
         if material is not None:
             l._spec.channels.append(material)
         if bump_map is not None:
             l._spec.channels.append(bump_map)
         return l
 
+    def material(self, type: str, *args, in_place: bool = False, **kwargs) -> "Layer":
+        """Overwrite material for this layer.
+
+        Args:
+            type (str): The material type.
+            in_place (bool, optional): Whether to modify the current layer in place or create new
+                layer. Defaults to False (i.e. create a new layer).
+            *args: Variable length argument list that will be forwarded to material constructor.
+            **kwargs: Arbitrary keyword arguments that will be forwarded to material constructor.
+
+        Returns:
+            result (Layer): The layer object with the channel component overwritten.
+        """
+        l = self.__get_working_layer(in_place)
+        match type:
+            case "diffuse" | "Diffuse" | "DIFFUSE":
+                l._spec.channels.append(Diffuse(*args, **kwargs))
+            case "conductor" | "Conductor" | "CONDUCTOR":
+                l._spec.channels.append(Conductor(*args, **kwargs))
+            case "rough_conductor" | "RoughConductor" | "ROUGH_CONDUCTOR":
+                l._spec.channels.append(RoughConductor(*args, **kwargs))
+            case "plastic" | "Plastic" | "PLASTIC":
+                l._spec.channels.append(Plastic(*args, **kwargs))
+            case "rough_plastic" | "RoughPlastic" | "ROUGH_PLASTIC":
+                l._spec.channels.append(RoughPlastic(*args, **kwargs))
+            case "principled" | "Principled" | "PRINCIPLED":
+                l._spec.channels.append(Principled(*args, **kwargs))
+            case "thin_principled" | "ThinPrincipled" | "THIN_PRINCIPLED":
+                l._spec.channels.append(ThinPrincipled(*args, **kwargs))
+            case "dielectric" | "Dielectric" | "DIELECTRIC":
+                l._spec.channels.append(Dielectric(*args, **kwargs))
+            case "thin_dielectric" | "ThinDielectric" | "THIN_DIELECTRIC":
+                l._spec.channels.append(ThinDielectric(*args, **kwargs))
+            case "rough_dielectric" | "RoughDielectric" | "ROUGH_DIELECTRIC":
+                l._spec.channels.append(RoughDielectric(*args, **kwargs))
+            case "hair" | "Hair" | "HAIR":
+                l._spec.channels.append(Hair(*args, **kwargs))
+            case _:
+                raise ValueError(f"Unsupported material type: {type}!")
+        return l
+
     def transform(self, transform: Transform, *, in_place: bool = False) -> "Layer":
         """Overwrite the transform component of this layer.
 
         Args:
             transform (Transform): The new transform component.
             in_place (bool, optional): Whether to modify the current layer in place or create new
                 layer. Defaults to False (i.e. create a new layer).
@@ -245,14 +309,34 @@
 
         if l._spec.transform is None:
             l._spec.transform = Affine(M)
         else:
             l._spec.transform *= Affine(M)
         return l
 
+    def scale(self, factor: float, in_place: bool = False) -> "Layer":
+        """Update the transform component of the current layer by applying uniform scaling.
+
+        Args:
+            factor (float): The scaling factor.
+            in_place (bool, optional): Whether to modify the current layer in place or create new
+                layer. Defaults to False (i.e. create a new layer).
+
+        Returns:
+            result (Layer): The layer object with transform component updated.
+        """
+        l = self.__get_working_layer(in_place)
+        M = np.eye(4)
+        M[0, 0] = M[1, 1] = M[2, 2] = factor
+        if l._spec.transform is None:
+            l._spec.transform = Affine(M)
+        else:
+            l._spec.transform *= Affine(M)
+        return l
+
     @property
     def children(self) -> list["Layer"]:
         """Get the child layers of this layer."""
         return self._children
 
     @children.setter
     def children(self, value: Sequence["Layer"]) -> None:
```

## hakowan/grammar/texture/texture.py

```diff
@@ -82,16 +82,15 @@
     """The scalar field texture converts an attribute to a either a value field or color field.
 
     Attributes:
         data (AttributeLike): The attribute to convert to a color field.
         colormap (str | list[ColorLike]): The name of the colormap to use or a list colors.
         domain (tuple[float, float]): The domain of the attribute to map to the colormap.
         range (tuple[float, float]): The range of the colormap to map the attribute to.
-        categories (int): The number of categories to use for the colormap.
-                          None if data is not categorical.
+        categories (bool): Whether the attribute represents categorical data (i.e. discrete values).
     """
 
     data: AttributeLike
     colormap: str | list[ColorLike] = "viridis"
     domain: tuple[float, float] | None = None
     range: tuple[float, float] | None = None
     categories: bool = False
```

## hakowan/grammar/transform/transform.py

```diff
@@ -1,9 +1,9 @@
 from dataclasses import dataclass
-from typing import Self, Callable, Optional
+from typing import Callable, Optional
 import copy
 import numpy.typing as npt
 
 from ..scale import Attribute, AttributeLike
 
 
 @dataclass(kw_only=True, slots=True)
@@ -48,16 +48,16 @@
 
     Attributes:
         data: The attribute to filter on. If None, the vertex position is used.
         condition: A callable that takes a single argument, the value of the attribute, and returns
             a boolean indicating whether the data should be kept.
     """
 
-    data: AttributeLike | None
-    condition: Callable
+    data: AttributeLike | None = None
+    condition: Callable = lambda x: True
 
 
 @dataclass(slots=True)
 class UVMesh(Transform):
     """Extract UV mesh from data.
 
     Attributes:
```

## hakowan/render/__init__.py

```diff
@@ -1,14 +1,14 @@
 from .render import render
 from ..common import logger
 
 import mitsuba as mi
 
 if mi.variant() is None:
-    for variant in ["cuda_ad_rgb", "llvm_ad_rgb", "scalar_rgb"]:
+    for variant in ["cuda_ad_rgb", "scalar_rgb", "llvm_ad_rgb"]:
         if variant in mi.variants():
             try:
                 mi.set_variant(variant)
                 break
             except:
                 pass
     assert mi.variant() is not None
```

## hakowan/render/render.py

```diff
@@ -86,38 +86,44 @@
     root: layer.Layer,
     config: Config | None = None,
     filename: Path | str | None = None,
     xml_filename: Path | None = None,
 ):
     logger.info(f"Using Mitsuba variant '{mi.variant()}'.")
     scene = compile(root)
+    logger.info("Compilation done")
 
     if config is None:
         config = Config()
 
     mi_config = generate_base_config(config)
     mi_config |= generate_scene_config(scene)
 
     if xml_filename is not None:
         mi.xml.dict_to_xml(mi_config, xml_filename)
+        logger.info(f"Scene saved to {xml_filename}")
 
     mi_scene = mi.load_dict(mi_config)
     image = mi.render(scene=mi_scene)  # type: ignore
+    logger.info("Rendering done")
 
     if config.albedo_only:
         # Select the albedo channels.
-        image = image[:, :, [4, 5, 6, 3]] # type: ignore
+        image = image[:, :, [4, 5, 6, 3]]  # type: ignore
 
     if filename is not None:
         if isinstance(filename, str):
             filename = Path(filename)
 
         if filename.suffix == ".exr":
-            mi.util.write_bitmap(str(filename), image) # type: ignore
+            mi.util.write_bitmap(str(filename), image)  # type: ignore
         else:
-            mi.Bitmap(image).convert( # type: ignore
+            mi.Bitmap(image).convert(  # type: ignore
                 pixel_format=mi.Bitmap.PixelFormat.RGBA,
                 component_format=mi.Struct.Type.UInt8,
                 srgb_gamma=True,
-            ).write(str(filename), quality=-1) # type: ignore
+            ).write(
+                str(filename), quality=-1
+            )  # type: ignore
+        logger.info(f"Rendering saved to {filename}")
 
     return image
```

## hakowan/render/shape.py

```diff
@@ -13,68 +13,68 @@
 import numpy as np
 import numpy.typing as npt
 import pathlib
 import re
 import tempfile
 
 
-def extract_size(view: View, n: int, default_size=0.01):
+def extract_size(view: View, default_size=0.01):
     """Extract the size attribute from a view.
 
     :param view: The view to extract size from.
     :param n: The cardinality of size attribute.
     :param default_size: The default size if size attribute is not specified.
 
     :return: A list of size values of length n.
     """
     assert view.data_frame is not None
     mesh = view.data_frame.mesh
 
-    radii = []
     if view.size_channel is not None:
         match view.size_channel.data:
             case float():
-                radii = [view.size_channel.data] * n
+                return view.size_channel.data
             case Attribute():
                 assert view.size_channel.data._internal_name is not None
-                radii = mesh.attribute(
+                return mesh.attribute(
                     view.size_channel.data._internal_name
                 ).data.tolist()
-                assert len(radii) == n
             case _:
                 raise NotImplementedError(
                     f"Unsupported size channel type: {type(view.size_channel.data)}"
                 )
     else:
-        radii = [default_size] * n
-
-    return radii
+        return default_size
 
 
 def generate_point_config(view: View):
     """Generate point cloud shapes from a View."""
     assert view.data_frame is not None
     mesh = view.data_frame.mesh
     shapes: list[dict[str, Any]] = []
 
     # Compute radii
-    radii = extract_size(view, mesh.num_vertices)
+    radii = extract_size(view)
+    if np.isscalar(radii):
+        radii = [radii] * mesh.num_vertices
 
     # Generate spheres.
     assert len(radii) == mesh.num_vertices
     global_transform = mi.ScalarTransform4f(view.global_transform)  # type: ignore
-    for i, v in enumerate(mesh.vertices):
-        shapes.append(
-            {
+    shapes = list(
+        map(
+            lambda itr: {
                 "type": "sphere",
-                "center": v.tolist(),
-                "radius": radii[i],
+                "center": itr[1].tolist(),
+                "radius": radii[itr[0]],
                 "to_world": global_transform,
-            }
+            },
+            enumerate(mesh.vertices),
         )
+    )
 
     # Generate bsdf
     bsdfs = generate_bsdf_config(view, is_primitive=True)
     if "type" in bsdfs:
         # Single bsdf
         bsdf = bsdfs
         for shape in shapes:
@@ -96,19 +96,23 @@
     assert attr_name is not None
     assert mesh.has_attribute(attr_name)
 
     attr = mesh.attribute(attr_name)
     match attr.element_type:
         case lagrange.AttributeElement.Vertex:
             base = mesh.vertices
-            size = extract_size(view, mesh.num_vertices)
+            size = extract_size(view)
+            if np.isscalar(size):
+                size = [size] * mesh.num_vertices
         case lagrange.AttributeElement.Facet:
             centroid_attr_id = lagrange.compute_facet_centroid(mesh)
             base = mesh.attribute(centroid_attr_id).data  # type: ignore
-            size = extract_size(view, mesh.num_facets)
+            size = extract_size(view)
+            if np.isscalar(size):
+                size = [size] * mesh.num_facets
         case _:
             raise NotImplementedError(
                 f"Unsupported vector field element type: {attr.element_type}"
             )
     tip = attr.data + base
     ctrl_pts_1: npt.NDArray | None = None
     ctrl_pts_2: npt.NDArray | None = None
@@ -200,15 +204,18 @@
     mesh.initialize_edges()
 
     base: npt.NDArray = np.ndarray((mesh.num_edges, mesh.dimension), dtype=np.float32)
     tip: npt.NDArray = np.ndarray((mesh.num_edges, mesh.dimension), dtype=np.float32)
     base_size: npt.NDArray = np.ndarray(mesh.num_edges, dtype=np.float32)
     tip_size: npt.NDArray = np.ndarray(mesh.num_edges, dtype=np.float32)
 
-    sizes = extract_size(view, mesh.num_vertices)
+    sizes = extract_size(view)
+    if np.isscalar(sizes):
+        sizes = [sizes] * mesh.num_vertices
+
     vertices = mesh.vertices
     for i in range(mesh.num_edges):
         edge_vts = mesh.get_edge_vertices(i)
         base[i] = vertices[edge_vts[0]]
         tip[i] = vertices[edge_vts[1]]
         base_size[i] = sizes[edge_vts[0]]
         tip_size[i] = sizes[edge_vts[1]]
@@ -347,15 +354,15 @@
     tmp_dir = pathlib.Path(tempfile.gettempdir())
     filename = tmp_dir / f"{stamp}-view-{index:03}.ply"
     logger.debug(f"Saving mesh to '{str(filename)}'.")
     lagrange.io.save_mesh(filename, mesh)  # type: ignore
 
     normal_ids = mesh.get_matching_attribute_ids(usage=lagrange.AttributeUsage.Normal)
     if len(normal_ids) > 0:
-        normal_attr = mesh.attribute(normal_ids[0]) # type: ignore
+        normal_attr = mesh.attribute(normal_ids[0])  # type: ignore
         use_facet_normal = normal_attr.element_type == lagrange.AttributeElement.Facet
     else:
         use_facet_normal = False
 
     mi_config = {
         "type": "ply",
         "filename": str(filename.resolve()),
```

## Comparing `hakowan-0.3.2.dist-info/LICENSE` & `hakowan-0.3.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `hakowan-0.3.2.dist-info/METADATA` & `hakowan-0.3.3.dist-info/METADATA`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 Metadata-Version: 2.1
 Name: hakowan
-Version: 0.3.2
+Version: 0.3.3
 Summary: Hakowan: A 3D data visualization grammer 
 Author-email: Qingnan Zhou <qnzhou@gmail.com>, Zhicheng Liu <leozcliu@umd.edu>
-Requires-Python: >=3.11
+Requires-Python: >=3.10
 Description-Content-Type: text/markdown
 Classifier: License :: OSI Approved :: Apache Software License
-Requires-Dist: lagrange-open==6.17
+Requires-Dist: lagrange-open~=6.21
 Requires-Dist: mitsuba~=3.4
-Requires-Dist: numpy>=1.21
+Requires-Dist: numpy>=1.22
 
 # Hakowan
 Hakowan is a 3D data visualization grammar. It is inspired by the grammar of graphics, and it is
 designed for easily creating beautiful 3D visualizations.
 
 ## Install
 
@@ -33,24 +33,18 @@
 
 base = hkw.layer("mesh.obj")            # Create a base layer
 hkw.render(base, filename="image.exr")  # Render!
 ```
 
 ## Documentation
 
-[HTML](https://qnzhou.github.io/hakowan/)
-
-## About
-
-Hakowan is developed and maintained by [Qingnan
-Zhou](https://research.adobe.com/person/qingnan-zhou/) and [Zhicheng Liu](https://www.zcliu.org/).
+[HTML](https://hakowan.github.io/hakowan/)
 
 ```bibtex
-@software{zhou2023hakowan,
+@software{hakowan,
     title = {Hakowan: A 3D Data Visualization Grammar},
-    author = {Qingnan Zhou and Zhicheng Liu}
-    version = {0.1.0},
-    year = 2023,
+    version = {0.3.2},
+    year = 2024,
 }
 ```
```

## Comparing `hakowan-0.3.2.dist-info/RECORD` & `hakowan-0.3.3.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,78 +1,78 @@
-hakowan/__init__.py,sha256=ecanFaEiBSAW26NgXukZBCHMHz2nQaqX6XCuxc3EhHs,396
+hakowan/__init__.py,sha256=OM4dLEUModmIh-_pTUAZ3778zeirxBNrSIM9TukmlXs,546
 hakowan/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hakowan/common/__init__.py,sha256=Es4t__Ougt4aIMVKMOgjGs9aOXiEJrs5teaNhaMPQwQ,27
 hakowan/common/color.py,sha256=OYVuD8LeWn6Loa7Dj6k_Rm6s8shU_mBAxim8thchD7s,1965
 hakowan/common/default.py,sha256=h-4Xlqzd9T7QV3_NMy_tcKHGLX1jTcx0tMqav5rUN0s,265
 hakowan/common/envmaps.py,sha256=Jr3lEsdQfJOQzDkP4NwrKTXUFECTLHZpji-9dBhwix8,135
 hakowan/common/exception.py,sha256=DtdFVsD2dcqJkOdMKYlzBU4VoIC2IE0u4Hi7VbNACIE,131
 hakowan/common/logger.py,sha256=NSoSPOVvjpOwWCzrb9GQjYXG1NHgsBQj5KcyoqMaHS8,117
 hakowan/common/named_colors.py,sha256=DMlRbMCCDn2BJ8e9PX5G-45-tphx7fjCkTYUVy_mV2Y,6543
-hakowan/common/to_color.py,sha256=E4Si1eBotTp36b_ZJut7DM4aI7nA20UoOJJUH7F-sIk,548
+hakowan/common/to_color.py,sha256=PQS9ds2Dzo_JiGdW_NdoOH1BcZUhRrS2awf_bcjoeQg,691
 hakowan/common/colormap/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hakowan/common/colormap/colorbrewer2.py,sha256=w1N1c9CrFsDQXTZWkB9PxMYr_mxWX_Rl6-Oqi0guzRA,2614
 hakowan/common/colormap/colormap.py,sha256=KReW3nQ-YoUHaZUPo78Wzm-Zd6SFZltOf3ZKP2hf9ZM,1235
 hakowan/common/colormap/coolwarm.py,sha256=VJF71YR0mrZYkYRJyxEAgauYeDHv3uwRwKNe8xqMIrY,19025
 hakowan/common/colormap/inferno.py,sha256=lVInpz4CI09lvxlzabyaQSGhK90iWB_U42A5Dpbyfp4,11519
 hakowan/common/colormap/magma.py,sha256=YHBr21VsBJUi4w9M8ssaobGJcN069UcHXEGDpnU5tgM,11515
 hakowan/common/colormap/named_colormaps.py,sha256=nlUscHOuyHU2DrOAhe2ERFNPv7eifTGdXdukwkWL810,575
 hakowan/common/colormap/plasma.py,sha256=UtOEEi2bDnJze6I4QBC6EbMU7nPPXQkkP_zs5H8nqss,11517
 hakowan/common/colormap/turbo.py,sha256=q9IEw3A2SQvJvjsREqLnnRan2QKfD5G8zjUheo_4Aok,10794
 hakowan/common/colormap/viridis.py,sha256=41EUbAYyUrPImo6vmWN7Y4CNE1e1WZ6Oa2wSlwENH4Y,11519
 hakowan/compiler/__init__.py,sha256=tA-nLriuWMbhV0WtcFUPmzGYI3zWEIfgU88WjTzeNxs,106
 hakowan/compiler/attribute.py,sha256=zhQZvUV2n3MaJduMy9xXoUw3owZdT1CTBejRWM1ebCo,10577
 hakowan/compiler/channel.py,sha256=u673eSx-gu6sE26ZwrsYG4Ex2LqHYIUgoIF2CYkO6Mg,7476
-hakowan/compiler/color.py,sha256=5PSIMpinmbUmLia0ceaxjvFwExhqY4aei2IpAwgc1lY,4033
+hakowan/compiler/color.py,sha256=dP3xsToRoWVBpk7h6bvegx1ZXOloVz27BBPDwWMkUXU,4044
 hakowan/compiler/compile.py,sha256=3A_Ea-86azpReUJU99gghc5WfeYwDXcnT8GqS25Key0,2548
 hakowan/compiler/scene.py,sha256=RRQJ6eWUULvgQwjU-PhkKawa0MLAvi-7lKpE_ULPztI,2030
-hakowan/compiler/texture.py,sha256=U_a_DFhfrXOwH1_eN8VyAU7b0yd1rHEm55dnZTGCbnw,8763
-hakowan/compiler/transform.py,sha256=ME66jrpOCipJqi3dwyRYSEujuNXo0Inz_rHJLx44i-g,11755
+hakowan/compiler/texture.py,sha256=-wrINMWkyhN8i4dk7lzGxmQxMa94GlZ5LjC5kex1RiI,8690
+hakowan/compiler/transform.py,sha256=6AsZzNG8U7LFcuaPxI6-fkal1T9NM2h77yhFcqeGtJM,11916
 hakowan/compiler/utils.py,sha256=_FPSZwRAO6sDfZZEbSlQ8voKYU7qfop59h02EtSgVYI,478
-hakowan/compiler/view.py,sha256=SXU2s42kmaswqGCEkL-ntYcUYbIHin5Vm4D6Kd4gsps,9039
+hakowan/compiler/view.py,sha256=F-01fWfv4Vquxgu96-k8JcXQAYrudmmf6PxrFkWmL1s,9320
 hakowan/envmaps/README.md,sha256=II8qn_GiLnrMP1dme2jz7gw2H7CgE93_NCNfAqNPFyI,292
 hakowan/envmaps/museum.exr,sha256=jji5kECaqM5KbOloAay-uuvxw8mVFPsPrBuQnuPTV9k,426040
 hakowan/grammar/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hakowan/grammar/channel/__init__.py,sha256=hu3XUiAc6E3in2ZSoG5YD7LP0FP_1Fk_alTXd2IoPMU,104
 hakowan/grammar/channel/channel.py,sha256=injxVn5FAqqFrd87n4jBa3w8nJJxBGxK7k0AKm0touc,3152
 hakowan/grammar/channel/curvestyle.py,sha256=um0-id1cf2y76osuP0psxlRK6lSvdTWXssXse0Ftrrs,476
 hakowan/grammar/channel/material/__init__.py,sha256=l4wAnbE8F9agPWkwmui7C6GrtfSgR4tofyDF_m7XodY,250
-hakowan/grammar/channel/material/material.py,sha256=uzwjGabogel1XSV32APXqGRiYd_Yz8t8VenZgg4clj8,3882
+hakowan/grammar/channel/material/material.py,sha256=qfYv75FiOZmegswRSCDWff6BAO1YblVaIAG7MrU1PSc,3766
 hakowan/grammar/channel/material/medium.py,sha256=l2BRc7RxFmY5shliMqe4ZxTikubn6sWu3IZSWqnL_-Q,366
 hakowan/grammar/dataframe/__init__.py,sha256=FSTbsha_pZPaVYQlZDj6c1O0S0OR9YxduO4g4_ZKnWI,48
 hakowan/grammar/dataframe/dataframe.py,sha256=-8I5UfknuaEIBUXNAnwVLPNay5iNMDW_dvg_pxhQBZw,1279
 hakowan/grammar/layer/__init__.py,sha256=rUK8cKRc_4TLUve8KToqkRDT08nGAdyhRJXNnS_WET4,25
-hakowan/grammar/layer/layer.py,sha256=OX2O0_iOI3cQ8De3bdM6Qe-INXdunZW10KSCXCW_4MA,9467
+hakowan/grammar/layer/layer.py,sha256=bjJxBe0dY-wz7Gtv7JiHfXpfKjvOjbHUcdF_psRAlkg,13160
 hakowan/grammar/layer/layer_spec.py,sha256=b9HxiVCq35GatEuab_I6GbYx3zKCKvw23TpDw1AC_hA,416
 hakowan/grammar/mark/__init__.py,sha256=dTMweYPxH1N_SzlpFmDQttk6OHFZRRtjOVLNjpiJe0Y,46
 hakowan/grammar/mark/mark.py,sha256=gDJl9ZYoT2QFsNuhkwpdPoFiu_EM0flCR7IVxMylx7w,375
 hakowan/grammar/scale/__init__.py,sha256=JhKpNd03udnmkcqg6FFrQ9xOgCn9ttM0W9Ok-yLGGOs,158
 hakowan/grammar/scale/attribute.py,sha256=Rye5DSRAt4dOPjrbAWONzBekRYNZ2e6H0g_xrK3pTxI,1301
 hakowan/grammar/scale/offset.py,sha256=k74iahzhD9OoeQhgIHozdbDD5DmQW7RsnyXPOd2pS7c,285
 hakowan/grammar/scale/scale.py,sha256=UF0YgXJZQXiCpdAD_QLgbtvjdYqpZCfE2V_b7OMjtt0,2887
 hakowan/grammar/texture/__init__.py,sha256=22AvZjOML-F14nsVXopKGXPasdIxtIxybiJQUQ01k5I,23
-hakowan/grammar/texture/texture.py,sha256=NuTcfn0najSgofdOTuXRkgiMH78mpmnI01eOQ6bfMBw,3188
+hakowan/grammar/texture/texture.py,sha256=T_Am7STfU5AAHdXN2UAujURnuzjfOt2S_wNeG__gIvU,3154
 hakowan/grammar/transform/__init__.py,sha256=dENM5wNH4Xils3v7SAh-xc5BVR5awJltaqjI-SEJhQU,25
-hakowan/grammar/transform/transform.py,sha256=sn2ygBHL5H-h-nDRalAc158j-aCG7qmZwGSQJG4vyis,3719
-hakowan/render/__init__.py,sha256=58Y_JhZQw3gDVpTKBk0yVk2-4Bn6f5QMYCjCKMot1rQ,361
+hakowan/grammar/transform/transform.py,sha256=hYwZpvdOkgze3LsuxPJBVpzUTnKUmNDJd0FdCVLymLs,3737
+hakowan/render/__init__.py,sha256=cdlmUJlayqdbxpUXLw8ZRCRMo63PNnmKQT0X5WmQQtc,361
 hakowan/render/bsdf.py,sha256=-DIQBFke3SBDQ157TXxoHYQZ1Fadye-GY34b8NWCqPc,9953
 hakowan/render/color.py,sha256=vYggCpD8p_ixmyj80Amw_A1-TdvHQbDfgz9H7A3IMpg,200
 hakowan/render/emitter.py,sha256=3hREbf-Ri_9lZdG_nbHNw_vBvcict-4bdjqmeABUCco,1344
 hakowan/render/film.py,sha256=PEiqPkbvQmn1dwyI-kXy6vHiAflCTLtagMMs7ysIdsE,623
 hakowan/render/integrator.py,sha256=hp7kZtoXbTSmMqP6XQZaDbBdC8DeaHiYn1mqTfr3Flg,1798
 hakowan/render/medium.py,sha256=-S1vk4dMfTeXFT26hl9KfwbbnAjzHYv2ooiLMHxy5xs,950
-hakowan/render/render.py,sha256=FeOXlmxiFJQFL3C-5-xX5oauMNcPpqE68bxv-HQlRBM,3921
+hakowan/render/render.py,sha256=RkJ_UVwHQC_7jWY3dEd7eeZGBlOz8tGLhGjZnBUBZu8,4133
 hakowan/render/sampler.py,sha256=3UCcVgqPbTMc-JkB9E5_ud5DFoM5Lr80Bb92Gxm7mIo,587
 hakowan/render/sensor.py,sha256=U_sEVoDiK_kH-XZEeGiDEYLcf-HZMl5_GEL71mYOZ3g,1057
-hakowan/render/shape.py,sha256=O8mHeHOTotOE5dxOn9_1cA35qxQUkPm-_DI2ka7QzRc,14185
+hakowan/render/shape.py,sha256=x_AA7Z-VPiGak4ZAsYldcwo9OdiNun8TtyJDOVmswJQ,14360
 hakowan/render/spectrum.py,sha256=Y2Dee9Ld8s0pbKPtfIjhRsFOKhDjRCfBMz_PPj_oJ9w,593
 hakowan/render/texture.py,sha256=EcFIFsh1EUpeuA8y168qYB6_Z_a64o8GoNXDIwRVSVU,4662
 hakowan/setup/__init__.py,sha256=nD9QWvUI4fRlQeAfsUuMJOB93cT3xSIrsthAb5695NE,137
 hakowan/setup/config.py,sha256=HVITR-k3fRwq4OJqYpczpV_cnoNimslvSvxBgSI-U0s,3410
 hakowan/setup/emitter.py,sha256=Hs-WN1cPABCMu-AhdGmE6fwFkE010_xtOQQDoEBNvQc,1096
 hakowan/setup/film.py,sha256=HwdV2930tfFElp58rrmYg7tRhMR4cMoi6rus7VfE4CQ,1144
 hakowan/setup/integrator.py,sha256=KlWcwrYFyil7mXd6jyGNlN6GoUYkxXtmfvNQBgC7OKQ,3123
 hakowan/setup/sampler.py,sha256=iyZdHyZsnxOsBOKs8934dG9GzggaZ-WLmX8dJj5NEpg,1009
 hakowan/setup/sensor.py,sha256=SSPu__qxSGafaaToBqP1QutHCOzedezg1JQijUk-UtA,1441
-hakowan-0.3.2.dist-info/LICENSE,sha256=hr3V2vq3dFEES2_W0u-rI-NBDOZY6wl_BMBPT1Su1i8,11335
-hakowan-0.3.2.dist-info/WHEEL,sha256=EZbGkh7Ie4PoZfRQ8I0ZuP9VklN_TvcZ6DSE5Uar4z4,81
-hakowan-0.3.2.dist-info/METADATA,sha256=Q-rqXeqnP_OqCzcffQXHvwOzUtcZNjc1J3iVp3zQuW0,1476
-hakowan-0.3.2.dist-info/RECORD,,
+hakowan-0.3.3.dist-info/LICENSE,sha256=hr3V2vq3dFEES2_W0u-rI-NBDOZY6wl_BMBPT1Su1i8,11335
+hakowan-0.3.3.dist-info/WHEEL,sha256=EZbGkh7Ie4PoZfRQ8I0ZuP9VklN_TvcZ6DSE5Uar4z4,81
+hakowan-0.3.3.dist-info/METADATA,sha256=1-EoUkz9-Px9Axw6BVPL4Uhpe5BINIhDDfpBWt29kwg,1266
+hakowan-0.3.3.dist-info/RECORD,,
```

