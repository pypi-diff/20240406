# Comparing `tmp/networkx-3.2rc0.tar.gz` & `tmp/networkx-3.3rc0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "networkx-3.2rc0.tar", last modified: Wed Oct 11 17:01:28 2023, max compression
+gzip compressed data, was "networkx-3.3rc0.tar", last modified: Fri Mar 22 20:12:27 2024, max compression
```

## Comparing `networkx-3.2rc0.tar` & `networkx-3.3rc0.tar`

### file list

```diff
@@ -1,940 +1,954 @@
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.166865 networkx-3.2rc0/
--rw-r--r--   0 runner    (1001) docker     (127)    17731 2023-10-11 17:01:11.000000 networkx-3.2rc0/CONTRIBUTING.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4083 2023-10-11 17:01:11.000000 networkx-3.2rc0/INSTALL.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1763 2023-10-11 17:01:11.000000 networkx-3.2rc0/LICENSE.txt
--rw-r--r--   0 runner    (1001) docker     (127)      872 2023-10-11 17:01:11.000000 networkx-3.2rc0/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (127)     5137 2023-10-11 17:01:28.166865 networkx-3.2rc0/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)     2416 2023-10-11 17:01:11.000000 networkx-3.2rc0/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.026862 networkx-3.2rc0/doc/
--rw-r--r--   0 runner    (1001) docker     (127)     4131 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/Makefile
--rw-r--r--   0 runner    (1001) docker     (127)     1221 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.026862 networkx-3.2rc0/doc/_static/
--rw-r--r--   0 runner    (1001) docker     (127)     2795 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/_static/copybutton.js
--rw-r--r--   0 runner    (1001) docker     (127)      380 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/_static/custom.css
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.018862 networkx-3.2rc0/doc/_templates/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.026862 networkx-3.2rc0/doc/_templates/autosummary/
--rw-r--r--   0 runner    (1001) docker     (127)      106 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/_templates/autosummary/base.rst
--rw-r--r--   0 runner    (1001) docker     (127)      667 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/_templates/autosummary/class.rst
--rw-r--r--   0 runner    (1001) docker     (127)     9218 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/conf.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.030862 networkx-3.2rc0/doc/developer/
--rw-r--r--   0 runner    (1001) docker     (127)     7415 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/about_us.rst
--rw-r--r--   0 runner    (1001) docker     (127)       39 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/code_of_conduct.rst
--rw-r--r--   0 runner    (1001) docker     (127)       36 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/contribute.rst
--rw-r--r--   0 runner    (1001) docker     (127)     7820 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/core_developer.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2745 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/deprecations.rst
--rw-r--r--   0 runner    (1001) docker     (127)      288 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)     5998 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/new_contributor_faq.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.030862 networkx-3.2rc0/doc/developer/nxeps/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.030862 networkx-3.2rc0/doc/developer/nxeps/_static/
--rw-r--r--   0 runner    (1001) docker     (127)    12925 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/_static/nxep-0000.png
--rw-r--r--   0 runner    (1001) docker     (127)      245 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)    11666 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-0000.rst
--rw-r--r--   0 runner    (1001) docker     (127)     7130 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-0001.rst
--rw-r--r--   0 runner    (1001) docker     (127)    13910 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-0002.rst
--rw-r--r--   0 runner    (1001) docker     (127)    17575 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-0003.rst
--rw-r--r--   0 runner    (1001) docker     (127)    13821 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-0004.rst
--rw-r--r--   0 runner    (1001) docker     (127)     3178 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/nxeps/nxep-template.rst
--rw-r--r--   0 runner    (1001) docker     (127)     7085 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/projects.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2628 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/release.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4398 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/roadmap.rst
--rw-r--r--   0 runner    (1001) docker     (127)    12737 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/teams.inc
--rw-r--r--   0 runner    (1001) docker     (127)     2521 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/developer/values.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4341 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)       28 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/install.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.030862 networkx-3.2rc0/doc/reference/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.042862 networkx-3.2rc0/doc/reference/algorithms/
--rw-r--r--   0 runner    (1001) docker     (127)     2429 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/approximation.rst
--rw-r--r--   0 runner    (1001) docker     (127)      874 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/assortativity.rst
--rw-r--r--   0 runner    (1001) docker     (127)      163 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/asteroidal.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2309 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/bipartite.rst
--rw-r--r--   0 runner    (1001) docker     (127)      150 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/boundary.rst
--rw-r--r--   0 runner    (1001) docker     (127)      146 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/bridges.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2624 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/centrality.rst
--rw-r--r--   0 runner    (1001) docker     (127)      123 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/chains.rst
--rw-r--r--   0 runner    (1001) docker     (127)      234 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/chordal.rst
--rw-r--r--   0 runner    (1001) docker     (127)      365 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/clique.rst
--rw-r--r--   0 runner    (1001) docker     (127)      228 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/clustering.rst
--rw-r--r--   0 runner    (1001) docker     (127)      534 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/coloring.rst
--rw-r--r--   0 runner    (1001) docker     (127)      189 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/communicability_alg.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1872 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/community.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1158 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/component.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2005 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/connectivity.rst
--rw-r--r--   0 runner    (1001) docker     (127)      188 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/core.rst
--rw-r--r--   0 runner    (1001) docker     (127)      150 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/covering.rst
--rw-r--r--   0 runner    (1001) docker     (127)      237 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/cuts.rst
--rw-r--r--   0 runner    (1001) docker     (127)      232 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/cycles.rst
--rw-r--r--   0 runner    (1001) docker     (127)      195 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/d_separation.rst
--rw-r--r--   0 runner    (1001) docker     (127)      489 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/dag.rst
--rw-r--r--   0 runner    (1001) docker     (127)      270 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/distance_measures.rst
--rw-r--r--   0 runner    (1001) docker     (127)      257 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/distance_regular.rst
--rw-r--r--   0 runner    (1001) docker     (127)      166 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/dominance.rst
--rw-r--r--   0 runner    (1001) docker     (127)      177 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/dominating.rst
--rw-r--r--   0 runner    (1001) docker     (127)      187 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/efficiency_measures.rst
--rw-r--r--   0 runner    (1001) docker     (127)      216 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/euler.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1152 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/flow.rst
--rw-r--r--   0 runner    (1001) docker     (127)      204 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/graph_hashing.rst
--rw-r--r--   0 runner    (1001) docker     (127)      328 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/graphical.rst
--rw-r--r--   0 runner    (1001) docker     (127)      137 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/hierarchy.rst
--rw-r--r--   0 runner    (1001) docker     (127)      151 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/hybrid.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1069 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)      162 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/isolates.rst
--rw-r--r--   0 runner    (1001) docker     (127)      201 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/isomorphism.ismags.rst
--rw-r--r--   0 runner    (1001) docker     (127)      728 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/isomorphism.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1424 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/isomorphism.vf2.rst
--rw-r--r--   0 runner    (1001) docker     (127)      317 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/link_analysis.rst
--rw-r--r--   0 runner    (1001) docker     (127)      357 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/link_prediction.rst
--rw-r--r--   0 runner    (1001) docker     (127)      275 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/lowest_common_ancestors.rst
--rw-r--r--   0 runner    (1001) docker     (127)      242 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/matching.rst
--rw-r--r--   0 runner    (1001) docker     (127)      207 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/minors.rst
--rw-r--r--   0 runner    (1001) docker     (127)      183 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/mis.rst
--rw-r--r--   0 runner    (1001) docker     (127)      118 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/moral.rst
--rw-r--r--   0 runner    (1001) docker     (127)      192 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/node_classification.rst
--rw-r--r--   0 runner    (1001) docker     (127)      157 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/non_randomness.rst
--rw-r--r--   0 runner    (1001) docker     (127)      746 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/operators.rst
--rw-r--r--   0 runner    (1001) docker     (127)      173 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/planar_drawing.rst
--rw-r--r--   0 runner    (1001) docker     (127)      170 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/planarity.rst
--rw-r--r--   0 runner    (1001) docker     (127)      189 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/polynomials.rst
--rw-r--r--   0 runner    (1001) docker     (127)      165 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/reciprocity.rst
--rw-r--r--   0 runner    (1001) docker     (127)      153 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/regular.rst
--rw-r--r--   0 runner    (1001) docker     (127)      143 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/rich_club.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1846 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/shortest_paths.rst
--rw-r--r--   0 runner    (1001) docker     (127)      319 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/similarity.rst
--rw-r--r--   0 runner    (1001) docker     (127)      219 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/simple_paths.rst
--rw-r--r--   0 runner    (1001) docker     (127)      185 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/smallworld.rst
--rw-r--r--   0 runner    (1001) docker     (127)      126 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/smetric.rst
--rw-r--r--   0 runner    (1001) docker     (127)      138 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/sparsifiers.rst
--rw-r--r--   0 runner    (1001) docker     (127)      198 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/structuralholes.rst
--rw-r--r--   0 runner    (1001) docker     (127)      168 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/summarization.rst
--rw-r--r--   0 runner    (1001) docker     (127)      172 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/swap.rst
--rw-r--r--   0 runner    (1001) docker     (127)      186 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/threshold.rst
--rw-r--r--   0 runner    (1001) docker     (127)      150 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/time_dependent.rst
--rw-r--r--   0 runner    (1001) docker     (127)      240 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/tournament.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1097 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/traversal.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1493 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/tree.rst
--rw-r--r--   0 runner    (1001) docker     (127)      215 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/triads.rst
--rw-r--r--   0 runner    (1001) docker     (127)      137 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/vitality.rst
--rw-r--r--   0 runner    (1001) docker     (127)      146 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/voronoi.rst
--rw-r--r--   0 runner    (1001) docker     (127)      122 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/walks.rst
--rw-r--r--   0 runner    (1001) docker     (127)      141 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/algorithms/wiener.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.042862 networkx-3.2rc0/doc/reference/classes/
--rw-r--r--   0 runner    (1001) docker     (127)     1643 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/classes/digraph.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1387 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/classes/graph.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2679 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/classes/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1979 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/classes/multidigraph.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1676 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/classes/multigraph.rst
--rw-r--r--   0 runner    (1001) docker     (127)      920 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/convert.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2414 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/drawing.rst
--rw-r--r--   0 runner    (1001) docker     (127)      713 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/exceptions.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1143 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/functions.rst
--rw-r--r--   0 runner    (1001) docker     (127)     6544 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/generators.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2412 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/glossary.rst
--rw-r--r--   0 runner    (1001) docker     (127)      300 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)    13817 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/introduction.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1439 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/linalg.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4131 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/randomness.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.042862 networkx-3.2rc0/doc/reference/readwrite/
--rw-r--r--   0 runner    (1001) docker     (127)      187 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/adjlist.rst
--rw-r--r--   0 runner    (1001) docker     (127)      234 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/edgelist.rst
--rw-r--r--   0 runner    (1001) docker     (127)      159 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/gexf.rst
--rw-r--r--   0 runner    (1001) docker     (127)      189 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/gml.rst
--rw-r--r--   0 runner    (1001) docker     (127)      173 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/graphml.rst
--rw-r--r--   0 runner    (1001) docker     (127)      270 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)      237 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/json_graph.rst
--rw-r--r--   0 runner    (1001) docker     (127)      122 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/leda.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2766 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/matrix_market.rst
--rw-r--r--   0 runner    (1001) docker     (127)      257 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/multiline_adjlist.rst
--rw-r--r--   0 runner    (1001) docker     (127)      157 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/pajek.rst
--rw-r--r--   0 runner    (1001) docker     (127)      964 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/sparsegraph6.rst
--rw-r--r--   0 runner    (1001) docker     (127)      156 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/readwrite/text.rst
--rw-r--r--   0 runner    (1001) docker     (127)      232 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/relabel.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1759 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/reference/utils.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.046862 networkx-3.2rc0/doc/release/
--rw-r--r--   0 runner    (1001) docker     (127)     9278 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_0.99.rst
--rw-r--r--   0 runner    (1001) docker     (127)     8982 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.0.rst
--rw-r--r--   0 runner    (1001) docker     (127)    10399 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.10.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1661 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.11.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2035 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.4.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4630 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.5.rst
--rw-r--r--   0 runner    (1001) docker     (127)     3999 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.6.rst
--rw-r--r--   0 runner    (1001) docker     (127)      720 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.7.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1400 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.8.rst
--rw-r--r--   0 runner    (1001) docker     (127)    10863 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/api_1.9.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2529 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/contribs.py
--rw-r--r--   0 runner    (1001) docker     (127)      668 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/index.rst
--rw-r--r--   0 runner    (1001) docker     (127)    13508 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/migration_guide_from_1.x_to_2.0.rst
--rw-r--r--   0 runner    (1001) docker     (127)     8349 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/migration_guide_from_2.x_to_3.0.rst
--rw-r--r--   0 runner    (1001) docker     (127)    34768 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/old_release_log.rst
--rw-r--r--   0 runner    (1001) docker     (127)    21108 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.0.rst
--rw-r--r--   0 runner    (1001) docker     (127)     9205 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.1.rst
--rw-r--r--   0 runner    (1001) docker     (127)     5603 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.2.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2773 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.3.rst
--rw-r--r--   0 runner    (1001) docker     (127)    13600 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.4.rst
--rw-r--r--   0 runner    (1001) docker     (127)    17124 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.5.rst
--rw-r--r--   0 runner    (1001) docker     (127)    32225 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.6.rst
--rw-r--r--   0 runner    (1001) docker     (127)      608 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.7.1.rst
--rw-r--r--   0 runner    (1001) docker     (127)    20576 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.7.rst
--rw-r--r--   0 runner    (1001) docker     (127)     4814 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.1.rst
--rw-r--r--   0 runner    (1001) docker     (127)      911 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.2.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1749 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.3.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2068 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.4.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1873 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.5.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2459 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.6.rst
--rw-r--r--   0 runner    (1001) docker     (127)     1632 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.7.rst
--rw-r--r--   0 runner    (1001) docker     (127)     2414 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.8.rst
--rw-r--r--   0 runner    (1001) docker     (127)     5520 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_2.8.rst
--rw-r--r--   0 runner    (1001) docker     (127)    15747 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_3.0.rst
--rw-r--r--   0 runner    (1001) docker     (127)     7098 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_3.1.rst
--rw-r--r--   0 runner    (1001) docker     (127)    28579 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/release_dev.rst
--rw-r--r--   0 runner    (1001) docker     (127)      777 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/release/report_functions_without_rst_generated.py
--rw-r--r--   0 runner    (1001) docker     (127)    19595 2023-10-11 17:01:11.000000 networkx-3.2rc0/doc/tutorial.rst
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.046862 networkx-3.2rc0/examples/
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.050862 networkx-3.2rc0/examples/3d_drawing/
--rw-r--r--   0 runner    (1001) docker     (127)       22 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/3d_drawing/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)      934 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/3d_drawing/mayavi2_spring.py
--rw-r--r--   0 runner    (1001) docker     (127)     1149 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/3d_drawing/plot_basic.py
--rw-r--r--   0 runner    (1001) docker     (127)      185 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/README.txt
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.054863 networkx-3.2rc0/examples/algorithms/
--rw-r--r--   0 runner    (1001) docker     (127)       22 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)  1346746 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/WormNet.v3.benchmark.txt
--rw-r--r--   0 runner    (1001) docker     (127)     2335 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/hartford_drug.edgelist
--rw-r--r--   0 runner    (1001) docker     (127)     4119 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_beam_search.py
--rw-r--r--   0 runner    (1001) docker     (127)     2126 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_betweenness_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     2680 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_blockmodel.py
--rw-r--r--   0 runner    (1001) docker     (127)     3496 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_circuits.py
--rw-r--r--   0 runner    (1001) docker     (127)     1194 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_davis_club.py
--rw-r--r--   0 runner    (1001) docker     (127)     2253 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_dedensification.py
--rw-r--r--   0 runner    (1001) docker     (127)     2477 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_girvan_newman.py
--rw-r--r--   0 runner    (1001) docker     (127)      838 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_greedy_coloring.py
--rw-r--r--   0 runner    (1001) docker     (127)     5996 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_iterated_dynamical_systems.py
--rw-r--r--   0 runner    (1001) docker     (127)      637 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_krackhardt_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     1395 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_lca.py
--rw-r--r--   0 runner    (1001) docker     (127)      901 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_maximum_independent_set.py
--rw-r--r--   0 runner    (1001) docker     (127)     2444 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_parallel_betweenness.py
--rw-r--r--   0 runner    (1001) docker     (127)     1039 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_rcm.py
--rw-r--r--   0 runner    (1001) docker     (127)     1485 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_shortest_path.py
--rw-r--r--   0 runner    (1001) docker     (127)     3110 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_snap.py
--rw-r--r--   0 runner    (1001) docker     (127)     6472 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/algorithms/plot_subgraphs.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.054863 networkx-3.2rc0/examples/basic/
--rw-r--r--   0 runner    (1001) docker     (127)       12 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/basic/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)     1065 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/basic/plot_properties.py
--rw-r--r--   0 runner    (1001) docker     (127)      525 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/basic/plot_read_write.py
--rw-r--r--   0 runner    (1001) docker     (127)     1240 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/basic/plot_simple_graph.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.058863 networkx-3.2rc0/examples/drawing/
--rw-r--r--   0 runner    (1001) docker     (127)       16 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)   100224 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/chess_masters_WCC.pgn.bz2
--rw-r--r--   0 runner    (1001) docker     (127)    20317 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/knuth_miles.txt.gz
--rw-r--r--   0 runner    (1001) docker     (127)      621 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_center_node.py
--rw-r--r--   0 runner    (1001) docker     (127)     4579 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_chess_masters.py
--rw-r--r--   0 runner    (1001) docker     (127)     2139 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_custom_node_icons.py
--rw-r--r--   0 runner    (1001) docker     (127)     1556 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_degree.py
--rw-r--r--   0 runner    (1001) docker     (127)     1115 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_directed.py
--rw-r--r--   0 runner    (1001) docker     (127)      441 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_edge_colormap.py
--rw-r--r--   0 runner    (1001) docker     (127)      910 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_ego_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)      552 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_eigenvalues.py
--rw-r--r--   0 runner    (1001) docker     (127)     1054 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_four_grids.py
--rw-r--r--   0 runner    (1001) docker     (127)      665 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_house_with_colors.py
--rw-r--r--   0 runner    (1001) docker     (127)     4103 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_knuth_miles.py
--rw-r--r--   0 runner    (1001) docker     (127)     1243 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_labels_and_colors.py
--rw-r--r--   0 runner    (1001) docker     (127)      993 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_multipartite_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)      288 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_node_colormap.py
--rw-r--r--   0 runner    (1001) docker     (127)     2172 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_rainbow_coloring.py
--rw-r--r--   0 runner    (1001) docker     (127)      938 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_random_geometric_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     1228 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_sampson.py
--rw-r--r--   0 runner    (1001) docker     (127)      753 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_selfloops.py
--rw-r--r--   0 runner    (1001) docker     (127)      252 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_simple_path.py
--rw-r--r--   0 runner    (1001) docker     (127)     1592 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_spectral_grid.py
--rw-r--r--   0 runner    (1001) docker     (127)     1368 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_tsp.py
--rw-r--r--   0 runner    (1001) docker     (127)     1964 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_unix_email.py
--rw-r--r--   0 runner    (1001) docker     (127)     1124 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/plot_weighted_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)      976 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/sampson_data.zip
--rw-r--r--   0 runner    (1001) docker     (127)     1709 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/drawing/unix_email.mbox
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.058863 networkx-3.2rc0/examples/external/
--rw-r--r--   0 runner    (1001) docker     (127)       91 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/README.txt
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.058863 networkx-3.2rc0/examples/external/force/
--rw-r--r--   0 runner    (1001) docker     (127)      251 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/force/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)      177 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/force/force.css
--rw-r--r--   0 runner    (1001) docker     (127)      367 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/force/force.html
--rw-r--r--   0 runner    (1001) docker     (127)     2062 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/force/force.js
--rw-r--r--   0 runner    (1001) docker     (127)      986 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/javascript_force.py
--rw-r--r--   0 runner    (1001) docker     (127)     1053 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/external/plot_igraph.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.058863 networkx-3.2rc0/examples/geospatial/
--rw-r--r--   0 runner    (1001) docker     (127)      317 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)     3079 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/plot_delaunay.py
--rw-r--r--   0 runner    (1001) docker     (127)     3896 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/plot_lines.py
--rw-r--r--   0 runner    (1001) docker     (127)     2183 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/plot_osmnx.py
--rw-r--r--   0 runner    (1001) docker     (127)     2233 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/plot_points.py
--rw-r--r--   0 runner    (1001) docker     (127)     2252 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/geospatial/plot_polygons.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.062863 networkx-3.2rc0/examples/graph/
--rw-r--r--   0 runner    (1001) docker     (127)       12 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)     1011 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_dag_layout.py
--rw-r--r--   0 runner    (1001) docker     (127)      806 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_degree_sequence.py
--rw-r--r--   0 runner    (1001) docker     (127)      841 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_erdos_renyi.py
--rw-r--r--   0 runner    (1001) docker     (127)      496 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_expected_degree_sequence.py
--rw-r--r--   0 runner    (1001) docker     (127)     1172 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_football.py
--rw-r--r--   0 runner    (1001) docker     (127)      494 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_karate_club.py
--rw-r--r--   0 runner    (1001) docker     (127)     2966 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_morse_trie.py
--rw-r--r--   0 runner    (1001) docker     (127)     1443 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_mst.py
--rw-r--r--   0 runner    (1001) docker     (127)     2901 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_napoleon_russian_campaign.py
--rw-r--r--   0 runner    (1001) docker     (127)     2126 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_roget.py
--rw-r--r--   0 runner    (1001) docker     (127)     1952 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_triad_types.py
--rw-r--r--   0 runner    (1001) docker     (127)     1436 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_visibility_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     2681 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/plot_words.py
--rw-r--r--   0 runner    (1001) docker     (127)    15758 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/roget_dat.txt.gz
--rw-r--r--   0 runner    (1001) docker     (127)    33695 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graph/words_dat.txt.gz
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.062863 networkx-3.2rc0/examples/graphviz_drawing/
--rw-r--r--   0 runner    (1001) docker     (127)      188 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_drawing/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)      694 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_drawing/plot_attributes.py
--rw-r--r--   0 runner    (1001) docker     (127)      610 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_drawing/plot_conversion.py
--rw-r--r--   0 runner    (1001) docker     (127)      715 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_drawing/plot_grid.py
--rw-r--r--   0 runner    (1001) docker     (127)      597 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_drawing/plot_mini_atlas.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.062863 networkx-3.2rc0/examples/graphviz_layout/
--rw-r--r--   0 runner    (1001) docker     (127)      183 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)    19008 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/lanl_routes.edgelist
--rw-r--r--   0 runner    (1001) docker     (127)     1428 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/plot_atlas.py
--rw-r--r--   0 runner    (1001) docker     (127)      374 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/plot_circular_tree.py
--rw-r--r--   0 runner    (1001) docker     (127)     1104 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/plot_decomposition.py
--rw-r--r--   0 runner    (1001) docker     (127)     1723 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/plot_giant_component.py
--rw-r--r--   0 runner    (1001) docker     (127)     1552 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/graphviz_layout/plot_lanl_routes.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.062863 networkx-3.2rc0/examples/subclass/
--rw-r--r--   0 runner    (1001) docker     (127)       18 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/subclass/README.txt
--rw-r--r--   0 runner    (1001) docker     (127)     6023 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/subclass/plot_antigraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     2286 2023-10-11 17:01:11.000000 networkx-3.2rc0/examples/subclass/plot_printgraph.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.066863 networkx-3.2rc0/networkx/
--rw-r--r--   0 runner    (1001) docker     (127)     1092 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.074863 networkx-3.2rc0/networkx/algorithms/
--rw-r--r--   0 runner    (1001) docker     (127)     6512 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.078863 networkx-3.2rc0/networkx/algorithms/approximation/
--rw-r--r--   0 runner    (1001) docker     (127)     1177 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7674 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/clique.py
--rw-r--r--   0 runner    (1001) docker     (127)     2084 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/clustering_coefficient.py
--rw-r--r--   0 runner    (1001) docker     (127)    13107 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     5593 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/distance_measures.py
--rw-r--r--   0 runner    (1001) docker     (127)     4214 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/dominating_set.py
--rw-r--r--   0 runner    (1001) docker     (127)    13282 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)     1170 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/matching.py
--rw-r--r--   0 runner    (1001) docker     (127)     3664 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/maxcut.py
--rw-r--r--   0 runner    (1001) docker     (127)     1353 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/ramsey.py
--rw-r--r--   0 runner    (1001) docker     (127)     7487 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/steinertree.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.078863 networkx-3.2rc0/networkx/algorithms/approximation/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1171 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_approx_clust_coeff.py
--rw-r--r--   0 runner    (1001) docker     (127)     3022 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_clique.py
--rw-r--r--   0 runner    (1001) docker     (127)     5952 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     2024 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_distance_measures.py
--rw-r--r--   0 runner    (1001) docker     (127)     2686 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_dominating_set.py
--rw-r--r--   0 runner    (1001) docker     (127)     9346 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)      186 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_matching.py
--rw-r--r--   0 runner    (1001) docker     (127)     2426 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_maxcut.py
--rw-r--r--   0 runner    (1001) docker     (127)     1143 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_ramsey.py
--rw-r--r--   0 runner    (1001) docker     (127)     6901 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_steinertree.py
--rw-r--r--   0 runner    (1001) docker     (127)    30697 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_traveling_salesman.py
--rw-r--r--   0 runner    (1001) docker     (127)     9096 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_treewidth.py
--rw-r--r--   0 runner    (1001) docker     (127)     1942 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/tests/test_vertex_cover.py
--rw-r--r--   0 runner    (1001) docker     (127)    54487 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/traveling_salesman.py
--rw-r--r--   0 runner    (1001) docker     (127)     8148 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/treewidth.py
--rw-r--r--   0 runner    (1001) docker     (127)     2798 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/approximation/vertex_cover.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.078863 networkx-3.2rc0/networkx/algorithms/assortativity/
--rw-r--r--   0 runner    (1001) docker     (127)      294 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4216 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     8654 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/correlation.py
--rw-r--r--   0 runner    (1001) docker     (127)     7551 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/mixing.py
--rw-r--r--   0 runner    (1001) docker     (127)     5278 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/neighbor_degree.py
--rw-r--r--   0 runner    (1001) docker     (127)     3393 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/pairs.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.078863 networkx-3.2rc0/networkx/algorithms/assortativity/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2651 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/base_test.py
--rw-r--r--   0 runner    (1001) docker     (127)     4978 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     5069 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_correlation.py
--rw-r--r--   0 runner    (1001) docker     (127)     6820 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_mixing.py
--rw-r--r--   0 runner    (1001) docker     (127)     3968 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_neighbor_degree.py
--rw-r--r--   0 runner    (1001) docker     (127)     3008 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_pairs.py
--rw-r--r--   0 runner    (1001) docker     (127)     5852 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/asteroidal.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.082863 networkx-3.2rc0/networkx/algorithms/bipartite/
--rw-r--r--   0 runner    (1001) docker     (127)     3768 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8350 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/basic.py
--rw-r--r--   0 runner    (1001) docker     (127)     9144 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     6925 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/cluster.py
--rw-r--r--   0 runner    (1001) docker     (127)     2160 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/covering.py
--rw-r--r--   0 runner    (1001) docker     (127)    11317 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/edgelist.py
--rw-r--r--   0 runner    (1001) docker     (127)    20231 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/generators.py
--rw-r--r--   0 runner    (1001) docker     (127)    21620 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/matching.py
--rw-r--r--   0 runner    (1001) docker     (127)     6127 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/matrix.py
--rw-r--r--   0 runner    (1001) docker     (127)    17165 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/projection.py
--rw-r--r--   0 runner    (1001) docker     (127)     3397 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/redundancy.py
--rw-r--r--   0 runner    (1001) docker     (127)     1880 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/spectral.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.082863 networkx-3.2rc0/networkx/algorithms/bipartite/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4291 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_basic.py
--rw-r--r--   0 runner    (1001) docker     (127)     6362 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     2801 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_cluster.py
--rw-r--r--   0 runner    (1001) docker     (127)     1221 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_covering.py
--rw-r--r--   0 runner    (1001) docker     (127)     7996 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_edgelist.py
--rw-r--r--   0 runner    (1001) docker     (127)    12794 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_generators.py
--rw-r--r--   0 runner    (1001) docker     (127)    11972 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_matching.py
--rw-r--r--   0 runner    (1001) docker     (127)     2900 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_matrix.py
--rw-r--r--   0 runner    (1001) docker     (127)    15134 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_project.py
--rw-r--r--   0 runner    (1001) docker     (127)      919 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_redundancy.py
--rw-r--r--   0 runner    (1001) docker     (127)     2358 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_spectral_bipartivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     5330 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/boundary.py
--rw-r--r--   0 runner    (1001) docker     (127)     6075 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/bridges.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.086863 networkx-3.2rc0/networkx/algorithms/centrality/
--rw-r--r--   0 runner    (1001) docker     (127)      558 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    14374 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/betweenness.py
--rw-r--r--   0 runner    (1001) docker     (127)     9327 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/betweenness_subset.py
--rw-r--r--   0 runner    (1001) docker     (127)    10252 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/closeness.py
--rw-r--r--   0 runner    (1001) docker     (127)    11871 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/current_flow_betweenness.py
--rw-r--r--   0 runner    (1001) docker     (127)     8046 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/current_flow_betweenness_subset.py
--rw-r--r--   0 runner    (1001) docker     (127)     3351 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/current_flow_closeness.py
--rw-r--r--   0 runner    (1001) docker     (127)     3881 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/degree_alg.py
--rw-r--r--   0 runner    (1001) docker     (127)     3627 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/dispersion.py
--rw-r--r--   0 runner    (1001) docker     (127)    12738 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/eigenvector.py
--rw-r--r--   0 runner    (1001) docker     (127)     3829 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/flow_matrix.py
--rw-r--r--   0 runner    (1001) docker     (127)    27866 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/group.py
--rw-r--r--   0 runner    (1001) docker     (127)     2626 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/harmonic.py
--rw-r--r--   0 runner    (1001) docker     (127)    10917 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/katz.py
--rw-r--r--   0 runner    (1001) docker     (127)     5403 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/laplacian.py
--rw-r--r--   0 runner    (1001) docker     (127)     6850 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/load.py
--rw-r--r--   0 runner    (1001) docker     (127)     4415 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/percolation.py
--rw-r--r--   0 runner    (1001) docker     (127)     7017 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/reaching.py
--rw-r--r--   0 runner    (1001) docker     (127)     4966 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/second_order.py
--rw-r--r--   0 runner    (1001) docker     (127)     9472 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/subgraph_alg.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.090863 networkx-3.2rc0/networkx/algorithms/centrality/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    26795 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)    12554 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality_subset.py
--rw-r--r--   0 runner    (1001) docker     (127)    10209 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_closeness_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     7870 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     5839 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py
--rw-r--r--   0 runner    (1001) docker     (127)     1379 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_closeness.py
--rw-r--r--   0 runner    (1001) docker     (127)     4105 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_degree_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     1959 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_dispersion.py
--rw-r--r--   0 runner    (1001) docker     (127)     4897 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_eigenvector_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     8686 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_group.py
--rw-r--r--   0 runner    (1001) docker     (127)     3658 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_harmonic_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)    11240 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_katz_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     5916 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_laplacian_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)    11343 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_load_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     2591 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_percolation_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     4143 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_reaching.py
--rw-r--r--   0 runner    (1001) docker     (127)     1999 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_second_order_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     3729 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_subgraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     8705 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_trophic.py
--rw-r--r--   0 runner    (1001) docker     (127)     1692 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/tests/test_voterank.py
--rw-r--r--   0 runner    (1001) docker     (127)     4654 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/trophic.py
--rw-r--r--   0 runner    (1001) docker     (127)     3227 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/centrality/voterank_alg.py
--rw-r--r--   0 runner    (1001) docker     (127)     6964 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/chains.py
--rw-r--r--   0 runner    (1001) docker     (127)    13285 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/chordal.py
--rw-r--r--   0 runner    (1001) docker     (127)    30539 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/clique.py
--rw-r--r--   0 runner    (1001) docker     (127)    20285 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/cluster.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.090863 networkx-3.2rc0/networkx/algorithms/coloring/
--rw-r--r--   0 runner    (1001) docker     (127)      182 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/coloring/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    16279 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/coloring/equitable_coloring.py
--rw-r--r--   0 runner    (1001) docker     (127)    20170 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/coloring/greedy_coloring.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.090863 networkx-3.2rc0/networkx/algorithms/coloring/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/coloring/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    23712 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/coloring/tests/test_coloring.py
--rw-r--r--   0 runner    (1001) docker     (127)     4536 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/communicability_alg.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.094863 networkx-3.2rc0/networkx/algorithms/community/
--rw-r--r--   0 runner    (1001) docker     (127)     1125 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5912 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/asyn_fluid.py
--rw-r--r--   0 runner    (1001) docker     (127)     6631 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)      903 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/community_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)     2456 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/kclique.py
--rw-r--r--   0 runner    (1001) docker     (127)     4345 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/kernighan_lin.py
--rw-r--r--   0 runner    (1001) docker     (127)    11846 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/label_propagation.py
--rw-r--r--   0 runner    (1001) docker     (127)    14764 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/louvain.py
--rw-r--r--   0 runner    (1001) docker     (127)     8086 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/lukes.py
--rw-r--r--   0 runner    (1001) docker     (127)    18020 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/modularity_max.py
--rw-r--r--   0 runner    (1001) docker     (127)    11686 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/quality.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.094863 networkx-3.2rc0/networkx/algorithms/community/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3057 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_asyn_fluid.py
--rw-r--r--   0 runner    (1001) docker     (127)     2931 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_centrality.py
--rw-r--r--   0 runner    (1001) docker     (127)     2413 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_kclique.py
--rw-r--r--   0 runner    (1001) docker     (127)     2709 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_kernighan_lin.py
--rw-r--r--   0 runner    (1001) docker     (127)     7870 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_label_propagation.py
--rw-r--r--   0 runner    (1001) docker     (127)     7255 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_louvain.py
--rw-r--r--   0 runner    (1001) docker     (127)     3961 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_lukes.py
--rw-r--r--   0 runner    (1001) docker     (127)    10365 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_modularity_max.py
--rw-r--r--   0 runner    (1001) docker     (127)     5274 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_quality.py
--rw-r--r--   0 runner    (1001) docker     (127)      706 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/community/tests/test_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.094863 networkx-3.2rc0/networkx/algorithms/components/
--rw-r--r--   0 runner    (1001) docker     (127)      173 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2699 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/attracting.py
--rw-r--r--   0 runner    (1001) docker     (127)    12765 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/biconnected.py
--rw-r--r--   0 runner    (1001) docker     (127)     4312 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/connected.py
--rw-r--r--   0 runner    (1001) docker     (127)     2025 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/semiconnected.py
--rw-r--r--   0 runner    (1001) docker     (127)    11712 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/strongly_connected.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.094863 networkx-3.2rc0/networkx/algorithms/components/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2243 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_attracting.py
--rw-r--r--   0 runner    (1001) docker     (127)     6036 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_biconnected.py
--rw-r--r--   0 runner    (1001) docker     (127)     3983 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_connected.py
--rw-r--r--   0 runner    (1001) docker     (127)     1792 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_semiconnected.py
--rw-r--r--   0 runner    (1001) docker     (127)     6639 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_strongly_connected.py
--rw-r--r--   0 runner    (1001) docker     (127)     2887 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/tests/test_weakly_connected.py
--rw-r--r--   0 runner    (1001) docker     (127)     4366 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/components/weakly_connected.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.098863 networkx-3.2rc0/networkx/algorithms/connectivity/
--rw-r--r--   0 runner    (1001) docker     (127)      281 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    29912 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)    23183 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/cuts.py
--rw-r--r--   0 runner    (1001) docker     (127)    14852 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/disjoint_paths.py
--rw-r--r--   0 runner    (1001) docker     (127)    43965 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/edge_augmentation.py
--rw-r--r--   0 runner    (1001) docker     (127)    20709 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/edge_kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)     8166 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)     9423 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/kcutsets.py
--rw-r--r--   0 runner    (1001) docker     (127)     5375 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/stoerwagner.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.098863 networkx-3.2rc0/networkx/algorithms/connectivity/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    15027 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)    10353 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_cuts.py
--rw-r--r--   0 runner    (1001) docker     (127)     8392 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_disjoint_paths.py
--rw-r--r--   0 runner    (1001) docker     (127)    15522 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_edge_augmentation.py
--rw-r--r--   0 runner    (1001) docker     (127)    16453 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_edge_kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)     8554 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_kcomponents.py
--rw-r--r--   0 runner    (1001) docker     (127)     8458 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_kcutsets.py
--rw-r--r--   0 runner    (1001) docker     (127)     3011 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_stoer_wagner.py
--rw-r--r--   0 runner    (1001) docker     (127)     3168 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/connectivity/utils.py
--rw-r--r--   0 runner    (1001) docker     (127)    15990 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/core.py
--rw-r--r--   0 runner    (1001) docker     (127)     5290 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/covering.py
--rw-r--r--   0 runner    (1001) docker     (127)     9960 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/cuts.py
--rw-r--r--   0 runner    (1001) docker     (127)    43080 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/cycles.py
--rw-r--r--   0 runner    (1001) docker     (127)    15440 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/d_separation.py
--rw-r--r--   0 runner    (1001) docker     (127)    39144 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/dag.py
--rw-r--r--   0 runner    (1001) docker     (127)    30735 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/distance_measures.py
--rw-r--r--   0 runner    (1001) docker     (127)     6914 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/distance_regular.py
--rw-r--r--   0 runner    (1001) docker     (127)     3422 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/dominance.py
--rw-r--r--   0 runner    (1001) docker     (127)     2675 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/dominating.py
--rw-r--r--   0 runner    (1001) docker     (127)     4786 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/efficiency_measures.py
--rw-r--r--   0 runner    (1001) docker     (127)    14160 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/euler.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.102863 networkx-3.2rc0/networkx/algorithms/flow/
--rw-r--r--   0 runner    (1001) docker     (127)      341 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    13435 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/boykovkolmogorov.py
--rw-r--r--   0 runner    (1001) docker     (127)    14459 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/capacityscaling.py
--rw-r--r--   0 runner    (1001) docker     (127)     7310 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/dinitz_alg.py
--rw-r--r--   0 runner    (1001) docker     (127)     8292 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/edmondskarp.py
--rw-r--r--   0 runner    (1001) docker     (127)     6320 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/gomory_hu.py
--rw-r--r--   0 runner    (1001) docker     (127)    22809 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/maxflow.py
--rw-r--r--   0 runner    (1001) docker     (127)    12248 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/mincost.py
--rw-r--r--   0 runner    (1001) docker     (127)    25175 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/networksimplex.py
--rw-r--r--   0 runner    (1001) docker     (127)    15823 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/preflowpush.py
--rw-r--r--   0 runner    (1001) docker     (127)    10474 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/shortestaugmentingpath.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.102863 networkx-3.2rc0/networkx/algorithms/flow/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    44623 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/gl1.gpickle.bz2
--rw-r--r--   0 runner    (1001) docker     (127)    42248 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/gw1.gpickle.bz2
--rw-r--r--   0 runner    (1001) docker     (127)    18972 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/netgen-2.gpickle.bz2
--rw-r--r--   0 runner    (1001) docker     (127)     4471 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/test_gomory_hu.py
--rw-r--r--   0 runner    (1001) docker     (127)    18727 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/test_maxflow.py
--rw-r--r--   0 runner    (1001) docker     (127)     4623 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/test_maxflow_large_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)    17816 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/test_mincost.py
--rw-r--r--   0 runner    (1001) docker     (127)    12103 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/test_networksimplex.py
--rw-r--r--   0 runner    (1001) docker     (127)    88132 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/tests/wlm3.gpickle.bz2
--rw-r--r--   0 runner    (1001) docker     (127)     6001 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/flow/utils.py
--rw-r--r--   0 runner    (1001) docker     (127)    11887 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/graph_hashing.py
--rw-r--r--   0 runner    (1001) docker     (127)    15807 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/graphical.py
--rw-r--r--   0 runner    (1001) docker     (127)     1541 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/hierarchy.py
--rw-r--r--   0 runner    (1001) docker     (127)     6180 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/hybrid.py
--rw-r--r--   0 runner    (1001) docker     (127)     2325 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isolate.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.102863 networkx-3.2rc0/networkx/algorithms/isomorphism/
--rw-r--r--   0 runner    (1001) docker     (127)      406 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    43529 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/ismags.py
--rw-r--r--   0 runner    (1001) docker     (127)     7097 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/isomorph.py
--rw-r--r--   0 runner    (1001) docker     (127)    40528 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/isomorphvf2.py
--rw-r--r--   0 runner    (1001) docker     (127)    10891 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/matchhelpers.py
--rw-r--r--   0 runner    (1001) docker     (127)    10948 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/temporalisomorphvf2.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1442 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.A99
--rw-r--r--   0 runner    (1001) docker     (127)     1442 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.B99
--rw-r--r--   0 runner    (1001) docker     (127)      310 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.A99
--rw-r--r--   0 runner    (1001) docker     (127)     1602 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.B99
--rw-r--r--   0 runner    (1001) docker     (127)    10585 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_ismags.py
--rw-r--r--   0 runner    (1001) docker     (127)     1663 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_isomorphism.py
--rw-r--r--   0 runner    (1001) docker     (127)    11751 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_isomorphvf2.py
--rw-r--r--   0 runner    (1001) docker     (127)     2483 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_match_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     7346 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_temporalisomorphvf2.py
--rw-r--r--   0 runner    (1001) docker     (127)     7066 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py
--rw-r--r--   0 runner    (1001) docker     (127)    49924 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2pp.py
--rw-r--r--   0 runner    (1001) docker     (127)    90080 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py
--rw-r--r--   0 runner    (1001) docker     (127)     6629 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2userfunc.py
--rw-r--r--   0 runner    (1001) docker     (127)     9397 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/tree_isomorphism.py
--rw-r--r--   0 runner    (1001) docker     (127)    36383 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/vf2pp.py
--rw-r--r--   0 runner    (1001) docker     (127)     7475 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/isomorphism/vf2userfunc.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/link_analysis/
--rw-r--r--   0 runner    (1001) docker     (127)      118 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    10244 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/hits_alg.py
--rw-r--r--   0 runner    (1001) docker     (127)    17183 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/pagerank_alg.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/link_analysis/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2525 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/tests/test_hits.py
--rw-r--r--   0 runner    (1001) docker     (127)     7530 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_analysis/tests/test_pagerank.py
--rw-r--r--   0 runner    (1001) docker     (127)    19968 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/link_prediction.py
--rw-r--r--   0 runner    (1001) docker     (127)     9186 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/lowest_common_ancestors.py
--rw-r--r--   0 runner    (1001) docker     (127)    44528 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/matching.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/minors/
--rw-r--r--   0 runner    (1001) docker     (127)      587 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/minors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    22735 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/minors/contraction.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/minors/tests/
--rw-r--r--   0 runner    (1001) docker     (127)    14212 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/minors/tests/test_contraction.py
--rw-r--r--   0 runner    (1001) docker     (127)     2339 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/mis.py
--rw-r--r--   0 runner    (1001) docker     (127)     1511 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/moral.py
--rw-r--r--   0 runner    (1001) docker     (127)     6461 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/node_classification.py
--rw-r--r--   0 runner    (1001) docker     (127)     2893 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/non_randomness.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.106864 networkx-3.2rc0/networkx/algorithms/operators/
--rw-r--r--   0 runner    (1001) docker     (127)      201 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     9544 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/all.py
--rw-r--r--   0 runner    (1001) docker     (127)    12689 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/binary.py
--rw-r--r--   0 runner    (1001) docker     (127)    16116 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/product.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.110864 networkx-3.2rc0/networkx/algorithms/operators/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8250 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/tests/test_all.py
--rw-r--r--   0 runner    (1001) docker     (127)    12795 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/tests/test_binary.py
--rw-r--r--   0 runner    (1001) docker     (127)    13402 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/tests/test_product.py
--rw-r--r--   0 runner    (1001) docker     (127)     1415 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/tests/test_unary.py
--rw-r--r--   0 runner    (1001) docker     (127)     1745 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/operators/unary.py
--rw-r--r--   0 runner    (1001) docker     (127)    16289 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/planar_drawing.py
--rw-r--r--   0 runner    (1001) docker     (127)    39476 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/planarity.py
--rw-r--r--   0 runner    (1001) docker     (127)    11270 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/polynomials.py
--rw-r--r--   0 runner    (1001) docker     (127)     2846 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/reciprocity.py
--rw-r--r--   0 runner    (1001) docker     (127)     6680 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/regular.py
--rw-r--r--   0 runner    (1001) docker     (127)     4166 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/richclub.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.110864 networkx-3.2rc0/networkx/algorithms/shortest_paths/
--rw-r--r--   0 runner    (1001) docker     (127)      285 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7674 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/astar.py
--rw-r--r--   0 runner    (1001) docker     (127)     8151 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/dense.py
--rw-r--r--   0 runner    (1001) docker     (127)    25321 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/generic.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.110864 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7176 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_astar.py
--rw-r--r--   0 runner    (1001) docker     (127)     6747 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_dense.py
--rw-r--r--   0 runner    (1001) docker     (127)     2300 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_dense_numpy.py
--rw-r--r--   0 runner    (1001) docker     (127)    18156 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_generic.py
--rw-r--r--   0 runner    (1001) docker     (127)     5899 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_unweighted.py
--rw-r--r--   0 runner    (1001) docker     (127)    35037 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_weighted.py
--rw-r--r--   0 runner    (1001) docker     (127)    15494 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/unweighted.py
--rw-r--r--   0 runner    (1001) docker     (127)    82339 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/shortest_paths/weighted.py
--rw-r--r--   0 runner    (1001) docker     (127)    59066 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/similarity.py
--rw-r--r--   0 runner    (1001) docker     (127)    30535 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/simple_paths.py
--rw-r--r--   0 runner    (1001) docker     (127)    13494 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/smallworld.py
--rw-r--r--   0 runner    (1001) docker     (127)     1933 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/smetric.py
--rw-r--r--   0 runner    (1001) docker     (127)    10073 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/sparsifiers.py
--rw-r--r--   0 runner    (1001) docker     (127)     9319 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/structuralholes.py
--rw-r--r--   0 runner    (1001) docker     (127)    23251 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/summarization.py
--rw-r--r--   0 runner    (1001) docker     (127)    14579 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/swap.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.126864 networkx-3.2rc0/networkx/algorithms/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      502 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_asteroidal.py
--rw-r--r--   0 runner    (1001) docker     (127)     6227 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_boundary.py
--rw-r--r--   0 runner    (1001) docker     (127)     4027 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_bridges.py
--rw-r--r--   0 runner    (1001) docker     (127)     4363 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_chains.py
--rw-r--r--   0 runner    (1001) docker     (127)     4438 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_chordal.py
--rw-r--r--   0 runner    (1001) docker     (127)    12189 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_clique.py
--rw-r--r--   0 runner    (1001) docker     (127)    15595 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_cluster.py
--rw-r--r--   0 runner    (1001) docker     (127)     2938 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_communicability.py
--rw-r--r--   0 runner    (1001) docker     (127)     7016 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_core.py
--rw-r--r--   0 runner    (1001) docker     (127)     2718 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_covering.py
--rw-r--r--   0 runner    (1001) docker     (127)     5377 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_cuts.py
--rw-r--r--   0 runner    (1001) docker     (127)    34243 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_cycles.py
--rw-r--r--   0 runner    (1001) docker     (127)     6600 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_d_separation.py
--rw-r--r--   0 runner    (1001) docker     (127)    27722 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_dag.py
--rw-r--r--   0 runner    (1001) docker     (127)    22327 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_distance_measures.py
--rw-r--r--   0 runner    (1001) docker     (127)     2312 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_distance_regular.py
--rw-r--r--   0 runner    (1001) docker     (127)     9373 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_dominance.py
--rw-r--r--   0 runner    (1001) docker     (127)     1228 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_dominating.py
--rw-r--r--   0 runner    (1001) docker     (127)     1894 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_efficiency.py
--rw-r--r--   0 runner    (1001) docker     (127)    10987 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_euler.py
--rw-r--r--   0 runner    (1001) docker     (127)    23517 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_graph_hashing.py
--rw-r--r--   0 runner    (1001) docker     (127)     5366 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_graphical.py
--rw-r--r--   0 runner    (1001) docker     (127)      941 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_hierarchy.py
--rw-r--r--   0 runner    (1001) docker     (127)      720 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_hybrid.py
--rw-r--r--   0 runner    (1001) docker     (127)      555 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_isolate.py
--rw-r--r--   0 runner    (1001) docker     (127)    19442 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_link_prediction.py
--rw-r--r--   0 runner    (1001) docker     (127)    13153 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_lowest_common_ancestors.py
--rw-r--r--   0 runner    (1001) docker     (127)    20174 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_matching.py
--rw-r--r--   0 runner    (1001) docker     (127)     6741 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_max_weight_clique.py
--rw-r--r--   0 runner    (1001) docker     (127)     1875 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_mis.py
--rw-r--r--   0 runner    (1001) docker     (127)      452 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_moral.py
--rw-r--r--   0 runner    (1001) docker     (127)     4663 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_node_classification.py
--rw-r--r--   0 runner    (1001) docker     (127)      782 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_non_randomness.py
--rw-r--r--   0 runner    (1001) docker     (127)     8771 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_planar_drawing.py
--rw-r--r--   0 runner    (1001) docker     (127)    13148 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_planarity.py
--rw-r--r--   0 runner    (1001) docker     (127)     1983 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_polynomials.py
--rw-r--r--   0 runner    (1001) docker     (127)     1296 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_reciprocity.py
--rw-r--r--   0 runner    (1001) docker     (127)     2457 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_regular.py
--rw-r--r--   0 runner    (1001) docker     (127)     2585 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_richclub.py
--rw-r--r--   0 runner    (1001) docker     (127)    32216 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_similarity.py
--rw-r--r--   0 runner    (1001) docker     (127)    24075 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_simple_paths.py
--rw-r--r--   0 runner    (1001) docker     (127)     2405 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_smallworld.py
--rw-r--r--   0 runner    (1001) docker     (127)      980 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_smetric.py
--rw-r--r--   0 runner    (1001) docker     (127)     4043 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_sparsifiers.py
--rw-r--r--   0 runner    (1001) docker     (127)     5536 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_structuralholes.py
--rw-r--r--   0 runner    (1001) docker     (127)    21313 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_summarization.py
--rw-r--r--   0 runner    (1001) docker     (127)     5307 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_swap.py
--rw-r--r--   0 runner    (1001) docker     (127)     9751 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_threshold.py
--rw-r--r--   0 runner    (1001) docker     (127)    13342 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_time_dependent.py
--rw-r--r--   0 runner    (1001) docker     (127)     4158 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_tournament.py
--rw-r--r--   0 runner    (1001) docker     (127)     9088 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_triads.py
--rw-r--r--   0 runner    (1001) docker     (127)     1380 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_vitality.py
--rw-r--r--   0 runner    (1001) docker     (127)     3477 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_voronoi.py
--rw-r--r--   0 runner    (1001) docker     (127)     1499 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_walks.py
--rw-r--r--   0 runner    (1001) docker     (127)     2080 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tests/test_wiener.py
--rw-r--r--   0 runner    (1001) docker     (127)    31088 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/threshold.py
--rw-r--r--   0 runner    (1001) docker     (127)     5757 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/time_dependent.py
--rw-r--r--   0 runner    (1001) docker     (127)    11676 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tournament.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.126864 networkx-3.2rc0/networkx/algorithms/traversal/
--rw-r--r--   0 runner    (1001) docker     (127)      142 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3424 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/beamsearch.py
--rw-r--r--   0 runner    (1001) docker     (127)    18107 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/breadth_first_search.py
--rw-r--r--   0 runner    (1001) docker     (127)    13730 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/depth_first_search.py
--rw-r--r--   0 runner    (1001) docker     (127)     6239 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/edgebfs.py
--rw-r--r--   0 runner    (1001) docker     (127)     5952 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/edgedfs.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.130864 networkx-3.2rc0/networkx/algorithms/traversal/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1076 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/test_beamsearch.py
--rw-r--r--   0 runner    (1001) docker     (127)     6796 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/test_bfs.py
--rw-r--r--   0 runner    (1001) docker     (127)     8616 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/test_dfs.py
--rw-r--r--   0 runner    (1001) docker     (127)     4702 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/test_edgebfs.py
--rw-r--r--   0 runner    (1001) docker     (127)     4775 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/traversal/tests/test_edgedfs.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.130864 networkx-3.2rc0/networkx/algorithms/tree/
--rw-r--r--   0 runner    (1001) docker     (127)      149 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    56002 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/branchings.py
--rw-r--r--   0 runner    (1001) docker     (127)    13407 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/coding.py
--rw-r--r--   0 runner    (1001) docker     (127)     3047 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/decomposition.py
--rw-r--r--   0 runner    (1001) docker     (127)    40276 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/mst.py
--rw-r--r--   0 runner    (1001) docker     (127)     4702 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/operations.py
--rw-r--r--   0 runner    (1001) docker     (127)     7553 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.134864 networkx-3.2rc0/networkx/algorithms/tree/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    18008 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_branchings.py
--rw-r--r--   0 runner    (1001) docker     (127)     3954 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_coding.py
--rw-r--r--   0 runner    (1001) docker     (127)     1871 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_decomposition.py
--rw-r--r--   0 runner    (1001) docker     (127)    24749 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_mst.py
--rw-r--r--   0 runner    (1001) docker     (127)     1961 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_operations.py
--rw-r--r--   0 runner    (1001) docker     (127)     4171 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/tree/tests/test_recognition.py
--rw-r--r--   0 runner    (1001) docker     (127)    15517 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/triads.py
--rw-r--r--   0 runner    (1001) docker     (127)     2331 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/vitality.py
--rw-r--r--   0 runner    (1001) docker     (127)     3178 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/voronoi.py
--rw-r--r--   0 runner    (1001) docker     (127)     2419 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/walks.py
--rw-r--r--   0 runner    (1001) docker     (127)     2328 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/algorithms/wiener.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.134864 networkx-3.2rc0/networkx/classes/
--rw-r--r--   0 runner    (1001) docker     (127)      364 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    11010 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/coreviews.py
--rw-r--r--   0 runner    (1001) docker     (127)    47159 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/digraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     1715 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/filters.py
--rw-r--r--   0 runner    (1001) docker     (127)    36323 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/function.py
--rw-r--r--   0 runner    (1001) docker     (127)    70379 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     8558 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/graphviews.py
--rw-r--r--   0 runner    (1001) docker     (127)    36283 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/multidigraph.py
--rw-r--r--   0 runner    (1001) docker     (127)    47127 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/multigraph.py
--rw-r--r--   0 runner    (1001) docker     (127)    45606 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/reportviews.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.138864 networkx-3.2rc0/networkx/classes/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6683 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/dispatch_interface.py
--rw-r--r--   0 runner    (1001) docker     (127)    16173 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/historical_tests.py
--rw-r--r--   0 runner    (1001) docker     (127)     2579 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_backends.py
--rw-r--r--   0 runner    (1001) docker     (127)    12128 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_coreviews.py
--rw-r--r--   0 runner    (1001) docker     (127)    12283 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_digraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     3683 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_digraph_historical.py
--rw-r--r--   0 runner    (1001) docker     (127)     5851 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_filters.py
--rw-r--r--   0 runner    (1001) docker     (127)    25770 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_function.py
--rw-r--r--   0 runner    (1001) docker     (127)    30913 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)      273 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_graph_historical.py
--rw-r--r--   0 runner    (1001) docker     (127)    11466 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_graphviews.py
--rw-r--r--   0 runner    (1001) docker     (127)    16342 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_multidigraph.py
--rw-r--r--   0 runner    (1001) docker     (127)    18777 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_multigraph.py
--rw-r--r--   0 runner    (1001) docker     (127)    41470 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_reportviews.py
--rw-r--r--   0 runner    (1001) docker     (127)     4103 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_special.py
--rw-r--r--   0 runner    (1001) docker     (127)    13223 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/classes/tests/test_subgraphviews.py
--rw-r--r--   0 runner    (1001) docker     (127)     7425 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/conftest.py
--rw-r--r--   0 runner    (1001) docker     (127)    15977 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/convert.py
--rw-r--r--   0 runner    (1001) docker     (127)    40378 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/convert_matrix.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.138864 networkx-3.2rc0/networkx/drawing/
--rw-r--r--   0 runner    (1001) docker     (127)      160 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    38829 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/layout.py
--rw-r--r--   0 runner    (1001) docker     (127)    14009 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/nx_agraph.py
--rw-r--r--   0 runner    (1001) docker     (127)    24805 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/nx_latex.py
--rw-r--r--   0 runner    (1001) docker     (127)    14135 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/nx_pydot.py
--rw-r--r--   0 runner    (1001) docker     (127)    51138 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/nx_pylab.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.142864 networkx-3.2rc0/networkx/drawing/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.142864 networkx-3.2rc0/networkx/drawing/tests/baseline/
--rw-r--r--   0 runner    (1001) docker     (127)    21918 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/baseline/test_house_with_colors.png
--rw-r--r--   0 runner    (1001) docker     (127)     9045 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/test_agraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     8710 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/test_latex.py
--rw-r--r--   0 runner    (1001) docker     (127)    17841 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/test_layout.py
--rw-r--r--   0 runner    (1001) docker     (127)     6242 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/test_pydot.py
--rw-r--r--   0 runner    (1001) docker     (127)    27576 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/drawing/tests/test_pylab.py
--rw-r--r--   0 runner    (1001) docker     (127)     3537 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/exception.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.146865 networkx-3.2rc0/networkx/generators/
--rw-r--r--   0 runner    (1001) docker     (127)     1318 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8887 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/atlas.dat.gz
--rw-r--r--   0 runner    (1001) docker     (127)     5557 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/atlas.py
--rw-r--r--   0 runner    (1001) docker     (127)    26475 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/classic.py
--rw-r--r--   0 runner    (1001) docker     (127)     1866 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/cographs.py
--rw-r--r--   0 runner    (1001) docker     (127)    34690 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/community.py
--rw-r--r--   0 runner    (1001) docker     (127)    30006 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/degree_seq.py
--rw-r--r--   0 runner    (1001) docker     (127)    15554 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/directed.py
--rw-r--r--   0 runner    (1001) docker     (127)     5013 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/duplication.py
--rw-r--r--   0 runner    (1001) docker     (127)     1873 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/ego.py
--rw-r--r--   0 runner    (1001) docker     (127)     6447 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/expanders.py
--rw-r--r--   0 runner    (1001) docker     (127)    30858 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/geometric.py
--rw-r--r--   0 runner    (1001) docker     (127)     6111 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/harary_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)    14148 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/internet_as_graphs.py
--rw-r--r--   0 runner    (1001) docker     (127)     4028 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/intersection.py
--rw-r--r--   0 runner    (1001) docker     (127)     2213 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/interval_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)    24717 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/joint_degree_seq.py
--rw-r--r--   0 runner    (1001) docker     (127)    13380 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/lattice.py
--rw-r--r--   0 runner    (1001) docker     (127)    17500 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/line.py
--rw-r--r--   0 runner    (1001) docker     (127)     3266 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/mycielski.py
--rw-r--r--   0 runner    (1001) docker     (127)     5232 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/nonisomorphic_trees.py
--rw-r--r--   0 runner    (1001) docker     (127)     4159 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/random_clustered.py
--rw-r--r--   0 runner    (1001) docker     (127)    44729 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/random_graphs.py
--rw-r--r--   0 runner    (1001) docker     (127)    27220 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/small.py
--rw-r--r--   0 runner    (1001) docker     (127)    22867 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/social.py
--rw-r--r--   0 runner    (1001) docker     (127)     4217 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/spectral_graph_forge.py
--rw-r--r--   0 runner    (1001) docker     (127)     1897 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/stochastic.py
--rw-r--r--   0 runner    (1001) docker     (127)     4264 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/sudoku.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.150864 networkx-3.2rc0/networkx/generators/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2530 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_atlas.py
--rw-r--r--   0 runner    (1001) docker     (127)    19798 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_classic.py
--rw-r--r--   0 runner    (1001) docker     (127)      460 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_cographs.py
--rw-r--r--   0 runner    (1001) docker     (127)    11311 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_community.py
--rw-r--r--   0 runner    (1001) docker     (127)     7093 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_degree_seq.py
--rw-r--r--   0 runner    (1001) docker     (127)     5258 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_directed.py
--rw-r--r--   0 runner    (1001) docker     (127)     1915 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_duplication.py
--rw-r--r--   0 runner    (1001) docker     (127)     1327 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_ego.py
--rw-r--r--   0 runner    (1001) docker     (127)     2896 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_expanders.py
--rw-r--r--   0 runner    (1001) docker     (127)    12512 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_geometric.py
--rw-r--r--   0 runner    (1001) docker     (127)     4937 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_harary_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     6795 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_internet_as_graphs.py
--rw-r--r--   0 runner    (1001) docker     (127)      819 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_intersection.py
--rw-r--r--   0 runner    (1001) docker     (127)     4278 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_interval_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     4270 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_joint_degree_seq.py
--rw-r--r--   0 runner    (1001) docker     (127)     9290 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_lattice.py
--rw-r--r--   0 runner    (1001) docker     (127)    10378 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_line.py
--rw-r--r--   0 runner    (1001) docker     (127)      822 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_mycielski.py
--rw-r--r--   0 runner    (1001) docker     (127)     2384 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_nonisomorphic_trees.py
--rw-r--r--   0 runner    (1001) docker     (127)      979 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_random_clustered.py
--rw-r--r--   0 runner    (1001) docker     (127)    13121 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_random_graphs.py
--rw-r--r--   0 runner    (1001) docker     (127)     6906 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_small.py
--rw-r--r--   0 runner    (1001) docker     (127)     1594 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_spectral_graph_forge.py
--rw-r--r--   0 runner    (1001) docker     (127)     2178 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_stochastic.py
--rw-r--r--   0 runner    (1001) docker     (127)     1968 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_sudoku.py
--rw-r--r--   0 runner    (1001) docker     (127)     2229 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_time_series.py
--rw-r--r--   0 runner    (1001) docker     (127)     7634 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_trees.py
--rw-r--r--   0 runner    (1001) docker     (127)      332 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/tests/test_triads.py
--rw-r--r--   0 runner    (1001) docker     (127)     2413 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/time_series.py
--rw-r--r--   0 runner    (1001) docker     (127)    39067 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/trees.py
--rw-r--r--   0 runner    (1001) docker     (127)     2233 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/generators/triads.py
--rw-r--r--   0 runner    (1001) docker     (127)     5778 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/lazy_imports.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.150864 networkx-3.2rc0/networkx/linalg/
--rw-r--r--   0 runner    (1001) docker     (127)      568 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    21106 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/algebraicconnectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)    15504 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/attrmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     2692 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/bethehessianmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     5513 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/graphmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)    13330 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/laplacianmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     4698 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/modularitymatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     4194 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/spectrum.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.154865 networkx-3.2rc0/networkx/linalg/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    13737 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_algebraic_connectivity.py
--rw-r--r--   0 runner    (1001) docker     (127)     2833 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_attrmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     1327 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_bethehessian.py
--rw-r--r--   0 runner    (1001) docker     (127)     8708 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_graphmatrix.py
--rw-r--r--   0 runner    (1001) docker     (127)     9934 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_laplacian.py
--rw-r--r--   0 runner    (1001) docker     (127)     3115 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_modularity.py
--rw-r--r--   0 runner    (1001) docker     (127)     2828 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/linalg/tests/test_spectrum.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.154865 networkx-3.2rc0/networkx/readwrite/
--rw-r--r--   0 runner    (1001) docker     (127)      562 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8386 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/adjlist.py
--rw-r--r--   0 runner    (1001) docker     (127)    14160 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/edgelist.py
--rw-r--r--   0 runner    (1001) docker     (127)    39668 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/gexf.py
--rw-r--r--   0 runner    (1001) docker     (127)    31104 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/gml.py
--rw-r--r--   0 runner    (1001) docker     (127)    11355 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/graph6.py
--rw-r--r--   0 runner    (1001) docker     (127)    39183 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/graphml.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.154865 networkx-3.2rc0/networkx/readwrite/json_graph/
--rw-r--r--   0 runner    (1001) docker     (127)      676 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4692 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/adjacency.py
--rw-r--r--   0 runner    (1001) docker     (127)     5234 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/cytoscape.py
--rw-r--r--   0 runner    (1001) docker     (127)     7450 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/node_link.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.154865 networkx-3.2rc0/networkx/readwrite/json_graph/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2456 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_adjacency.py
--rw-r--r--   0 runner    (1001) docker     (127)     2044 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_cytoscape.py
--rw-r--r--   0 runner    (1001) docker     (127)     4536 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_node_link.py
--rw-r--r--   0 runner    (1001) docker     (127)     1352 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_tree.py
--rw-r--r--   0 runner    (1001) docker     (127)     3827 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/json_graph/tree.py
--rw-r--r--   0 runner    (1001) docker     (127)     2749 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/leda.py
--rw-r--r--   0 runner    (1001) docker     (127)    11255 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/multiline_adjlist.py
--rw-r--r--   0 runner    (1001) docker     (127)     3043 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/p2g.py
--rw-r--r--   0 runner    (1001) docker     (127)     8690 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/pajek.py
--rw-r--r--   0 runner    (1001) docker     (127)    10269 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/sparse6.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.158865 networkx-3.2rc0/networkx/readwrite/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     9922 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_adjlist.py
--rw-r--r--   0 runner    (1001) docker     (127)     9969 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_edgelist.py
--rw-r--r--   0 runner    (1001) docker     (127)    19405 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_gexf.py
--rw-r--r--   0 runner    (1001) docker     (127)    21334 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_gml.py
--rw-r--r--   0 runner    (1001) docker     (127)     6069 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_graph6.py
--rw-r--r--   0 runner    (1001) docker     (127)    67149 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_graphml.py
--rw-r--r--   0 runner    (1001) docker     (127)     1392 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_leda.py
--rw-r--r--   0 runner    (1001) docker     (127)     1320 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_p2g.py
--rw-r--r--   0 runner    (1001) docker     (127)     4703 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_pajek.py
--rw-r--r--   0 runner    (1001) docker     (127)     5470 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_sparse6.py
--rw-r--r--   0 runner    (1001) docker     (127)    56562 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/tests/test_text.py
--rw-r--r--   0 runner    (1001) docker     (127)    32132 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/readwrite/text.py
--rw-r--r--   0 runner    (1001) docker     (127)    10279 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/relabel.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.158865 networkx-3.2rc0/networkx/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     8653 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_all_random_functions.py
--rw-r--r--   0 runner    (1001) docker     (127)    12731 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_convert.py
--rw-r--r--   0 runner    (1001) docker     (127)    14951 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_convert_numpy.py
--rw-r--r--   0 runner    (1001) docker     (127)    12257 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_convert_pandas.py
--rw-r--r--   0 runner    (1001) docker     (127)    10436 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_convert_scipy.py
--rw-r--r--   0 runner    (1001) docker     (127)      927 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (127)      220 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_import.py
--rw-r--r--   0 runner    (1001) docker     (127)     2680 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_lazy_imports.py
--rw-r--r--   0 runner    (1001) docker     (127)    14517 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/tests/test_relabel.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.162865 networkx-3.2rc0/networkx/utils/
--rw-r--r--   0 runner    (1001) docker     (127)      227 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    40939 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/backends.py
--rw-r--r--   0 runner    (1001) docker     (127)    46464 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/decorators.py
--rw-r--r--   0 runner    (1001) docker     (127)    10391 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/heaps.py
--rw-r--r--   0 runner    (1001) docker     (127)    10185 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/mapped_queue.py
--rw-r--r--   0 runner    (1001) docker     (127)    14351 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (127)     4237 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/random_sequence.py
--rw-r--r--   0 runner    (1001) docker     (127)     4623 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/rcm.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.162865 networkx-3.2rc0/networkx/utils/tests/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      363 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test__init.py
--rw-r--r--   0 runner    (1001) docker     (127)    13334 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_decorators.py
--rw-r--r--   0 runner    (1001) docker     (127)     3711 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_heaps.py
--rw-r--r--   0 runner    (1001) docker     (127)     7354 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_mapped_queue.py
--rw-r--r--   0 runner    (1001) docker     (127)     8218 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_misc.py
--rw-r--r--   0 runner    (1001) docker     (127)      925 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_random_sequence.py
--rw-r--r--   0 runner    (1001) docker     (127)     1421 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_rcm.py
--rw-r--r--   0 runner    (1001) docker     (127)     1579 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/tests/test_unionfind.py
--rw-r--r--   0 runner    (1001) docker     (127)     3338 2023-10-11 17:01:11.000000 networkx-3.2rc0/networkx/utils/union_find.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.066863 networkx-3.2rc0/networkx.egg-info/
--rw-r--r--   0 runner    (1001) docker     (127)     5137 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    34944 2023-10-11 17:01:28.000000 networkx-3.2rc0/networkx.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (127)       87 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (127)      354 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (127)        9 2023-10-11 17:01:27.000000 networkx-3.2rc0/networkx.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (127)     5184 2023-10-11 17:01:11.000000 networkx-3.2rc0/pyproject.toml
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2023-10-11 17:01:28.162865 networkx-3.2rc0/requirements/
--rw-r--r--   0 runner    (1001) docker     (127)      836 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/README.md
--rw-r--r--   0 runner    (1001) docker     (127)        4 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/benchmarking.txt
--rw-r--r--   0 runner    (1001) docker     (127)      193 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/default.txt
--rw-r--r--   0 runner    (1001) docker     (127)      156 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/developer.txt
--rw-r--r--   0 runner    (1001) docker     (127)      249 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/doc.txt
--rw-r--r--   0 runner    (1001) docker     (127)       81 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/example.txt
--rw-r--r--   0 runner    (1001) docker     (127)      176 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/extra.txt
--rw-r--r--   0 runner    (1001) docker     (127)       35 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/release.txt
--rw-r--r--   0 runner    (1001) docker     (127)      152 2023-10-11 17:01:11.000000 networkx-3.2rc0/requirements/test.txt
--rw-r--r--   0 runner    (1001) docker     (127)       38 2023-10-11 17:01:28.166865 networkx-3.2rc0/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.921310 networkx-3.3rc0/
+-rw-r--r--   0 runner    (1001) docker     (127)    17739 2024-03-22 20:12:12.000000 networkx-3.3rc0/CONTRIBUTING.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4084 2024-03-22 20:12:12.000000 networkx-3.3rc0/INSTALL.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1763 2024-03-22 20:12:12.000000 networkx-3.3rc0/LICENSE.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      872 2024-03-22 20:12:12.000000 networkx-3.3rc0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (127)     5093 2024-03-22 20:12:27.921310 networkx-3.3rc0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     2416 2024-03-22 20:12:12.000000 networkx-3.3rc0/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.785310 networkx-3.3rc0/doc/
+-rw-r--r--   0 runner    (1001) docker     (127)     4131 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/Makefile
+-rw-r--r--   0 runner    (1001) docker     (127)     1221 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.785310 networkx-3.3rc0/doc/_static/
+-rw-r--r--   0 runner    (1001) docker     (127)     2795 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/_static/copybutton.js
+-rw-r--r--   0 runner    (1001) docker     (127)      380 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/_static/custom.css
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.773310 networkx-3.3rc0/doc/_templates/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.785310 networkx-3.3rc0/doc/_templates/autosummary/
+-rw-r--r--   0 runner    (1001) docker     (127)      106 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/_templates/autosummary/base.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      667 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/_templates/autosummary/class.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     9762 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/conf.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.785310 networkx-3.3rc0/doc/developer/
+-rw-r--r--   0 runner    (1001) docker     (127)     7691 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/about_us.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       39 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/code_of_conduct.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       36 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/contribute.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     7820 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/core_developer.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     3215 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/deprecations.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      288 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     6713 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/new_contributor_faq.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.789310 networkx-3.3rc0/doc/developer/nxeps/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.789310 networkx-3.3rc0/doc/developer/nxeps/_static/
+-rw-r--r--   0 runner    (1001) docker     (127)    12925 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/_static/nxep-0000.png
+-rw-r--r--   0 runner    (1001) docker     (127)      245 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    11666 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-0000.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     7130 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-0001.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    13910 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-0002.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    17579 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-0003.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    13821 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-0004.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     3178 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/nxeps/nxep-template.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     8494 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/projects.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2603 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/release.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4398 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/roadmap.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    12737 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/teams.inc
+-rw-r--r--   0 runner    (1001) docker     (127)     2521 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/developer/values.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4341 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)       28 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/install.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.789310 networkx-3.3rc0/doc/reference/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.801310 networkx-3.3rc0/doc/reference/algorithms/
+-rw-r--r--   0 runner    (1001) docker     (127)     2429 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/approximation.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1126 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/assortativity.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      163 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/asteroidal.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2464 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/bipartite.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      150 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/boundary.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      146 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/bridges.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      179 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/broadcasting.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     3570 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/centrality.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      123 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/chains.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      234 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/chordal.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      288 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/clique.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      228 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/clustering.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      638 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/coloring.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      189 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/communicability_alg.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2123 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/community.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1463 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/component.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2005 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/connectivity.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      188 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/core.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      150 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/covering.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      237 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/cuts.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      232 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/cycles.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      203 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/d_separation.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      513 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/dag.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      300 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/distance_measures.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      257 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/distance_regular.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      166 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/dominance.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      177 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/dominating.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      187 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/efficiency_measures.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      216 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/euler.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1620 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/flow.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      204 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/graph_hashing.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      328 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/graphical.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      137 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/hierarchy.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      151 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/hybrid.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1085 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      162 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/isolates.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      201 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/isomorphism.ismags.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      774 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/isomorphism.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1600 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/isomorphism.vf2.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      317 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/link_analysis.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      357 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/link_prediction.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      275 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/lowest_common_ancestors.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      242 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/matching.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      252 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/minors.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      183 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/mis.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      118 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/moral.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      192 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/node_classification.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      157 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/non_randomness.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      765 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/operators.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      173 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/planar_drawing.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      170 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/planarity.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      189 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/polynomials.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      165 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/reciprocity.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      153 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/regular.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      143 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/rich_club.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1846 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/shortest_paths.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      319 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/similarity.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      219 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/simple_paths.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      185 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/smallworld.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      126 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/smetric.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      138 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/sparsifiers.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      198 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/structuralholes.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      168 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/summarization.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      172 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/swap.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      186 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/threshold.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      150 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/time_dependent.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      240 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/tournament.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1097 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/traversal.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1521 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/tree.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      215 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/triads.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      137 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/vitality.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      146 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/voronoi.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      122 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/walks.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      174 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/algorithms/wiener.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.801310 networkx-3.3rc0/doc/reference/classes/
+-rw-r--r--   0 runner    (1001) docker     (127)     1643 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/classes/digraph.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1387 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/classes/graph.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2679 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/classes/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1979 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/classes/multidigraph.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1676 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/classes/multigraph.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      920 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/convert.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2428 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/drawing.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      713 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/exceptions.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1143 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/functions.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     6697 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/generators.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2412 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/glossary.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      300 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1469 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/linalg.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4139 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/randomness.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.801310 networkx-3.3rc0/doc/reference/readwrite/
+-rw-r--r--   0 runner    (1001) docker     (127)      187 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/adjlist.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      573 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/dot.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      234 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/edgelist.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      159 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/gexf.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      189 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/gml.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      173 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/graphml.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      277 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      413 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/json_graph.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      122 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/leda.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2766 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/matrix_market.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      257 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/multiline_adjlist.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      157 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/pajek.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      964 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/sparsegraph6.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      156 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/readwrite/text.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      232 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/relabel.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1694 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/reference/utils.rst
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.809310 networkx-3.3rc0/doc/release/
+-rw-r--r--   0 runner    (1001) docker     (127)     9278 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_0.99.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     8982 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.0.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    10399 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.10.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1661 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.11.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2035 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.4.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4630 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.5.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     3999 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.6.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      720 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.7.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1400 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.8.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    10863 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/api_1.9.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2529 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/contribs.py
+-rw-r--r--   0 runner    (1001) docker     (127)      999 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/index.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    13508 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/migration_guide_from_1.x_to_2.0.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     8349 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/migration_guide_from_2.x_to_3.0.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    34768 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/old_release_log.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    21108 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.0.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     9205 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.1.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     5603 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.2.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2773 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.3.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    13600 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.4.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    17124 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.5.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    32225 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.6.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      608 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.7.1.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    20576 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.7.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     4814 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.1.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      911 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.2.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1749 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.3.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2068 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.4.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1873 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.5.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2459 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.6.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     1632 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.7.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     2414 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.8.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     5520 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_2.8.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    15747 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_3.0.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     7098 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_3.1.rst
+-rw-r--r--   0 runner    (1001) docker     (127)     3416 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_3.2.1.rst
+-rw-r--r--   0 runner    (1001) docker     (127)    30230 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/release_3.2.rst
+-rw-r--r--   0 runner    (1001) docker     (127)      777 2024-03-22 20:12:12.000000 networkx-3.3rc0/doc/release/report_functions_without_rst_generated.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.809310 networkx-3.3rc0/examples/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.809310 networkx-3.3rc0/examples/3d_drawing/
+-rw-r--r--   0 runner    (1001) docker     (127)       22 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/3d_drawing/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      934 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/3d_drawing/mayavi2_spring.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2818 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/3d_drawing/plot_3d_rotation_animation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1149 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/3d_drawing/plot_basic.py
+-rw-r--r--   0 runner    (1001) docker     (127)      185 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/README.txt
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.813310 networkx-3.3rc0/examples/algorithms/
+-rw-r--r--   0 runner    (1001) docker     (127)       22 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)  1346746 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/WormNet.v3.benchmark.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     2335 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/hartford_drug.edgelist
+-rw-r--r--   0 runner    (1001) docker     (127)     4119 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_beam_search.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2126 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_betweenness_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2680 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_blockmodel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3496 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_circuits.py
+-rw-r--r--   0 runner    (1001) docker     (127)      849 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_cycle_detection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1194 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_davis_club.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2253 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_dedensification.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2477 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_girvan_newman.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2175 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_greedy_coloring.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6110 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_image_segmentation_spectral_graph_partiion.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5996 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_iterated_dynamical_systems.py
+-rw-r--r--   0 runner    (1001) docker     (127)      637 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_krackhardt_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1395 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_lca.py
+-rw-r--r--   0 runner    (1001) docker     (127)      901 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_maximum_independent_set.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2444 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_parallel_betweenness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1039 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_rcm.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1485 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_shortest_path.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3110 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_snap.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6472 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/algorithms/plot_subgraphs.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.813310 networkx-3.3rc0/examples/basic/
+-rw-r--r--   0 runner    (1001) docker     (127)       12 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/basic/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     1065 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/basic/plot_properties.py
+-rw-r--r--   0 runner    (1001) docker     (127)      525 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/basic/plot_read_write.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1240 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/basic/plot_simple_graph.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.821310 networkx-3.3rc0/examples/drawing/
+-rw-r--r--   0 runner    (1001) docker     (127)       16 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)   100224 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/chess_masters_WCC.pgn.bz2
+-rw-r--r--   0 runner    (1001) docker     (127)    20317 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/knuth_miles.txt.gz
+-rw-r--r--   0 runner    (1001) docker     (127)      621 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_center_node.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4579 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_chess_masters.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1186 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_clusters.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2139 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_custom_node_icons.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1556 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_degree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1115 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_directed.py
+-rw-r--r--   0 runner    (1001) docker     (127)      441 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_edge_colormap.py
+-rw-r--r--   0 runner    (1001) docker     (127)      910 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_ego_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)      552 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_eigenvalues.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1054 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_four_grids.py
+-rw-r--r--   0 runner    (1001) docker     (127)      665 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_house_with_colors.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4103 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_knuth_miles.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1243 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_labels_and_colors.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2263 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_multigraphs.py
+-rw-r--r--   0 runner    (1001) docker     (127)      993 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_multipartite_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)      288 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_node_colormap.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2172 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_rainbow_coloring.py
+-rw-r--r--   0 runner    (1001) docker     (127)      938 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_random_geometric_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1228 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_sampson.py
+-rw-r--r--   0 runner    (1001) docker     (127)      753 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_selfloops.py
+-rw-r--r--   0 runner    (1001) docker     (127)      252 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_simple_path.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1592 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_spectral_grid.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1368 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_tsp.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1964 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_unix_email.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1124 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/plot_weighted_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)      976 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/sampson_data.zip
+-rw-r--r--   0 runner    (1001) docker     (127)     1709 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/drawing/unix_email.mbox
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.821310 networkx-3.3rc0/examples/external/
+-rw-r--r--   0 runner    (1001) docker     (127)       91 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/README.txt
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.821310 networkx-3.3rc0/examples/external/force/
+-rw-r--r--   0 runner    (1001) docker     (127)      251 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/force/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      177 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/force/force.css
+-rw-r--r--   0 runner    (1001) docker     (127)      367 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/force/force.html
+-rw-r--r--   0 runner    (1001) docker     (127)     2062 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/force/force.js
+-rw-r--r--   0 runner    (1001) docker     (127)      986 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/javascript_force.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1053 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/external/plot_igraph.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.821310 networkx-3.3rc0/examples/geospatial/
+-rw-r--r--   0 runner    (1001) docker     (127)      317 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     3167 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/plot_delaunay.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4062 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/plot_lines.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2183 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/plot_osmnx.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2325 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/plot_points.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2252 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/geospatial/plot_polygons.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.825310 networkx-3.3rc0/examples/graph/
+-rw-r--r--   0 runner    (1001) docker     (127)       12 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     1011 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_dag_layout.py
+-rw-r--r--   0 runner    (1001) docker     (127)      806 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_degree_sequence.py
+-rw-r--r--   0 runner    (1001) docker     (127)      841 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_erdos_renyi.py
+-rw-r--r--   0 runner    (1001) docker     (127)      496 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_expected_degree_sequence.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1172 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_football.py
+-rw-r--r--   0 runner    (1001) docker     (127)      494 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_karate_club.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2966 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_morse_trie.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1443 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_mst.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2901 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_napoleon_russian_campaign.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2126 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_roget.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1952 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_triad_types.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1436 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_visibility_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2681 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/plot_words.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15758 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/roget_dat.txt.gz
+-rw-r--r--   0 runner    (1001) docker     (127)    33695 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graph/words_dat.txt.gz
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.825310 networkx-3.3rc0/examples/graphviz_drawing/
+-rw-r--r--   0 runner    (1001) docker     (127)      188 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_drawing/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      694 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_drawing/plot_attributes.py
+-rw-r--r--   0 runner    (1001) docker     (127)      610 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_drawing/plot_conversion.py
+-rw-r--r--   0 runner    (1001) docker     (127)      715 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_drawing/plot_grid.py
+-rw-r--r--   0 runner    (1001) docker     (127)      597 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_drawing/plot_mini_atlas.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.825310 networkx-3.3rc0/examples/graphviz_layout/
+-rw-r--r--   0 runner    (1001) docker     (127)      183 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)    19008 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/lanl_routes.edgelist
+-rw-r--r--   0 runner    (1001) docker     (127)     1428 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/plot_atlas.py
+-rw-r--r--   0 runner    (1001) docker     (127)      374 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/plot_circular_tree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1104 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/plot_decomposition.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1723 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/plot_giant_component.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1552 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/graphviz_layout/plot_lanl_routes.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.825310 networkx-3.3rc0/examples/subclass/
+-rw-r--r--   0 runner    (1001) docker     (127)       18 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/subclass/README.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     6023 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/subclass/plot_antigraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2286 2024-03-22 20:12:12.000000 networkx-3.3rc0/examples/subclass/plot_printgraph.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.825310 networkx-3.3rc0/networkx/
+-rw-r--r--   0 runner    (1001) docker     (127)     1104 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.837310 networkx-3.3rc0/networkx/algorithms/
+-rw-r--r--   0 runner    (1001) docker     (127)     6559 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.841310 networkx-3.3rc0/networkx/algorithms/approximation/
+-rw-r--r--   0 runner    (1001) docker     (127)     1177 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7690 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/clique.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2164 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/clustering_coefficient.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13119 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5805 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/distance_measures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4709 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/dominating_set.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13286 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1174 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/matching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4333 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/maxcut.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1357 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/ramsey.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7414 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/steinertree.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.841310 networkx-3.3rc0/networkx/algorithms/approximation/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1171 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_approx_clust_coeff.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3022 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_clique.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5952 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2024 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_distance_measures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2686 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_dominating_set.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9346 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)      186 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_matching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2804 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_maxcut.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1143 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_ramsey.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8368 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_steinertree.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30932 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_traveling_salesman.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9096 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_treewidth.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1942 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/tests/test_vertex_cover.py
+-rw-r--r--   0 runner    (1001) docker     (127)    55432 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/traveling_salesman.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8216 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/treewidth.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2802 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/approximation/vertex_cover.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.841310 networkx-3.3rc0/networkx/algorithms/assortativity/
+-rw-r--r--   0 runner    (1001) docker     (127)      294 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4220 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8689 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/correlation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7568 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/mixing.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5282 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/neighbor_degree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3401 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/pairs.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.845310 networkx-3.3rc0/networkx/algorithms/assortativity/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2651 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/base_test.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4978 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5069 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_correlation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6820 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_mixing.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3968 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_neighbor_degree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3008 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_pairs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5864 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/asteroidal.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.845310 networkx-3.3rc0/networkx/algorithms/bipartite/
+-rw-r--r--   0 runner    (1001) docker     (127)     3826 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8374 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/basic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9156 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6937 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/cluster.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2164 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/covering.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11358 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/edgelist.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3991 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/extendability.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20423 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/generators.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21636 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/matching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6155 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/matrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17207 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/projection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3401 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/redundancy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1901 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/spectral.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.849310 networkx-3.3rc0/networkx/algorithms/bipartite/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4291 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_basic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6362 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2801 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_cluster.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1221 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_covering.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7764 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_edgelist.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7043 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_extendability.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12794 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_generators.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11972 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_matching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3094 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_matrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15134 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_project.py
+-rw-r--r--   0 runner    (1001) docker     (127)      919 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_redundancy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2358 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_spectral_bipartivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5338 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/boundary.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6087 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/bridges.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4854 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/broadcasting.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.853310 networkx-3.3rc0/networkx/algorithms/centrality/
+-rw-r--r--   0 runner    (1001) docker     (127)      558 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14382 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/betweenness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9335 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/betweenness_subset.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10280 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/closeness.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11847 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/current_flow_betweenness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8106 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/current_flow_betweenness_subset.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3326 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/current_flow_closeness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3893 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/degree_alg.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3631 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/dispersion.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12757 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/eigenvector.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3833 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/flow_matrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)    27902 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/group.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2630 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/harmonic.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11041 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/katz.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5639 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/laplacian.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6858 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/load.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4419 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/percolation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7025 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/reaching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5012 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/second_order.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9512 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/subgraph_alg.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.857310 networkx-3.3rc0/networkx/algorithms/centrality/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    26795 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12554 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality_subset.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10209 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_closeness_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7870 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5839 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1379 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_closeness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4105 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_degree_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1959 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_dispersion.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4897 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_eigenvector_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8686 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_group.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3658 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_harmonic_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11240 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_katz_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5916 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_laplacian_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11343 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_load_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2591 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_percolation_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4143 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_reaching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1999 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_second_order_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3729 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_subgraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8705 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_trophic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1692 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/tests/test_voterank.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4678 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/trophic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3230 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/centrality/voterank_alg.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6968 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/chains.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13410 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/chordal.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25871 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/clique.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20359 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/cluster.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.857310 networkx-3.3rc0/networkx/algorithms/coloring/
+-rw-r--r--   0 runner    (1001) docker     (127)      182 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/coloring/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16315 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/coloring/equitable_coloring.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20045 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/coloring/greedy_coloring.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.857310 networkx-3.3rc0/networkx/algorithms/coloring/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/coloring/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23699 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/coloring/tests/test_coloring.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4544 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/communicability_alg.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.857310 networkx-3.3rc0/networkx/algorithms/community/
+-rw-r--r--   0 runner    (1001) docker     (127)     1178 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5935 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/asyn_fluid.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6635 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)      907 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/community_utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6416 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/divisive.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2460 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/kclique.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4349 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/kernighan_lin.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11877 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/label_propagation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15365 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/louvain.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8090 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/lukes.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18082 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/modularity_max.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11939 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/quality.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.861310 networkx-3.3rc0/networkx/algorithms/community/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3332 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_asyn_fluid.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2931 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_centrality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3441 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_divisive.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2413 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_kclique.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2709 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_kernighan_lin.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7985 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_label_propagation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8071 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_louvain.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3961 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_lukes.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10617 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_modularity_max.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5274 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_quality.py
+-rw-r--r--   0 runner    (1001) docker     (127)      706 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/community/tests/test_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.861310 networkx-3.3rc0/networkx/algorithms/components/
+-rw-r--r--   0 runner    (1001) docker     (127)      173 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2711 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/attracting.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12781 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/biconnected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4433 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/connected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2029 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/semiconnected.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11744 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/strongly_connected.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.861310 networkx-3.3rc0/networkx/algorithms/components/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2243 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_attracting.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6036 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_biconnected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3987 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_connected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1792 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_semiconnected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6479 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_strongly_connected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3083 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/tests/test_weakly_connected.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4344 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/components/weakly_connected.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.865310 networkx-3.3rc0/networkx/algorithms/connectivity/
+-rw-r--r--   0 runner    (1001) docker     (127)      281 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    29920 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23199 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/cuts.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14860 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/disjoint_paths.py
+-rw-r--r--   0 runner    (1001) docker     (127)    44060 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/edge_augmentation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20893 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/edge_kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8170 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9370 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/kcutsets.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5379 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/stoerwagner.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.865310 networkx-3.3rc0/networkx/algorithms/connectivity/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15027 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10353 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_cuts.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8392 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_disjoint_paths.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15731 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_edge_augmentation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16453 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_edge_kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8554 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_kcomponents.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8610 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_kcutsets.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3011 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_stoer_wagner.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3216 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/connectivity/utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19183 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/core.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5295 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/covering.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9992 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/cuts.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43154 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/cycles.py
+-rw-r--r--   0 runner    (1001) docker     (127)    27283 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/d_separation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39428 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/dag.py
+-rw-r--r--   0 runner    (1001) docker     (127)    31778 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/distance_measures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7053 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/distance_regular.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3430 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/dominance.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2668 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/dominating.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4798 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/efficiency_measures.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14204 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/euler.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.869310 networkx-3.3rc0/networkx/algorithms/flow/
+-rw-r--r--   0 runner    (1001) docker     (127)      341 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13463 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/boykovkolmogorov.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14469 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/capacityscaling.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8470 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/dinitz_alg.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8348 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/edmondskarp.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6344 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/gomory_hu.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22759 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/maxflow.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12853 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/mincost.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25185 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/networksimplex.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15851 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/preflowpush.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10502 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/shortestaugmentingpath.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.869310 networkx-3.3rc0/networkx/algorithms/flow/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    44623 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/gl1.gpickle.bz2
+-rw-r--r--   0 runner    (1001) docker     (127)    42248 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/gw1.gpickle.bz2
+-rw-r--r--   0 runner    (1001) docker     (127)    18972 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/netgen-2.gpickle.bz2
+-rw-r--r--   0 runner    (1001) docker     (127)     4471 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/test_gomory_hu.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18727 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/test_maxflow.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4623 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/test_maxflow_large_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17816 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/test_mincost.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12103 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/test_networksimplex.py
+-rw-r--r--   0 runner    (1001) docker     (127)    88132 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/tests/wlm3.gpickle.bz2
+-rw-r--r--   0 runner    (1001) docker     (127)     6033 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/flow/utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12427 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/graph_hashing.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15831 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/graphical.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1545 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/hierarchy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6208 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/hybrid.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2337 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isolate.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.869310 networkx-3.3rc0/networkx/algorithms/isomorphism/
+-rw-r--r--   0 runner    (1001) docker     (127)      406 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43239 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/ismags.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7113 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/isomorph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    40980 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/isomorphvf2.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10883 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/matchhelpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10888 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/temporalisomorphvf2.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.873310 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1442 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.A99
+-rw-r--r--   0 runner    (1001) docker     (127)     1442 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.B99
+-rw-r--r--   0 runner    (1001) docker     (127)      310 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.A99
+-rw-r--r--   0 runner    (1001) docker     (127)     1602 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.B99
+-rw-r--r--   0 runner    (1001) docker     (127)    10585 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_ismags.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2022 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_isomorphism.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11751 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_isomorphvf2.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2483 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_match_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7346 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_temporalisomorphvf2.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7412 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py
+-rw-r--r--   0 runner    (1001) docker     (127)    49924 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2pp.py
+-rw-r--r--   0 runner    (1001) docker     (127)    90125 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6629 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2userfunc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9454 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/tree_isomorphism.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36375 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/vf2pp.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7475 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/isomorphism/vf2userfunc.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.873310 networkx-3.3rc0/networkx/algorithms/link_analysis/
+-rw-r--r--   0 runner    (1001) docker     (127)      118 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10421 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/hits_alg.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17191 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/pagerank_alg.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.873310 networkx-3.3rc0/networkx/algorithms/link_analysis/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2547 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/tests/test_hits.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7534 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_analysis/tests/test_pagerank.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22256 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/link_prediction.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9197 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/lowest_common_ancestors.py
+-rw-r--r--   0 runner    (1001) docker     (127)    44549 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/matching.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.873310 networkx-3.3rc0/networkx/algorithms/minors/
+-rw-r--r--   0 runner    (1001) docker     (127)      587 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/minors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22869 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/minors/contraction.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.873310 networkx-3.3rc0/networkx/algorithms/minors/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)    14212 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/minors/tests/test_contraction.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2343 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/mis.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1535 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/moral.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6469 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/node_classification.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2904 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/non_randomness.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.877310 networkx-3.3rc0/networkx/algorithms/operators/
+-rw-r--r--   0 runner    (1001) docker     (127)      201 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9652 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/all.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12935 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/binary.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19603 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/product.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.877310 networkx-3.3rc0/networkx/algorithms/operators/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8250 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/tests/test_all.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12909 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/tests/test_binary.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15156 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/tests/test_product.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1415 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/tests/test_unary.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1794 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/operators/unary.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16254 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/planar_drawing.py
+-rw-r--r--   0 runner    (1001) docker     (127)    47189 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/planarity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11278 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/polynomials.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2854 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/reciprocity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6793 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/regular.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4892 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/richclub.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.877310 networkx-3.3rc0/networkx/algorithms/shortest_paths/
+-rw-r--r--   0 runner    (1001) docker     (127)      285 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8943 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/astar.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8167 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25734 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/generic.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.877310 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8941 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_astar.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6747 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2300 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_dense_numpy.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18456 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_generic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5899 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_unweighted.py
+-rw-r--r--   0 runner    (1001) docker     (127)    35038 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_weighted.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15617 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/unweighted.py
+-rw-r--r--   0 runner    (1001) docker     (127)    82473 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/shortest_paths/weighted.py
+-rw-r--r--   0 runner    (1001) docker     (127)    60956 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/similarity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    29610 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/simple_paths.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13564 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/smallworld.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1937 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/smetric.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10047 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/sparsifiers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9342 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/structuralholes.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23250 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/summarization.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14745 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/swap.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.889310 networkx-3.3rc0/networkx/algorithms/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      502 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_asteroidal.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6227 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_boundary.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4026 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_bridges.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2020 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_broadcasting.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4363 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_chains.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4438 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_chordal.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9413 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_clique.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15883 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_cluster.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2938 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_communicability.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9555 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2718 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_covering.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5377 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_cuts.py
+-rw-r--r--   0 runner    (1001) docker     (127)    34382 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_cycles.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10929 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_d_separation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    27930 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_dag.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25396 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_distance_measures.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2915 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_distance_regular.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9373 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_dominance.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1228 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_dominating.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1894 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_efficiency.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11209 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_euler.py
+-rw-r--r--   0 runner    (1001) docker     (127)    24534 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_graph_hashing.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5366 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_graphical.py
+-rw-r--r--   0 runner    (1001) docker     (127)      941 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_hierarchy.py
+-rw-r--r--   0 runner    (1001) docker     (127)      720 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_hybrid.py
+-rw-r--r--   0 runner    (1001) docker     (127)      555 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_isolate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20004 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_link_prediction.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13153 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_lowest_common_ancestors.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20174 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_matching.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6741 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_max_weight_clique.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1865 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_mis.py
+-rw-r--r--   0 runner    (1001) docker     (127)      452 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_moral.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4663 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_node_classification.py
+-rw-r--r--   0 runner    (1001) docker     (127)      782 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_non_randomness.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8765 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_planar_drawing.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16386 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_planarity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1983 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_polynomials.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1296 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_reciprocity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2626 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_regular.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3965 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_richclub.py
+-rw-r--r--   0 runner    (1001) docker     (127)    33189 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_similarity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    24839 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_simple_paths.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2405 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_smallworld.py
+-rw-r--r--   0 runner    (1001) docker     (127)      980 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_smetric.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4043 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_sparsifiers.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5540 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_structuralholes.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21313 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_summarization.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6121 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_swap.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9751 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_threshold.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13342 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_time_dependent.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4158 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_tournament.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9383 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_triads.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1380 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_vitality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3477 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_voronoi.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1499 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_walks.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3209 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tests/test_wiener.py
+-rw-r--r--   0 runner    (1001) docker     (127)    31149 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/threshold.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5762 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/time_dependent.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11766 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tournament.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.889310 networkx-3.3rc0/networkx/algorithms/traversal/
+-rw-r--r--   0 runner    (1001) docker     (127)      142 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3472 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/beamsearch.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19241 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/breadth_first_search.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16794 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/depth_first_search.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6243 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/edgebfs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5956 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/edgedfs.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.889310 networkx-3.3rc0/networkx/algorithms/traversal/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      899 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/test_beamsearch.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6796 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/test_bfs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10604 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/test_dfs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4702 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/test_edgebfs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4775 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/traversal/tests/test_edgedfs.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.889310 networkx-3.3rc0/networkx/algorithms/tree/
+-rw-r--r--   0 runner    (1001) docker     (127)      149 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    56274 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/branchings.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13463 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/coding.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3071 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/decomposition.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45858 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/mst.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4726 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/operations.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7569 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.889310 networkx-3.3rc0/networkx/algorithms/tree/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18999 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_branchings.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3954 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_coding.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1871 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_decomposition.py
+-rw-r--r--   0 runner    (1001) docker     (127)    29502 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_mst.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1961 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_operations.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4521 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/tree/tests/test_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16852 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/triads.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2335 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/vitality.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3182 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/voronoi.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2428 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/walks.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7640 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/algorithms/wiener.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.893310 networkx-3.3rc0/networkx/classes/
+-rw-r--r--   0 runner    (1001) docker     (127)      364 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12414 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/coreviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)    47159 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/digraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2501 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/filters.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36899 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/function.py
+-rw-r--r--   0 runner    (1001) docker     (127)    70397 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8588 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/graphviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36290 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/multidigraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    47127 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/multigraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45859 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/reportviews.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.893310 networkx-3.3rc0/networkx/classes/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6687 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/dispatch_interface.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16173 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/historical_tests.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2910 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_backends.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12128 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_coreviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12283 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_digraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3683 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_digraph_historical.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5851 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_filters.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25842 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_function.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30913 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)      273 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_graph_historical.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11466 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_graphviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16342 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_multidigraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18777 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_multigraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    41633 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_reportviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4103 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_special.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13223 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/classes/tests/test_subgraphviews.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8623 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16027 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/convert.py
+-rw-r--r--   0 runner    (1001) docker     (127)    41409 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/convert_matrix.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.897310 networkx-3.3rc0/networkx/drawing/
+-rw-r--r--   0 runner    (1001) docker     (127)      160 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    40756 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/layout.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14004 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/nx_agraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    24804 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/nx_latex.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12357 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/nx_pydot.py
+-rw-r--r--   0 runner    (1001) docker     (127)    61617 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/nx_pylab.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.897310 networkx-3.3rc0/networkx/drawing/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.897310 networkx-3.3rc0/networkx/drawing/tests/baseline/
+-rw-r--r--   0 runner    (1001) docker     (127)    21918 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/baseline/test_house_with_colors.png
+-rw-r--r--   0 runner    (1001) docker     (127)     8788 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/test_agraph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8710 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/test_latex.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19801 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/test_layout.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6107 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/test_pydot.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30188 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/drawing/tests/test_pylab.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3537 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/exception.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.901310 networkx-3.3rc0/networkx/generators/
+-rw-r--r--   0 runner    (1001) docker     (127)     1365 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8887 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/atlas.dat.gz
+-rw-r--r--   0 runner    (1001) docker     (127)     5605 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/atlas.py
+-rw-r--r--   0 runner    (1001) docker     (127)    31576 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/classic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1890 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/cographs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    34910 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/community.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30174 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/degree_seq.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15696 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/directed.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5051 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/duplication.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1899 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/ego.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14391 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/expanders.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39589 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/geometric.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6159 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/harary_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14172 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/internet_as_graphs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4100 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/intersection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2203 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/interval_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)    24773 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/joint_degree_seq.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13500 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/lattice.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17530 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/line.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3314 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/mycielski.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6453 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/nonisomorphic_trees.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4183 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/random_clustered.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45097 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/random_graphs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    28171 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/small.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22963 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/social.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4241 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/spectral_graph_forge.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1958 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/stochastic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4288 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/sudoku.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.905310 networkx-3.3rc0/networkx/generators/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2530 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_atlas.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23413 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_classic.py
+-rw-r--r--   0 runner    (1001) docker     (127)      460 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_cographs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11311 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_community.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7093 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_degree_seq.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5258 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_directed.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2350 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_duplication.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1327 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_ego.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5604 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_expanders.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18087 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_geometric.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4937 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_harary_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6795 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_internet_as_graphs.py
+-rw-r--r--   0 runner    (1001) docker     (127)      819 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_intersection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4278 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_interval_graph.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4270 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_joint_degree_seq.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9290 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_lattice.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10378 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_line.py
+-rw-r--r--   0 runner    (1001) docker     (127)      946 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_mycielski.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2453 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_nonisomorphic_trees.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1297 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_random_clustered.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13121 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_random_graphs.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7060 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_small.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1594 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_spectral_graph_forge.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2178 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_stochastic.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1968 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_sudoku.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2229 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_time_series.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7634 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_trees.py
+-rw-r--r--   0 runner    (1001) docker     (127)      332 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/tests/test_triads.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2438 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/time_series.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39283 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/trees.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2451 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/generators/triads.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5764 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/lazy_imports.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.905310 networkx-3.3rc0/networkx/linalg/
+-rw-r--r--   0 runner    (1001) docker     (127)      568 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21148 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/algebraicconnectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15512 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/attrmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2696 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/bethehessianmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5521 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/graphmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20537 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/laplacianmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4706 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/modularitymatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4214 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/spectrum.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.905310 networkx-3.3rc0/networkx/linalg/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13737 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_algebraic_connectivity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2833 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_attrmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1327 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_bethehessian.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8708 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_graphmatrix.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14081 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_laplacian.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3115 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_modularity.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2828 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/linalg/tests/test_spectrum.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.909310 networkx-3.3rc0/networkx/readwrite/
+-rw-r--r--   0 runner    (1001) docker     (127)      562 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8430 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/adjlist.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14232 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/edgelist.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39692 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/gexf.py
+-rw-r--r--   0 runner    (1001) docker     (127)    31150 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/gml.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11400 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/graph6.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39317 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/graphml.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.909310 networkx-3.3rc0/networkx/readwrite/json_graph/
+-rw-r--r--   0 runner    (1001) docker     (127)      676 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4716 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/adjacency.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5338 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/cytoscape.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7473 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/node_link.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.909310 networkx-3.3rc0/networkx/readwrite/json_graph/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2456 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_adjacency.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2044 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_cytoscape.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4536 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_node_link.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1352 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_tree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3851 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/json_graph/tree.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2797 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/leda.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11291 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/multiline_adjlist.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3091 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/p2g.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8738 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/pajek.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10314 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/sparse6.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.913310 networkx-3.3rc0/networkx/readwrite/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9430 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_adjlist.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9617 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_edgelist.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19405 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_gexf.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21391 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_gml.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6067 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_graph6.py
+-rw-r--r--   0 runner    (1001) docker     (127)    67573 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_graphml.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1392 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_leda.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1320 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_p2g.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4628 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_pajek.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5284 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_sparse6.py
+-rw-r--r--   0 runner    (1001) docker     (127)    56562 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/tests/test_text.py
+-rw-r--r--   0 runner    (1001) docker     (127)    32126 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/readwrite/text.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10300 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/relabel.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.913310 networkx-3.3rc0/networkx/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8653 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_all_random_functions.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12731 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_convert.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14951 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_convert_numpy.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12257 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_convert_pandas.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10436 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_convert_scipy.py
+-rw-r--r--   0 runner    (1001) docker     (127)      927 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (127)      220 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_import.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2680 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_lazy_imports.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14517 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/tests/test_relabel.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.917310 networkx-3.3rc0/networkx/utils/
+-rw-r--r--   0 runner    (1001) docker     (127)      227 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    58609 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/backends.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7526 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/configs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    46829 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/decorators.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10391 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/heaps.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10185 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/mapped_queue.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19038 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4237 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/random_sequence.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4623 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/rcm.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.917310 networkx-3.3rc0/networkx/utils/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      363 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test__init.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5674 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_config.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14050 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_decorators.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3711 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_heaps.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7354 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_mapped_queue.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8671 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_misc.py
+-rw-r--r--   0 runner    (1001) docker     (127)      925 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_random_sequence.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1421 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_rcm.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1579 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/tests/test_unionfind.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3338 2024-03-22 20:12:12.000000 networkx-3.3rc0/networkx/utils/union_find.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.917310 networkx-3.3rc0/networkx.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)     5093 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)    35581 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       87 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (127)      353 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        9 2024-03-22 20:12:27.000000 networkx-3.3rc0/networkx.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (127)     5189 2024-03-22 20:12:12.000000 networkx-3.3rc0/pyproject.toml
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-03-22 20:12:27.917310 networkx-3.3rc0/requirements/
+-rw-r--r--   0 runner    (1001) docker     (127)      836 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/README.md
+-rw-r--r--   0 runner    (1001) docker     (127)        4 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/benchmarking.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      193 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/default.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      172 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/developer.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      234 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/doc.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      101 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/example.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      174 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/extra.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       35 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/release.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      152 2024-03-22 20:12:12.000000 networkx-3.3rc0/requirements/test.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       38 2024-03-22 20:12:27.921310 networkx-3.3rc0/setup.cfg
```

### Comparing `networkx-3.2rc0/CONTRIBUTING.rst` & `networkx-3.3rc0/CONTRIBUTING.rst`

 * *Files 1% similar despite different names*

```diff
@@ -74,16 +74,16 @@
          # conda install -c conda-forge --file requirements/extra.txt
          #
          # Install networkx from source
          pip install -e .
          # Test your installation
          pytest --pyargs networkx
 
-   * Finally, we recommend you use a pre-commit hook, which runs black when
-     you type ``git commit``::
+   * Finally, we recommend you install pre-commit which checks
+     that your code matches formatting guidelines::
 
        pre-commit install
 
 2. Develop your contribution:
 
    * Pull the latest changes from upstream::
 
@@ -118,28 +118,28 @@
      formatting changes.
 
    * If the above fails for whatever reason, you can also run the linter over
      the entire codebase with::
 
          pre-commit run --all-files
 
-4. Submit your contribution:
+5. Submit your contribution:
 
    * Push your changes back to your fork on GitHub::
 
       git push origin bugfix-for-issue-1480
 
    * Go to GitHub. The new branch will show up with a green Pull Request
      button---click it.
 
    * If you want, post on the `mailing list
      <http://groups.google.com/group/networkx-discuss>`_ to explain your changes or
      to ask for review.
 
-5. Review process:
+6. Review process:
 
    * Every Pull Request (PR) update triggers a set of `continuous integration
      <https://en.wikipedia.org/wiki/Continuous_integration>`_ services
      that check that the code is up to standards and passes all our tests.
      These checks must pass before your PR can be merged.  If one of the
      checks fails, you can find out why by clicking on the "failed" icon (red
      cross) and inspecting the build and test log.
@@ -161,15 +161,15 @@
    .. note::
 
       If the PR closes an issue, make sure that GitHub knows to automatically
       close the issue when the PR is merged.  For example, if the PR closes
       issue number 1480, you could use the phrase "Fixes #1480" in the PR
       description or commit message.
 
-6. Document deprecations and API changes
+7. Document deprecations and API changes
    
    If your change introduces any API modifications including deprecations,
    please make sure the PR has the ``type: API`` label.
 
    To set up a function for deprecation:
 
    - Use a deprecation warning to warn users. For example::
```

### Comparing `networkx-3.2rc0/INSTALL.rst` & `networkx-3.3rc0/INSTALL.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 Install
 =======
 
-NetworkX requires Python 3.9, 3.10, or 3.11.  If you do not already
+NetworkX requires Python 3.10, 3.11, or 3.12.  If you do not already
 have a Python environment configured on your computer, please see the
 instructions for installing the full `scientific Python stack
 <https://scipy.org/install.html>`_.
 
 Below we assume you have the default Python environment already configured on
 your computer and you intend to install ``networkx`` inside of it.  If you want
 to create and work with Python virtual environments, please follow instructions
```

### Comparing `networkx-3.2rc0/LICENSE.txt` & `networkx-3.3rc0/LICENSE.txt`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 NetworkX is distributed with the 3-clause BSD license.
 
 ::
 
-   Copyright (C) 2004-2023, NetworkX Developers
+   Copyright (C) 2004-2024, NetworkX Developers
    Aric Hagberg <hagberg@lanl.gov>
    Dan Schult <dschult@colgate.edu>
    Pieter Swart <swart@lanl.gov>
    All rights reserved.
 
    Redistribution and use in source and binary forms, with or without
    modification, are permitted provided that the following conditions are
```

### Comparing `networkx-3.2rc0/MANIFEST.in` & `networkx-3.3rc0/MANIFEST.in`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/PKG-INFO` & `networkx-3.3rc0/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: networkx
-Version: 3.2rc0
+Version: 3.3rc0
 Summary: Python package for creating and manipulating graphs and networks
 Author-email: Aric Hagberg <hagberg@lanl.gov>
 Maintainer-email: NetworkX Developers <networkx-discuss@googlegroups.com>
 Project-URL: Homepage, https://networkx.org/
 Project-URL: Bug Tracker, https://github.com/networkx/networkx/issues
 Project-URL: Documentation, https://networkx.org/documentation/stable/
 Project-URL: Source Code, https://github.com/networkx/networkx
@@ -15,49 +15,48 @@
 Platform: Unix
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
 Classifier: Topic :: Scientific/Engineering :: Information Analysis
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Physics
-Requires-Python: >=3.9
+Requires-Python: >=3.10
 Description-Content-Type: text/x-rst
 License-File: LICENSE.txt
 Provides-Extra: default
-Requires-Dist: numpy>=1.22; extra == "default"
+Requires-Dist: numpy>=1.23; extra == "default"
 Requires-Dist: scipy!=1.11.0,!=1.11.1,>=1.9; extra == "default"
-Requires-Dist: matplotlib>=3.5; extra == "default"
+Requires-Dist: matplotlib>=3.6; extra == "default"
 Requires-Dist: pandas>=1.4; extra == "default"
 Provides-Extra: developer
+Requires-Dist: changelist==0.5; extra == "developer"
 Requires-Dist: pre-commit>=3.2; extra == "developer"
 Requires-Dist: mypy>=1.1; extra == "developer"
 Requires-Dist: rtoml; extra == "developer"
 Provides-Extra: doc
 Requires-Dist: sphinx>=7; extra == "doc"
 Requires-Dist: pydata-sphinx-theme>=0.14; extra == "doc"
 Requires-Dist: sphinx-gallery>=0.14; extra == "doc"
 Requires-Dist: numpydoc>=1.6; extra == "doc"
 Requires-Dist: pillow>=9.4; extra == "doc"
-Requires-Dist: nb2plots>=0.7; extra == "doc"
 Requires-Dist: texext>=0.6.7; extra == "doc"
-Requires-Dist: nbconvert<7.9; extra == "doc"
+Requires-Dist: myst-nb>=1.0; extra == "doc"
 Provides-Extra: extra
 Requires-Dist: lxml>=4.6; extra == "extra"
-Requires-Dist: pygraphviz>=1.11; extra == "extra"
-Requires-Dist: pydot>=1.4.2; extra == "extra"
+Requires-Dist: pygraphviz>=1.12; extra == "extra"
+Requires-Dist: pydot>=2.0; extra == "extra"
 Requires-Dist: sympy>=1.10; extra == "extra"
 Provides-Extra: test
 Requires-Dist: pytest>=7.2; extra == "test"
 Requires-Dist: pytest-cov>=4.0; extra == "test"
 
 NetworkX
 ========
@@ -124,11 +123,11 @@
 see `CONTRIBUTING.rst`).
 
 License
 -------
 
 Released under the 3-Clause BSD license (see `LICENSE.txt`)::
 
-   Copyright (C) 2004-2023 NetworkX Developers
+   Copyright (C) 2004-2024 NetworkX Developers
    Aric Hagberg <hagberg@lanl.gov>
    Dan Schult <dschult@colgate.edu>
    Pieter Swart <swart@lanl.gov>
```

### Comparing `networkx-3.2rc0/README.rst` & `networkx-3.3rc0/README.rst`

 * *Files 1% similar despite different names*

```diff
@@ -63,11 +63,11 @@
 see `CONTRIBUTING.rst`).
 
 License
 -------
 
 Released under the 3-Clause BSD license (see `LICENSE.txt`)::
 
-   Copyright (C) 2004-2023 NetworkX Developers
+   Copyright (C) 2004-2024 NetworkX Developers
    Aric Hagberg <hagberg@lanl.gov>
    Dan Schult <dschult@colgate.edu>
    Pieter Swart <swart@lanl.gov>
```

### Comparing `networkx-3.2rc0/doc/Makefile` & `networkx-3.3rc0/doc/Makefile`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/README.rst` & `networkx-3.3rc0/doc/README.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/_static/copybutton.js` & `networkx-3.3rc0/doc/_static/copybutton.js`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/_templates/autosummary/class.rst` & `networkx-3.3rc0/doc/_templates/autosummary/class.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/conf.py` & `networkx-3.3rc0/doc/conf.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,17 +18,18 @@
     "sphinx.ext.coverage",
     "sphinx.ext.doctest",
     "sphinx.ext.intersphinx",
     "sphinx.ext.mathjax",
     "sphinx.ext.todo",
     "sphinx.ext.viewcode",
     "sphinx_gallery.gen_gallery",
-    "nb2plots",
     "texext",
     "numpydoc",
+    "matplotlib.sphinxext.plot_directive",
+    "myst_nb",
 ]
 
 # https://github.com/sphinx-gallery/sphinx-gallery
 sphinx_gallery_conf = {
     # path to your examples scripts
     "examples_dirs": "../examples",
     "subsection_order": ExplicitOrder(
@@ -47,15 +48,17 @@
         ]
     ),
     "within_subsection_order": FileNameSortKey,
     # path where to save gallery generated examples
     "gallery_dirs": "auto_examples",
     "backreferences_dir": "modules/generated",
     "image_scrapers": ("matplotlib",),
+    "matplotlib_animations": True,
     "plot_gallery": "True",
+    "reference_url": {"sphinx_gallery": None},
 }
 # Add pygraphviz png scraper, if available
 try:
     from pygraphviz.scraper import PNGScraper
 
     sphinx_gallery_conf["image_scrapers"] += (PNGScraper(),)
 except ImportError:
@@ -71,16 +74,17 @@
 
 # The suffix of source filenames.
 source_suffix = ".rst"
 
 # The encoding of source files.
 source_encoding = "utf-8"
 
-# Do not include release announcement template
-exclude_patterns = ["release/release_template.rst"]
+# Items to exclude during source collection, including release announcement
+# template, build outputs, and READMEs (markdown only)
+exclude_patterns = ["release/release_template.rst", "build/*", "README.md"]
 
 # General substitutions.
 project = "NetworkX"
 copyright = f"2004-{date.today().year}, NetworkX Developers"
 
 # Used in networkx.utils.backends for cleaner rendering of functions.
 # We need to set this before we import networkx.
@@ -155,14 +159,15 @@
     "**": ["sidebar-nav-bs", "sidebar-ethical-ads"],
     "index": [],
     "install": [],
     "tutorial": [],
     "auto_examples/index": [],
 }
 html_logo = "_static/networkx_banner.svg"
+html_favicon = "_static/favicon.ico"
 
 # The style sheet to use for HTML and HTML Help pages. A file of that name
 # must exist either in Sphinx' static/ path, or in one of the custom paths
 # given in html_static_path.
 # html_style = ''
 
 # Add any paths that contain custom static files (such as style sheets) here,
@@ -239,18 +244,29 @@
 
 # The reST default role (used for this markup: `text`) to use for all
 # documents.
 default_role = "obj"
 
 numpydoc_show_class_members = False
 
+plot_pre_code = """
+import networkx as nx
+import numpy as np
+np.random.seed(42)
+"""
+
+plot_formats = [("png", 100)]
+
 
 def setup(app):
     app.add_css_file("custom.css")
     app.add_js_file("copybutton.js")
+    # Workaround to prevent duplicate file warnings from sphinx w/ myst-nb.
+    # See executablebooks/MyST-NB#363
+    app.registry.source_suffix.pop(".ipynb")
 
 
 # Monkeypatch numpydoc to show "Backends" section
 from numpydoc.docscrape import NumpyDocString
 
 orig_setitem = NumpyDocString.__setitem__
```

### Comparing `networkx-3.2rc0/doc/developer/about_us.rst` & `networkx-3.3rc0/doc/developer/about_us.rst`

 * *Files 3% similar despite different names*

```diff
@@ -147,14 +147,16 @@
 - Andrew Knyazev, GitHub: `lobpcg <https://github.com/lobpcg>`_, LinkedIn: `andrew-knyazev <https://www.linkedin.com/in/andrew-knyazev>`_
 - Luca Cappelletti, GitHub: `LucaCappelletti94 <https://github.com/LucaCappelletti94>`_
 - Sultan Orazbayev, GitHub: `SultanOrazbayev <https://github.com/SultanOrazbayev>`_, LinkedIn: `Sultan Orazbayev <https://www.linkedin.com/in/sultan-orazbayev/>`_
 - Paolo Boldi, Github: `https://github.com/boldip`
 - Davide D'Ascenzo, Github: `https://github.com/kidara`
 - Flavio Furia, Github: `https://github.com/flaviofuria`
 - Sebastiano Vigna, Github: `https://github.com/vigna`
+- Aaron Zolnai-Lucas, GitHub: `aaronzo <https://github.com/aaronzo>`_, LinkedIn: `aaronzolnailucas <https://www.linkedin.com/in/aaronzolnailucas/>`_
+- Erik Welch, GitHub: `eriknw <https://github.com/eriknw>`_, LinkedIn: `eriknwelch <https://www.linkedin.com/in/eriknwelch/>`_
 
 A supplementary (but still incomplete) list of contributors is given by the
 list of names that have commits in ``networkx``'s
 `git <http://git-scm.com>`_ repository. This can be obtained via::
 
     git log --raw | grep "^Author: " | sort | uniq
```

### Comparing `networkx-3.2rc0/doc/developer/core_developer.rst` & `networkx-3.3rc0/doc/developer/core_developer.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/deprecations.rst` & `networkx-3.3rc0/doc/developer/deprecations.rst`

 * *Files 12% similar despite different names*

```diff
@@ -39,27 +39,37 @@
 Todo
 ----
 
 Make sure to review ``networkx/conftest.py`` after removing deprecated code.
 
 Version 3.3
 ~~~~~~~~~~~
-* Remove pydot functionality ``drawing/nx_pydot.py``, if pydot is still not being maintained. See #5723
 * Remove the ``forest_str`` function from ``readwrite/text.py``. Replace
   existing usages with ``write_network_text``.
-* Change ``single_target_shortest_path_length`` in ``algorithms/shortest_path/unweighted.py``
-  to return a dict. See #6527
-* Change ``shortest_path`` in ``algorithms/shortest_path/generic.py``
-  to return a iterator. See #6527
 
 Version 3.4
 ~~~~~~~~~~~
 * Remove the ``random_tree`` function from ``generators/trees.py``. Replace
   existing usages with ``random_labeled_tree``.
 * Remove the ``sort_neighbors`` input parameter from ``generic_bfs_edges``.
 * Remove ``MultiDiGraph_EdgeKey`` class from ``algorithms/tree/branchings.py``. 
 * Remove ``Edmonds`` class from ``algorithms/tree/branchings.py``.
 * Remove ``normalized`` kwarg from ``algorithms.s_metric``
 * Remove renamed function ``join()`` in ``algorithms/tree/operations.py`` and
   in ``doc/reference/algorithms/trees.rst``
 * Remove ``strongly_connected_components_recursive`` from
   ``algorithms/components/strongly_connected.py``
+
+Version 3.5
+~~~~~~~~~~~
+* Remove ``all_triplets`` from ``algorithms/triads.py``
+* Remove ``random_triad`` from ``algorithms/triad.py``.
+* Remove ``d_separated`` from ``algorithms/d_separation.py``.
+* Remove ``minimal_d_separator`` from ``algorithms/d_separation.py``.
+* Add `not_implemented_for("multigraph”)` decorator to ``k_core``, ``k_shell``, ``k_crust`` and ``k_corona`` functions.
+* Change ``single_target_shortest_path_length`` in ``algorithms/shortest_path/unweighted.py``
+  to return a dict. See #6527
+* Change ``shortest_path`` in ``algorithms/shortest_path/generic.py``
+  to return a iterator. See #6527
+* Remove ``total_spanning_tree_weight`` from ``linalg/laplacianmatrix.py``
+* Remove ``create`` keyword argument from ``nonisomorphic_trees`` in 
+  ``generators/nonisomorphic_trees``.
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `networkx-3.2rc0/doc/developer/new_contributor_faq.rst` & `networkx-3.3rc0/doc/developer/new_contributor_faq.rst`

 * *Files 5% similar despite different names*

```diff
@@ -133,7 +133,22 @@
 Q: What is the policy for deciding whether to include a new algorithm?
 ----------------------------------------------------------------------
 
 There is no official policy setting explicit inclusion criteria for new
 algorithms in NetworkX. New algorithms are more likely to be included if they
 have been published and are cited by others. More important than number of
 citations is how well proposed additions fit the project :ref:`mission_and_values`.
+
+Testing is also an important factor in determining whether algorithms
+should be included. Proposals that include thorough tests which illustrate
+expected behavior are much easier to review, and therefore likely to progress more rapidly.
+
+.. note::
+   *Thorough* does not mean *exhaustive*. The quality of unit tests is much
+   more important than quantity. Thorough tests should address questions like:
+
+   - Does the algorithm support different graph types (undirected, directed,
+     multigraphs)?
+   - How does the algorithm behave with disconnected inputs and graphs which
+     contain self-loops?
+   - Are there explicit test cases outlined in the literature which can be
+     incorporated in the test suite?
```

### Comparing `networkx-3.2rc0/doc/developer/nxeps/_static/nxep-0000.png` & `networkx-3.3rc0/doc/developer/nxeps/_static/nxep-0000.png`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-0000.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-0000.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-0001.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-0001.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-0002.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-0002.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-0003.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-0003.rst`

 * *Files 1% similar despite different names*

```diff
@@ -286,15 +286,15 @@
 
 
 Related Work
 ------------
 
 This proposal is based on ideas and discussions from #3036 and #1393.
 
-This proposal does not delve into backends using the `_dispatch` functionality
+This proposal does not delve into backends using the `_dispatchable` functionality
 and whether we should be providing or allowing control over the builder
 functions for backend libraries. This is a potentially helpful discussion
 but is beyond the scope of this NXEP.
 
 
 Implementation
 --------------
```

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-0004.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-0004.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/nxeps/nxep-template.rst` & `networkx-3.3rc0/doc/developer/nxeps/nxep-template.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/projects.rst` & `networkx-3.3rc0/doc/developer/projects.rst`

 * *Files 12% similar despite different names*

```diff
@@ -53,14 +53,15 @@
 
 - Recommended Skills: Python, matplotlib experience.
 
 - Expected Outcome: A roadmap for a refined API for the matplotlib tools within NetworkX
   as well as code in the form of PR(s) which implement (part of) that API with tests.
 
 - Interested Mentors: `@dschult <https://github.com/dschult/>`__,
+  `@rossbar <https://github.com/rossbar/>`__
 
 - Expected time commitment: This project will be a full time 10 week project (~350 hrs).
 
 Incorporate a Python library for ISMAGs isomorphism calculations
 ----------------------------------------------------------------
 
 - Abstract: A team from Sandia Labs has converted the original java implementation of
@@ -73,17 +74,45 @@
 
 - Recommended Skills: Python, graph algorithms.
 
 - Expected Outcome: A plan for how to best incorporate ISMAGS into NetworkX along
   with code to do that incorporation.
 
 - Interested Mentors: `@dschult <https://github.com/dschult/>`__,
+  `@rossbar <https://github.com/rossbar/>`__
 
 - Expected time commitment: This project will be a full time 10 week project (~350 hrs).
 
+Centrality Atlas
+----------------
+
+- Abstract: The goal of this project would be to produce a comprehensive review
+  of network centrality measures.
+  Centrality is a central concept in network science and has many applications
+  across domains. NetworkX provides many functions for measuring
+  various types of :doc:`network centrality</reference/algorithms/centrality>`.
+  The individual centrality functions are typically well-described by their
+  docstrings (though there's always room for improvement!); however, there
+  currently is no big-picture overview of centrality.
+  Furthermore, many of the centrality measures are closely related, but there is
+  no documentation that describes these relationships.
+
+- Recommended Skills: Python, literature review, technical writing
+
+- Expected Outcome: An executable document that provides an overview and applications
+  of network centrality measures. Potential outputs include (but are not limited
+  to): an article for ``nx-guides`` (see above) and/or an example gallery for centrality
+  measures.
+
+- Interested Mentors: `@dschult <https://github.com/dschult/>`__,
+  `@rossbar <https://github.com/rossbar/>`__
+
+- Expected time commitment: Variable, though a high-quality review article would
+  be expected to take several months of dedicated research (~350 hours).
+
 Completed Projects
 ==================
 
 - `VF2++ algorithm for graph isomorphism`_
     - Program: Google Summer of Code 2022
     - Contributor: `@kpetridis24 <https://github.com/kpetridis24/>`__
     - Link to Proposal: `GSoC 2022: VF2++ Algorithm <https://github.com/networkx/archive/blob/main/proposals-gsoc/GSoC-2022-VF2plusplus-isomorphism.pdf>`_
```

### Comparing `networkx-3.2rc0/doc/developer/release.rst` & `networkx-3.3rc0/doc/developer/release.rst`

 * *Files 15% similar despite different names*

```diff
@@ -51,21 +51,21 @@
 
   - Wait for the CI service to deploy to GitHub Pages
   - Sync your branch with the remote repo: ``git pull``.
   - Copy the documentation built by the CI service.
     Assuming you are at the top-level of the ``documentation`` repo::
 
       # FIXME - use eol_banner.html
-      cp -a latest ../networkx-<major>.<minor>
+      cp -a latest ../networkx-${VERSION}
       git reset --hard <commit from last release>
-      mv ../networkx-<major>.<minor> .
+      mv ../networkx-${VERSION} .
       rm -rf stable
-      cp -rf networkx-<major>.<minor> stable
-      git add networkx-<major>.<minor> stable
-      git commit -m "Add <major>.<minor> docs"
+      cp -rf networkx-${VERSION} stable
+      git add networkx-${VERSION} stable
+      git commit -m "Add ${VERSION} docs"
       git push  # force push---be careful!
 
 - Update ``__version__`` in ``networkx/__init__.py``.
 
  - Commit and push changes::
 
     git add networkx/__init__.py
```

### Comparing `networkx-3.2rc0/doc/developer/roadmap.rst` & `networkx-3.3rc0/doc/developer/roadmap.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/teams.inc` & `networkx-3.3rc0/doc/developer/teams.inc`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/developer/values.rst` & `networkx-3.3rc0/doc/developer/values.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/index.rst` & `networkx-3.3rc0/doc/index.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/algorithms/approximation.rst` & `networkx-3.3rc0/doc/reference/algorithms/approximation.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/algorithms/bipartite.rst` & `networkx-3.3rc0/doc/reference/algorithms/bipartite.rst`

 * *Files 4% similar despite different names*

```diff
@@ -128,8 +128,15 @@
 .. automodule:: networkx.algorithms.bipartite.covering
 .. autosummary::
    :toctree: generated/
 
    min_edge_cover
 
 
+Extendability
+-------------
+.. automodule:: networkx.algorithms.bipartite.extendability
+.. autosummary::
+   :toctree: generated/
+
+   maximal_extendability
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/coloring.rst` & `networkx-3.3rc0/doc/reference/algorithms/coloring.rst`

 * *Files 19% similar despite different names*

```diff
@@ -1,7 +1,10 @@
+.. _networkx.algorithms.coloring.greedy_coloring:
+.. _networkx.algorithms.coloring.equitable_coloring:
+
 ********
 Coloring
 ********
 
 .. automodule:: networkx.algorithms.coloring
 .. autosummary::
    :toctree: generated/
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/community.rst` & `networkx-3.3rc0/doc/reference/algorithms/community.rst`

 * *Files 8% similar despite different names*

```diff
@@ -10,14 +10,23 @@
 ------------
 .. automodule:: networkx.algorithms.community.kernighan_lin
 .. autosummary::
    :toctree: generated/
 
    kernighan_lin_bisection
 
+Divisive Communities
+--------------------
+.. automodule:: networkx.algorithms.community.divisive
+.. autosummary::
+   :toctree: generated/
+
+   edge_betweenness_partition
+   edge_current_flow_betweenness_partition
+
 K-Clique
 --------
 .. automodule:: networkx.algorithms.community.kclique
 .. autosummary::
    :toctree: generated/
 
    k_clique_communities
@@ -43,14 +52,15 @@
 -----------------
 .. automodule:: networkx.algorithms.community.label_propagation
 .. autosummary::
    :toctree: generated/
 
    asyn_lpa_communities
    label_propagation_communities
+   fast_label_propagation_communities
 
 Louvain Community Detection
 ---------------------------
 .. automodule:: networkx.algorithms.community.louvain
 .. autosummary::
     :toctree: generated/
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/component.rst` & `networkx-3.3rc0/doc/reference/algorithms/component.rst`

 * *Files 12% similar despite different names*

```diff
@@ -1,61 +1,73 @@
 **********
 Components
 **********
 .. automodule:: networkx.algorithms.components
 
+.. _networkx.algorithms.components.connected:
+
 Connectivity
 ------------
 .. autosummary::
    :toctree: generated/
 
    is_connected
    number_connected_components
    connected_components
    node_connected_component
 
+.. _networkx.algorithms.components.strongly_connected:
+
 Strong connectivity
 -------------------
 .. autosummary::
    :toctree: generated/
 
    is_strongly_connected
    number_strongly_connected_components
    strongly_connected_components
    strongly_connected_components_recursive
    kosaraju_strongly_connected_components
    condensation
 
+.. _networkx.algorithms.components.weakly_connected:
+
 Weak connectivity
 -----------------
 .. autosummary::
    :toctree: generated/
 
    is_weakly_connected
    number_weakly_connected_components
    weakly_connected_components
 
+.. _networkx.algorithms.components.attracting:
+
 Attracting components
 ---------------------
 .. autosummary::
    :toctree: generated/
 
    is_attracting_component
    number_attracting_components
    attracting_components
 
+.. _networkx.algorithms.components.biconnected:
+
 Biconnected components
 ----------------------
 .. autosummary::
    :toctree: generated/
 
    is_biconnected
    biconnected_components
    biconnected_component_edges
    articulation_points
 
+.. _networkx.algorithms.components.semiconnected:
+
 Semiconnectedness
 -----------------
 .. autosummary::
    :toctree: generated/
 
    is_semiconnected
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/connectivity.rst` & `networkx-3.3rc0/doc/reference/algorithms/connectivity.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/algorithms/index.rst` & `networkx-3.3rc0/doc/reference/algorithms/index.rst`

 * *Files 2% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 
    approximation
    assortativity
    asteroidal
    bipartite
    boundary
    bridges
+   broadcasting
    centrality
    chains
    chordal
    clique
    clustering
    coloring
    communicability_alg
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/isomorphism.rst` & `networkx-3.3rc0/doc/reference/algorithms/isomorphism.rst`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 .. _isomorphism:
+.. _networkx.algorithms.isomorphism.isomorph:
 
 ***********
 Isomorphism
 ***********
 
 .. automodule:: networkx.algorithms.isomorphism
 .. autosummary::
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/isomorphism.vf2.rst` & `networkx-3.3rc0/doc/reference/algorithms/isomorphism.vf2.rst`

 * *Files 3% similar despite different names*

```diff
@@ -13,16 +13,18 @@
 .. autosummary::
    :toctree: generated/
 
     GraphMatcher.__init__
     GraphMatcher.initialize
     GraphMatcher.is_isomorphic
     GraphMatcher.subgraph_is_isomorphic
+    GraphMatcher.subgraph_is_monomorphic
     GraphMatcher.isomorphisms_iter
     GraphMatcher.subgraph_isomorphisms_iter
+    GraphMatcher.subgraph_monomorphisms_iter
     GraphMatcher.candidate_pairs_iter
     GraphMatcher.match
     GraphMatcher.semantic_feasibility
     GraphMatcher.syntactic_feasibility
 
 
 DiGraph Matcher
@@ -32,16 +34,18 @@
 .. autosummary::
    :toctree: generated/
 
     DiGraphMatcher.__init__
     DiGraphMatcher.initialize
     DiGraphMatcher.is_isomorphic
     DiGraphMatcher.subgraph_is_isomorphic
+    DiGraphMatcher.subgraph_is_monomorphic
     DiGraphMatcher.isomorphisms_iter
     DiGraphMatcher.subgraph_isomorphisms_iter
+    DiGraphMatcher.subgraph_monomorphisms_iter
     DiGraphMatcher.candidate_pairs_iter
     DiGraphMatcher.match
     DiGraphMatcher.semantic_feasibility
     DiGraphMatcher.syntactic_feasibility
 
 
 Match helpers
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/operators.rst` & `networkx-3.3rc0/doc/reference/algorithms/operators.rst`

 * *Files 14% similar despite different names*

```diff
@@ -40,7 +40,8 @@
    cartesian_product
    lexicographic_product
    rooted_product
    strong_product
    tensor_product
    power
    corona_product
+   modular_product
```

### Comparing `networkx-3.2rc0/doc/reference/algorithms/shortest_paths.rst` & `networkx-3.3rc0/doc/reference/algorithms/shortest_paths.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/algorithms/traversal.rst` & `networkx-3.3rc0/doc/reference/algorithms/traversal.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/algorithms/tree.rst` & `networkx-3.3rc0/doc/reference/algorithms/tree.rst`

 * *Files 8% similar despite different names*

```diff
@@ -60,14 +60,15 @@
 
    minimum_spanning_tree
    maximum_spanning_tree
    random_spanning_tree
    minimum_spanning_edges
    maximum_spanning_edges
    SpanningTreeIterator
+   number_of_spanning_trees
 
 Decomposition
 -------------
 .. automodule:: networkx.algorithms.tree.decomposition
 .. autosummary::
    :toctree: generated/
```

### Comparing `networkx-3.2rc0/doc/reference/classes/digraph.rst` & `networkx-3.3rc0/doc/reference/classes/digraph.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/classes/graph.rst` & `networkx-3.3rc0/doc/reference/classes/graph.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/classes/index.rst` & `networkx-3.3rc0/doc/reference/classes/index.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/classes/multidigraph.rst` & `networkx-3.3rc0/doc/reference/classes/multidigraph.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/classes/multigraph.rst` & `networkx-3.3rc0/doc/reference/classes/multigraph.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/convert.rst` & `networkx-3.3rc0/doc/reference/convert.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/drawing.rst` & `networkx-3.3rc0/doc/reference/drawing.rst`

 * *Files 2% similar despite different names*

```diff
@@ -80,14 +80,15 @@
 Graph Layout
 ============
 .. automodule:: networkx.drawing.layout
 .. autosummary::
    :toctree: generated/
 
    bipartite_layout
+   bfs_layout
    circular_layout
    kamada_kawai_layout
    planar_layout
    random_layout
    rescale_layout
    rescale_layout_dict
    shell_layout
```

### Comparing `networkx-3.2rc0/doc/reference/exceptions.rst` & `networkx-3.3rc0/doc/reference/exceptions.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/functions.rst` & `networkx-3.3rc0/doc/reference/functions.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/generators.rst` & `networkx-3.3rc0/doc/reference/generators.rst`

 * *Files 2% similar despite different names*

```diff
@@ -30,33 +30,38 @@
    complete_multipartite_graph
    circular_ladder_graph
    circulant_graph
    cycle_graph
    dorogovtsev_goltsev_mendes_graph
    empty_graph
    full_rary_tree
+   kneser_graph
    ladder_graph
    lollipop_graph
    null_graph
    path_graph
    star_graph
+   tadpole_graph
    trivial_graph
    turan_graph
    wheel_graph
 
 
 Expanders
 ---------
 .. automodule:: networkx.generators.expanders
 .. autosummary::
    :toctree: generated/
 
    margulis_gabber_galil_graph
    chordal_cycle_graph
    paley_graph
+   maybe_regular_expander
+   is_regular_expander
+   random_regular_expander_graph
 
 Lattice
 -------
 .. automodule:: networkx.generators.lattice
 .. autosummary::
    :toctree: generated/
 
@@ -184,14 +189,15 @@
    geometric_edges
    geographical_threshold_graph
    navigable_small_world_graph
    random_geometric_graph
    soft_random_geometric_graph
    thresholded_random_geometric_graph
    waxman_graph
+   geometric_soft_configuration_graph
 
 Line Graph
 ----------
 .. automodule:: networkx.generators.line
 .. autosummary::
    :toctree: generated/
```

### Comparing `networkx-3.2rc0/doc/reference/glossary.rst` & `networkx-3.3rc0/doc/reference/glossary.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/introduction.rst` & `networkx-3.3rc0/networkx/algorithms/centrality/eigenvector.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,344 +1,341 @@
-Introduction
-============
+"""Functions for computing eigenvector centrality."""
+import math
 
-.. currentmodule:: networkx
+import networkx as nx
+from networkx.utils import not_implemented_for
 
-The structure of NetworkX can be seen by the organization of its source code.
-The package provides classes for graph objects, generators to create standard
-graphs, IO routines for reading in existing datasets, algorithms to analyze
-the resulting networks and some basic drawing tools.
-
-Most of the NetworkX API is provided by functions which take a graph object
-as an argument.  Methods of the graph object are limited to basic manipulation
-and reporting.  This provides modularity of code and documentation.
-It also makes it easier for newcomers to learn about the package in stages.
-The source code for each module is meant to be easy to read and reading
-this Python code is actually a good way to learn more about network algorithms,
-but we have put a lot of effort into making the documentation sufficient and friendly.
-If you have suggestions or questions please contact us by joining the
-`NetworkX Google group <http://groups.google.com/group/networkx-discuss>`_.
-
-Classes are named using ``CamelCase`` (capital letters at the start of each word).
-functions, methods and variable names are ``lower_case_underscore`` (lowercase with
-an underscore representing a space between words).
-
-
-NetworkX Basics
----------------
-
-After starting Python, import the networkx module with (the recommended way)
-
-.. nbplot::
-
-   >>> import networkx as nx
-
-To save repetition, in the documentation we assume that
-NetworkX has been imported this way.
-
-If importing networkx fails, it means that Python cannot find the installed
-module. Check your installation and your ``PYTHONPATH``.
-
-The following basic graph types are provided as Python classes:
-
-:class:`Graph`
-   This class implements an undirected graph. It ignores
-   multiple edges between two nodes.  It does allow self-loop
-   edges between a node and itself.
-
-:class:`DiGraph`
-   Directed graphs, that is, graphs with directed edges.
-   Provides operations common to directed graphs,
-   (a subclass of Graph).
-
-:class:`MultiGraph`
-   A flexible graph class that allows multiple undirected edges between
-   pairs of nodes.  The additional flexibility leads to some degradation
-   in performance, though usually not significant.
-
-:class:`MultiDiGraph`
-   A directed version of a MultiGraph.
-
-Empty graph-like objects are created with
-
-.. nbplot::
-
-   >>> G = nx.Graph()
-   >>> G = nx.DiGraph()
-   >>> G = nx.MultiGraph()
-   >>> G = nx.MultiDiGraph()
-
-All graph classes allow any :term:`hashable` object as a node.
-Hashable objects include strings, tuples, integers, and more.
-Arbitrary edge attributes such as weights and labels
-can be associated with an edge.
-
-
-The graph internal data structures are based on an
-adjacency list representation and implemented using
-Python :term:`dictionary` datastructures.
-The graph adjacency structure is
-implemented as a Python dictionary of
-dictionaries; the outer dictionary is keyed by nodes to values that are
-themselves dictionaries keyed by neighboring node to the
-edge attributes associated with that edge.  This "dict-of-dicts" structure
-allows fast addition, deletion, and lookup of nodes and neighbors in
-large graphs.  The underlying datastructure is accessed directly
-by methods (the programming interface "API") in the class definitions.
-All functions, on the other hand, manipulate graph-like objects
-solely via those API methods and not by acting directly on the datastructure.
-This design allows for possible replacement of the 'dicts-of-dicts'-based
-datastructure with an alternative datastructure that implements the
-same methods.
-
-
-Graphs
-------
-
-The first choice to be made when using NetworkX is what type of graph
-object to use.  A graph (network) is a collection of nodes together
-with a collection of edges that are pairs of nodes.  Attributes are
-often associated with nodes and/or edges.  NetworkX graph objects come in
-different flavors depending on two main properties of the network:
-
- - Directed: Are the edges **directed**?  Does the order of the edge
-   pairs $(u, v)$ matter?  A directed graph is specified by the "Di"
-   prefix in the class name, e.g. `DiGraph()`.  We make this distinction
-   because many classical graph properties are defined differently for
-   directed graphs.
-
- - Multi-edges: Are multiple edges allowed between each pair of nodes?
-   As you might imagine, multiple edges requires a different data
-   structure, though clever users could design edge data attributes to
-   support this functionality.  We provide a standard data structure
-   and interface for this type of graph using the prefix "Multi",
-   e.g., `MultiGraph()`.
-
-The basic graph classes are named:
-:doc:`Graph </reference/classes/graph>`,
-:doc:`DiGraph</reference/classes/digraph>`,
-:doc:`MultiGraph </reference/classes/multigraph>`, and
-:doc:`MultiDiGraph </reference/classes/multidigraph>`
-
-
-Nodes and Edges
-^^^^^^^^^^^^^^^
-
-The next choice you have to make when specifying a graph is what kinds
-of nodes and edges to use.
-
-If the topology of the network is all you
-care about then using integers or strings as the nodes makes sense and
-you need not worry about edge data.  If you have a data structure
-already in place to describe nodes you can simply use that structure
-as your nodes provided it is :term:`hashable`.  If it is not hashable you can
-use a unique identifier to represent the node and assign the data
-as a :term:`node attribute`.
-
-Edges often have data associated with them.  Arbitrary data
-can be associated with edges as an :term:`edge attribute`.
-If the data is numeric and the intent is to represent
-a *weighted* graph then use the 'weight' keyword for the attribute.
-Some of the graph algorithms, such as
-Dijkstra's shortest path algorithm, use this attribute
-name by default to get the weight for each edge.
-
-Attributes can be assigned to an edge by using keyword/value
-pairs when adding edges.  You can use any keyword
-to name your attribute and can then query the edge
-data using that attribute keyword.
-
-Once you've decided how to encode the nodes and edges, and whether you have
-an undirected/directed graph with or without multiedges you are ready to build
-your network.
-
-Graph Creation
---------------
-
-NetworkX graph objects can be created in one of three ways:
-
-- Graph generators---standard algorithms to create network topologies.
-- Importing data from preexisting (usually file) sources.
-- Adding edges and nodes explicitly.
-
-Explicit addition and removal of nodes/edges is the easiest to describe.
-Each graph object supplies methods to manipulate the graph.  For example,
-
-.. nbplot::
-
-   >>> import networkx as nx
-   >>> G = nx.Graph()
-   >>> G.add_edge(1, 2)  # default edge data=1
-   >>> G.add_edge(2, 3, weight=0.9)  # specify edge data
-
-Edge attributes can be anything:
-
-.. nbplot::
-
-   >>> import math
-   >>> G.add_edge('y', 'x', function=math.cos)
-   >>> G.add_node(math.cos)  # any hashable can be a node
-
-You can add many edges at one time:
-
-.. nbplot::
-
-   >>> elist = [(1, 2), (2, 3), (1, 4), (4, 2)]
-   >>> G.add_edges_from(elist)
-   >>> elist = [('a', 'b', 5.0), ('b', 'c', 3.0), ('a', 'c', 1.0), ('c', 'd', 7.3)]
-   >>> G.add_weighted_edges_from(elist)
-
-See the :doc:`/tutorial` for more examples.
-
-Some basic graph operations such as union and intersection
-are described in the :ref:`operators module <operators>` documentation.
-
-Graph generators such as :func:`~generators.random_graphs.binomial_graph`
-and :func:`~generators.random_graphs.erdos_renyi_graph` are
-provided in the :ref:`graph generators <generators>` subpackage.
-
-For importing network data from formats such as GML, GraphML, edge list text files
-see the :ref:`reading and writing graphs <readwrite>` subpackage.
-
-
-Graph Reporting
----------------
-
-Class views provide basic reporting of nodes, neighbors, edges and degree.
-These views provide iteration over the properties as well as membership
-queries and data attribute lookup. The views refer to the graph data structure
-so changes to the graph are reflected in the views. This is analogous to
-dictionary views in Python 3. If you want to change the graph while iterating
-you will need to use e.g. ``for e in list(G.edges):``. The views provide
-set-like operations, e.g. union and intersection, as well as dict-like
-lookup and iteration of the data attributes using ``G.edges[u, v]['color']``
-and ``for e, datadict in G.edges.items():``. Methods ``G.edges.items()`` and
-``G.edges.values()`` are familiar from python dicts. In addition ``G.edges.data()``
-provides specific attribute iteration e.g. ``for e, e_color in G.edges.data('color'):``.
-
-The basic graph relationship of an edge can be obtained in two ways.
-One can look for neighbors of a node or one can look for edges.
-We jokingly refer to people who focus on nodes/neighbors as node-centric
-and people who focus on edges as edge-centric.  The designers of NetworkX
-tend to be node-centric and view edges as a relationship between nodes.
-You can see this by our choice of lookup notation like ``G[u]`` providing neighbors
-(adjacency) while edge lookup is ``G.edges[u, v]``.
-Most data structures for sparse graphs are essentially adjacency lists and so
-fit this perspective. In the end, of course, it doesn't really matter which way
-you examine the graph. ``G.edges`` removes duplicate representations of undirected
-edges while neighbor reporting across all nodes will naturally report both directions.
-
-Any properties that are more complicated than edges, neighbors and degree are
-provided by functions.  For example ``nx.triangles(G, n)`` gives the number of triangles
-which include node n as a vertex.  These functions are grouped in the code and
-documentation under the term :ref:`algorithms<algorithms>`.
-
-
-Algorithms
-----------
-
-A number of graph algorithms are provided with NetworkX.
-These include shortest path, and breadth first search
-(see :ref:`traversal<traversal>`),
-clustering and isomorphism algorithms and others.  There are
-many that we have not developed yet too.  If you implement a
-graph algorithm that might be useful for others please let
-us know through the
-`NetworkX Google group <http://groups.google.com/group/networkx-discuss>`_
-or the GitHub `Developer Zone <https://github.com/networkx/networkx>`_.
-
-As an example here is code to use Dijkstra's algorithm to
-find the shortest weighted path:
-
-.. nbplot::
-
-   >>> G = nx.Graph()
-   >>> e = [('a', 'b', 0.3), ('b', 'c', 0.9), ('a', 'c', 0.5), ('c', 'd', 1.2)]
-   >>> G.add_weighted_edges_from(e)
-   >>> print(nx.dijkstra_path(G, 'a', 'd'))
-   ['a', 'c', 'd']
-
-Drawing
--------
-
-While NetworkX is not designed as a network drawing tool, we provide
-a simple interface to drawing packages and some simple layout algorithms.
-We interface to the excellent Graphviz layout tools like dot and neato
-with the (suggested) pygraphviz package or the pydot interface.
-Drawing can be done using external programs or the Matplotlib Python
-package.  Interactive GUI interfaces are possible, though not provided.
-The drawing tools are provided in the module :ref:`drawing <drawing>`.
-
-The basic drawing functions essentially place the nodes on a scatterplot
-using the positions you provide via a dictionary or the positions are
-computed with a layout function. The edges are lines between those dots.
-
-.. nbplot::
-
-   >>> import matplotlib.pyplot as plt
-   >>> G = nx.cubical_graph()
-   >>> subax1 = plt.subplot(121)
-   >>> nx.draw(G)   # default spring_layout
-   >>> subax2 = plt.subplot(122)
-   >>> nx.draw(G, pos=nx.circular_layout(G), node_color='r', edge_color='b')
-
-See the :doc:`examples </auto_examples/index>` for more ideas.
-
-Data Structure
---------------
-
-NetworkX uses a "dictionary of dictionaries of dictionaries" as the
-basic network data structure.  This allows fast lookup with reasonable
-storage for large sparse networks.  The keys are nodes so ``G[u]`` returns
-an adjacency dictionary keyed by neighbor to the edge attribute
-dictionary. A view of the adjacency data structure is provided
-by the dict-like object ``G.adj`` as e.g. ``for node, nbrsdict in G.adj.items():``.
-The expression ``G[u][v]`` returns the edge attribute dictionary itself.
-A dictionary of lists would have also been possible, but not allow
-fast edge detection nor convenient storage of edge data.
-
-Advantages of dict-of-dicts-of-dicts data structure:
-
- - Find edges and remove edges with two dictionary look-ups.
- - Prefer to "lists" because of fast lookup with sparse storage.
- - Prefer to "sets" since data can be attached to edge.
- - ``G[u][v]`` returns the edge attribute dictionary.
- - ``n in G`` tests if node ``n`` is in graph ``G``.
- - ``for n in G:`` iterates through the graph.
- - ``for nbr in G[n]:`` iterates through neighbors.
-
-As an example, here is a representation of an undirected graph with the
-edges $(A, B)$ and $(B, C)$.
-
-.. nbplot::
-
-   >>> G = nx.Graph()
-   >>> G.add_edge('A', 'B')
-   >>> G.add_edge('B', 'C')
-   >>> print(G.adj)
-   {'A': {'B': {}}, 'B': {'A': {}, 'C': {}}, 'C': {'B': {}}}
-
-The data structure gets morphed slightly for each base graph class.
-For DiGraph two dict-of-dicts-of-dicts structures are provided, one
-for successors (``G.succ``) and one for predecessors (``G.pred``).
-For MultiGraph/MultiDiGraph we use a dict-of-dicts-of-dicts-of-dicts [#turtles]_
-where the third dictionary is keyed by an edge key identifier to the fourth
-dictionary which contains the edge attributes for that edge between
-the two nodes.
-
-Graphs provide two interfaces to the edge data attributes: adjacency
-and edges. So ``G[u][v]['width']`` is the same as ``G.edges[u, v]['width']``.
-
-.. nbplot::
-
-   >>> G = nx.Graph()
-   >>> G.add_edge(1, 2, color='red', weight=0.84, size=300)
-   >>> print(G[1][2]['size'])
-   300
-   >>> print(G.edges[1, 2]['color'])
-   red
+__all__ = ["eigenvector_centrality", "eigenvector_centrality_numpy"]
 
-.. code-links::
 
-.. rubric:: Footnotes
-
-.. [#turtles] "It's dictionaries all the way down."
+@not_implemented_for("multigraph")
+@nx._dispatchable(edge_attrs="weight")
+def eigenvector_centrality(G, max_iter=100, tol=1.0e-6, nstart=None, weight=None):
+    r"""Compute the eigenvector centrality for the graph G.
+
+    Eigenvector centrality computes the centrality for a node by adding
+    the centrality of its predecessors. The centrality for node $i$ is the
+    $i$-th element of a left eigenvector associated with the eigenvalue $\lambda$
+    of maximum modulus that is positive. Such an eigenvector $x$ is
+    defined up to a multiplicative constant by the equation
+
+    .. math::
+
+         \lambda x^T = x^T A,
+
+    where $A$ is the adjacency matrix of the graph G. By definition of
+    row-column product, the equation above is equivalent to
+
+    .. math::
+
+        \lambda x_i = \sum_{j\to i}x_j.
+
+    That is, adding the eigenvector centralities of the predecessors of
+    $i$ one obtains the eigenvector centrality of $i$ multiplied by
+    $\lambda$. In the case of undirected graphs, $x$ also solves the familiar
+    right-eigenvector equation $Ax = \lambda x$.
+
+    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly
+    connected there is a unique eigenvector $x$, and all its entries
+    are strictly positive.
+
+    If G is not strongly connected there might be several left
+    eigenvectors associated with $\lambda$, and some of their elements
+    might be zero.
+
+    Parameters
+    ----------
+    G : graph
+      A networkx graph.
+
+    max_iter : integer, optional (default=100)
+      Maximum number of power iterations.
+
+    tol : float, optional (default=1.0e-6)
+      Error tolerance (in Euclidean norm) used to check convergence in
+      power iteration.
+
+    nstart : dictionary, optional (default=None)
+      Starting value of power iteration for each node. Must have a nonzero
+      projection on the desired eigenvector for the power method to converge.
+      If None, this implementation uses an all-ones vector, which is a safe
+      choice.
+
+    weight : None or string, optional (default=None)
+      If None, all edge weights are considered equal. Otherwise holds the
+      name of the edge attribute used as weight. In this measure the
+      weight is interpreted as the connection strength.
+
+    Returns
+    -------
+    nodes : dictionary
+       Dictionary of nodes with eigenvector centrality as the value. The
+       associated vector has unit Euclidean norm and the values are
+       nonegative.
+
+    Examples
+    --------
+    >>> G = nx.path_graph(4)
+    >>> centrality = nx.eigenvector_centrality(G)
+    >>> sorted((v, f"{c:0.2f}") for v, c in centrality.items())
+    [(0, '0.37'), (1, '0.60'), (2, '0.60'), (3, '0.37')]
+
+    Raises
+    ------
+    NetworkXPointlessConcept
+        If the graph G is the null graph.
+
+    NetworkXError
+        If each value in `nstart` is zero.
+
+    PowerIterationFailedConvergence
+        If the algorithm fails to converge to the specified tolerance
+        within the specified number of iterations of the power iteration
+        method.
+
+    See Also
+    --------
+    eigenvector_centrality_numpy
+    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
+    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
+
+    Notes
+    -----
+    Eigenvector centrality was introduced by Landau [2]_ for chess
+    tournaments. It was later rediscovered by Wei [3]_ and then
+    popularized by Kendall [4]_ in the context of sport ranking. Berge
+    introduced a general definition for graphs based on social connections
+    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made
+    it popular in link analysis.
+
+    This function computes the left dominant eigenvector, which corresponds
+    to adding the centrality of predecessors: this is the usual approach.
+    To add the centrality of successors first reverse the graph with
+    ``G.reverse()``.
+
+    The implementation uses power iteration [7]_ to compute a dominant
+    eigenvector starting from the provided vector `nstart`. Convergence is
+    guaranteed as long as `nstart` has a nonzero projection on a dominant
+    eigenvector, which certainly happens using the default value.
+
+    The method stops when the change in the computed vector between two
+    iterations is smaller than an error tolerance of ``G.number_of_nodes()
+    * tol`` or after ``max_iter`` iterations, but in the second case it
+    raises an exception.
+
+    This implementation uses $(A + I)$ rather than the adjacency matrix
+    $A$ because the change preserves eigenvectors, but it shifts the
+    spectrum, thus guaranteeing convergence even for networks with
+    negative eigenvalues of maximum modulus.
+
+    References
+    ----------
+    .. [1] Abraham Berman and Robert J. Plemmons.
+       "Nonnegative Matrices in the Mathematical Sciences."
+       Classics in Applied Mathematics. SIAM, 1994.
+
+    .. [2] Edmund Landau.
+       "Zur relativen Wertbemessung der Turnierresultate."
+       Deutsches Wochenschach, 11:366–369, 1895.
+
+    .. [3] Teh-Hsing Wei.
+       "The Algebraic Foundations of Ranking Theory."
+       PhD thesis, University of Cambridge, 1952.
+
+    .. [4] Maurice G. Kendall.
+       "Further contributions to the theory of paired comparisons."
+       Biometrics, 11(1):43–62, 1955.
+       https://www.jstor.org/stable/3001479
+
+    .. [5] Claude Berge
+       "Théorie des graphes et ses applications."
+       Dunod, Paris, France, 1958.
+
+    .. [6] Phillip Bonacich.
+       "Technique for analyzing overlapping memberships."
+       Sociological Methodology, 4:176–185, 1972.
+       https://www.jstor.org/stable/270732
+
+    .. [7] Power iteration:: https://en.wikipedia.org/wiki/Power_iteration
+
+    """
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept(
+            "cannot compute centrality for the null graph"
+        )
+    # If no initial vector is provided, start with the all-ones vector.
+    if nstart is None:
+        nstart = {v: 1 for v in G}
+    if all(v == 0 for v in nstart.values()):
+        raise nx.NetworkXError("initial vector cannot have all zero values")
+    # Normalize the initial vector so that each entry is in [0, 1]. This is
+    # guaranteed to never have a divide-by-zero error by the previous line.
+    nstart_sum = sum(nstart.values())
+    x = {k: v / nstart_sum for k, v in nstart.items()}
+    nnodes = G.number_of_nodes()
+    # make up to max_iter iterations
+    for _ in range(max_iter):
+        xlast = x
+        x = xlast.copy()  # Start with xlast times I to iterate with (A+I)
+        # do the multiplication y^T = x^T A (left eigenvector)
+        for n in x:
+            for nbr in G[n]:
+                w = G[n][nbr].get(weight, 1) if weight else 1
+                x[nbr] += xlast[n] * w
+        # Normalize the vector. The normalization denominator `norm`
+        # should never be zero by the Perron--Frobenius
+        # theorem. However, in case it is due to numerical error, we
+        # assume the norm to be one instead.
+        norm = math.hypot(*x.values()) or 1
+        x = {k: v / norm for k, v in x.items()}
+        # Check for convergence (in the L_1 norm).
+        if sum(abs(x[n] - xlast[n]) for n in x) < nnodes * tol:
+            return x
+    raise nx.PowerIterationFailedConvergence(max_iter)
+
+
+@nx._dispatchable(edge_attrs="weight")
+def eigenvector_centrality_numpy(G, weight=None, max_iter=50, tol=0):
+    r"""Compute the eigenvector centrality for the graph G.
+
+    Eigenvector centrality computes the centrality for a node by adding
+    the centrality of its predecessors. The centrality for node $i$ is the
+    $i$-th element of a left eigenvector associated with the eigenvalue $\lambda$
+    of maximum modulus that is positive. Such an eigenvector $x$ is
+    defined up to a multiplicative constant by the equation
+
+    .. math::
+
+         \lambda x^T = x^T A,
+
+    where $A$ is the adjacency matrix of the graph G. By definition of
+    row-column product, the equation above is equivalent to
+
+    .. math::
+
+        \lambda x_i = \sum_{j\to i}x_j.
+
+    That is, adding the eigenvector centralities of the predecessors of
+    $i$ one obtains the eigenvector centrality of $i$ multiplied by
+    $\lambda$. In the case of undirected graphs, $x$ also solves the familiar
+    right-eigenvector equation $Ax = \lambda x$.
+
+    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly
+    connected there is a unique eigenvector $x$, and all its entries
+    are strictly positive.
+
+    If G is not strongly connected there might be several left
+    eigenvectors associated with $\lambda$, and some of their elements
+    might be zero.
+
+    Parameters
+    ----------
+    G : graph
+      A networkx graph.
+
+    max_iter : integer, optional (default=50)
+      Maximum number of Arnoldi update iterations allowed.
+
+    tol : float, optional (default=0)
+      Relative accuracy for eigenvalues (stopping criterion).
+      The default value of 0 implies machine precision.
+
+    weight : None or string, optional (default=None)
+      If None, all edge weights are considered equal. Otherwise holds the
+      name of the edge attribute used as weight. In this measure the
+      weight is interpreted as the connection strength.
+
+    Returns
+    -------
+    nodes : dictionary
+       Dictionary of nodes with eigenvector centrality as the value. The
+       associated vector has unit Euclidean norm and the values are
+       nonegative.
+
+    Examples
+    --------
+    >>> G = nx.path_graph(4)
+    >>> centrality = nx.eigenvector_centrality_numpy(G)
+    >>> print([f"{node} {centrality[node]:0.2f}" for node in centrality])
+    ['0 0.37', '1 0.60', '2 0.60', '3 0.37']
+
+    Raises
+    ------
+    NetworkXPointlessConcept
+        If the graph G is the null graph.
+
+    ArpackNoConvergence
+        When the requested convergence is not obtained. The currently
+        converged eigenvalues and eigenvectors can be found as
+        eigenvalues and eigenvectors attributes of the exception object.
+
+    See Also
+    --------
+    :func:`scipy.sparse.linalg.eigs`
+    eigenvector_centrality
+    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
+    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
+
+    Notes
+    -----
+    Eigenvector centrality was introduced by Landau [2]_ for chess
+    tournaments. It was later rediscovered by Wei [3]_ and then
+    popularized by Kendall [4]_ in the context of sport ranking. Berge
+    introduced a general definition for graphs based on social connections
+    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made
+    it popular in link analysis.
+
+    This function computes the left dominant eigenvector, which corresponds
+    to adding the centrality of predecessors: this is the usual approach.
+    To add the centrality of successors first reverse the graph with
+    ``G.reverse()``.
+
+    This implementation uses the
+    :func:`SciPy sparse eigenvalue solver<scipy.sparse.linalg.eigs>` (ARPACK)
+    to find the largest eigenvalue/eigenvector pair using Arnoldi iterations
+    [7]_.
+
+    References
+    ----------
+    .. [1] Abraham Berman and Robert J. Plemmons.
+       "Nonnegative Matrices in the Mathematical Sciences."
+       Classics in Applied Mathematics. SIAM, 1994.
+
+    .. [2] Edmund Landau.
+       "Zur relativen Wertbemessung der Turnierresultate."
+       Deutsches Wochenschach, 11:366–369, 1895.
+
+    .. [3] Teh-Hsing Wei.
+       "The Algebraic Foundations of Ranking Theory."
+       PhD thesis, University of Cambridge, 1952.
+
+    .. [4] Maurice G. Kendall.
+       "Further contributions to the theory of paired comparisons."
+       Biometrics, 11(1):43–62, 1955.
+       https://www.jstor.org/stable/3001479
+
+    .. [5] Claude Berge
+       "Théorie des graphes et ses applications."
+       Dunod, Paris, France, 1958.
+
+    .. [6] Phillip Bonacich.
+       "Technique for analyzing overlapping memberships."
+       Sociological Methodology, 4:176–185, 1972.
+       https://www.jstor.org/stable/270732
+
+    .. [7] Arnoldi iteration:: https://en.wikipedia.org/wiki/Arnoldi_iteration
+
+    """
+    import numpy as np
+    import scipy as sp
+
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept(
+            "cannot compute centrality for the null graph"
+        )
+    M = nx.to_scipy_sparse_array(G, nodelist=list(G), weight=weight, dtype=float)
+    _, eigenvector = sp.sparse.linalg.eigs(
+        M.T, k=1, which="LR", maxiter=max_iter, tol=tol
+    )
+    largest = eigenvector.flatten().real
+    norm = np.sign(largest.sum()) * sp.linalg.norm(largest)
+    return dict(zip(G, (largest / norm).tolist()))
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `networkx-3.2rc0/doc/reference/linalg.rst` & `networkx-3.3rc0/doc/reference/linalg.rst`

 * *Files 8% similar despite different names*

```diff
@@ -21,14 +21,15 @@
 .. autosummary::
    :toctree: generated/
 
    laplacian_matrix
    normalized_laplacian_matrix
    directed_laplacian_matrix
    directed_combinatorial_laplacian_matrix
+   total_spanning_tree_weight
 
 Bethe Hessian Matrix
 --------------------
 .. automodule:: networkx.linalg.bethehessianmatrix
 .. autosummary::
    :toctree: generated/
```

### Comparing `networkx-3.2rc0/doc/reference/randomness.rst` & `networkx-3.3rc0/doc/reference/randomness.rst`

 * *Files 2% similar despite different names*

```diff
@@ -23,29 +23,29 @@
 to any integer, thus determining the subsequent generated values.
 Since this package (and many others) use both RNGs you may need to
 set the `seed` of both RNGs.  Even if we strictly only used one of the
 RNGs, you may find yourself using another package that uses the other.
 Setting the state of the two global RNGs is as simple setting the
 seed of each RNG to an arbitrary integer:
 
-.. nbplot::
+.. code-block::
 
    >>> import random
    >>> random.seed(246)        # or any integer
    >>> import numpy
    >>> numpy.random.seed(4812)
 
 Many users will be satisfied with this level of control.
 
 For people who want even more control, we include an optional argument
 to functions that use an RNG.  This argument is called `seed`, but
 determines more than the seed of the RNG. It tells the function which
 RNG package to use, and whether to use a global or local RNG.
 
-.. nbplot::
+.. code-block::
 
     >>> from networkx import path_graph, random_layout
     >>> G = path_graph(9)
     >>> pos = random_layout(G, seed=None)  # use (either) global default RNG
     >>> pos = random_layout(G, seed=42)  # local RNG just for this call
     >>> pos = random_layout(G, seed=numpy.random)  # use numpy global RNG
     >>> random_state = numpy.random.RandomState(42)
```

### Comparing `networkx-3.2rc0/doc/reference/readwrite/matrix_market.rst` & `networkx-3.3rc0/doc/reference/readwrite/matrix_market.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/readwrite/sparsegraph6.rst` & `networkx-3.3rc0/doc/reference/readwrite/sparsegraph6.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/reference/utils.rst` & `networkx-3.3rc0/doc/reference/utils.rst`

 * *Files 16% similar despite different names*

```diff
@@ -72,17 +72,16 @@
 .. autosummary::
    :toctree: generated/
 
    MappedQueue
 
 Backends
 --------
-.. note:: This is an experimental feature to dispatch your computations to an alternate
-   backend like `GraphBLAS <https://github.com/python-graphblas/graphblas-algorithms>`_
-   instead of using pure Python dictionaries for computation.
-   Things will change and break in the future!
+.. note:: NetworkX backends are experimental. They let you execute an alternate
+   backend implementation instead of NetworkX's pure Python dictionaries
+   implementation. Things will change and break in the future!
 
 .. automodule:: networkx.utils.backends
 .. autosummary::
    :toctree: generated/
 
-   _dispatch
+   _dispatchable
```

### Comparing `networkx-3.2rc0/doc/release/api_0.99.rst` & `networkx-3.3rc0/doc/release/api_0.99.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.0.rst` & `networkx-3.3rc0/doc/release/api_1.0.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.10.rst` & `networkx-3.3rc0/doc/release/api_1.10.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.11.rst` & `networkx-3.3rc0/doc/release/api_1.11.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.4.rst` & `networkx-3.3rc0/doc/release/api_1.4.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.5.rst` & `networkx-3.3rc0/doc/release/api_1.5.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.6.rst` & `networkx-3.3rc0/doc/release/api_1.6.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.7.rst` & `networkx-3.3rc0/doc/release/api_1.7.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.8.rst` & `networkx-3.3rc0/doc/release/api_1.8.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/api_1.9.rst` & `networkx-3.3rc0/doc/release/api_1.9.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/contribs.py` & `networkx-3.3rc0/doc/release/contribs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/migration_guide_from_1.x_to_2.0.rst` & `networkx-3.3rc0/doc/release/migration_guide_from_1.x_to_2.0.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/migration_guide_from_2.x_to_3.0.rst` & `networkx-3.3rc0/doc/release/migration_guide_from_2.x_to_3.0.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/old_release_log.rst` & `networkx-3.3rc0/doc/release/old_release_log.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.0.rst` & `networkx-3.3rc0/doc/release/release_2.0.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.1.rst` & `networkx-3.3rc0/doc/release/release_2.1.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.2.rst` & `networkx-3.3rc0/doc/release/release_2.2.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.3.rst` & `networkx-3.3rc0/doc/release/release_2.3.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.4.rst` & `networkx-3.3rc0/doc/release/release_2.4.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.5.rst` & `networkx-3.3rc0/doc/release/release_2.5.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.6.rst` & `networkx-3.3rc0/doc/release/release_2.6.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.7.1.rst` & `networkx-3.3rc0/doc/release/release_2.7.1.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.7.rst` & `networkx-3.3rc0/doc/release/release_2.7.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.1.rst` & `networkx-3.3rc0/doc/release/release_2.8.1.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.2.rst` & `networkx-3.3rc0/doc/release/release_2.8.2.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.3.rst` & `networkx-3.3rc0/doc/release/release_2.8.3.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.4.rst` & `networkx-3.3rc0/doc/release/release_2.8.4.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.5.rst` & `networkx-3.3rc0/doc/release/release_2.8.5.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.6.rst` & `networkx-3.3rc0/doc/release/release_2.8.6.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.7.rst` & `networkx-3.3rc0/doc/release/release_2.8.7.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.8.rst` & `networkx-3.3rc0/doc/release/release_2.8.8.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_2.8.rst` & `networkx-3.3rc0/doc/release/release_2.8.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_3.0.rst` & `networkx-3.3rc0/doc/release/release_3.0.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_3.1.rst` & `networkx-3.3rc0/doc/release/release_3.1.rst`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/release/release_dev.rst` & `networkx-3.3rc0/doc/release/release_3.2.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,21 @@
-NetworkX 3.2rc0
-===============
+NetworkX 3.2
+============
 
-We're happy to announce the release of networkx 3.2rc0!
+Release date: 18 October 2023
+
+Supports Python 3.9, 3.10, 3.11, and 3.12.
+
+NetworkX is a Python package for the creation, manipulation, and study of the
+structure, dynamics, and functions of complex networks.
+
+For more information, please visit our `website <https://networkx.org/>`_
+and our :ref:`gallery of examples <examples_gallery>`.
+Please send comments and questions to the `networkx-discuss mailing list
+<http://groups.google.com/group/networkx-discuss>`_.
 
 Highlights
 ----------
 
 - Add ``@nx._dispatch`` decorator to most algorithms (`#6688 <https://github.com/networkx/networkx/pull/6688>`_).
 
 API Changes
@@ -22,14 +32,15 @@
 - Rm deprecated ``create_using`` kwarg from scale_free_graph (`#6940 <https://github.com/networkx/networkx/pull/6940>`_).
 - Make position part of the API for geometric_edges (`#6816 <https://github.com/networkx/networkx/pull/6816>`_).
 - Undeprecate literal_(de)stringizer (`#6943 <https://github.com/networkx/networkx/pull/6943>`_).
 - Make new dtype param for incidence_matrix kwarg-only (`#6954 <https://github.com/networkx/networkx/pull/6954>`_).
 - Make weight and seed for ``fast_label_propagation_communities`` kwarg only (`#6955 <https://github.com/networkx/networkx/pull/6955>`_).
 - API: Rm default value from time_delta for cd_index (`#6953 <https://github.com/networkx/networkx/pull/6953>`_).
 - Deprecate strongly_connected_components_recursive (`#6957 <https://github.com/networkx/networkx/pull/6957>`_).
+- Rm deprecated clique helper functions (`#6941 <https://github.com/networkx/networkx/pull/6941>`_).
 
 Enhancements
 ------------
 
 - Update calculation of triangles (`#6258 <https://github.com/networkx/networkx/pull/6258>`_).
 - Add single_source_all_shortest_paths and all_pairs_all_shortest_paths (`#5959 <https://github.com/networkx/networkx/pull/5959>`_).
 - Add ``@nx._dispatch`` decorator to most algorithms (`#6688 <https://github.com/networkx/networkx/pull/6688>`_).
@@ -38,14 +49,15 @@
 - Fast label propagation algorithm for community detection (`#6843 <https://github.com/networkx/networkx/pull/6843>`_).
 - Add time series Visibility Graph generator (`#6880 <https://github.com/networkx/networkx/pull/6880>`_).
 - Random trees & forests (`#6758 <https://github.com/networkx/networkx/pull/6758>`_).
 - Add support for tuple-nodes to default gml parser (`#6950 <https://github.com/networkx/networkx/pull/6950>`_).
 - Add Kemeny's constant (`#6929 <https://github.com/networkx/networkx/pull/6929>`_).
 - Speedup resistance_distance (`#6925 <https://github.com/networkx/networkx/pull/6925>`_).
 - Allow graph generators and conversion functions to be dispatched (`#6876 <https://github.com/networkx/networkx/pull/6876>`_).
+- adding extendability problem (2nd try) (`#4890 <https://github.com/networkx/networkx/pull/4890>`_).
 
 Bug Fixes
 ---------
 
 - Fixing DOT format for to_agraph() (`#6474 <https://github.com/networkx/networkx/pull/6474>`_).
 - Remove ``topo_order`` kwarg from ``is_semiconnected`` without deprecation (`#6651 <https://github.com/networkx/networkx/pull/6651>`_).
 - Stabilize test of approximation.connected_components (`#6715 <https://github.com/networkx/networkx/pull/6715>`_).
@@ -57,14 +69,15 @@
 - Add test about zero weight cycles and fix goldberg-radzik (`#6892 <https://github.com/networkx/networkx/pull/6892>`_).
 - Modify ``s_metric`` ``normalized`` default so function doesn't raise (`#6841 <https://github.com/networkx/networkx/pull/6841>`_).
 - Error handling for invalid prufer sequence ``from_prufer_sequence``: issue #6420 (`#6457 <https://github.com/networkx/networkx/pull/6457>`_).
 - FIX: Better default behaviour for percolation centrality with no node attrs (`#6894 <https://github.com/networkx/networkx/pull/6894>`_).
 - FIX: MultiDiGraphs keys got lost in weighted shortest paths (`#6963 <https://github.com/networkx/networkx/pull/6963>`_).
 - Handle edge cases in Laplacian centrality (`#6938 <https://github.com/networkx/networkx/pull/6938>`_).
 - adding a formula that ignores self-loops at the each level of directed louvain algorithm (`#6630 <https://github.com/networkx/networkx/pull/6630>`_).
+- Fix ``````is_k_edge_connected`````` for case of k=2 (`#7024 <https://github.com/networkx/networkx/pull/7024>`_).
 
 Documentation
 -------------
 
 - Fix links in laplacian_centrality and laplacian_matrix (`#6623 <https://github.com/networkx/networkx/pull/6623>`_).
 - Add Greedy Coloring Example to Gallery (`#6647 <https://github.com/networkx/networkx/pull/6647>`_).
 - Add linting to contributor guide (`#6692 <https://github.com/networkx/networkx/pull/6692>`_).
@@ -91,14 +104,17 @@
 - Update developer deprecation todo list (`#6985 <https://github.com/networkx/networkx/pull/6985>`_).
 - Add "networkx.plugin_info" entry point and update docstring (`#6911 <https://github.com/networkx/networkx/pull/6911>`_).
 - document graph type; add links; rm unused import (`#6992 <https://github.com/networkx/networkx/pull/6992>`_).
 - Add GraphBLAS backend to online docs (`#6998 <https://github.com/networkx/networkx/pull/6998>`_).
 - Add 3.2rc0 release notes (`#6997 <https://github.com/networkx/networkx/pull/6997>`_).
 - Update release process for changelist (`#7005 <https://github.com/networkx/networkx/pull/7005>`_).
 - Update contributing guide for changelist workflow (`#7004 <https://github.com/networkx/networkx/pull/7004>`_).
+- Fix definition of $m$ parameter in docstring of ``modularity`` function (`#6990 <https://github.com/networkx/networkx/pull/6990>`_).
+- updated docs of SA_tsp and TA_tsp (`#7013 <https://github.com/networkx/networkx/pull/7013>`_).
+- Update katz_centrality missing default alpha value (`#7015 <https://github.com/networkx/networkx/pull/7015>`_).
 
 Maintenance
 -----------
 
 - Replacing codecov Python CLI with gh action (`#6635 <https://github.com/networkx/networkx/pull/6635>`_).
 - Bump pyupgrade minimum Python version to 3.9 (`#6634 <https://github.com/networkx/networkx/pull/6634>`_).
 - MAINT: minor coverage cleanup (`#6674 <https://github.com/networkx/networkx/pull/6674>`_).
@@ -149,14 +165,16 @@
 - Enhancements change default join trees 6947 (`#6948 <https://github.com/networkx/networkx/pull/6948>`_).
 - Update sphinx theme (`#6930 <https://github.com/networkx/networkx/pull/6930>`_).
 - Generate requirements files from pyproject.toml (`#6987 <https://github.com/networkx/networkx/pull/6987>`_).
 - Use trusted publisher (`#6988 <https://github.com/networkx/networkx/pull/6988>`_).
 - Prefer "backend" instead of "plugin" (`#6989 <https://github.com/networkx/networkx/pull/6989>`_).
 - CI: Pin scientific-python/upload-nightly-action to 0.2.0 (`#6993 <https://github.com/networkx/networkx/pull/6993>`_).
 - Support Python 3.12 (`#7009 <https://github.com/networkx/networkx/pull/7009>`_).
+- pip install nx-cugraph from git, not nightly wheels, for docs (`#7011 <https://github.com/networkx/networkx/pull/7011>`_).
+- Fix typos (`#7012 <https://github.com/networkx/networkx/pull/7012>`_).
 
 Other
 -----
 
 - Update release process (`#6622 <https://github.com/networkx/networkx/pull/6622>`_).
 - Add Lowest Common Ancestor example to Gallery (`#6542 <https://github.com/networkx/networkx/pull/6542>`_).
 - Add examples to bipartite centrality.py (`#6613 <https://github.com/networkx/networkx/pull/6613>`_).
@@ -228,32 +246,36 @@
 - Patch view signature (`#6267 <https://github.com/networkx/networkx/pull/6267>`_).
 - Doc add nongraphical examples 6944 (`#6946 <https://github.com/networkx/networkx/pull/6946>`_).
 - feat: docstring examples for algorithms/operators/all.py (`#6974 <https://github.com/networkx/networkx/pull/6974>`_).
 
 Contributors
 ------------
 
-64 authors added to this release (alphabetically):
+70 authors added to this release (alphabetically):
 
 - =510 (`@diohabara <https://github.com/diohabara>`_)
+- `@achluma <https://github.com/achluma>`_
 - `@anthonimes <https://github.com/anthonimes>`_
 - `@axtavt <https://github.com/axtavt>`_
 - `@cnfionawu <https://github.com/cnfionawu>`_
 - `@dependabot[bot] <https://github.com/apps/dependabot>`_
 - `@DiamondJoseph <https://github.com/DiamondJoseph>`_
+- `@gsemer <https://github.com/gsemer>`_
 - `@IbrH <https://github.com/IbrH>`_
 - `@peijenburg <https://github.com/peijenburg>`_
 - `@Tortar <https://github.com/Tortar>`_
 - Adam Li (`@adam2392 <https://github.com/adam2392>`_)
 - Adam Richardson (`@AdamWRichardson <https://github.com/AdamWRichardson>`_)
+- Aditi Juneja (`@Schefflera-Arboricola <https://github.com/Schefflera-Arboricola>`_)
 - AKSHAYA MADHURI (`@akshayamadhuri <https://github.com/akshayamadhuri>`_)
 - Alex Markham (`@Alex-Markham <https://github.com/Alex-Markham>`_)
 - Alimi Qudirah (`@Qudirah <https://github.com/Qudirah>`_)
 - Andreas Wilm (`@andreas-wilm <https://github.com/andreas-wilm>`_)
 - Anthony Labarre (`@alabarre <https://github.com/alabarre>`_)
+- Arturo (`@ArturoSbr <https://github.com/ArturoSbr>`_)
 - Dan Schult (`@dschult <https://github.com/dschult>`_)
 - Davide Bonin (`@davidbonin92 <https://github.com/davidbonin92>`_)
 - Davide D'Ascenzo (`@Kidara <https://github.com/Kidara>`_)
 - Dhaval Kumar (`@still-n0thing <https://github.com/still-n0thing>`_)
 - Dheeraj Ravindranath (`@dheerajrav <https://github.com/dheerajrav>`_)
 - Dilara Tekinoglu (`@dtekinoglu <https://github.com/dtekinoglu>`_)
 - Efrem Braun (`@EfremBraun <https://github.com/EfremBraun>`_)
@@ -269,14 +291,16 @@
 - Jeremy Foote (`@jdfoote <https://github.com/jdfoote>`_)
 - Jim Kitchen (`@jim22k <https://github.com/jim22k>`_)
 - Jon Crall (`@Erotemic <https://github.com/Erotemic>`_)
 - Jordan Matelsky (`@j6k4m8 <https://github.com/j6k4m8>`_)
 - Josh Soref (`@jsoref <https://github.com/jsoref>`_)
 - Juanita Gomez (`@juanis2112 <https://github.com/juanis2112>`_)
 - Kelly Boothby (`@boothby <https://github.com/boothby>`_)
+- Kian-Meng Ang (`@kianmeng <https://github.com/kianmeng>`_)
+- Koen van Walstijn (`@kbvw <https://github.com/kbvw>`_)
 - Lovro Šubelj (`@lovre <https://github.com/lovre>`_)
 - Lukong Anne (`@Lukong123 <https://github.com/Lukong123>`_)
 - Matt Schwennesen (`@mjschwenne <https://github.com/mjschwenne>`_)
 - Matthew Feickert (`@matthewfeickert <https://github.com/matthewfeickert>`_)
 - Matthias Bussonnier (`@Carreau <https://github.com/Carreau>`_)
 - Mohamed Rezk (`@mohamedrezk122 <https://github.com/mohamedrezk122>`_)
 - Mridul Seth (`@MridulS <https://github.com/MridulS>`_)
@@ -295,16 +319,17 @@
 - Stefan van der Walt (`@stefanv <https://github.com/stefanv>`_)
 - Sultan Orazbayev (`@SultanOrazbayev <https://github.com/SultanOrazbayev>`_)
 - Vanshika Mishra (`@vanshika230 <https://github.com/vanshika230>`_)
 - William Zijie Zhang (`@Transurgeon <https://github.com/Transurgeon>`_)
 - Yaroslav Halchenko (`@yarikoptic <https://github.com/yarikoptic>`_)
 - Zhaoyuan Deng (`@dzy49 <https://github.com/dzy49>`_)
 
-40 reviewers added to this release (alphabetically):
+41 reviewers added to this release (alphabetically):
 
+- `@gsemer <https://github.com/gsemer>`_
 - `@IbrH <https://github.com/IbrH>`_
 - `@peijenburg <https://github.com/peijenburg>`_
 - `@Tortar <https://github.com/Tortar>`_
 - Aaron Z. (`@aaronzo <https://github.com/aaronzo>`_)
 - Adam Li (`@adam2392 <https://github.com/adam2392>`_)
 - Adam Richardson (`@AdamWRichardson <https://github.com/AdamWRichardson>`_)
 - Alimi Qudirah (`@Qudirah <https://github.com/Qudirah>`_)
@@ -340,7 +365,8 @@
 - Sebastiano Vigna (`@vigna <https://github.com/vigna>`_)
 - Sultan Orazbayev (`@SultanOrazbayev <https://github.com/SultanOrazbayev>`_)
 - Vanshika Mishra (`@vanshika230 <https://github.com/vanshika230>`_)
 - Yaroslav Halchenko (`@yarikoptic <https://github.com/yarikoptic>`_)
 
 _These lists are automatically generated, and may not be complete or may contain
 duplicates._
+
```

### Comparing `networkx-3.2rc0/doc/release/report_functions_without_rst_generated.py` & `networkx-3.3rc0/doc/release/report_functions_without_rst_generated.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/doc/tutorial.rst` & `networkx-3.3rc0/networkx/algorithms/cluster.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,635 +1,609 @@
-Tutorial
-========
+"""Algorithms to characterize the number of triangles in a graph."""
 
-.. currentmodule:: networkx
+from collections import Counter
+from itertools import chain, combinations
 
-This guide can help you start working with NetworkX.
+import networkx as nx
+from networkx.utils import not_implemented_for
 
-Creating a graph
-----------------
-
-Create an empty graph with no nodes and no edges.
-
-.. nbplot::
-
-    >>> import networkx as nx
-    >>> G = nx.Graph()
-
-By definition, a :class:`Graph` is a collection of nodes (vertices) along with
-identified pairs of nodes (called edges, links, etc).  In NetworkX, nodes can
-be any :py:term:`hashable` object e.g., a text string, an image, an XML object,
-another Graph, a customized node object, etc.
-
-.. note:: Python's ``None`` object is not allowed to be used as a node. It
-    determines whether optional function arguments have been assigned in many
-    functions.
-
-Nodes
------
-
-The graph ``G`` can be grown in several ways.  NetworkX includes many
-:doc:`graph generator functions <reference/generators>` and
-:doc:`facilities to read and write graphs in many formats <reference/readwrite/index>`.
-To get started though we'll look at simple manipulations.  You can add one node
-at a time,
-
-.. nbplot::
-
-    >>> G.add_node(1)
-
-or add nodes from any :py:term:`iterable` container, such as a list
-
-.. nbplot::
-
-    >>> G.add_nodes_from([2, 3])
-
-You can also add nodes along with node
-attributes if your container yields 2-tuples of the form 
-``(node, node_attribute_dict)``::
-
-    >>> G.add_nodes_from([
-    ...     (4, {"color": "red"}),
-    ...     (5, {"color": "green"}),
-    ... ])
-
-Node attributes are discussed further :ref:`below <attributes>`.
-
-Nodes from one graph can be incorporated into another:
-
-.. nbplot::
-
-    >>> H = nx.path_graph(10)
-    >>> G.add_nodes_from(H)
-
-``G`` now contains the nodes of ``H`` as nodes of ``G``.
-In contrast, you could use the graph ``H`` as a node in ``G``.
-
-.. nbplot::
-
-    >>> G.add_node(H)
-
-The graph ``G`` now contains ``H`` as a node.  This flexibility is very powerful as
-it allows graphs of graphs, graphs of files, graphs of functions and much more.
-It is worth thinking about how to structure your application so that the nodes
-are useful entities.  Of course you can always use a unique identifier in ``G``
-and have a separate dictionary keyed by identifier to the node information if
-you prefer.
-
-.. note:: You should not change the node object if the hash depends
-   on its contents.
-
-Edges
------
-
-``G`` can also be grown by adding one edge at a time,
-
-.. nbplot::
-
-    >>> G.add_edge(1, 2)
-    >>> e = (2, 3)
-    >>> G.add_edge(*e)  # unpack edge tuple*
-
-by adding a list of edges,
-
-.. nbplot::
-
-    >>> G.add_edges_from([(1, 2), (1, 3)])
-
-or by adding any :term:`ebunch` of edges.  An *ebunch* is any iterable
-container of edge-tuples.  An edge-tuple can be a 2-tuple of nodes or a 3-tuple
-with 2 nodes followed by an edge attribute dictionary, e.g.,
-``(2, 3, {'weight': 3.1415})``.  Edge attributes are discussed further
-:ref:`below <attributes>`.
-
-.. nbplot::
-
-    >>> G.add_edges_from(H.edges)
-
-There are no complaints when adding existing nodes or edges. For example,
-after removing all nodes and edges,
-
-.. nbplot::
-
-    >>> G.clear()
-
-we add new nodes/edges and NetworkX quietly ignores any that are
-already present.
-
-.. nbplot::
-
-    >>> G.add_edges_from([(1, 2), (1, 3)])
-    >>> G.add_node(1)
-    >>> G.add_edge(1, 2)
-    >>> G.add_node("spam")        # adds node "spam"
-    >>> G.add_nodes_from("spam")  # adds 4 nodes: 's', 'p', 'a', 'm'
-    >>> G.add_edge(3, 'm')
-
-At this stage the graph ``G`` consists of 8 nodes and 3 edges, as can be seen by:
-
-.. nbplot::
-
-    >>> G.number_of_nodes()
-    8
-    >>> G.number_of_edges()
-    3
-
-.. note:: 
-   
-   The order of adjacency reporting (e.g., :meth:`G.adj <networkx.Graph.adj>`,
-   :meth:`G.successors <networkx.DiGraph.successors>`,
-   :meth:`G.predecessors <networkx.DiGraph.predecessors>`) is the order of
-   edge addition. However, the order of G.edges is the order of the adjacencies
-   which includes both the order of the nodes and each 
-   node's adjacencies. See example below:
-
-.. nbplot::
-
-    >>> DG = nx.DiGraph()
-    >>> DG.add_edge(2, 1)   # adds the nodes in order 2, 1
-    >>> DG.add_edge(1, 3)
-    >>> DG.add_edge(2, 4)
-    >>> DG.add_edge(1, 2)
-    >>> assert list(DG.successors(2)) == [1, 4]
-    >>> assert list(DG.edges) == [(2, 1), (2, 4), (1, 3), (1, 2)]
-
-Examining elements of a graph
------------------------------
-
-We can examine the nodes and edges. Four basic graph properties facilitate
-reporting: ``G.nodes``, ``G.edges``, ``G.adj`` and ``G.degree``.  These
-are set-like views of the nodes, edges, neighbors (adjacencies), and degrees
-of nodes in a graph. They offer a continually updated read-only view into
-the graph structure. They are also dict-like in that you can look up node
-and edge data attributes via the views and iterate with data attributes
-using methods ``.items()``, ``.data()``.
-If you want a specific container type instead of a view, you can specify one.
-Here we use lists, though sets, dicts, tuples and other containers may be
-better in other contexts.
-
-.. nbplot::
-
-    >>> list(G.nodes)
-    [1, 2, 3, 'spam', 's', 'p', 'a', 'm']
-    >>> list(G.edges)
-    [(1, 2), (1, 3), (3, 'm')]
-    >>> list(G.adj[1])  # or list(G.neighbors(1))
-    [2, 3]
-    >>> G.degree[1]  # the number of edges incident to 1
-    2
-
-One can specify to report the edges and degree from a subset of all nodes
-using an :term:`nbunch`. An *nbunch* is any of: ``None`` (meaning all nodes),
-a node, or an iterable container of nodes that is not itself a node in the
-graph.
-
-.. nbplot::
-
-    >>> G.edges([2, 'm'])
-    EdgeDataView([(2, 1), ('m', 3)])
-    >>> G.degree([2, 3])
-    DegreeView({2: 1, 3: 2})
-
-Removing elements from a graph
-------------------------------
-
-One can remove nodes and edges from the graph in a similar fashion to adding.
-Use methods
-:meth:`Graph.remove_node`,
-:meth:`Graph.remove_nodes_from`,
-:meth:`Graph.remove_edge`
-and
-:meth:`Graph.remove_edges_from`, e.g.
-
-.. nbplot::
-
-    >>> G.remove_node(2)
-    >>> G.remove_nodes_from("spam")
-    >>> list(G.nodes)
-    [1, 3, 'spam']
-    >>> G.remove_edge(1, 3)
-
-Using the graph constructors
-----------------------------
-
-Graph objects do not have to be built up incrementally - data specifying
-graph structure can be passed directly to the constructors of the various
-graph classes.
-When creating a graph structure by instantiating one of the graph
-classes you can specify data in several formats.
-
-.. nbplot::
-
-    >>> G.add_edge(1, 2)
-    >>> H = nx.DiGraph(G)  # create a DiGraph using the connections from G
-    >>> list(H.edges())
-    [(1, 2), (2, 1)]
-    >>> edgelist = [(0, 1), (1, 2), (2, 3)]
-    >>> H = nx.Graph(edgelist)  # create a graph from an edge list
-    >>> list(H.edges())
-    [(0, 1), (1, 2), (2, 3)]
-    >>> adjacency_dict = {0: (1, 2), 1: (0, 2), 2: (0, 1)}
-    >>> H = nx.Graph(adjacency_dict)  # create a Graph dict mapping nodes to nbrs
-    >>> list(H.edges())
-    [(0, 1), (0, 2), (1, 2)]
-
-What to use as nodes and edges
-------------------------------
-
-You might notice that nodes and edges are not specified as NetworkX
-objects.  This leaves you free to use meaningful items as nodes and
-edges. The most common choices are numbers or strings, but a node can
-be any hashable object (except ``None``), and an edge can be associated
-with any object ``x`` using ``G.add_edge(n1, n2, object=x)``.
-
-As an example, ``n1`` and ``n2`` could be protein objects from the RCSB Protein
-Data Bank, and ``x`` could refer to an XML record of publications detailing
-experimental observations of their interaction.
-
-We have found this power quite useful, but its abuse
-can lead to surprising behavior unless one is familiar with Python.
-If in doubt, consider using :func:`~relabel.convert_node_labels_to_integers` to obtain
-a more traditional graph with integer labels.
-
-Accessing edges and neighbors
------------------------------
-
-In addition to the views :attr:`Graph.edges`, and :attr:`Graph.adj`,
-access to edges and neighbors is possible using subscript notation.
-
-.. nbplot::
-
-    >>> G = nx.Graph([(1, 2, {"color": "yellow"})])
-    >>> G[1]  # same as G.adj[1]
-    AtlasView({2: {'color': 'yellow'}})
-    >>> G[1][2]
-    {'color': 'yellow'}
-    >>> G.edges[1, 2]
-    {'color': 'yellow'}
-
-You can get/set the attributes of an edge using subscript notation
-if the edge already exists.
-
-.. nbplot::
-
-    >>> G.add_edge(1, 3)
-    >>> G[1][3]['color'] = "blue"
-    >>> G.edges[1, 2]['color'] = "red"
-    >>> G.edges[1, 2]
-    {'color': 'red'}
-
-Fast examination of all (node, adjacency) pairs is achieved using
-``G.adjacency()``, or ``G.adj.items()``.
-Note that for undirected graphs, adjacency iteration sees each edge twice.
-
-.. nbplot::
-
-    >>> FG = nx.Graph()
-    >>> FG.add_weighted_edges_from([(1, 2, 0.125), (1, 3, 0.75), (2, 4, 1.2), (3, 4, 0.375)])
-    >>> for n, nbrs in FG.adj.items():
-    ...    for nbr, eattr in nbrs.items():
-    ...        wt = eattr['weight']
-    ...        if wt < 0.5: print(f"({n}, {nbr}, {wt:.3})")
-    (1, 2, 0.125)
-    (2, 1, 0.125)
-    (3, 4, 0.375)
-    (4, 3, 0.375)
-
-Convenient access to all edges is achieved with the edges property.
-
-.. nbplot::
-
-    >>> for (u, v, wt) in FG.edges.data('weight'):
-    ...     if wt < 0.5:
-    ...         print(f"({u}, {v}, {wt:.3})")
-    (1, 2, 0.125)
-    (3, 4, 0.375)
-
-.. _attributes:
-
-Adding attributes to graphs, nodes, and edges
----------------------------------------------
-
-Attributes such as weights, labels, colors, or whatever Python object you like,
-can be attached to graphs, nodes, or edges.
-
-Each graph, node, and edge can hold key/value attribute pairs in an associated
-attribute dictionary (the keys must be hashable).  By default these are empty,
-but attributes can be added or changed using ``add_edge``, ``add_node`` or direct
-manipulation of the attribute dictionaries named ``G.graph``, ``G.nodes``, and
-``G.edges`` for a graph ``G``.
-
-Graph attributes
-~~~~~~~~~~~~~~~~
-
-Assign graph attributes when creating a new graph
-
-.. nbplot::
-
-    >>> G = nx.Graph(day="Friday")
-    >>> G.graph
-    {'day': 'Friday'}
-
-Or you can modify attributes later
-
-.. nbplot::
-
-    >>> G.graph['day'] = "Monday"
-    >>> G.graph
-    {'day': 'Monday'}
-
-Node attributes
-~~~~~~~~~~~~~~~
-
-Add node attributes using ``add_node()``, ``add_nodes_from()``, or ``G.nodes``
-
-.. nbplot::
-
-    >>> G.add_node(1, time='5pm')
-    >>> G.add_nodes_from([3], time='2pm')
-    >>> G.nodes[1]
-    {'time': '5pm'}
-    >>> G.nodes[1]['room'] = 714
-    >>> G.nodes.data()
-    NodeDataView({1: {'time': '5pm', 'room': 714}, 3: {'time': '2pm'}})
-
-Note that adding a node to ``G.nodes`` does not add it to the graph, use
-``G.add_node()`` to add new nodes. Similarly for edges.
-
-Edge Attributes
-~~~~~~~~~~~~~~~
-
-Add/change edge attributes using ``add_edge()``, ``add_edges_from()``,
-or subscript notation.
-
-.. nbplot::
-
-    >>> G.add_edge(1, 2, weight=4.7 )
-    >>> G.add_edges_from([(3, 4), (4, 5)], color='red')
-    >>> G.add_edges_from([(1, 2, {'color': 'blue'}), (2, 3, {'weight': 8})])
-    >>> G[1][2]['weight'] = 4.7
-    >>> G.edges[3, 4]['weight'] = 4.2
-
-The special attribute ``weight`` should be numeric as it is used by
-algorithms requiring weighted edges.
-
-Directed graphs
----------------
-
-The :class:`DiGraph` class provides additional methods and properties specific
-to directed edges, e.g.,
-:attr:`DiGraph.out_edges`, :attr:`DiGraph.in_degree`,
-`DiGraph.predecessors`, `DiGraph.successors` etc.
-To allow algorithms to work with both classes easily, the directed versions of
-:meth:`neighbors <DiGraph.neighbors>` is equivalent to
-`successors <DiGraph.successors>` while `~DiGraph.degree` reports the sum
-of `~DiGraph.in_degree` and `~DiGraph.out_degree` even though that may feel inconsistent at times.
-
-.. nbplot::
-
-    >>> DG = nx.DiGraph()
-    >>> DG.add_weighted_edges_from([(1, 2, 0.5), (3, 1, 0.75)])
-    >>> DG.out_degree(1, weight='weight')
-    0.5
-    >>> DG.degree(1, weight='weight')
-    1.25
-    >>> list(DG.successors(1))
-    [2]
-    >>> list(DG.neighbors(1))
-    [2]
-
-Some algorithms work only for directed graphs and others are not well
-defined for directed graphs.  Indeed the tendency to lump directed
-and undirected graphs together is dangerous.  If you want to treat
-a directed graph as undirected for some measurement you should probably
-convert it using :meth:`Graph.to_undirected` or with
-
-.. nbplot::
-
-    >>> H = nx.Graph(G)  # create an undirected graph H from a directed graph G
-
-Multigraphs
------------
-
-NetworkX provides classes for graphs which allow multiple edges
-between any pair of nodes.  The :class:`MultiGraph` and
-:class:`MultiDiGraph`
-classes allow you to add the same edge twice, possibly with different
-edge data.  This can be powerful for some applications, but many
-algorithms are not well defined on such graphs.
-Where results are well defined,
-e.g., :meth:`MultiGraph.degree` we provide the function.  Otherwise you
-should convert to a standard graph in a way that makes the measurement
-well defined.
-
-.. nbplot::
-
-    >>> MG = nx.MultiGraph()
-    >>> MG.add_weighted_edges_from([(1, 2, 0.5), (1, 2, 0.75), (2, 3, 0.5)])
-    >>> dict(MG.degree(weight='weight'))
-    {1: 1.25, 2: 1.75, 3: 0.5}
-    >>> GG = nx.Graph()
-    >>> for n, nbrs in MG.adjacency():
-    ...    for nbr, edict in nbrs.items():
-    ...        minvalue = min([d['weight'] for d in edict.values()])
-    ...        GG.add_edge(n, nbr, weight = minvalue)
-    ...
-    >>> nx.shortest_path(GG, 1, 3)
-    [1, 2, 3]
-
-Graph generators and graph operations
--------------------------------------
-
-In addition to constructing graphs node-by-node or edge-by-edge, they
-can also be generated by
-
-1. Applying classic graph operations, such as:
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-
-    ~networkx.classes.function.subgraph
-    ~networkx.algorithms.operators.binary.union
-    ~networkx.algorithms.operators.binary.disjoint_union
-    ~networkx.algorithms.operators.product.cartesian_product
-    ~networkx.algorithms.operators.binary.compose
-    ~networkx.algorithms.operators.unary.complement
-    ~networkx.classes.function.create_empty_copy
-    ~networkx.classes.function.to_undirected
-    ~networkx.classes.function.to_directed
-
-2. Using a call to one of the classic small graphs, e.g.,
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-
-    ~networkx.generators.small.petersen_graph
-    ~networkx.generators.small.tutte_graph
-    ~networkx.generators.small.sedgewick_maze_graph
-    ~networkx.generators.small.tetrahedral_graph
-
-3. Using a (constructive) generator for a classic graph, e.g.,
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-
-    ~networkx.generators.classic.complete_graph
-    ~networkx.algorithms.bipartite.generators.complete_bipartite_graph
-    ~networkx.generators.classic.barbell_graph
-    ~networkx.generators.classic.lollipop_graph
-
-like so:
-
-.. nbplot::
-
-    >>> K_5 = nx.complete_graph(5)
-    >>> K_3_5 = nx.complete_bipartite_graph(3, 5)
-    >>> barbell = nx.barbell_graph(10, 10)
-    >>> lollipop = nx.lollipop_graph(10, 20)
-
-4. Using a stochastic graph generator, e.g,
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-
-    ~networkx.generators.random_graphs.erdos_renyi_graph
-    ~networkx.generators.random_graphs.watts_strogatz_graph
-    ~networkx.generators.random_graphs.barabasi_albert_graph
-    ~networkx.generators.random_graphs.random_lobster
-
-like so:
-
-.. nbplot::
-
-    >>> er = nx.erdos_renyi_graph(100, 0.15)
-    >>> ws = nx.watts_strogatz_graph(30, 3, 0.1)
-    >>> ba = nx.barabasi_albert_graph(100, 5)
-    >>> red = nx.random_lobster(100, 0.9, 0.9)
-
-5. Reading a graph stored in a file using common graph formats
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-NetworkX supports many popular formats, such as edge lists, adjacency lists,
-GML, GraphML, LEDA and others.
-
-.. nbplot::
-
-    >>> nx.write_gml(red, "path.to.file")
-    >>> mygraph = nx.read_gml("path.to.file")
-
-For details on graph formats see :doc:`/reference/readwrite/index`
-and for graph generator functions see :doc:`/reference/generators`
-
-Analyzing graphs
-----------------
-
-The structure of ``G`` can be analyzed using various graph-theoretic
-functions such as:
-
-.. nbplot::
-
-    >>> G = nx.Graph()
-    >>> G.add_edges_from([(1, 2), (1, 3)])
-    >>> G.add_node("spam")       # adds node "spam"
-    >>> list(nx.connected_components(G))
-    [{1, 2, 3}, {'spam'}]
-    >>> sorted(d for n, d in G.degree())
-    [0, 1, 1, 2]
-    >>> nx.clustering(G)
-    {1: 0, 2: 0, 3: 0, 'spam': 0}
-
-Some functions with large output iterate over (node, value) 2-tuples.
-These are easily stored in a `dict` structure if you desire.
-
-.. nbplot::
-
-    >>> sp = dict(nx.all_pairs_shortest_path(G))
-    >>> sp[3]
-    {3: [3], 1: [3, 1], 2: [3, 1, 2]}
-
-See :doc:`/reference/algorithms/index` for details on graph algorithms
-supported.
-
-Drawing graphs
---------------
-
-NetworkX is not primarily a graph drawing package but basic drawing with
-Matplotlib as well as an interface to use the open source Graphviz software
-package are included.  These are part of the :doc:`networkx.drawing <reference/drawing>`
-module and will be imported if possible.
-
-First import Matplotlib's plot interface (pylab works too)
-
-.. nbplot::
-
-    >>> import matplotlib.pyplot as plt
-
-To test if the import of `~networkx.drawing.nx_pylab` was successful draw ``G``
-using one of
-
-.. nbplot::
-
-    >>> G = nx.petersen_graph()
-    >>> subax1 = plt.subplot(121)
-    >>> nx.draw(G, with_labels=True, font_weight='bold')
-    >>> subax2 = plt.subplot(122)
-    >>> nx.draw_shell(G, nlist=[range(5, 10), range(5)], with_labels=True, font_weight='bold')
-
-when drawing to an interactive display.  Note that you may need to issue a
-Matplotlib
-
->>> plt.show()  # doctest: +SKIP
-
-command if you are not using matplotlib in interactive mode.
-
-.. nbplot::
-
-    >>> options = {
-    ...     'node_color': 'black',
-    ...     'node_size': 100,
-    ...     'width': 3,
-    ... }
-    >>> subax1 = plt.subplot(221)
-    >>> nx.draw_random(G, **options)
-    >>> subax2 = plt.subplot(222)
-    >>> nx.draw_circular(G, **options)
-    >>> subax3 = plt.subplot(223)
-    >>> nx.draw_spectral(G, **options)
-    >>> subax4 = plt.subplot(224)
-    >>> nx.draw_shell(G, nlist=[range(5,10), range(5)], **options)
-
-You can find additional options via :func:`~drawing.nx_pylab.draw_networkx` and
-layouts via the :mod:`layout module<networkx.drawing.layout>`.
-You can use multiple shells with :func:`~drawing.nx_pylab.draw_shell`.
-
-.. nbplot::
-
-    >>> G = nx.dodecahedral_graph()
-    >>> shells = [[2, 3, 4, 5, 6], [8, 1, 0, 19, 18, 17, 16, 15, 14, 7], [9, 10, 11, 12, 13]]
-    >>> nx.draw_shell(G, nlist=shells, **options)
-
-To save drawings to a file, use, for example
-
->>> nx.draw(G)
->>> plt.savefig("path.png")
-
-This function writes to the file ``path.png`` in the local directory. If Graphviz and
-PyGraphviz or pydot, are available on your system, you can also use
-`networkx.drawing.nx_agraph.graphviz_layout` or
-`networkx.drawing.nx_pydot.graphviz_layout` to get the node positions, or write
-the graph in dot format for further processing.
-
->>> from networkx.drawing.nx_pydot import write_dot
->>> pos = nx.nx_agraph.graphviz_layout(G)
->>> nx.draw(G, pos=pos)
->>> write_dot(G, 'file.dot')
-
-See :doc:`/reference/drawing` for additional details.
-
-.. code-links::
-
-NX-Guides
----------
-If you are interested in learning more about NetworkX, graph theory and network analysis 
-then you should check out :doc:`nx-guides <nx-guides:index>`. There you can find tutorials,
-real-world applications and in-depth examinations of graphs and network algorithms. 
-All the material is official and was developed and curated by the NetworkX community. 
+__all__ = [
+    "triangles",
+    "average_clustering",
+    "clustering",
+    "transitivity",
+    "square_clustering",
+    "generalized_degree",
+]
+
+
+@not_implemented_for("directed")
+@nx._dispatchable
+def triangles(G, nodes=None):
+    """Compute the number of triangles.
+
+    Finds the number of triangles that include a node as one vertex.
+
+    Parameters
+    ----------
+    G : graph
+       A networkx graph
+
+    nodes : node, iterable of nodes, or None (default=None)
+        If a singleton node, return the number of triangles for that node.
+        If an iterable, compute the number of triangles for each of those nodes.
+        If `None` (the default) compute the number of triangles for all nodes in `G`.
+
+    Returns
+    -------
+    out : dict or int
+       If `nodes` is a container of nodes, returns number of triangles keyed by node (dict).
+       If `nodes` is a specific node, returns number of triangles for the node (int).
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.triangles(G, 0))
+    6
+    >>> print(nx.triangles(G))
+    {0: 6, 1: 6, 2: 6, 3: 6, 4: 6}
+    >>> print(list(nx.triangles(G, [0, 1]).values()))
+    [6, 6]
+
+    Notes
+    -----
+    Self loops are ignored.
+
+    """
+    if nodes is not None:
+        # If `nodes` represents a single node, return only its number of triangles
+        if nodes in G:
+            return next(_triangles_and_degree_iter(G, nodes))[2] // 2
+
+        # if `nodes` is a container of nodes, then return a
+        # dictionary mapping node to number of triangles.
+        return {v: t // 2 for v, d, t, _ in _triangles_and_degree_iter(G, nodes)}
+
+    # if nodes is None, then compute triangles for the complete graph
+
+    # dict used to avoid visiting the same nodes twice
+    # this allows calculating/counting each triangle only once
+    later_nbrs = {}
+
+    # iterate over the nodes in a graph
+    for node, neighbors in G.adjacency():
+        later_nbrs[node] = {n for n in neighbors if n not in later_nbrs and n != node}
+
+    # instantiate Counter for each node to include isolated nodes
+    # add 1 to the count if a nodes neighbor's neighbor is also a neighbor
+    triangle_counts = Counter(dict.fromkeys(G, 0))
+    for node1, neighbors in later_nbrs.items():
+        for node2 in neighbors:
+            third_nodes = neighbors & later_nbrs[node2]
+            m = len(third_nodes)
+            triangle_counts[node1] += m
+            triangle_counts[node2] += m
+            triangle_counts.update(third_nodes)
+
+    return dict(triangle_counts)
+
+
+@not_implemented_for("multigraph")
+def _triangles_and_degree_iter(G, nodes=None):
+    """Return an iterator of (node, degree, triangles, generalized degree).
+
+    This double counts triangles so you may want to divide by 2.
+    See degree(), triangles() and generalized_degree() for definitions
+    and details.
+
+    """
+    if nodes is None:
+        nodes_nbrs = G.adj.items()
+    else:
+        nodes_nbrs = ((n, G[n]) for n in G.nbunch_iter(nodes))
+
+    for v, v_nbrs in nodes_nbrs:
+        vs = set(v_nbrs) - {v}
+        gen_degree = Counter(len(vs & (set(G[w]) - {w})) for w in vs)
+        ntriangles = sum(k * val for k, val in gen_degree.items())
+        yield (v, len(vs), ntriangles, gen_degree)
+
+
+@not_implemented_for("multigraph")
+def _weighted_triangles_and_degree_iter(G, nodes=None, weight="weight"):
+    """Return an iterator of (node, degree, weighted_triangles).
+
+    Used for weighted clustering.
+    Note: this returns the geometric average weight of edges in the triangle.
+    Also, each triangle is counted twice (each direction).
+    So you may want to divide by 2.
+
+    """
+    import numpy as np
+
+    if weight is None or G.number_of_edges() == 0:
+        max_weight = 1
+    else:
+        max_weight = max(d.get(weight, 1) for u, v, d in G.edges(data=True))
+    if nodes is None:
+        nodes_nbrs = G.adj.items()
+    else:
+        nodes_nbrs = ((n, G[n]) for n in G.nbunch_iter(nodes))
+
+    def wt(u, v):
+        return G[u][v].get(weight, 1) / max_weight
+
+    for i, nbrs in nodes_nbrs:
+        inbrs = set(nbrs) - {i}
+        weighted_triangles = 0
+        seen = set()
+        for j in inbrs:
+            seen.add(j)
+            # This avoids counting twice -- we double at the end.
+            jnbrs = set(G[j]) - seen
+            # Only compute the edge weight once, before the inner inner
+            # loop.
+            wij = wt(i, j)
+            weighted_triangles += np.cbrt(
+                [(wij * wt(j, k) * wt(k, i)) for k in inbrs & jnbrs]
+            ).sum()
+        yield (i, len(inbrs), 2 * float(weighted_triangles))
+
+
+@not_implemented_for("multigraph")
+def _directed_triangles_and_degree_iter(G, nodes=None):
+    """Return an iterator of
+    (node, total_degree, reciprocal_degree, directed_triangles).
+
+    Used for directed clustering.
+    Note that unlike `_triangles_and_degree_iter()`, this function counts
+    directed triangles so does not count triangles twice.
+
+    """
+    nodes_nbrs = ((n, G._pred[n], G._succ[n]) for n in G.nbunch_iter(nodes))
+
+    for i, preds, succs in nodes_nbrs:
+        ipreds = set(preds) - {i}
+        isuccs = set(succs) - {i}
+
+        directed_triangles = 0
+        for j in chain(ipreds, isuccs):
+            jpreds = set(G._pred[j]) - {j}
+            jsuccs = set(G._succ[j]) - {j}
+            directed_triangles += sum(
+                1
+                for k in chain(
+                    (ipreds & jpreds),
+                    (ipreds & jsuccs),
+                    (isuccs & jpreds),
+                    (isuccs & jsuccs),
+                )
+            )
+        dtotal = len(ipreds) + len(isuccs)
+        dbidirectional = len(ipreds & isuccs)
+        yield (i, dtotal, dbidirectional, directed_triangles)
+
+
+@not_implemented_for("multigraph")
+def _directed_weighted_triangles_and_degree_iter(G, nodes=None, weight="weight"):
+    """Return an iterator of
+    (node, total_degree, reciprocal_degree, directed_weighted_triangles).
+
+    Used for directed weighted clustering.
+    Note that unlike `_weighted_triangles_and_degree_iter()`, this function counts
+    directed triangles so does not count triangles twice.
+
+    """
+    import numpy as np
+
+    if weight is None or G.number_of_edges() == 0:
+        max_weight = 1
+    else:
+        max_weight = max(d.get(weight, 1) for u, v, d in G.edges(data=True))
+
+    nodes_nbrs = ((n, G._pred[n], G._succ[n]) for n in G.nbunch_iter(nodes))
+
+    def wt(u, v):
+        return G[u][v].get(weight, 1) / max_weight
+
+    for i, preds, succs in nodes_nbrs:
+        ipreds = set(preds) - {i}
+        isuccs = set(succs) - {i}
+
+        directed_triangles = 0
+        for j in ipreds:
+            jpreds = set(G._pred[j]) - {j}
+            jsuccs = set(G._succ[j]) - {j}
+            directed_triangles += np.cbrt(
+                [(wt(j, i) * wt(k, i) * wt(k, j)) for k in ipreds & jpreds]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(j, i) * wt(k, i) * wt(j, k)) for k in ipreds & jsuccs]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(j, i) * wt(i, k) * wt(k, j)) for k in isuccs & jpreds]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(j, i) * wt(i, k) * wt(j, k)) for k in isuccs & jsuccs]
+            ).sum()
+
+        for j in isuccs:
+            jpreds = set(G._pred[j]) - {j}
+            jsuccs = set(G._succ[j]) - {j}
+            directed_triangles += np.cbrt(
+                [(wt(i, j) * wt(k, i) * wt(k, j)) for k in ipreds & jpreds]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(i, j) * wt(k, i) * wt(j, k)) for k in ipreds & jsuccs]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(i, j) * wt(i, k) * wt(k, j)) for k in isuccs & jpreds]
+            ).sum()
+            directed_triangles += np.cbrt(
+                [(wt(i, j) * wt(i, k) * wt(j, k)) for k in isuccs & jsuccs]
+            ).sum()
+
+        dtotal = len(ipreds) + len(isuccs)
+        dbidirectional = len(ipreds & isuccs)
+        yield (i, dtotal, dbidirectional, float(directed_triangles))
+
+
+@nx._dispatchable(edge_attrs="weight")
+def average_clustering(G, nodes=None, weight=None, count_zeros=True):
+    r"""Compute the average clustering coefficient for the graph G.
+
+    The clustering coefficient for the graph is the average,
+
+    .. math::
+
+       C = \frac{1}{n}\sum_{v \in G} c_v,
+
+    where :math:`n` is the number of nodes in `G`.
+
+    Parameters
+    ----------
+    G : graph
+
+    nodes : container of nodes, optional (default=all nodes in G)
+       Compute average clustering for nodes in this container.
+
+    weight : string or None, optional (default=None)
+       The edge attribute that holds the numerical value used as a weight.
+       If None, then each edge has weight 1.
+
+    count_zeros : bool
+       If False include only the nodes with nonzero clustering in the average.
+
+    Returns
+    -------
+    avg : float
+       Average clustering
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.average_clustering(G))
+    1.0
+
+    Notes
+    -----
+    This is a space saving routine; it might be faster
+    to use the clustering function to get a list and then take the average.
+
+    Self loops are ignored.
+
+    References
+    ----------
+    .. [1] Generalizations of the clustering coefficient to weighted
+       complex networks by J. Saramäki, M. Kivelä, J.-P. Onnela,
+       K. Kaski, and J. Kertész, Physical Review E, 75 027105 (2007).
+       http://jponnela.com/web_documents/a9.pdf
+    .. [2] Marcus Kaiser,  Mean clustering coefficients: the role of isolated
+       nodes and leafs on clustering measures for small-world networks.
+       https://arxiv.org/abs/0802.2512
+    """
+    c = clustering(G, nodes, weight=weight).values()
+    if not count_zeros:
+        c = [v for v in c if abs(v) > 0]
+    return sum(c) / len(c)
+
+
+@nx._dispatchable(edge_attrs="weight")
+def clustering(G, nodes=None, weight=None):
+    r"""Compute the clustering coefficient for nodes.
+
+    For unweighted graphs, the clustering of a node :math:`u`
+    is the fraction of possible triangles through that node that exist,
+
+    .. math::
+
+      c_u = \frac{2 T(u)}{deg(u)(deg(u)-1)},
+
+    where :math:`T(u)` is the number of triangles through node :math:`u` and
+    :math:`deg(u)` is the degree of :math:`u`.
+
+    For weighted graphs, there are several ways to define clustering [1]_.
+    the one used here is defined
+    as the geometric average of the subgraph edge weights [2]_,
+
+    .. math::
+
+       c_u = \frac{1}{deg(u)(deg(u)-1))}
+             \sum_{vw} (\hat{w}_{uv} \hat{w}_{uw} \hat{w}_{vw})^{1/3}.
+
+    The edge weights :math:`\hat{w}_{uv}` are normalized by the maximum weight
+    in the network :math:`\hat{w}_{uv} = w_{uv}/\max(w)`.
+
+    The value of :math:`c_u` is assigned to 0 if :math:`deg(u) < 2`.
+
+    Additionally, this weighted definition has been generalized to support negative edge weights [3]_.
+
+    For directed graphs, the clustering is similarly defined as the fraction
+    of all possible directed triangles or geometric average of the subgraph
+    edge weights for unweighted and weighted directed graph respectively [4]_.
+
+    .. math::
+
+       c_u = \frac{T(u)}{2(deg^{tot}(u)(deg^{tot}(u)-1) - 2deg^{\leftrightarrow}(u))},
+
+    where :math:`T(u)` is the number of directed triangles through node
+    :math:`u`, :math:`deg^{tot}(u)` is the sum of in degree and out degree of
+    :math:`u` and :math:`deg^{\leftrightarrow}(u)` is the reciprocal degree of
+    :math:`u`.
+
+
+    Parameters
+    ----------
+    G : graph
+
+    nodes : node, iterable of nodes, or None (default=None)
+        If a singleton node, return the number of triangles for that node.
+        If an iterable, compute the number of triangles for each of those nodes.
+        If `None` (the default) compute the number of triangles for all nodes in `G`.
+
+    weight : string or None, optional (default=None)
+       The edge attribute that holds the numerical value used as a weight.
+       If None, then each edge has weight 1.
+
+    Returns
+    -------
+    out : float, or dictionary
+       Clustering coefficient at specified nodes
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.clustering(G, 0))
+    1.0
+    >>> print(nx.clustering(G))
+    {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}
+
+    Notes
+    -----
+    Self loops are ignored.
+
+    References
+    ----------
+    .. [1] Generalizations of the clustering coefficient to weighted
+       complex networks by J. Saramäki, M. Kivelä, J.-P. Onnela,
+       K. Kaski, and J. Kertész, Physical Review E, 75 027105 (2007).
+       http://jponnela.com/web_documents/a9.pdf
+    .. [2] Intensity and coherence of motifs in weighted complex
+       networks by J. P. Onnela, J. Saramäki, J. Kertész, and K. Kaski,
+       Physical Review E, 71(6), 065103 (2005).
+    .. [3] Generalization of Clustering Coefficients to Signed Correlation Networks
+       by G. Costantini and M. Perugini, PloS one, 9(2), e88669 (2014).
+    .. [4] Clustering in complex directed networks by G. Fagiolo,
+       Physical Review E, 76(2), 026107 (2007).
+    """
+    if G.is_directed():
+        if weight is not None:
+            td_iter = _directed_weighted_triangles_and_degree_iter(G, nodes, weight)
+            clusterc = {
+                v: 0 if t == 0 else t / ((dt * (dt - 1) - 2 * db) * 2)
+                for v, dt, db, t in td_iter
+            }
+        else:
+            td_iter = _directed_triangles_and_degree_iter(G, nodes)
+            clusterc = {
+                v: 0 if t == 0 else t / ((dt * (dt - 1) - 2 * db) * 2)
+                for v, dt, db, t in td_iter
+            }
+    else:
+        # The formula 2*T/(d*(d-1)) from docs is t/(d*(d-1)) here b/c t==2*T
+        if weight is not None:
+            td_iter = _weighted_triangles_and_degree_iter(G, nodes, weight)
+            clusterc = {v: 0 if t == 0 else t / (d * (d - 1)) for v, d, t in td_iter}
+        else:
+            td_iter = _triangles_and_degree_iter(G, nodes)
+            clusterc = {v: 0 if t == 0 else t / (d * (d - 1)) for v, d, t, _ in td_iter}
+    if nodes in G:
+        # Return the value of the sole entry in the dictionary.
+        return clusterc[nodes]
+    return clusterc
+
+
+@nx._dispatchable
+def transitivity(G):
+    r"""Compute graph transitivity, the fraction of all possible triangles
+    present in G.
+
+    Possible triangles are identified by the number of "triads"
+    (two edges with a shared vertex).
+
+    The transitivity is
+
+    .. math::
+
+        T = 3\frac{\#triangles}{\#triads}.
+
+    Parameters
+    ----------
+    G : graph
+
+    Returns
+    -------
+    out : float
+       Transitivity
+
+    Notes
+    -----
+    Self loops are ignored.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.transitivity(G))
+    1.0
+    """
+    triangles_contri = [
+        (t, d * (d - 1)) for v, d, t, _ in _triangles_and_degree_iter(G)
+    ]
+    # If the graph is empty
+    if len(triangles_contri) == 0:
+        return 0
+    triangles, contri = map(sum, zip(*triangles_contri))
+    return 0 if triangles == 0 else triangles / contri
+
+
+@nx._dispatchable
+def square_clustering(G, nodes=None):
+    r"""Compute the squares clustering coefficient for nodes.
+
+    For each node return the fraction of possible squares that exist at
+    the node [1]_
+
+    .. math::
+       C_4(v) = \frac{ \sum_{u=1}^{k_v}
+       \sum_{w=u+1}^{k_v} q_v(u,w) }{ \sum_{u=1}^{k_v}
+       \sum_{w=u+1}^{k_v} [a_v(u,w) + q_v(u,w)]},
+
+    where :math:`q_v(u,w)` are the number of common neighbors of :math:`u` and
+    :math:`w` other than :math:`v` (ie squares), and :math:`a_v(u,w) = (k_u -
+    (1+q_v(u,w)+\theta_{uv})) + (k_w - (1+q_v(u,w)+\theta_{uw}))`, where
+    :math:`\theta_{uw} = 1` if :math:`u` and :math:`w` are connected and 0
+    otherwise. [2]_
+
+    Parameters
+    ----------
+    G : graph
+
+    nodes : container of nodes, optional (default=all nodes in G)
+       Compute clustering for nodes in this container.
+
+    Returns
+    -------
+    c4 : dictionary
+       A dictionary keyed by node with the square clustering coefficient value.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.square_clustering(G, 0))
+    1.0
+    >>> print(nx.square_clustering(G))
+    {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}
+
+    Notes
+    -----
+    While :math:`C_3(v)` (triangle clustering) gives the probability that
+    two neighbors of node v are connected with each other, :math:`C_4(v)` is
+    the probability that two neighbors of node v share a common
+    neighbor different from v. This algorithm can be applied to both
+    bipartite and unipartite networks.
+
+    References
+    ----------
+    .. [1] Pedro G. Lind, Marta C. González, and Hans J. Herrmann. 2005
+        Cycles and clustering in bipartite networks.
+        Physical Review E (72) 056127.
+    .. [2] Zhang, Peng et al. Clustering Coefficient and Community Structure of
+        Bipartite Networks. Physica A: Statistical Mechanics and its Applications 387.27 (2008): 6869–6875.
+        https://arxiv.org/abs/0710.0117v1
+    """
+    if nodes is None:
+        node_iter = G
+    else:
+        node_iter = G.nbunch_iter(nodes)
+    clustering = {}
+    for v in node_iter:
+        clustering[v] = 0
+        potential = 0
+        for u, w in combinations(G[v], 2):
+            squares = len((set(G[u]) & set(G[w])) - {v})
+            clustering[v] += squares
+            degm = squares + 1
+            if w in G[u]:
+                degm += 1
+            potential += (len(G[u]) - degm) + (len(G[w]) - degm) + squares
+        if potential > 0:
+            clustering[v] /= potential
+    if nodes in G:
+        # Return the value of the sole entry in the dictionary.
+        return clustering[nodes]
+    return clustering
+
+
+@not_implemented_for("directed")
+@nx._dispatchable
+def generalized_degree(G, nodes=None):
+    r"""Compute the generalized degree for nodes.
+
+    For each node, the generalized degree shows how many edges of given
+    triangle multiplicity the node is connected to. The triangle multiplicity
+    of an edge is the number of triangles an edge participates in. The
+    generalized degree of node :math:`i` can be written as a vector
+    :math:`\mathbf{k}_i=(k_i^{(0)}, \dotsc, k_i^{(N-2)})` where
+    :math:`k_i^{(j)}` is the number of edges attached to node :math:`i` that
+    participate in :math:`j` triangles.
+
+    Parameters
+    ----------
+    G : graph
+
+    nodes : container of nodes, optional (default=all nodes in G)
+       Compute the generalized degree for nodes in this container.
+
+    Returns
+    -------
+    out : Counter, or dictionary of Counters
+       Generalized degree of specified nodes. The Counter is keyed by edge
+       triangle multiplicity.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> print(nx.generalized_degree(G, 0))
+    Counter({3: 4})
+    >>> print(nx.generalized_degree(G))
+    {0: Counter({3: 4}), 1: Counter({3: 4}), 2: Counter({3: 4}), 3: Counter({3: 4}), 4: Counter({3: 4})}
+
+    To recover the number of triangles attached to a node:
+
+    >>> k1 = nx.generalized_degree(G, 0)
+    >>> sum([k * v for k, v in k1.items()]) / 2 == nx.triangles(G, 0)
+    True
+
+    Notes
+    -----
+    Self loops are ignored.
+
+    In a network of N nodes, the highest triangle multiplicity an edge can have
+    is N-2.
+
+    The return value does not include a `zero` entry if no edges of a
+    particular triangle multiplicity are present.
+
+    The number of triangles node :math:`i` is attached to can be recovered from
+    the generalized degree :math:`\mathbf{k}_i=(k_i^{(0)}, \dotsc,
+    k_i^{(N-2)})` by :math:`(k_i^{(1)}+2k_i^{(2)}+\dotsc +(N-2)k_i^{(N-2)})/2`.
+
+    References
+    ----------
+    .. [1] Networks with arbitrary edge multiplicities by V. Zlatić,
+        D. Garlaschelli and G. Caldarelli, EPL (Europhysics Letters),
+        Volume 97, Number 2 (2012).
+        https://iopscience.iop.org/article/10.1209/0295-5075/97/28005
+    """
+    if nodes in G:
+        return next(_triangles_and_degree_iter(G, nodes))[3]
+    return {v: gd for v, d, t, gd in _triangles_and_degree_iter(G, nodes)}
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `networkx-3.2rc0/examples/3d_drawing/mayavi2_spring.py` & `networkx-3.3rc0/examples/3d_drawing/mayavi2_spring.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/3d_drawing/plot_basic.py` & `networkx-3.3rc0/examples/3d_drawing/plot_basic.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/WormNet.v3.benchmark.txt` & `networkx-3.3rc0/examples/algorithms/WormNet.v3.benchmark.txt`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/hartford_drug.edgelist` & `networkx-3.3rc0/examples/algorithms/hartford_drug.edgelist`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_beam_search.py` & `networkx-3.3rc0/examples/algorithms/plot_beam_search.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_betweenness_centrality.py` & `networkx-3.3rc0/examples/algorithms/plot_betweenness_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_blockmodel.py` & `networkx-3.3rc0/examples/algorithms/plot_blockmodel.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_circuits.py` & `networkx-3.3rc0/examples/algorithms/plot_circuits.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_davis_club.py` & `networkx-3.3rc0/examples/algorithms/plot_davis_club.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_dedensification.py` & `networkx-3.3rc0/examples/algorithms/plot_dedensification.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_girvan_newman.py` & `networkx-3.3rc0/examples/algorithms/plot_girvan_newman.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_iterated_dynamical_systems.py` & `networkx-3.3rc0/examples/algorithms/plot_iterated_dynamical_systems.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_krackhardt_centrality.py` & `networkx-3.3rc0/examples/algorithms/plot_krackhardt_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_lca.py` & `networkx-3.3rc0/examples/algorithms/plot_lca.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_maximum_independent_set.py` & `networkx-3.3rc0/examples/algorithms/plot_maximum_independent_set.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_parallel_betweenness.py` & `networkx-3.3rc0/examples/algorithms/plot_parallel_betweenness.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_rcm.py` & `networkx-3.3rc0/examples/algorithms/plot_rcm.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_shortest_path.py` & `networkx-3.3rc0/examples/algorithms/plot_shortest_path.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_snap.py` & `networkx-3.3rc0/examples/algorithms/plot_snap.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/algorithms/plot_subgraphs.py` & `networkx-3.3rc0/examples/algorithms/plot_subgraphs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/basic/plot_properties.py` & `networkx-3.3rc0/examples/basic/plot_properties.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/basic/plot_read_write.py` & `networkx-3.3rc0/examples/basic/plot_read_write.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/basic/plot_simple_graph.py` & `networkx-3.3rc0/examples/basic/plot_simple_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/chess_masters_WCC.pgn.bz2` & `networkx-3.3rc0/examples/drawing/chess_masters_WCC.pgn.bz2`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/knuth_miles.txt.gz` & `networkx-3.3rc0/examples/drawing/knuth_miles.txt.gz`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_center_node.py` & `networkx-3.3rc0/examples/drawing/plot_center_node.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_chess_masters.py` & `networkx-3.3rc0/examples/drawing/plot_chess_masters.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_custom_node_icons.py` & `networkx-3.3rc0/examples/drawing/plot_custom_node_icons.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_degree.py` & `networkx-3.3rc0/examples/drawing/plot_degree.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_directed.py` & `networkx-3.3rc0/examples/drawing/plot_directed.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_ego_graph.py` & `networkx-3.3rc0/examples/drawing/plot_ego_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_eigenvalues.py` & `networkx-3.3rc0/examples/drawing/plot_eigenvalues.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_four_grids.py` & `networkx-3.3rc0/examples/drawing/plot_four_grids.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_house_with_colors.py` & `networkx-3.3rc0/examples/drawing/plot_house_with_colors.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_knuth_miles.py` & `networkx-3.3rc0/examples/drawing/plot_knuth_miles.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_labels_and_colors.py` & `networkx-3.3rc0/examples/drawing/plot_labels_and_colors.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_multipartite_graph.py` & `networkx-3.3rc0/examples/drawing/plot_multipartite_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_rainbow_coloring.py` & `networkx-3.3rc0/examples/drawing/plot_rainbow_coloring.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_random_geometric_graph.py` & `networkx-3.3rc0/examples/drawing/plot_random_geometric_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_sampson.py` & `networkx-3.3rc0/examples/drawing/plot_sampson.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_selfloops.py` & `networkx-3.3rc0/examples/drawing/plot_selfloops.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_spectral_grid.py` & `networkx-3.3rc0/examples/drawing/plot_spectral_grid.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_tsp.py` & `networkx-3.3rc0/examples/drawing/plot_tsp.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_unix_email.py` & `networkx-3.3rc0/examples/drawing/plot_unix_email.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/plot_weighted_graph.py` & `networkx-3.3rc0/examples/drawing/plot_weighted_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/sampson_data.zip` & `networkx-3.3rc0/examples/drawing/sampson_data.zip`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/drawing/unix_email.mbox` & `networkx-3.3rc0/examples/drawing/unix_email.mbox`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/external/force/force.js` & `networkx-3.3rc0/examples/external/force/force.js`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/external/javascript_force.py` & `networkx-3.3rc0/examples/external/javascript_force.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/external/plot_igraph.py` & `networkx-3.3rc0/examples/external/plot_igraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/geospatial/plot_delaunay.py` & `networkx-3.3rc0/examples/geospatial/plot_delaunay.py`

 * *Files 3% similar despite different names*

```diff
@@ -54,15 +54,19 @@
 
 # To plot with networkx, we need to merge the nodes back to
 # their positions in order to plot in networkx
 positions = dict(zip(delaunay_graph.nodes, coordinates))
 
 # Now, we can plot with a nice basemap.
 ax = cells.plot(facecolor="lightblue", alpha=0.50, edgecolor="cornsilk", linewidth=2)
-add_basemap(ax)
+try:  # Try-except for issues with timeout/parsing failures in CI
+    add_basemap(ax)
+except:
+    pass
+
 ax.axis("off")
 nx.draw(
     delaunay_graph,
     positions,
     ax=ax,
     node_size=2,
     node_color="k",
```

### Comparing `networkx-3.2rc0/examples/geospatial/plot_lines.py` & `networkx-3.3rc0/examples/geospatial/plot_lines.py`

 * *Files 8% similar despite different names*

```diff
@@ -72,15 +72,18 @@
 
 # Plot
 f, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)
 streets.plot(color="k", ax=ax[0])
 for i, facet in enumerate(ax):
     facet.set_title(("Streets", "Graph")[i])
     facet.axis("off")
-    add_basemap(facet)
+    try:  # For issues with downloading/parsing in CI
+        add_basemap(facet)
+    except:
+        pass
 nx.draw(
     G_primal, {n: [n[0], n[1]] for n in list(G_primal.nodes)}, ax=ax[1], node_size=50
 )
 
 # %%
 # Construct the dual graph. momepy will store row attributes as node attributes and
 # automatically measures angle between lines.
@@ -88,15 +91,18 @@
 
 # Plot
 f, ax = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)
 streets.plot(color="k", ax=ax[0])
 for i, facet in enumerate(ax):
     facet.set_title(("Streets", "Graph")[i])
     facet.axis("off")
-    add_basemap(facet)
+    try:  # For issues with downloading/parsing in CI
+        add_basemap(facet)
+    except:
+        pass
 nx.draw(G_dual, {n: [n[0], n[1]] for n in list(G_dual.nodes)}, ax=ax[1], node_size=50)
 plt.show()
 
 # Convert dual graph back to GeoDataFrame. Returns only original line geometry.
 lines = momepy.nx_to_gdf(G_dual)
 
 # %%
```

### Comparing `networkx-3.2rc0/examples/geospatial/plot_osmnx.py` & `networkx-3.3rc0/examples/geospatial/plot_osmnx.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/geospatial/plot_points.py` & `networkx-3.3rc0/examples/geospatial/plot_points.py`

 * *Files 14% similar despite different names*

```diff
@@ -47,13 +47,16 @@
 # their positions in order to plot in networkx
 positions = dict(zip(knn_graph.nodes, coordinates))
 
 # plot with a nice basemap
 f, ax = plt.subplots(1, 2, figsize=(8, 4))
 for i, facet in enumerate(ax):
     cases.plot(marker=".", color="orangered", ax=facet)
-    add_basemap(facet)
+    try:  # For issues with downloading/parsing basemaps in CI
+        add_basemap(facet)
+    except:
+        pass
     facet.set_title(("KNN-3", "50-meter Distance Band")[i])
     facet.axis("off")
 nx.draw(knn_graph, positions, ax=ax[0], node_size=5, node_color="b")
 nx.draw(dist_graph, positions, ax=ax[1], node_size=5, node_color="b")
 plt.show()
```

### Comparing `networkx-3.2rc0/examples/geospatial/plot_polygons.py` & `networkx-3.3rc0/examples/geospatial/plot_polygons.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_dag_layout.py` & `networkx-3.3rc0/examples/graph/plot_dag_layout.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_degree_sequence.py` & `networkx-3.3rc0/examples/graph/plot_degree_sequence.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_erdos_renyi.py` & `networkx-3.3rc0/examples/graph/plot_erdos_renyi.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_football.py` & `networkx-3.3rc0/examples/graph/plot_football.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_morse_trie.py` & `networkx-3.3rc0/examples/graph/plot_morse_trie.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_mst.py` & `networkx-3.3rc0/examples/graph/plot_mst.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_napoleon_russian_campaign.py` & `networkx-3.3rc0/examples/graph/plot_napoleon_russian_campaign.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_roget.py` & `networkx-3.3rc0/examples/graph/plot_roget.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_triad_types.py` & `networkx-3.3rc0/examples/graph/plot_triad_types.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_visibility_graph.py` & `networkx-3.3rc0/examples/graph/plot_visibility_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/plot_words.py` & `networkx-3.3rc0/examples/graph/plot_words.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/roget_dat.txt.gz` & `networkx-3.3rc0/examples/graph/roget_dat.txt.gz`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graph/words_dat.txt.gz` & `networkx-3.3rc0/examples/graph/words_dat.txt.gz`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_drawing/plot_attributes.py` & `networkx-3.3rc0/examples/graphviz_drawing/plot_attributes.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_drawing/plot_conversion.py` & `networkx-3.3rc0/examples/graphviz_drawing/plot_conversion.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_drawing/plot_grid.py` & `networkx-3.3rc0/examples/graphviz_drawing/plot_grid.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_drawing/plot_mini_atlas.py` & `networkx-3.3rc0/examples/graphviz_drawing/plot_mini_atlas.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_layout/lanl_routes.edgelist` & `networkx-3.3rc0/examples/graphviz_layout/lanl_routes.edgelist`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_layout/plot_atlas.py` & `networkx-3.3rc0/examples/graphviz_layout/plot_atlas.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_layout/plot_decomposition.py` & `networkx-3.3rc0/examples/graphviz_layout/plot_decomposition.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_layout/plot_giant_component.py` & `networkx-3.3rc0/examples/graphviz_layout/plot_giant_component.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/graphviz_layout/plot_lanl_routes.py` & `networkx-3.3rc0/examples/graphviz_layout/plot_lanl_routes.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/subclass/plot_antigraph.py` & `networkx-3.3rc0/examples/subclass/plot_antigraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/examples/subclass/plot_printgraph.py` & `networkx-3.3rc0/examples/subclass/plot_printgraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/__init__.py` & `networkx-3.3rc0/networkx/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,24 +4,24 @@
 
 NetworkX is a Python package for the creation, manipulation, and study of the
 structure, dynamics, and functions of complex networks.
 
 See https://networkx.org for complete documentation.
 """
 
-__version__ = "3.2rc0"
+__version__ = "3.3rc0"
 
 
 # These are imported in order as listed
 from networkx.lazy_imports import _lazy_import
 
 from networkx.exception import *
 
 from networkx import utils
-from networkx.utils.backends import _dispatch
+from networkx.utils.backends import _dispatchable, config
 
 from networkx import classes
 from networkx.classes import filters
 from networkx.classes import *
 
 from networkx import convert
 from networkx.convert import *
```

### Comparing `networkx-3.2rc0/networkx/algorithms/__init__.py` & `networkx-3.3rc0/networkx/algorithms/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 from networkx.algorithms.assortativity import *
 from networkx.algorithms.asteroidal import *
 from networkx.algorithms.boundary import *
+from networkx.algorithms.broadcasting import *
 from networkx.algorithms.bridges import *
 from networkx.algorithms.chains import *
 from networkx.algorithms.centrality import *
 from networkx.algorithms.chordal import *
 from networkx.algorithms.cluster import *
 from networkx.algorithms.clique import *
 from networkx.algorithms.communicability_alg import *
@@ -33,14 +34,15 @@
 from networkx.algorithms.minors import *
 from networkx.algorithms.mis import *
 from networkx.algorithms.moral import *
 from networkx.algorithms.non_randomness import *
 from networkx.algorithms.operators import *
 from networkx.algorithms.planarity import *
 from networkx.algorithms.planar_drawing import *
+from networkx.algorithms.polynomials import *
 from networkx.algorithms.reciprocity import *
 from networkx.algorithms.regular import *
 from networkx.algorithms.richclub import *
 from networkx.algorithms.shortest_paths import *
 from networkx.algorithms.similarity import *
 from networkx.algorithms.graph_hashing import *
 from networkx.algorithms.simple_paths import *
@@ -53,15 +55,14 @@
 from networkx.algorithms.time_dependent import *
 from networkx.algorithms.traversal import *
 from networkx.algorithms.triads import *
 from networkx.algorithms.vitality import *
 from networkx.algorithms.voronoi import *
 from networkx.algorithms.walks import *
 from networkx.algorithms.wiener import *
-from networkx.algorithms.polynomials import *
 
 # Make certain subpackages available to the user as direct imports from
 # the `networkx` namespace.
 from networkx.algorithms import approximation
 from networkx.algorithms import assortativity
 from networkx.algorithms import bipartite
 from networkx.algorithms import node_classification
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/__init__.py` & `networkx-3.3rc0/networkx/algorithms/approximation/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/clique.py` & `networkx-3.3rc0/networkx/algorithms/approximation/clique.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     "large_clique_size",
     "maximum_independent_set",
 ]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def maximum_independent_set(G):
     """Returns an approximate maximum independent set.
 
     Independent set or stable set is a set of vertices in a graph, no two of
     which are adjacent. That is, it is a set I of vertices such that for every
     two vertices in I, there is no edge connecting the two. Equivalently, each
     edge in the graph has at most one endpoint in I. The size of an independent
@@ -66,15 +66,15 @@
     """
     iset, _ = clique_removal(G)
     return iset
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def max_clique(G):
     r"""Find the Maximum Clique
 
     Finds the $O(|V|/(log|V|)^2)$ apx of maximum clique/independent set
     in the worst case.
 
     Parameters
@@ -125,15 +125,15 @@
     cgraph = nx.complement(G)
     iset, _ = clique_removal(cgraph)
     return iset
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def clique_removal(G):
     r"""Repeatedly remove cliques from the graph.
 
     Results in a $O(|V|/(\log |V|)^2)$ approximation of maximum clique
     and independent set. Returns the largest independent set found, along
     with found maximal cliques.
 
@@ -178,15 +178,15 @@
     # Determine the largest independent set as measured by cardinality.
     maxiset = max(isets, key=len)
     return maxiset, cliques
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def large_clique_size(G):
     """Find the size of a large clique in a graph.
 
     A *clique* is a subset of nodes in which each pair of nodes is
     adjacent. This function is a heuristic for finding the size of a
     large clique in the graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/clustering_coefficient.py` & `networkx-3.3rc0/networkx/algorithms/approximation/clustering_coefficient.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from networkx.utils import not_implemented_for, py_random_state
 
 __all__ = ["average_clustering"]
 
 
 @not_implemented_for("directed")
 @py_random_state(2)
-@nx._dispatch(name="approximate_average_clustering")
+@nx._dispatchable(name="approximate_average_clustering")
 def average_clustering(G, trials=1000, seed=None):
     r"""Estimates the average clustering coefficient of G.
 
     The local clustering of each node in `G` is the fraction of triangles
     that actually exist over all possible triangles in its neighborhood.
     The average clustering coefficient of a graph `G` is the mean of
     local clusterings.
@@ -41,14 +41,19 @@
     Examples
     --------
     >>> from networkx.algorithms import approximation
     >>> G = nx.erdos_renyi_graph(10, 0.2, seed=10)
     >>> approximation.average_clustering(G, trials=1000, seed=10)
     0.214
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If G is directed.
+
     References
     ----------
     .. [1] Schank, Thomas, and Dorothea Wagner. Approximating clustering
        coefficient and transitivity. Universität Karlsruhe, Fakultät für
        Informatik, 2004.
        https://doi.org/10.5445/IR/1000001239
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/connectivity.py` & `networkx-3.3rc0/networkx/algorithms/approximation/connectivity.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 __all__ = [
     "local_node_connectivity",
     "node_connectivity",
     "all_pairs_node_connectivity",
 ]
 
 
-@nx._dispatch(name="approximate_local_node_connectivity")
+@nx._dispatchable(name="approximate_local_node_connectivity")
 def local_node_connectivity(G, source, target, cutoff=None):
     """Compute node connectivity between source and target.
 
     Pairwise or local node connectivity between two distinct and nonadjacent
     nodes is the minimum number of nodes that must be removed (minimum
     separating cutset) to disconnect them. By Menger's theorem, this is equal
     to the number of node independent paths (paths that share no nodes other
@@ -104,15 +104,15 @@
             K += 1
         except nx.NetworkXNoPath:
             break
 
     return K
 
 
-@nx._dispatch(name="approximate_node_connectivity")
+@nx._dispatchable(name="approximate_node_connectivity")
 def node_connectivity(G, s=None, t=None):
     r"""Returns an approximation for node connectivity for a graph or digraph G.
 
     Node connectivity is equal to the minimum number of nodes that
     must be removed to disconnect G or render it trivial. By Menger's theorem,
     this is equal to the number of node independent paths (paths that
     share no nodes other than source and target).
@@ -210,15 +210,15 @@
     # Same for non adjacent pairs of neighbors of v
     for x, y in iter_func(neighbors(v), 2):
         if y not in G[x] and x != y:
             K = min(K, local_node_connectivity(G, x, y, cutoff=K))
     return K
 
 
-@nx._dispatch(name="approximate_all_pairs_node_connectivity")
+@nx._dispatchable(name="approximate_all_pairs_node_connectivity")
 def all_pairs_node_connectivity(G, nbunch=None, cutoff=None):
     """Compute node connectivity between all pairs of nodes.
 
     Pairwise or local node connectivity between two distinct and nonadjacent
     nodes is the minimum number of nodes that must be removed (minimum
     separating cutset) to disconnect them. By Menger's theorem, this is equal
     to the number of node independent paths (paths that share no nodes other
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/distance_measures.py` & `networkx-3.3rc0/networkx/algorithms/approximation/distance_measures.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import networkx as nx
 from networkx.utils.decorators import py_random_state
 
 __all__ = ["diameter"]
 
 
 @py_random_state(1)
-@nx._dispatch(name="approximate_diameter")
+@nx._dispatchable(name="approximate_diameter")
 def diameter(G, seed=None):
     """Returns a lower bound on the diameter of the graph G.
 
     The function computes a lower bound on the diameter (i.e., the maximum eccentricity)
     of a directed or undirected graph G. The procedure used varies depending on the graph
     being directed or not.
 
@@ -36,14 +36,23 @@
         See :ref:`Randomness<randomness>`.
 
     Returns
     -------
     d : integer
        Lower Bound on the Diameter of G
 
+    Examples
+    --------
+    >>> G = nx.path_graph(10)  # undirected graph
+    >>> nx.diameter(G)
+    9
+    >>> G = nx.cycle_graph(3, create_using=nx.DiGraph)  # directed graph
+    >>> nx.diameter(G)
+    2
+
     Raises
     ------
     NetworkXError
         If the graph is empty or
         If the graph is undirected and not connected or
         If the graph is directed and not strongly connected.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/dominating_set.py` & `networkx-3.3rc0/networkx/algorithms/approximation/dominating_set.py`

 * *Files 11% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 from ..matching import maximal_matching
 
 __all__ = ["min_weighted_dominating_set", "min_edge_dominating_set"]
 
 
 # TODO Why doesn't this algorithm work for directed graphs?
 @not_implemented_for("directed")
-@nx._dispatch(node_attrs="weight")
+@nx._dispatchable(node_attrs="weight")
 def min_weighted_dominating_set(G, weight=None):
     r"""Returns a dominating set that approximates the minimum weight node
     dominating set.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -39,14 +39,25 @@
     -------
     min_weight_dominating_set : set
         A set of nodes, the sum of whose weights is no more than `(\log
         w(V)) w(V^*)`, where `w(V)` denotes the sum of the weights of
         each node in the graph and `w(V^*)` denotes the sum of the
         weights of each node in the minimum weight dominating set.
 
+    Examples
+    --------
+    >>> G = nx.Graph([(0, 1), (0, 4), (1, 4), (1, 2), (2, 3), (3, 4), (2, 5)])
+    >>> nx.approximation.min_weighted_dominating_set(G)
+    {1, 2, 4}
+
+    Raises
+    ------
+    NetworkXNotImplemented
+        If G is directed.
+
     Notes
     -----
     This algorithm computes an approximate minimum weighted dominating
     set for the graph `G`. The returned solution has weight `(\log
     w(V)) w(V^*)`, where `w(V)` denotes the sum of the weights of each
     node in the graph and `w(V^*)` denotes the sum of the weights of
     each node in the minimum weight dominating set for the graph.
@@ -97,28 +108,39 @@
         dom_set.add(dom_node)
         del neighborhoods[dom_node]
         vertices -= min_set
 
     return dom_set
 
 
-@nx._dispatch
+@nx._dispatchable
 def min_edge_dominating_set(G):
     r"""Returns minimum cardinality edge dominating set.
 
     Parameters
     ----------
     G : NetworkX graph
       Undirected graph
 
     Returns
     -------
     min_edge_dominating_set : set
       Returns a set of dominating edges whose size is no more than 2 * OPT.
 
+    Examples
+    --------
+    >>> G = nx.petersen_graph()
+    >>> nx.approximation.min_edge_dominating_set(G)
+    {(0, 1), (4, 9), (6, 8), (5, 7), (2, 3)}
+
+    Raises
+    ------
+    ValueError
+        If the input graph `G` is empty.
+
     Notes
     -----
     The algorithm computes an approximate solution to the edge dominating set
     problem. The result is no more than 2 * OPT in terms of size of the set.
     Runtime of the algorithm is $O(|E|)$.
     """
     if not G:
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/approximation/kcomponents.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 from networkx.exception import NetworkXError
 from networkx.utils import not_implemented_for
 
 __all__ = ["k_components"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(name="approximate_k_components")
+@nx._dispatchable(name="approximate_k_components")
 def k_components(G, min_density=0.95):
     r"""Returns the approximate k-component structure of a graph G.
 
     A `k`-component is a maximal subgraph of a graph G that has, at least,
     node connectivity `k`: we need to remove at least `k` nodes to break it
     into more components. `k`-components have an inherent hierarchical
     structure because they are nested in terms of connectivity: a connected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/matching.py` & `networkx-3.3rc0/networkx/algorithms/approximation/matching.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 `Wikipedia: Matching <https://en.wikipedia.org/wiki/Matching_(graph_theory)>`_
 """
 import networkx as nx
 
 __all__ = ["min_maximal_matching"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def min_maximal_matching(G):
     r"""Returns the minimum maximal matching of G. That is, out of all maximal
     matchings of the graph G, the smallest is returned.
 
     Parameters
     ----------
     G : NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/maxcut.py` & `networkx-3.3rc0/networkx/algorithms/approximation/maxcut.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,17 @@
 import networkx as nx
 from networkx.utils.decorators import not_implemented_for, py_random_state
 
 __all__ = ["randomized_partitioning", "one_exchange"]
 
 
-@not_implemented_for("directed", "multigraph")
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
 @py_random_state(1)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def randomized_partitioning(G, seed=None, p=0.5, weight=None):
     """Compute a random partitioning of the graph nodes and its cut value.
 
     A partitioning is calculated by observing each node
     and deciding to add it to the partition with probability `p`,
     returning a random cut and its corresponding value (the
     sum of weights of edges connecting different partitions).
@@ -34,28 +35,43 @@
     Returns
     -------
     cut_size : scalar
         Value of the minimum cut.
 
     partition : pair of node sets
         A partitioning of the nodes that defines a minimum cut.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> cut_size, partition = nx.approximation.randomized_partitioning(G, seed=1)
+    >>> cut_size
+    6
+    >>> partition
+    ({0, 3, 4}, {1, 2})
+
+    Raises
+    ------
+    NetworkXNotImplemented
+        If the graph is directed or is a multigraph.
     """
     cut = {node for node in G.nodes() if seed.random() < p}
     cut_size = nx.algorithms.cut_size(G, cut, weight=weight)
     partition = (cut, G.nodes - cut)
     return cut_size, partition
 
 
 def _swap_node_partition(cut, node):
     return cut - {node} if node in cut else cut.union({node})
 
 
-@not_implemented_for("directed", "multigraph")
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
 @py_random_state(2)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def one_exchange(G, initial_cut=None, seed=None, weight=None):
     """Compute a partitioning of the graphs nodes and the corresponding cut value.
 
     Use a greedy one exchange strategy to find a locally maximal cut
     and its value, it works by finding the best node (one that gives
     the highest gain to the cut value) to add to the current cut
     and repeats this process until no improvement can be made.
@@ -80,14 +96,28 @@
     Returns
     -------
     cut_value : scalar
         Value of the maximum cut.
 
     partition : pair of node sets
         A partitioning of the nodes that defines a maximum cut.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> curr_cut_size, partition = nx.approximation.one_exchange(G, seed=1)
+    >>> curr_cut_size
+    6
+    >>> partition
+    ({0, 2}, {1, 3, 4})
+
+    Raises
+    ------
+    NetworkXNotImplemented
+        If the graph is directed or is a multigraph.
     """
     if initial_cut is None:
         initial_cut = set()
     cut = set(initial_cut)
     current_cut_size = nx.algorithms.cut_size(G, cut, weight=weight)
     while True:
         nodes = list(G.nodes())
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/ramsey.py` & `networkx-3.3rc0/networkx/algorithms/approximation/ramsey.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from ...utils import arbitrary_element
 
 __all__ = ["ramsey_R2"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def ramsey_R2(G):
     r"""Compute the largest clique and largest independent set in `G`.
 
     This can be used to estimate bounds for the 2-color
     Ramsey number `R(2;s,t)` for `G`.
 
     This is a recursive implementation which could run into trouble
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/steinertree.py` & `networkx-3.3rc0/networkx/algorithms/approximation/steinertree.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for, pairwise
 
 __all__ = ["metric_closure", "steiner_tree"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight", returns_graph=True)
 def metric_closure(G, weight="weight"):
     """Return the metric closure of a graph.
 
     The metric closure of a graph *G* is the complete graph in which each edge
     is weighted by the shortest path distance between the nodes in *G* .
 
     Parameters
@@ -60,15 +60,15 @@
     G_1_prime = nx.Graph()
     for u, v, data in G.edges(data=True):
         su, sv = s[u], s[v]
         weight_here = d_1[(u, su)] + data.get(weight, 1) + d_1[(v, sv)]
         if not G_1_prime.has_edge(su, sv):
             G_1_prime.add_edge(su, sv, weight=weight_here)
         else:
-            new_weight = min(weight_here, G_1_prime[su][sv][weight])
+            new_weight = min(weight_here, G_1_prime[su][sv]["weight"])
             G_1_prime.add_edge(su, sv, weight=new_weight)
 
     G_2 = nx.minimum_spanning_edges(G_1_prime, data=True)
 
     G_3 = nx.Graph()
     for u, v, d in G_2:
         path = nx.shortest_path(G, u, v, weight)
@@ -122,15 +122,15 @@
 ALGORITHMS = {
     "kou": _kou_steiner_tree,
     "mehlhorn": _mehlhorn_steiner_tree,
 }
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def steiner_tree(G, terminal_nodes, weight="weight", method=None):
     r"""Return an approximation to the minimum Steiner tree of a graph.
 
     The minimum Steiner tree of `G` w.r.t a set of `terminal_nodes` (also *S*)
     is a tree within `G` that spans those nodes and has minimum size (sum of
     edge weights) among all such trees.
 
@@ -160,25 +160,33 @@
          A list of terminal nodes for which minimum steiner tree is
          to be found.
 
     weight : string (default = 'weight')
         Use the edge attribute specified by this string as the edge weight.
         Any edge attribute not present defaults to 1.
 
-    method : string, optional (default = 'kou')
+    method : string, optional (default = 'mehlhorn')
         The algorithm to use to approximate the Steiner tree.
         Supported options: 'kou', 'mehlhorn'.
         Other inputs produce a ValueError.
 
     Returns
     -------
     NetworkX graph
         Approximation to the minimum steiner tree of `G` induced by
         `terminal_nodes` .
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is directed.
+
+    ValueError
+        If the specified `method` is not supported.
+
     Notes
     -----
     For multigraphs, the edge between two nodes with minimum weight is the
     edge put into the Steiner tree.
 
 
     References
@@ -191,28 +199,20 @@
            https://doi.org/10.1007/BF00288961.
     .. [3] Mehlhorn, Kurt. 1988.
            ‘A Faster Approximation Algorithm for the Steiner Problem in Graphs’.
            Information Processing Letters 27 (3): 125–28.
            https://doi.org/10.1016/0020-0190(88)90066-X.
     """
     if method is None:
-        import warnings
-
-        msg = (
-            "steiner_tree will change default method from 'kou' to 'mehlhorn' "
-            "in version 3.2.\nSet the `method` kwarg to remove this warning."
-        )
-        warnings.warn(msg, FutureWarning, stacklevel=4)
-        method = "kou"
+        method = "mehlhorn"
 
     try:
         algo = ALGORITHMS[method]
     except KeyError as e:
-        msg = f"{method} is not a valid choice for an algorithm."
-        raise ValueError(msg) from e
+        raise ValueError(f"{method} is not a valid choice for an algorithm.") from e
 
     edges = algo(G, terminal_nodes, weight)
     # For multigraph we should add the minimal weight edge keys
     if G.is_multigraph():
         edges = (
             (u, v, min(G[u][v], key=lambda k: G[u][v][k][weight])) for u, v in edges
         )
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_approx_clust_coeff.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_approx_clust_coeff.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_clique.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_clique.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_connectivity.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_connectivity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_distance_measures.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_distance_measures.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_dominating_set.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_dominating_set.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_kcomponents.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_maxcut.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_maxcut.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,25 @@
 import random
 
+import pytest
+
 import networkx as nx
 from networkx.algorithms.approximation import maxcut
 
 
+@pytest.mark.parametrize(
+    "f", (nx.approximation.randomized_partitioning, nx.approximation.one_exchange)
+)
+@pytest.mark.parametrize("graph_constructor", (nx.DiGraph, nx.MultiGraph))
+def test_raises_on_directed_and_multigraphs(f, graph_constructor):
+    G = graph_constructor([(0, 1), (1, 2)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        f(G)
+
+
 def _is_valid_cut(G, set1, set2):
     union = set1.union(set2)
     assert union == set(G.nodes)
     assert len(set1) + len(set2) == G.number_of_nodes()
 
 
 def _cut_is_locally_optimal(G, cut_size, set1):
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_ramsey.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_ramsey.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_traveling_salesman.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_traveling_salesman.py`

 * *Files 1% similar despite different names*

```diff
@@ -752,17 +752,23 @@
     #
     # For the second condition it is possible to have the tour pass through the
     # same vertex more then. Imagine that the tour on the complete version takes
     # an edge not in the original graph. In the output this is substituted with
     # the shortest path between those vertices, allowing vertices to appear more
     # than once.
     #
-    # However, we are using a fixed random number generator so we know what the
-    # expected tour is.
-    expected_tours = [[1, 4, 5, 0, 2, 3, 2, 1], [3, 2, 0, 1, 4, 5, 3]]
+    # Even though we are using a fixed seed, multiple tours have been known to
+    # be returned. The first two are from the original delevopment of this test,
+    # and the third one from issue #5913 on GitHub. If other tours are returned,
+    # add it on the list of expected tours.
+    expected_tours = [
+        [1, 4, 5, 0, 2, 3, 2, 1],
+        [3, 2, 0, 1, 4, 5, 3],
+        [3, 2, 1, 0, 5, 4, 3],
+    ]
 
     assert tour in expected_tours
 
 
 def test_asadpour_real_world():
     """
     This test uses airline prices between the six largest cities in the US.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_treewidth.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_treewidth.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/tests/test_vertex_cover.py` & `networkx-3.3rc0/networkx/algorithms/approximation/tests/test_vertex_cover.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/traveling_salesman.py` & `networkx-3.3rc0/networkx/algorithms/approximation/traveling_salesman.py`

 * *Files 3% similar despite different names*

```diff
@@ -120,15 +120,15 @@
     """
     a, b = seed.sample(range(1, len(soln) - 1), k=2)
     soln.insert(b, soln.pop(a))
     return soln
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def christofides(G, weight="weight", tree=None):
     """Approximate a solution of the traveling salesman problem
 
     Compute a 3/2-approximation of the traveling salesman problem
     in a complete undirected graph using Christofides [1]_ algorithm.
 
     Parameters
@@ -193,15 +193,15 @@
         if not nodes:
             nodes.append(u)
         nodes.append(v)
     nodes.append(nodes[0])
     return nodes
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def traveling_salesman_problem(G, weight="weight", nodes=None, cycle=True, method=None):
     """Find the shortest path in `G` connecting specified nodes
 
     This function allows approximate solution to the traveling salesman
     problem on networks that are not complete graphs and/or where the
     salesman does not need to visit all nodes.
 
@@ -220,14 +220,18 @@
      - asadpour_atsp
 
     Once the Hamiltonian Cycle is found, this function post-processes to
     accommodate the structure of the original graph. If `cycle` is ``False``,
     the biggest weight edge is removed to make a Hamiltonian path.
     Then each edge on the new complete graph used for that analysis is
     replaced by the shortest_path between those nodes on the original graph.
+    If the input graph `G` includes edges with weights that do not adhere to
+    the triangle inequality, such as when `G` is not a complete graph (i.e
+    length of non-existent edges is infinity), then the returned path may
+    contain some repeating nodes (other than the starting node).
 
     Parameters
     ----------
     G : NetworkX graph
         A possibly weighted graph
 
     nodes : collection of nodes (default=G.nodes)
@@ -261,15 +265,14 @@
 
     Returns
     -------
     list
         List of nodes in `G` along a path with an approximation of the minimal
         path through `nodes`.
 
-
     Raises
     ------
     NetworkXError
         If `G` is a directed graph it has to be strongly connected or the
         complete version cannot be generated.
 
     Examples
@@ -333,15 +336,15 @@
         best_path.extend(path[u][v][:-1])
     best_path.append(v)
     return best_path
 
 
 @not_implemented_for("undirected")
 @py_random_state(2)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def asadpour_atsp(G, weight="weight", seed=None, source=None):
     """
     Returns an approximate solution to the traveling salesman problem.
 
     This approximate solution is one of the best known approximations for the
     asymmetric traveling salesman problem developed by Asadpour et al,
     [1]_. The algorithm first solves the Held-Karp relaxation to find a lower
@@ -400,16 +403,18 @@
        pp. 1043–1061
 
     Examples
     --------
     >>> import networkx as nx
     >>> import networkx.algorithms.approximation as approx
     >>> G = nx.complete_graph(3, create_using=nx.DiGraph)
-    >>> nx.set_edge_attributes(G, {(0, 1): 2, (1, 2): 2, (2, 0): 2, (0, 2): 1, (2, 1): 1, (1, 0): 1}, "weight")
-    >>> tour = approx.asadpour_atsp(G,source=0)
+    >>> nx.set_edge_attributes(
+    ...     G, {(0, 1): 2, (1, 2): 2, (2, 0): 2, (0, 2): 1, (2, 1): 1, (1, 0): 1}, "weight"
+    ... )
+    >>> tour = approx.asadpour_atsp(G, source=0)
     >>> tour
     [0, 2, 1, 0]
     """
     from math import ceil, exp
     from math import log as ln
 
     # Check that G is a complete graph
@@ -483,15 +488,15 @@
                     t_star.add_edge(source, target)
 
     # Return the shortcut eulerian circuit
     circuit = nx.eulerian_circuit(t_star, source=source)
     return _shortcutting(circuit)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight", returns_graph=True)
 def held_karp_ascent(G, weight="weight"):
     """
     Minimizes the Held-Karp relaxation of the TSP for `G`
 
     Solves the Held-Karp relaxation of the input complete digraph and scales
     the output solution for use in the Asadpour [1]_ ASTP algorithm.
 
@@ -674,15 +679,17 @@
             b_eq[len(G)] = 1
             for arb_count, arborescence in enumerate(minimum_1_arborescences):
                 n_count = len(G) - 1
                 for n, deg in arborescence.degree:
                     a_eq[n_count][arb_count] = deg - 2
                     n_count -= 1
                 a_eq[len(G)][arb_count] = 1
-            program_result = optimize.linprog(c, A_eq=a_eq, b_eq=b_eq)
+            program_result = optimize.linprog(
+                c, A_eq=a_eq, b_eq=b_eq, method="highs-ipm"
+            )
             # If the constants exist, then the direction of ascent doesn't
             if program_result.success:
                 # There is no direction of ascent
                 return None, minimum_1_arborescences
 
             # 5. GO TO 2
 
@@ -794,15 +801,15 @@
         if frequency > 0:
             z_star[(u, v)] = scale_factor * frequency
     del x_star
     # Return the optimal weight and the z dict
     return next(k_max.__iter__()).size(weight), z_star
 
 
-@nx._dispatch
+@nx._dispatchable
 def spanning_tree_distribution(G, z):
     """
     Find the asadpour exponential distribution of spanning trees.
 
     Solves the Maximum Entropy Convex Program in the Asadpour algorithm [1]_
     using the approach in section 7 to build an exponential distribution of
     undirected spanning trees.
@@ -905,15 +912,15 @@
     for _, _, d in G.edges(data=True):
         if lambda_key in d:
             del d[lambda_key]
 
     return gamma
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def greedy_tsp(G, weight="weight", source=None):
     """Return a low cost cycle starting at `source` and its cost.
 
     This approximates a solution to the traveling salesman problem.
     It finds a cycle of all the nodes that a salesman can visit in order
     to visit many nodes while minimizing total distance.
     It uses a simple greedy algorithm.
@@ -944,19 +951,30 @@
     NetworkXError
         If `G` is not complete, the algorithm raises an exception.
 
     Examples
     --------
     >>> from networkx.algorithms import approximation as approx
     >>> G = nx.DiGraph()
-    >>> G.add_weighted_edges_from({
-    ...     ("A", "B", 3), ("A", "C", 17), ("A", "D", 14), ("B", "A", 3),
-    ...     ("B", "C", 12), ("B", "D", 16), ("C", "A", 13),("C", "B", 12),
-    ...     ("C", "D", 4), ("D", "A", 14), ("D", "B", 15), ("D", "C", 2)
-    ... })
+    >>> G.add_weighted_edges_from(
+    ...     {
+    ...         ("A", "B", 3),
+    ...         ("A", "C", 17),
+    ...         ("A", "D", 14),
+    ...         ("B", "A", 3),
+    ...         ("B", "C", 12),
+    ...         ("B", "D", 16),
+    ...         ("C", "A", 13),
+    ...         ("C", "B", 12),
+    ...         ("C", "D", 4),
+    ...         ("D", "A", 14),
+    ...         ("D", "B", 15),
+    ...         ("D", "C", 2),
+    ...     }
+    ... )
     >>> cycle = approx.greedy_tsp(G, source="D")
     >>> cost = sum(G[n][nbr]["weight"] for n, nbr in nx.utils.pairwise(cycle))
     >>> cycle
     ['D', 'C', 'B', 'A', 'D']
     >>> cost
     31
 
@@ -998,15 +1016,15 @@
         cycle.append(next_node)
         nodeset.remove(next_node)
     cycle.append(cycle[0])
     return cycle
 
 
 @py_random_state(9)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def simulated_annealing_tsp(
     G,
     init_cycle,
     weight="weight",
     source=None,
     temp=100,
     move="1-1",
@@ -1029,15 +1047,15 @@
     the temperature (annealing has a physical analogue of steel hardening
     as it cools). As the temperature is reduced, the chance of moves that
     increase cost goes down.
 
     Parameters
     ----------
     G : Graph
-        `G` should be a complete weighted undirected graph.
+        `G` should be a complete weighted graph.
         The distance between all pairs of nodes should be included.
 
     init_cycle : list of all nodes or "greedy"
         The initial solution (a cycle through all nodes returning to the start).
         This argument has no default to make you think about it.
         If "greedy", use `greedy_tsp(G, weight)`.
         Other common starting cycles are `list(G) + [next(iter(G))]` or the final
@@ -1107,19 +1125,30 @@
     NetworkXError
         If `G` is not complete the algorithm raises an exception.
 
     Examples
     --------
     >>> from networkx.algorithms import approximation as approx
     >>> G = nx.DiGraph()
-    >>> G.add_weighted_edges_from({
-    ...     ("A", "B", 3), ("A", "C", 17), ("A", "D", 14), ("B", "A", 3),
-    ...     ("B", "C", 12), ("B", "D", 16), ("C", "A", 13),("C", "B", 12),
-    ...     ("C", "D", 4), ("D", "A", 14), ("D", "B", 15), ("D", "C", 2)
-    ... })
+    >>> G.add_weighted_edges_from(
+    ...     {
+    ...         ("A", "B", 3),
+    ...         ("A", "C", 17),
+    ...         ("A", "D", 14),
+    ...         ("B", "A", 3),
+    ...         ("B", "C", 12),
+    ...         ("B", "D", 16),
+    ...         ("C", "A", 13),
+    ...         ("C", "B", 12),
+    ...         ("C", "D", 4),
+    ...         ("D", "A", 14),
+    ...         ("D", "B", 15),
+    ...         ("D", "C", 2),
+    ...     }
+    ... )
     >>> cycle = approx.simulated_annealing_tsp(G, "greedy", source="D")
     >>> cost = sum(G[n][nbr]["weight"] for n, nbr in nx.utils.pairwise(cycle))
     >>> cycle
     ['D', 'C', 'B', 'A', 'D']
     >>> cost
     31
     >>> incycle = ["D", "B", "A", "C", "D"]
@@ -1217,15 +1246,15 @@
                     cost = adj_cost
         temp -= temp * alpha
 
     return best_cycle
 
 
 @py_random_state(9)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def threshold_accepting_tsp(
     G,
     init_cycle,
     weight="weight",
     source=None,
     threshold=1,
     move="1-1",
@@ -1245,15 +1274,15 @@
     The threshold is decreased slowly as iterations proceed helping to ensure
     an optimum. In summary, the function returns a cycle starting at `source`
     for which the total cost is minimized.
 
     Parameters
     ----------
     G : Graph
-        `G` should be a complete weighted undirected graph.
+        `G` should be a complete weighted graph.
         The distance between all pairs of nodes should be included.
 
     init_cycle : list or "greedy"
         The initial solution (a cycle through all nodes returning to the start).
         This argument has no default to make you think about it.
         If "greedy", use `greedy_tsp(G, weight)`.
         Other common starting cycles are `list(G) + [next(iter(G))]` or the final
@@ -1324,19 +1353,30 @@
     NetworkXError
         If `G` is not complete the algorithm raises an exception.
 
     Examples
     --------
     >>> from networkx.algorithms import approximation as approx
     >>> G = nx.DiGraph()
-    >>> G.add_weighted_edges_from({
-    ...     ("A", "B", 3), ("A", "C", 17), ("A", "D", 14), ("B", "A", 3),
-    ...     ("B", "C", 12), ("B", "D", 16), ("C", "A", 13),("C", "B", 12),
-    ...     ("C", "D", 4), ("D", "A", 14), ("D", "B", 15), ("D", "C", 2)
-    ... })
+    >>> G.add_weighted_edges_from(
+    ...     {
+    ...         ("A", "B", 3),
+    ...         ("A", "C", 17),
+    ...         ("A", "D", 14),
+    ...         ("B", "A", 3),
+    ...         ("B", "C", 12),
+    ...         ("B", "D", 16),
+    ...         ("C", "A", 13),
+    ...         ("C", "B", 12),
+    ...         ("C", "D", 4),
+    ...         ("D", "A", 14),
+    ...         ("D", "B", 15),
+    ...         ("D", "C", 2),
+    ...     }
+    ... )
     >>> cycle = approx.threshold_accepting_tsp(G, "greedy", source="D")
     >>> cost = sum(G[n][nbr]["weight"] for n, nbr in nx.utils.pairwise(cycle))
     >>> cycle
     ['D', 'C', 'B', 'A', 'D']
     >>> cost
     31
     >>> incycle = ["D", "B", "A", "C", "D"]
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/treewidth.py` & `networkx-3.3rc0/networkx/algorithms/approximation/treewidth.py`

 * *Files 6% similar despite different names*

```diff
@@ -37,15 +37,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["treewidth_min_degree", "treewidth_min_fill_in"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def treewidth_min_degree(G):
     """Returns a treewidth decomposition using the Minimum Degree heuristic.
 
     The heuristic chooses the nodes according to their degree, i.e., first
     the node with the lowest degree is chosen, then the graph is updated
     and the corresponding node is removed. Next, a new node with the lowest
     degree is chosen, and so on.
@@ -61,20 +61,20 @@
     """
     deg_heuristic = MinDegreeHeuristic(G)
     return treewidth_decomp(G, lambda graph: deg_heuristic.best_node(graph))
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def treewidth_min_fill_in(G):
     """Returns a treewidth decomposition using the Minimum Fill-in heuristic.
 
     The heuristic chooses a node from the graph, where the number of edges
-    added turning the neighbourhood of the chosen node into clique is as
+    added turning the neighborhood of the chosen node into clique is as
     small as possible.
 
     Parameters
     ----------
     G : NetworkX graph
 
     Returns
@@ -85,15 +85,15 @@
     return treewidth_decomp(G, min_fill_in_heuristic)
 
 
 class MinDegreeHeuristic:
     """Implements the Minimum Degree heuristic.
 
     The heuristic chooses the nodes according to their degree
-    (number of neighbours), i.e., first the node with the lowest degree is
+    (number of neighbors), i.e., first the node with the lowest degree is
     chosen, then the graph is updated and the corresponding node is
     removed. Next, a new node with the lowest degree is chosen, and so on.
     """
 
     def __init__(self, graph):
         self._graph = graph
 
@@ -132,15 +132,15 @@
         return None
 
 
 def min_fill_in_heuristic(graph):
     """Implements the Minimum Degree heuristic.
 
     Returns the node from the graph, where the number of edges added when
-    turning the neighbourhood of the chosen node into clique is as small as
+    turning the neighborhood of the chosen node into clique is as small as
     possible. This algorithm chooses the nodes using the Minimum Fill-In
     heuristic. The running time of the algorithm is :math:`O(V^3)` and it uses
     additional constant memory."""
 
     if len(graph) == 0:
         return None
 
@@ -173,15 +173,15 @@
                 return node
             min_fill_in = num_fill_in
             min_fill_in_node = node
 
     return min_fill_in_node
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def treewidth_decomp(G, heuristic=min_fill_in_heuristic):
     """Returns a treewidth decomposition using the passed heuristic.
 
     Parameters
     ----------
     G : NetworkX graph
     heuristic : heuristic function
@@ -197,15 +197,15 @@
 
     # stack containing nodes and neighbors in the order from the heuristic
     node_stack = []
 
     # get first node from heuristic
     elim_node = heuristic(graph)
     while elim_node is not None:
-        # connect all neighbours with each other
+        # connect all neighbors with each other
         nbrs = graph[elim_node]
         for u, v in itertools.permutations(nbrs, 2):
             if v not in graph[u]:
                 graph[u].add(v)
 
         # push node and its current neighbors on stack
         node_stack.append((elim_node, nbrs))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/approximation/vertex_cover.py` & `networkx-3.3rc0/networkx/algorithms/approximation/vertex_cover.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 
 """
 import networkx as nx
 
 __all__ = ["min_weighted_vertex_cover"]
 
 
-@nx._dispatch(node_attrs="weight")
+@nx._dispatchable(node_attrs="weight")
 def min_weighted_vertex_cover(G, weight=None):
     r"""Returns an approximate minimum weighted vertex cover.
 
     The set of nodes returned by this function is guaranteed to be a
     vertex cover, and the total weight of the set is guaranteed to be at
     most twice the total weight of the minimum weight vertex cover. In
     other words,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/connectivity.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/connectivity.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from collections import defaultdict
 
 import networkx as nx
 
 __all__ = ["average_degree_connectivity"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def average_degree_connectivity(
     G, source="in+out", target="in+out", nodes=None, weight=None
 ):
     r"""Compute the average degree connectivity of graph.
 
     The average degree connectivity is the average nearest neighbor degree of
     nodes with degree k. For weighted graphs, an analogous measure can
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/correlation.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/correlation.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
     "degree_pearson_correlation_coefficient",
     "degree_assortativity_coefficient",
     "attribute_assortativity_coefficient",
     "numeric_assortativity_coefficient",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def degree_assortativity_coefficient(G, x="out", y="in", weight=None, nodes=None):
     """Compute degree assortativity of graph.
 
     Assortativity measures the similarity of connections
     in the graph with respect to the node degree.
 
     Parameters
@@ -90,21 +90,21 @@
             if "out" in (x, y)
             else set()
         )
         degrees = set.union(indeg, outdeg)
     else:
         degrees = {d for _, d in G.degree(nodes, weight=weight)}
 
-    mapping = {d: i for i, d, in enumerate(degrees)}
+    mapping = {d: i for i, d in enumerate(degrees)}
     M = degree_mixing_matrix(G, x=x, y=y, nodes=nodes, weight=weight, mapping=mapping)
 
     return _numeric_ac(M, mapping=mapping)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def degree_pearson_correlation_coefficient(G, x="out", y="in", weight=None, nodes=None):
     """Compute degree assortativity of graph.
 
     Assortativity measures the similarity of connections
     in the graph with respect to the node degree.
 
     This is the same as degree_assortativity_coefficient but uses the
@@ -152,18 +152,18 @@
     .. [2] Foster, J.G., Foster, D.V., Grassberger, P. & Paczuski, M.
        Edge direction and the structure of networks, PNAS 107, 10815-20 (2010).
     """
     import scipy as sp
 
     xy = node_degree_xy(G, x=x, y=y, nodes=nodes, weight=weight)
     x, y = zip(*xy)
-    return sp.stats.pearsonr(x, y)[0]
+    return float(sp.stats.pearsonr(x, y)[0])
 
 
-@nx._dispatch(node_attrs="attribute")
+@nx._dispatchable(node_attrs="attribute")
 def attribute_assortativity_coefficient(G, attribute, nodes=None):
     """Compute assortativity for node attributes.
 
     Assortativity measures the similarity of connections
     in the graph with respect to the given attribute.
 
     Parameters
@@ -202,15 +202,15 @@
     .. [1] M. E. J. Newman, Mixing patterns in networks,
        Physical Review E, 67 026126, 2003
     """
     M = attribute_mixing_matrix(G, attribute, nodes)
     return attribute_ac(M)
 
 
-@nx._dispatch(node_attrs="attribute")
+@nx._dispatchable(node_attrs="attribute")
 def numeric_assortativity_coefficient(G, attribute, nodes=None):
     """Compute assortativity for numerical node attributes.
 
     Assortativity measures the similarity of connections
     in the graph with respect to the given numeric attribute.
 
     Parameters
@@ -247,15 +247,15 @@
     ----------
     .. [1] M. E. J. Newman, Mixing patterns in networks
            Physical Review E, 67 026126, 2003
     """
     if nodes is None:
         nodes = G.nodes
     vals = {G.nodes[n][attribute] for n in nodes}
-    mapping = {d: i for i, d, in enumerate(vals)}
+    mapping = {d: i for i, d in enumerate(vals)}
     M = attribute_mixing_matrix(G, attribute, nodes, mapping)
     return _numeric_ac(M, mapping)
 
 
 def attribute_ac(M):
     """Compute assortativity for attribute matrix M.
 
@@ -276,15 +276,15 @@
        Physical Review E, 67 026126, 2003
     """
     if M.sum() != 1.0:
         M = M / M.sum()
     s = (M @ M).sum()
     t = M.trace()
     r = (t - s) / (1 - s)
-    return r
+    return float(r)
 
 
 def _numeric_ac(M, mapping):
     # M is a 2D numpy array
     # numeric assortativity coefficient, pearsonr
     import numpy as np
 
@@ -295,8 +295,8 @@
     idx = list(mapping.values())
     a = M.sum(axis=0)
     b = M.sum(axis=1)
     vara = (a[idx] * x**2).sum() - ((a[idx] * x).sum()) ** 2
     varb = (b[idx] * y**2).sum() - ((b[idx] * y).sum()) ** 2
     xy = np.outer(x, y)
     ab = np.outer(a[idx], b[idx])
-    return (xy * (M - ab)).sum() / np.sqrt(vara * varb)
+    return float((xy * (M - ab)).sum() / np.sqrt(vara * varb))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/mixing.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/mixing.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     "attribute_mixing_dict",
     "degree_mixing_matrix",
     "degree_mixing_dict",
     "mixing_dict",
 ]
 
 
-@nx._dispatch(node_attrs="attribute")
+@nx._dispatchable(node_attrs="attribute")
 def attribute_mixing_dict(G, attribute, nodes=None, normalized=False):
     """Returns dictionary representation of mixing matrix for attribute.
 
     Parameters
     ----------
     G : graph
        NetworkX graph object.
@@ -49,15 +49,15 @@
     d : dictionary
        Counts or joint probability of occurrence of attribute pairs.
     """
     xy_iter = node_attribute_xy(G, attribute, nodes)
     return mixing_dict(xy_iter, normalized=normalized)
 
 
-@nx._dispatch(node_attrs="attribute")
+@nx._dispatchable(node_attrs="attribute")
 def attribute_mixing_matrix(G, attribute, nodes=None, mapping=None, normalized=True):
     """Returns mixing matrix for attribute.
 
     Parameters
     ----------
     G : graph
        NetworkX graph object.
@@ -94,30 +94,30 @@
     should include rows for attribute values that don't arise. Here we
     do not include such empty-rows. But you can force them to appear
     by inputting a `mapping` that includes those values.
 
     Examples
     --------
     >>> G = nx.path_graph(3)
-    >>> gender = {0: 'male', 1: 'female', 2: 'female'}
-    >>> nx.set_node_attributes(G, gender, 'gender')
-    >>> mapping = {'male': 0, 'female': 1}
-    >>> mix_mat = nx.attribute_mixing_matrix(G, 'gender', mapping=mapping)
+    >>> gender = {0: "male", 1: "female", 2: "female"}
+    >>> nx.set_node_attributes(G, gender, "gender")
+    >>> mapping = {"male": 0, "female": 1}
+    >>> mix_mat = nx.attribute_mixing_matrix(G, "gender", mapping=mapping)
     >>> # mixing from male nodes to female nodes
-    >>> mix_mat[mapping['male'], mapping['female']]
+    >>> mix_mat[mapping["male"], mapping["female"]]
     0.25
     """
     d = attribute_mixing_dict(G, attribute, nodes)
     a = dict_to_numpy_array(d, mapping=mapping)
     if normalized:
         a = a / a.sum()
     return a
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def degree_mixing_dict(G, x="out", y="in", weight=None, nodes=None, normalized=False):
     """Returns dictionary representation of mixing matrix for degree.
 
     Parameters
     ----------
     G : graph
         NetworkX graph object.
@@ -141,15 +141,15 @@
     d: dictionary
        Counts or joint probability of occurrence of degree pairs.
     """
     xy_iter = node_degree_xy(G, x=x, y=y, nodes=nodes, weight=weight)
     return mixing_dict(xy_iter, normalized=normalized)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def degree_mixing_matrix(
     G, x="out", y="in", weight=None, nodes=None, normalized=True, mapping=None
 ):
     """Returns mixing matrix for attribute.
 
     Parameters
     ----------
@@ -197,15 +197,15 @@
     >>> mix_mat[0, 1]  # mixing from node degree 1 to node degree 3
     0.5
 
     If you want every possible degree to appear as a row, even if no nodes
     have that degree, use `mapping` as follows,
 
     >>> max_degree = max(deg for n, deg in G.degree)
-    >>> mapping = {x: x for x in range(max_degree + 1)} # identity mapping
+    >>> mapping = {x: x for x in range(max_degree + 1)}  # identity mapping
     >>> mix_mat = nx.degree_mixing_matrix(G, mapping=mapping)
     >>> mix_mat[3, 1]  # mixing from node degree 3 to node degree 1
     0.5
     """
     d = degree_mixing_dict(G, x=x, y=y, nodes=nodes, weight=weight)
     a = dict_to_numpy_array(d, mapping=mapping)
     if normalized:
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/neighbor_degree.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/neighbor_degree.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import networkx as nx
 
 __all__ = ["average_neighbor_degree"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def average_neighbor_degree(G, source="out", target="out", nodes=None, weight=None):
     r"""Returns the average degree of the neighborhood of each node.
 
     In an undirected graph, the neighborhood `N(i)` of node `i` contains the
     nodes that are connected to `i` by an edge.
 
     For directed graphs, `N(i)` is defined according to the parameter `source`:
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/pairs.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/pairs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Generators of  x-y pairs of node data."""
 import networkx as nx
 
 __all__ = ["node_attribute_xy", "node_degree_xy"]
 
 
-@nx._dispatch(node_attrs="attribute")
+@nx._dispatchable(node_attrs="attribute")
 def node_attribute_xy(G, attribute, nodes=None):
     """Returns iterator of node-attribute pairs for all edges in G.
 
     Parameters
     ----------
     G: NetworkX graph
 
@@ -55,15 +55,15 @@
                     yield (uattr, vattr)
         else:
             for v in nbrsdict:
                 vattr = Gnodes[v].get(attribute, None)
                 yield (uattr, vattr)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def node_degree_xy(G, x="out", y="in", weight=None, nodes=None):
     """Generate node degree-degree pairs for edges in G.
 
     Parameters
     ----------
     G: NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/base_test.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/base_test.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_connectivity.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_connectivity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_correlation.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_correlation.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_mixing.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_mixing.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_neighbor_degree.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_neighbor_degree.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/assortativity/tests/test_pairs.py` & `networkx-3.3rc0/networkx/algorithms/assortativity/tests/test_pairs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/asteroidal.py` & `networkx-3.3rc0/networkx/algorithms/asteroidal.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["is_at_free", "find_asteroidal_triple"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def find_asteroidal_triple(G):
     r"""Find an asteroidal triple in the given graph.
 
     An asteroidal triple is a triple of non-adjacent vertices such that
     there exists a path between any two of them which avoids the closed
     neighborhood of the third. It checks all independent triples of vertices
     and whether they are an asteroidal triple or not. This is done with the
@@ -87,15 +87,15 @@
             ):
                 return [u, v, w]
     return None
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_at_free(G):
     """Check if a graph is AT-free.
 
     The method uses the `find_asteroidal_triple` method to recognize
     an AT-free graph. If no asteroidal triple is found the graph is
     AT-free and True is returned. If at least one asteroidal triple is
     found the graph is not AT-free and False is returned.
@@ -121,15 +121,15 @@
     False
     """
     return find_asteroidal_triple(G) is None
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def create_component_structure(G):
     r"""Create component structure for G.
 
     A *component structure* is an `nxn` array, denoted `c`, where `n` is
     the number of vertices,  where each row and column corresponds to a vertex.
 
     .. math::
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/__init__.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -80,7 +80,8 @@
 from networkx.algorithms.bipartite.edgelist import *
 from networkx.algorithms.bipartite.matching import *
 from networkx.algorithms.bipartite.matrix import *
 from networkx.algorithms.bipartite.projection import *
 from networkx.algorithms.bipartite.redundancy import *
 from networkx.algorithms.bipartite.spectral import *
 from networkx.algorithms.bipartite.generators import *
+from networkx.algorithms.bipartite.extendability import *
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/basic.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/basic.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     "color",
     "sets",
     "density",
     "degrees",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def color(G):
     """Returns a two-coloring of the graph.
 
     Raises an exception if the graph is not bipartite.
 
     Parameters
     ----------
@@ -79,15 +79,15 @@
                     color[w] = c
                     queue.append(w)
     # color isolates with 0
     color.update(dict.fromkeys(nx.isolates(G), 0))
     return color
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_bipartite(G):
     """Returns True if graph G is bipartite, False if not.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -105,15 +105,15 @@
     try:
         color(G)
         return True
     except nx.NetworkXError:
         return False
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_bipartite_node_set(G, nodes):
     """Returns True if nodes and G/nodes are a bipartition of G.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -150,15 +150,15 @@
         if not (
             (X.issubset(S) and Y.isdisjoint(S)) or (Y.issubset(S) and X.isdisjoint(S))
         ):
             return False
     return True
 
 
-@nx._dispatch
+@nx._dispatchable
 def sets(G, top_nodes=None):
     """Returns bipartite node sets of graph G.
 
     Raises an exception if the graph is not bipartite or if the input
     graph is disconnected and thus more than one valid solution exists.
     See :mod:`bipartite documentation <networkx.algorithms.bipartite>`
     for further details on how bipartite graphs are handled in NetworkX.
@@ -217,15 +217,15 @@
             raise nx.AmbiguousSolution(msg)
         c = color(G)
         X = {n for n, is_top in c.items() if is_top}
         Y = {n for n, is_top in c.items() if not is_top}
     return (X, Y)
 
 
-@nx._dispatch(graphs="B")
+@nx._dispatchable(graphs="B")
 def density(B, nodes):
     """Returns density of bipartite graph B.
 
     Parameters
     ----------
     B : NetworkX graph
 
@@ -270,15 +270,15 @@
         if B.is_directed():
             d = m / (2 * nb * nt)
         else:
             d = m / (nb * nt)
     return d
 
 
-@nx._dispatch(graphs="B", edge_attrs="weight")
+@nx._dispatchable(graphs="B", edge_attrs="weight")
 def degrees(B, nodes, weight=None):
     """Returns the degrees of the two node sets in the bipartite graph B.
 
     Parameters
     ----------
     B : NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/centrality.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/centrality.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import networkx as nx
 
 __all__ = ["degree_centrality", "betweenness_centrality", "closeness_centrality"]
 
 
-@nx._dispatch(name="bipartite_degree_centrality")
+@nx._dispatchable(name="bipartite_degree_centrality")
 def degree_centrality(G, nodes):
     r"""Compute the degree centrality for nodes in a bipartite network.
 
     The degree centrality for a node `v` is the fraction of nodes
     connected to it.
 
     Parameters
@@ -74,15 +74,15 @@
     s = 1.0 / len(bottom)
     centrality = {n: d * s for n, d in G.degree(top)}
     s = 1.0 / len(top)
     centrality.update({n: d * s for n, d in G.degree(bottom)})
     return centrality
 
 
-@nx._dispatch(name="bipartite_betweenness_centrality")
+@nx._dispatchable(name="bipartite_betweenness_centrality")
 def betweenness_centrality(G, nodes):
     r"""Compute betweenness centrality for nodes in a bipartite network.
 
     Betweenness centrality of a node `v` is the sum of the
     fraction of all-pairs shortest paths that pass through `v`.
 
     Values of betweenness are normalized by the maximum possible
@@ -178,15 +178,15 @@
     for node in top:
         betweenness[node] /= bet_max_top
     for node in bottom:
         betweenness[node] /= bet_max_bot
     return betweenness
 
 
-@nx._dispatch(name="bipartite_closeness_centrality")
+@nx._dispatchable(name="bipartite_closeness_centrality")
 def closeness_centrality(G, nodes, normalized=True):
     r"""Compute the closeness centrality for nodes in a bipartite network.
 
     The closeness of a node is the distance to all other nodes in the
     graph or in the case that the graph is not connected to all other nodes
     in the connected component containing that node.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/cluster.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/cluster.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 def cc_min(nu, nv):
     return len(nu & nv) / min(len(nu), len(nv))
 
 
 modes = {"dot": cc_dot, "min": cc_min, "max": cc_max}
 
 
-@nx._dispatch
+@nx._dispatchable
 def latapy_clustering(G, nodes=None, mode="dot"):
     r"""Compute a bipartite clustering coefficient for nodes.
 
     The bipartite clustering coefficient is a measure of local density
     of connections defined as [1]_:
 
     .. math::
@@ -130,15 +130,15 @@
         ccs[v] = cc
     return ccs
 
 
 clustering = latapy_clustering
 
 
-@nx._dispatch(name="bipartite_average_clustering")
+@nx._dispatchable(name="bipartite_average_clustering")
 def average_clustering(G, nodes=None, mode="dot"):
     r"""Compute the average bipartite clustering coefficient.
 
     A clustering coefficient for the whole graph is the average,
 
     .. math::
 
@@ -207,15 +207,15 @@
     """
     if nodes is None:
         nodes = G
     ccs = latapy_clustering(G, nodes=nodes, mode=mode)
     return sum(ccs[v] for v in nodes) / len(nodes)
 
 
-@nx._dispatch
+@nx._dispatchable
 def robins_alexander_clustering(G):
     r"""Compute the bipartite clustering of G.
 
     Robins and Alexander [1]_ defined bipartite clustering coefficient as
     four times the number of four cycles `C_4` divided by the number of
     three paths `L_3` in a bipartite graph:
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/covering.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/covering.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["min_edge_cover"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(name="bipartite_min_edge_cover")
+@nx._dispatchable(name="bipartite_min_edge_cover")
 def min_edge_cover(G, matching_algorithm=None):
     """Returns a set of edges which constitutes
     the minimum edge cover of the graph.
 
     The smallest edge cover can be found in polynomial time by finding
     a maximum matching and extending it greedily so that all nodes
     are covered.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/edgelist.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/edgelist.py`

 * *Files 2% similar despite different names*

```diff
@@ -142,15 +142,15 @@
                 try:
                     edge.extend(d[k] for k in data)
                 except KeyError:
                     pass  # missing data for this edge, should warn?
                 yield delimiter.join(map(str, edge))
 
 
-@nx._dispatch(name="bipartite_parse_edgelist", graphs=None)
+@nx._dispatchable(name="bipartite_parse_edgelist", graphs=None, returns_graph=True)
 def parse_edgelist(
     lines, comments="#", delimiter=None, create_using=None, nodetype=None, data=True
 ):
     """Parse lines of an edge list representation of a bipartite graph.
 
     Parameters
     ----------
@@ -227,27 +227,27 @@
         d = s
         if nodetype is not None:
             try:
                 u = nodetype(u)
                 v = nodetype(v)
             except BaseException as err:
                 raise TypeError(
-                    f"Failed to convert nodes {u},{v} " f"to type {nodetype}."
+                    f"Failed to convert nodes {u},{v} to type {nodetype}."
                 ) from err
 
         if len(d) == 0 or data is False:
             # no data or data type specified
             edgedata = {}
         elif data is True:
             # no edge types specified
             try:  # try to evaluate as dictionary
                 edgedata = dict(literal_eval(" ".join(d)))
             except BaseException as err:
                 raise TypeError(
-                    f"Failed to convert edge data ({d})" f"to dictionary."
+                    f"Failed to convert edge data ({d}) to dictionary."
                 ) from err
         else:
             # convert edge data to dictionary with specified keys and type
             if len(d) != len(data):
                 raise IndexError(
                     f"Edge data {d} and data_keys {data} are not the same length"
                 )
@@ -264,15 +264,15 @@
         G.add_node(u, bipartite=0)
         G.add_node(v, bipartite=1)
         G.add_edge(u, v, **edgedata)
     return G
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(name="bipartite_read_edgelist", graphs=None)
+@nx._dispatchable(name="bipartite_read_edgelist", graphs=None, returns_graph=True)
 def read_edgelist(
     path,
     comments="#",
     delimiter=None,
     create_using=None,
     nodetype=None,
     data=True,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/generators.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/generators.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,16 +16,16 @@
     "preferential_attachment_graph",
     "random_graph",
     "gnmk_random_graph",
     "complete_bipartite_graph",
 ]
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number([0, 1])
-@nx._dispatch(graphs=None)
 def complete_bipartite_graph(n1, n2, create_using=None):
     """Returns the complete bipartite graph `K_{n_1,n_2}`.
 
     The graph is composed of two partitions with nodes 0 to (n1 - 1)
     in the first and nodes n1 to (n1 + n2 - 1) in the second.
     Each node in the first is connected to each node in the second.
 
@@ -63,15 +63,15 @@
         raise nx.NetworkXError("Inputs n1 and n2 must contain distinct nodes")
     G.add_edges_from((u, v) for u in top for v in bottom)
     G.graph["name"] = f"complete_bipartite_graph({n1}, {n2})"
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(name="bipartite_configuration_model", graphs=None)
+@nx._dispatchable(name="bipartite_configuration_model", graphs=None, returns_graph=True)
 def configuration_model(aseq, bseq, create_using=None, seed=None):
     """Returns a random bipartite graph from two given degree sequences.
 
     Parameters
     ----------
     aseq : list
        Degree sequence for node set A.
@@ -134,15 +134,15 @@
 
     G.add_edges_from([astubs[i], bstubs[i]] for i in range(suma))
 
     G.name = "bipartite_configuration_model"
     return G
 
 
-@nx._dispatch(name="bipartite_havel_hakimi_graph", graphs=None)
+@nx._dispatchable(name="bipartite_havel_hakimi_graph", graphs=None, returns_graph=True)
 def havel_hakimi_graph(aseq, bseq, create_using=None):
     """Returns a bipartite graph from two given degree sequences using a
     Havel-Hakimi style construction.
 
     The graph is composed of two partitions. Set A has nodes 0 to
     (len(aseq) - 1) and set B has nodes len(aseq) to (len(bseq) - 1).
     Nodes from the set A are connected to nodes in the set B by
@@ -209,15 +209,15 @@
             if target[0] == 0:
                 bstubs.remove(target)
 
     G.name = "bipartite_havel_hakimi_graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def reverse_havel_hakimi_graph(aseq, bseq, create_using=None):
     """Returns a bipartite graph from two given degree sequences using a
     Havel-Hakimi style construction.
 
     The graph is composed of two partitions. Set A has nodes 0 to
     (len(aseq) - 1) and set B has nodes len(aseq) to (len(bseq) - 1).
     Nodes from set A are connected to nodes in the set B by connecting
@@ -283,15 +283,15 @@
             if target[0] == 0:
                 bstubs.remove(target)
 
     G.name = "bipartite_reverse_havel_hakimi_graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def alternating_havel_hakimi_graph(aseq, bseq, create_using=None):
     """Returns a bipartite graph from two given degree sequences using
     an alternating Havel-Hakimi style construction.
 
     The graph is composed of two partitions. Set A has nodes 0 to
     (len(aseq) - 1) and set B has nodes len(aseq) to (len(bseq) - 1).
     Nodes from the set A are connected to nodes in the set B by
@@ -362,15 +362,15 @@
                 bstubs.remove(target)
 
     G.name = "bipartite_alternating_havel_hakimi_graph"
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def preferential_attachment_graph(aseq, p, create_using=None, seed=None):
     """Create a bipartite graph with a preferential attachment model from
     a given single degree sequence.
 
     The graph is composed of two partitions. Set A has nodes 0 to
     (len(aseq) - 1) and set B has nodes starting with node len(aseq).
     The number of nodes in set B is random.
@@ -434,15 +434,15 @@
                 G.add_edge(source, target)
         vv.remove(vv[0])
     G.name = "bipartite_preferential_attachment_model"
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_graph(n, m, p, seed=None, directed=False):
     """Returns a bipartite random graph.
 
     This is a bipartite version of the binomial (Erdős-Rényi) graph.
     The graph is composed of two partitions. Set A has nodes 0 to
     (n - 1) and set B has nodes n to (n + m - 1).
 
@@ -521,15 +521,15 @@
             if v < n:
                 G.add_edge(n + w, v)
 
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def gnmk_random_graph(n, m, k, seed=None, directed=False):
     """Returns a random bipartite graph G_{n,m,k}.
 
     Produces a bipartite graph chosen randomly out of the set of all graphs
     with n top nodes, m bottom nodes, and k edges.
     The graph is composed of two sets of nodes.
     Set A has nodes 0 to (n - 1) and set B has nodes n to (n + m - 1).
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/matching.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/matching.py`

 * *Files 2% similar despite different names*

```diff
@@ -50,15 +50,15 @@
     "to_vertex_cover",
     "minimum_weight_full_matching",
 ]
 
 INFINITY = float("inf")
 
 
-@nx._dispatch
+@nx._dispatchable
 def hopcroft_karp_matching(G, top_nodes=None):
     """Returns the maximum cardinality matching of the bipartite graph `G`.
 
     A matching is a set of edges that do not share any nodes. A maximum
     cardinality matching is a matching with the most edges possible. It
     is not always unique. Finding a matching in a bipartite graph can be
     treated as a networkx flow problem.
@@ -177,15 +177,15 @@
     #
     #     leftmatches == {v, k for k, v in rightmatches.items()}
     #
     # Finally, we combine both the left matches and right matches.
     return dict(itertools.chain(leftmatches.items(), rightmatches.items()))
 
 
-@nx._dispatch
+@nx._dispatchable
 def eppstein_matching(G, top_nodes=None):
     """Returns the maximum cardinality matching of the bipartite graph `G`.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -416,15 +416,15 @@
         if v in targets
         or _is_connected_by_alternating_path(
             G, v, matched_edges, unmatched_edges, targets
         )
     }
 
 
-@nx._dispatch
+@nx._dispatchable
 def to_vertex_cover(G, matching, top_nodes=None):
     """Returns the minimum vertex cover corresponding to the given maximum
     matching of the bipartite graph `G`.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -497,15 +497,15 @@
 
 #: Returns the maximum cardinality matching in the given bipartite graph.
 #:
 #: This function is simply an alias for :func:`hopcroft_karp_matching`.
 maximum_matching = hopcroft_karp_matching
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def minimum_weight_full_matching(G, top_nodes=None, weight="weight"):
     r"""Returns a minimum weight full matching of the bipartite graph `G`.
 
     Let :math:`G = ((U, V), E)` be a weighted bipartite graph with real weights
     :math:`w : E \to \mathbb{R}`. This function then produces a matching
     :math:`M \subseteq E` with cardinality
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/matrix.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/matrix.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 import networkx as nx
 from networkx.convert_matrix import _generate_weighted_edges
 
 __all__ = ["biadjacency_matrix", "from_biadjacency_matrix"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def biadjacency_matrix(
     G, row_order, column_order=None, dtype=None, weight="weight", format="csr"
 ):
     r"""Returns the biadjacency matrix of the bipartite graph G.
 
     Let `G = (U, V, E)` be a bipartite graph with node sets
     `U = u_{1},...,u_{r}` and `V = v_{1},...,v_{s}`. The biadjacency
@@ -106,15 +106,15 @@
     A = sp.sparse.coo_array((data, (row, col)), shape=(nlen, mlen), dtype=dtype)
     try:
         return A.asformat(format)
     except ValueError as err:
         raise nx.NetworkXError(f"Unknown sparse array format: {format}") from err
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_biadjacency_matrix(A, create_using=None, edge_attribute="weight"):
     r"""Creates a new bipartite graph from a biadjacency matrix given as a
     SciPy sparse array.
 
     Parameters
     ----------
     A: scipy sparse array
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/projection.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/projection.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,17 @@
     "weighted_projected_graph",
     "collaboration_weighted_projected_graph",
     "overlap_weighted_projected_graph",
     "generic_weighted_projected_graph",
 ]
 
 
-@nx._dispatch(graphs="B", preserve_node_attrs=True, preserve_graph_attrs=True)
+@nx._dispatchable(
+    graphs="B", preserve_node_attrs=True, preserve_graph_attrs=True, returns_graph=True
+)
 def projected_graph(B, nodes, multigraph=False):
     r"""Returns the projection of B onto one of its node sets.
 
     Returns the graph G that is the projection of the bipartite graph B
     onto the specified nodes. They retain their attributes and are connected
     in G if they have a common neighbor in B.
 
@@ -113,15 +115,15 @@
                         G.add_edge(u, n, key=l)
         else:
             G.add_edges_from((u, n) for n in nbrs2)
     return G
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs="B")
+@nx._dispatchable(graphs="B", returns_graph=True)
 def weighted_projected_graph(B, nodes, ratio=False):
     r"""Returns a weighted projection of B onto one of its node sets.
 
     The weighted projected graph is the projection of the bipartite
     network B onto the specified nodes with weights representing the
     number of shared neighbors or the ratio between actual shared
     neighbors and possible shared neighbors if ``ratio is True`` [1]_.
@@ -214,15 +216,15 @@
             else:
                 weight = len(common) / n_top
             G.add_edge(u, v, weight=weight)
     return G
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs="B")
+@nx._dispatchable(graphs="B", returns_graph=True)
 def collaboration_weighted_projected_graph(B, nodes):
     r"""Newman's weighted projection of B onto one of its node sets.
 
     The collaboration weighted projection is the projection of the
     bipartite network B onto the specified nodes with weights assigned
     using Newman's collaboration model [1]_:
 
@@ -259,15 +261,14 @@
     >>> B = nx.path_graph(5)
     >>> B.add_edge(1, 5)
     >>> G = bipartite.collaboration_weighted_projected_graph(B, [0, 2, 4, 5])
     >>> list(G)
     [0, 2, 4, 5]
     >>> for edge in sorted(G.edges(data=True)):
     ...     print(edge)
-    ...
     (0, 2, {'weight': 0.5})
     (0, 5, {'weight': 0.5})
     (2, 4, {'weight': 1.0})
     (2, 5, {'weight': 0.5})
 
     Notes
     -----
@@ -309,15 +310,15 @@
             common_degree = (len(B[n]) for n in unbrs & vnbrs)
             weight = sum(1.0 / (deg - 1) for deg in common_degree if deg > 1)
             G.add_edge(u, v, weight=weight)
     return G
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs="B")
+@nx._dispatchable(graphs="B", returns_graph=True)
 def overlap_weighted_projected_graph(B, nodes, jaccard=True):
     r"""Overlap weighted projection of B onto one of its node sets.
 
     The overlap weighted projection is the projection of the bipartite
     network B onto the specified nodes with weights representing
     the Jaccard index between the neighborhoods of the two nodes in the
     original bipartite network [1]_:
@@ -409,15 +410,15 @@
             else:
                 wt = len(unbrs & vnbrs) / min(len(unbrs), len(vnbrs))
             G.add_edge(u, v, weight=wt)
     return G
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs="B", preserve_all_attrs=True)
+@nx._dispatchable(graphs="B", preserve_all_attrs=True, returns_graph=True)
 def generic_weighted_projected_graph(B, nodes, weight_function=None):
     r"""Weighted projection of B with a user-specified weight function.
 
     The bipartite network B is projected on to the specified nodes
     with weights computed by a user-specified function.  This function
     must accept as a parameter the neighborhood sets of two nodes and
     return an integer or a float.
@@ -447,47 +448,39 @@
     --------
     >>> from networkx.algorithms import bipartite
     >>> # Define some custom weight functions
     >>> def jaccard(G, u, v):
     ...     unbrs = set(G[u])
     ...     vnbrs = set(G[v])
     ...     return float(len(unbrs & vnbrs)) / len(unbrs | vnbrs)
-    ...
     >>> def my_weight(G, u, v, weight="weight"):
     ...     w = 0
     ...     for nbr in set(G[u]) & set(G[v]):
     ...         w += G[u][nbr].get(weight, 1) + G[v][nbr].get(weight, 1)
     ...     return w
-    ...
     >>> # A complete bipartite graph with 4 nodes and 4 edges
     >>> B = nx.complete_bipartite_graph(2, 2)
     >>> # Add some arbitrary weight to the edges
     >>> for i, (u, v) in enumerate(B.edges()):
     ...     B.edges[u, v]["weight"] = i + 1
-    ...
     >>> for edge in B.edges(data=True):
     ...     print(edge)
-    ...
     (0, 2, {'weight': 1})
     (0, 3, {'weight': 2})
     (1, 2, {'weight': 3})
     (1, 3, {'weight': 4})
     >>> # By default, the weight is the number of shared neighbors
     >>> G = bipartite.generic_weighted_projected_graph(B, [0, 1])
     >>> print(list(G.edges(data=True)))
     [(0, 1, {'weight': 2})]
     >>> # To specify a custom weight function use the weight_function parameter
-    >>> G = bipartite.generic_weighted_projected_graph(
-    ...     B, [0, 1], weight_function=jaccard
-    ... )
+    >>> G = bipartite.generic_weighted_projected_graph(B, [0, 1], weight_function=jaccard)
     >>> print(list(G.edges(data=True)))
     [(0, 1, {'weight': 1.0})]
-    >>> G = bipartite.generic_weighted_projected_graph(
-    ...     B, [0, 1], weight_function=my_weight
-    ... )
+    >>> G = bipartite.generic_weighted_projected_graph(B, [0, 1], weight_function=my_weight)
     >>> print(list(G.edges(data=True)))
     [(0, 1, {'weight': 10})]
 
     Notes
     -----
     No attempt is made to verify that the input graph B is bipartite.
     The graph and node properties are (shallow) copied to the projected graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/redundancy.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/redundancy.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import networkx as nx
 from networkx import NetworkXError
 
 __all__ = ["node_redundancy"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def node_redundancy(G, nodes=None):
     r"""Computes the node redundancy coefficients for the nodes in the bipartite
     graph `G`.
 
     The redundancy coefficient of a node `v` is the fraction of pairs of
     neighbors of `v` that are both linked to other nodes. In a one-mode
     projection these nodes would be linked together even if `v` were
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/spectral.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/spectral.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Spectral bipartivity measure.
 """
 import networkx as nx
 
 __all__ = ["spectral_bipartivity"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def spectral_bipartivity(G, nodes=None, weight="weight"):
     """Returns the spectral bipartivity.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -53,16 +53,16 @@
     nodelist = list(G)  # ordering of nodes in matrix
     A = nx.to_numpy_array(G, nodelist, weight=weight)
     expA = sp.linalg.expm(A)
     expmA = sp.linalg.expm(-A)
     coshA = 0.5 * (expA + expmA)
     if nodes is None:
         # return single number for entire graph
-        return coshA.diagonal().sum() / expA.diagonal().sum()
+        return float(coshA.diagonal().sum() / expA.diagonal().sum())
     else:
         # contribution for individual nodes
         index = dict(zip(nodelist, range(len(nodelist))))
         sb = {}
         for n in nodes:
             i = index[n]
-            sb[n] = coshA[i, i] / expA[i, i]
+            sb[n] = coshA.item(i, i) / expA.item(i, i)
         return sb
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_basic.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_basic.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_centrality.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_cluster.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_cluster.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_covering.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_covering.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_edgelist.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_edgelist.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 """
     Unit tests for bipartite edgelists.
 """
 import io
-import os
-import tempfile
 
 import pytest
 
 import networkx as nx
 from networkx.algorithms import bipartite
 from networkx.utils import edges_equal, graphs_equal, nodes_equal
 
@@ -97,92 +95,82 @@
         G.add_node(1, bipartite=0)
         G.add_node(2, bipartite=1)
         G.add_node(3, bipartite=0)
         bipartite.write_edgelist(G, fh, data=[("weight")])
         fh.seek(0)
         assert fh.read() == b"1 2 2.0\n3 2 3.0\n"
 
-    def test_unicode(self):
+    def test_unicode(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
         G.add_node(name1, bipartite=0)
         G.add_node("Radiohead", bipartite=1)
-        fd, fname = tempfile.mkstemp()
+
+        fname = tmp_path / "edgelist.txt"
         bipartite.write_edgelist(G, fname)
         H = bipartite.read_edgelist(fname)
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_latin1_issue(self):
+    def test_latin1_issue(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
         G.add_node(name1, bipartite=0)
         G.add_node("Radiohead", bipartite=1)
-        fd, fname = tempfile.mkstemp()
-        pytest.raises(
-            UnicodeEncodeError, bipartite.write_edgelist, G, fname, encoding="latin-1"
-        )
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_latin1(self):
+        fname = tmp_path / "edgelist.txt"
+        with pytest.raises(UnicodeEncodeError):
+            bipartite.write_edgelist(G, fname, encoding="latin-1")
+
+    def test_latin1(self, tmp_path):
         G = nx.Graph()
         name1 = "Bj" + chr(246) + "rk"
         name2 = chr(220) + "ber"
         G.add_edge(name1, "Radiohead", **{name2: 3})
         G.add_node(name1, bipartite=0)
         G.add_node("Radiohead", bipartite=1)
-        fd, fname = tempfile.mkstemp()
+
+        fname = tmp_path / "edgelist.txt"
         bipartite.write_edgelist(G, fname, encoding="latin-1")
         H = bipartite.read_edgelist(fname, encoding="latin-1")
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_graph(self):
+    def test_edgelist_graph(self, tmp_path):
         G = self.G
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "edgelist.txt"
         bipartite.write_edgelist(G, fname)
         H = bipartite.read_edgelist(fname)
         H2 = bipartite.read_edgelist(fname)
         assert H is not H2  # they should be different graphs
         G.remove_node("g")  # isolated nodes are not written in edgelist
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_integers(self):
+    def test_edgelist_integers(self, tmp_path):
         G = nx.convert_node_labels_to_integers(self.G)
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "edgelist.txt"
         bipartite.write_edgelist(G, fname)
         H = bipartite.read_edgelist(fname, nodetype=int)
         # isolated nodes are not written in edgelist
         G.remove_nodes_from(list(nx.isolates(G)))
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_multigraph(self):
+    def test_edgelist_multigraph(self, tmp_path):
         G = self.MG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "edgelist.txt"
         bipartite.write_edgelist(G, fname)
         H = bipartite.read_edgelist(fname, nodetype=int, create_using=nx.MultiGraph())
         H2 = bipartite.read_edgelist(fname, nodetype=int, create_using=nx.MultiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
     def test_empty_digraph(self):
         with pytest.raises(nx.NetworkXNotImplemented):
             bytesIO = io.BytesIO()
             bipartite.write_edgelist(nx.DiGraph(), bytesIO)
 
     def test_raise_attribute(self):
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_generators.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_generators.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_matching.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_matching.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_matrix.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_matrix.py`

 * *Files 4% similar despite different names*

```diff
@@ -35,14 +35,19 @@
         G = nx.path_graph(5)
         G.add_edge(0, 1, weight=2)
         X = [3, 1]
         Y = [4, 2, 0]
         M = bipartite.biadjacency_matrix(G, X, Y, weight="weight")
         assert M[1, 2] == 2
 
+    def test_biadjacency_matrix_empty_graph(self):
+        G = nx.empty_graph(2)
+        M = nx.bipartite.biadjacency_matrix(G, [0])
+        assert np.array_equal(M.toarray(), np.array([[0]]))
+
     def test_null_graph(self):
         with pytest.raises(nx.NetworkXError):
             bipartite.biadjacency_matrix(nx.Graph(), [])
 
     def test_empty_graph(self):
         with pytest.raises(nx.NetworkXError):
             bipartite.biadjacency_matrix(nx.Graph([(1, 0)]), [])
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_project.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_project.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_redundancy.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_redundancy.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/bipartite/tests/test_spectral_bipartivity.py` & `networkx-3.3rc0/networkx/algorithms/bipartite/tests/test_spectral_bipartivity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/boundary.py` & `networkx-3.3rc0/networkx/algorithms/boundary.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 from itertools import chain
 
 import networkx as nx
 
 __all__ = ["edge_boundary", "node_boundary"]
 
 
-@nx._dispatch(edge_attrs={"data": "default"}, preserve_edge_attrs="data")
+@nx._dispatchable(edge_attrs={"data": "default"}, preserve_edge_attrs="data")
 def edge_boundary(G, nbunch1, nbunch2=None, data=False, keys=False, default=None):
     """Returns the edge boundary of `nbunch1`.
 
     The *edge boundary* of a set *S* with respect to a set *T* is the
     set of edges (*u*, *v*) such that *u* is in *S* and *v* is in *T*.
     If *T* is not specified, it is assumed to be the set of all nodes
     not in *S*.
@@ -102,15 +102,15 @@
     return (
         e
         for e in edges
         if (e[0] in nset1 and e[1] in nset2) or (e[1] in nset1 and e[0] in nset2)
     )
 
 
-@nx._dispatch
+@nx._dispatchable
 def node_boundary(G, nbunch1, nbunch2=None):
     """Returns the node boundary of `nbunch1`.
 
     The *node boundary* of a set *S* with respect to a set *T* is the
     set of nodes *v* in *T* such that for some *u* in *S*, there is an
     edge joining *u* to *v*. If *T* is not specified, it is assumed to
     be the set of all nodes not in *S*.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/bridges.py` & `networkx-3.3rc0/networkx/algorithms/bridges.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["bridges", "has_bridges", "local_bridges"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def bridges(G, root=None):
     """Generate all bridges in a graph.
 
     A *bridge* in a graph is an edge whose removal causes the number of
     connected components of the graph to increase.  Equivalently, a bridge is an
     edge that does not belong to any cycle. Bridges are also known as cut-edges,
     isthmuses, or cut arcs.
@@ -77,15 +77,15 @@
         if (u, v) not in chain_edges and (v, u) not in chain_edges:
             if multigraph and len(G[u][v]) > 1:
                 continue
             yield u, v
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def has_bridges(G, root=None):
     """Decide whether a graph has any bridges.
 
     A *bridge* in a graph is an edge whose removal causes the number of
     connected components of the graph to increase.
 
     Parameters
@@ -138,15 +138,15 @@
         return False
     else:
         return True
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def local_bridges(G, with_span=True, weight=None):
     """Iterate over local bridges of `G` optionally computing the span
 
     A *local bridge* is an edge whose endpoints have no common neighbors.
     That is, the edge is not part of a triangle in the graph.
 
     The *span* of a *local bridge* is the shortest path length between
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/__init__.py` & `networkx-3.3rc0/networkx/algorithms/centrality/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/betweenness.py` & `networkx-3.3rc0/networkx/algorithms/centrality/betweenness.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 from networkx.utils import py_random_state
 from networkx.utils.decorators import not_implemented_for
 
 __all__ = ["betweenness_centrality", "edge_betweenness_centrality"]
 
 
 @py_random_state(5)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def betweenness_centrality(
     G, k=None, normalized=True, weight=None, endpoints=False, seed=None
 ):
     r"""Compute the shortest-path betweenness centrality for nodes.
 
     Betweenness centrality of a node $v$ is the sum of the
     fraction of all-pairs shortest paths that pass through $v$
@@ -150,15 +150,15 @@
         k=k,
         endpoints=endpoints,
     )
     return betweenness
 
 
 @py_random_state(4)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):
     r"""Compute betweenness centrality for edges.
 
     Betweenness centrality of an edge $e$ is the sum of the
     fraction of all-pairs shortest paths that pass through $e$
 
     .. math::
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/betweenness_subset.py` & `networkx-3.3rc0/networkx/algorithms/centrality/betweenness_subset.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 __all__ = [
     "betweenness_centrality_subset",
     "edge_betweenness_centrality_subset",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def betweenness_centrality_subset(G, sources, targets, normalized=False, weight=None):
     r"""Compute betweenness centrality for a subset of nodes.
 
     .. math::
 
        c_B(v) =\sum_{s\in S, t \in T} \frac{\sigma(s, t|v)}{\sigma(s, t)}
 
@@ -110,15 +110,15 @@
         else:  # use Dijkstra's algorithm
             S, P, sigma, _ = dijkstra(G, s, weight)
         b = _accumulate_subset(b, S, P, sigma, s, targets)
     b = _rescale(b, len(G), normalized=normalized, directed=G.is_directed())
     return b
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def edge_betweenness_centrality_subset(
     G, sources, targets, normalized=False, weight=None
 ):
     r"""Compute betweenness centrality for edges for a subset of nodes.
 
     .. math::
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/closeness.py` & `networkx-3.3rc0/networkx/algorithms/centrality/closeness.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import networkx as nx
 from networkx.exception import NetworkXError
 from networkx.utils.decorators import not_implemented_for
 
 __all__ = ["closeness_centrality", "incremental_closeness_centrality"]
 
 
-@nx._dispatch(edge_attrs="distance")
+@nx._dispatchable(edge_attrs="distance")
 def closeness_centrality(G, u=None, distance=None, wf_improved=True):
     r"""Compute closeness centrality for nodes.
 
     Closeness centrality [1]_ of a node `u` is the reciprocal of the
     average shortest path distance to `u` over all `n-1` reachable nodes.
 
     .. math::
@@ -133,15 +133,15 @@
         closeness_dict[n] = _closeness_centrality
     if u is not None:
         return closeness_dict[u]
     return closeness_dict
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable(mutates_input=True)
 def incremental_closeness_centrality(
     G, edge, prev_cc=None, insertion=True, wf_improved=True
 ):
     r"""Incremental closeness centrality for nodes.
 
     Compute closeness centrality for nodes using level-based work filtering
     as described in Incremental Algorithms for Closeness Centrality by Sariyuce et al.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/current_flow_betweenness.py` & `networkx-3.3rc0/networkx/algorithms/centrality/current_flow_betweenness.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     "approximate_current_flow_betweenness_centrality",
     "edge_current_flow_betweenness_centrality",
 ]
 
 
 @not_implemented_for("directed")
 @py_random_state(7)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def approximate_current_flow_betweenness_centrality(
     G,
     normalized=True,
     weight=None,
     dtype=float,
     solver="full",
     epsilon=0.5,
@@ -130,25 +130,25 @@
         b[t] = -1
         p = C.solve(b)
         for v in H:
             if v in pair:
                 continue
             for nbr in H[v]:
                 w = H[v][nbr].get(weight, 1.0)
-                betweenness[v] += w * np.abs(p[v] - p[nbr]) * cstar2k
+                betweenness[v] += float(w * np.abs(p[v] - p[nbr]) * cstar2k)
     if normalized:
         factor = 1.0
     else:
         factor = nb / 2.0
     # remap to original node names and "unnormalize" if required
     return {ordering[k]: v * factor for k, v in betweenness.items()}
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def current_flow_betweenness_centrality(
     G, normalized=True, weight=None, dtype=float, solver="full"
 ):
     r"""Compute current-flow betweenness centrality for nodes.
 
     Current-flow betweenness centrality uses an electrical current
     model for information spreading in contrast to betweenness
@@ -216,36 +216,34 @@
        https://doi.org/10.1007/978-3-540-31856-9_44
 
     .. [2] A measure of betweenness centrality based on random walks,
        M. E. J. Newman, Social Networks 27, 39-54 (2005).
     """
     if not nx.is_connected(G):
         raise nx.NetworkXError("Graph not connected.")
-    n = G.number_of_nodes()
+    N = G.number_of_nodes()
     ordering = list(reverse_cuthill_mckee_ordering(G))
     # make a copy with integer labels according to rcm ordering
     # this could be done without a copy if we really wanted to
-    H = nx.relabel_nodes(G, dict(zip(ordering, range(n))))
-    betweenness = dict.fromkeys(H, 0.0)  # b[v]=0 for v in H
+    H = nx.relabel_nodes(G, dict(zip(ordering, range(N))))
+    betweenness = dict.fromkeys(H, 0.0)  # b[n]=0 for n in H
     for row, (s, t) in flow_matrix_row(H, weight=weight, dtype=dtype, solver=solver):
-        pos = dict(zip(row.argsort()[::-1], range(n)))
-        for i in range(n):
-            betweenness[s] += (i - pos[i]) * row[i]
-            betweenness[t] += (n - i - 1 - pos[i]) * row[i]
+        pos = dict(zip(row.argsort()[::-1], range(N)))
+        for i in range(N):
+            betweenness[s] += (i - pos[i]) * row.item(i)
+            betweenness[t] += (N - i - 1 - pos[i]) * row.item(i)
     if normalized:
-        nb = (n - 1.0) * (n - 2.0)  # normalization factor
+        nb = (N - 1.0) * (N - 2.0)  # normalization factor
     else:
         nb = 2.0
-    for v in H:
-        betweenness[v] = float((betweenness[v] - v) * 2.0 / nb)
-    return {ordering[k]: v for k, v in betweenness.items()}
+    return {ordering[n]: (b - n) * 2.0 / nb for n, b in betweenness.items()}
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def edge_current_flow_betweenness_centrality(
     G, normalized=True, weight=None, dtype=float, solver="full"
 ):
     r"""Compute current-flow betweenness centrality for edges.
 
     Current-flow betweenness centrality uses an electrical current
     model for information spreading in contrast to betweenness
@@ -319,25 +317,25 @@
        https://doi.org/10.1007/978-3-540-31856-9_44
 
     .. [2] A measure of betweenness centrality based on random walks,
        M. E. J. Newman, Social Networks 27, 39-54 (2005).
     """
     if not nx.is_connected(G):
         raise nx.NetworkXError("Graph not connected.")
-    n = G.number_of_nodes()
+    N = G.number_of_nodes()
     ordering = list(reverse_cuthill_mckee_ordering(G))
     # make a copy with integer labels according to rcm ordering
     # this could be done without a copy if we really wanted to
-    H = nx.relabel_nodes(G, dict(zip(ordering, range(n))))
+    H = nx.relabel_nodes(G, dict(zip(ordering, range(N))))
     edges = (tuple(sorted((u, v))) for u, v in H.edges())
     betweenness = dict.fromkeys(edges, 0.0)
     if normalized:
-        nb = (n - 1.0) * (n - 2.0)  # normalization factor
+        nb = (N - 1.0) * (N - 2.0)  # normalization factor
     else:
         nb = 2.0
     for row, (e) in flow_matrix_row(H, weight=weight, dtype=dtype, solver=solver):
-        pos = dict(zip(row.argsort()[::-1], range(1, n + 1)))
-        for i in range(n):
-            betweenness[e] += (i + 1 - pos[i]) * row[i]
-            betweenness[e] += (n - i - pos[i]) * row[i]
+        pos = dict(zip(row.argsort()[::-1], range(1, N + 1)))
+        for i in range(N):
+            betweenness[e] += (i + 1 - pos[i]) * row.item(i)
+            betweenness[e] += (N - i - pos[i]) * row.item(i)
         betweenness[e] /= nb
-    return {(ordering[s], ordering[t]): v for (s, t), v in betweenness.items()}
+    return {(ordering[s], ordering[t]): b for (s, t), b in betweenness.items()}
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/current_flow_betweenness_subset.py` & `networkx-3.3rc0/networkx/algorithms/centrality/current_flow_betweenness_subset.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 __all__ = [
     "current_flow_betweenness_centrality_subset",
     "edge_current_flow_betweenness_centrality_subset",
 ]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def current_flow_betweenness_centrality_subset(
     G, sources, targets, normalized=True, weight=None, dtype=float, solver="lu"
 ):
     r"""Compute current-flow betweenness centrality for subsets of nodes.
 
     Current-flow betweenness centrality uses an electrical current
     model for information spreading in contrast to betweenness
@@ -92,39 +92,39 @@
     """
     import numpy as np
 
     from networkx.utils import reverse_cuthill_mckee_ordering
 
     if not nx.is_connected(G):
         raise nx.NetworkXError("Graph not connected.")
-    n = G.number_of_nodes()
+    N = G.number_of_nodes()
     ordering = list(reverse_cuthill_mckee_ordering(G))
     # make a copy with integer labels according to rcm ordering
     # this could be done without a copy if we really wanted to
-    mapping = dict(zip(ordering, range(n)))
+    mapping = dict(zip(ordering, range(N)))
     H = nx.relabel_nodes(G, mapping)
-    betweenness = dict.fromkeys(H, 0.0)  # b[v]=0 for v in H
+    betweenness = dict.fromkeys(H, 0.0)  # b[n]=0 for n in H
     for row, (s, t) in flow_matrix_row(H, weight=weight, dtype=dtype, solver=solver):
         for ss in sources:
             i = mapping[ss]
             for tt in targets:
                 j = mapping[tt]
-                betweenness[s] += 0.5 * np.abs(row[i] - row[j])
-                betweenness[t] += 0.5 * np.abs(row[i] - row[j])
+                betweenness[s] += 0.5 * abs(row.item(i) - row.item(j))
+                betweenness[t] += 0.5 * abs(row.item(i) - row.item(j))
     if normalized:
-        nb = (n - 1.0) * (n - 2.0)  # normalization factor
+        nb = (N - 1.0) * (N - 2.0)  # normalization factor
     else:
         nb = 2.0
-    for v in H:
-        betweenness[v] = betweenness[v] / nb + 1.0 / (2 - n)
-    return {ordering[k]: v for k, v in betweenness.items()}
+    for node in H:
+        betweenness[node] = betweenness[node] / nb + 1.0 / (2 - N)
+    return {ordering[node]: value for node, value in betweenness.items()}
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def edge_current_flow_betweenness_centrality_subset(
     G, sources, targets, normalized=True, weight=None, dtype=float, solver="lu"
 ):
     r"""Compute current-flow betweenness centrality for edges using subsets
     of nodes.
 
     Current-flow betweenness centrality uses an electrical current
@@ -200,27 +200,27 @@
     .. [2] A measure of betweenness centrality based on random walks,
        M. E. J. Newman, Social Networks 27, 39-54 (2005).
     """
     import numpy as np
 
     if not nx.is_connected(G):
         raise nx.NetworkXError("Graph not connected.")
-    n = G.number_of_nodes()
+    N = G.number_of_nodes()
     ordering = list(reverse_cuthill_mckee_ordering(G))
     # make a copy with integer labels according to rcm ordering
     # this could be done without a copy if we really wanted to
-    mapping = dict(zip(ordering, range(n)))
+    mapping = dict(zip(ordering, range(N)))
     H = nx.relabel_nodes(G, mapping)
     edges = (tuple(sorted((u, v))) for u, v in H.edges())
     betweenness = dict.fromkeys(edges, 0.0)
     if normalized:
-        nb = (n - 1.0) * (n - 2.0)  # normalization factor
+        nb = (N - 1.0) * (N - 2.0)  # normalization factor
     else:
         nb = 2.0
     for row, (e) in flow_matrix_row(H, weight=weight, dtype=dtype, solver=solver):
         for ss in sources:
             i = mapping[ss]
             for tt in targets:
                 j = mapping[tt]
-                betweenness[e] += 0.5 * np.abs(row[i] - row[j])
+                betweenness[e] += 0.5 * abs(row.item(i) - row.item(j))
         betweenness[e] /= nb
-    return {(ordering[s], ordering[t]): v for (s, t), v in betweenness.items()}
+    return {(ordering[s], ordering[t]): value for (s, t), value in betweenness.items()}
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/current_flow_closeness.py` & `networkx-3.3rc0/networkx/algorithms/centrality/current_flow_closeness.py`

 * *Files 16% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 )
 from networkx.utils import not_implemented_for, reverse_cuthill_mckee_ordering
 
 __all__ = ["current_flow_closeness_centrality", "information_centrality"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def current_flow_closeness_centrality(G, weight=None, dtype=float, solver="lu"):
     """Compute current-flow closeness centrality for nodes.
 
     Current-flow closeness centrality is variant of closeness
     centrality based on effective resistance between nodes in
     a network. This metric is also known as information centrality.
 
@@ -70,28 +70,26 @@
     if not nx.is_connected(G):
         raise nx.NetworkXError("Graph not connected.")
     solvername = {
         "full": FullInverseLaplacian,
         "lu": SuperLUInverseLaplacian,
         "cg": CGInverseLaplacian,
     }
-    n = G.number_of_nodes()
+    N = G.number_of_nodes()
     ordering = list(reverse_cuthill_mckee_ordering(G))
     # make a copy with integer labels according to rcm ordering
     # this could be done without a copy if we really wanted to
-    H = nx.relabel_nodes(G, dict(zip(ordering, range(n))))
-    betweenness = dict.fromkeys(H, 0.0)  # b[v]=0 for v in H
-    n = H.number_of_nodes()
-    L = nx.laplacian_matrix(H, nodelist=range(n), weight=weight).asformat("csc")
+    H = nx.relabel_nodes(G, dict(zip(ordering, range(N))))
+    betweenness = dict.fromkeys(H, 0.0)  # b[n]=0 for n in H
+    N = H.number_of_nodes()
+    L = nx.laplacian_matrix(H, nodelist=range(N), weight=weight).asformat("csc")
     L = L.astype(dtype)
     C2 = solvername[solver](L, width=1, dtype=dtype)  # initialize solver
     for v in H:
         col = C2.get_row(v)
         for w in H:
-            betweenness[v] += col[v] - 2 * col[w]
-            betweenness[w] += col[v]
-    for v in H:
-        betweenness[v] = 1 / (betweenness[v])
-    return {ordering[k]: v for k, v in betweenness.items()}
+            betweenness[v] += col.item(v) - 2 * col.item(w)
+            betweenness[w] += col.item(v)
+    return {ordering[node]: 1 / value for node, value in betweenness.items()}
 
 
 information_centrality = current_flow_closeness_centrality
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/degree_alg.py` & `networkx-3.3rc0/networkx/algorithms/centrality/degree_alg.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Degree centrality measures."""
 import networkx as nx
 from networkx.utils.decorators import not_implemented_for
 
 __all__ = ["degree_centrality", "in_degree_centrality", "out_degree_centrality"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def degree_centrality(G):
     """Compute the degree centrality for nodes.
 
     The degree centrality for a node v is the fraction of nodes it
     is connected to.
 
     Parameters
@@ -46,15 +46,15 @@
 
     s = 1.0 / (len(G) - 1.0)
     centrality = {n: d * s for n, d in G.degree()}
     return centrality
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def in_degree_centrality(G):
     """Compute the in-degree centrality for nodes.
 
     The in-degree centrality for a node v is the fraction of nodes its
     incoming edges are connected to.
 
     Parameters
@@ -96,15 +96,15 @@
 
     s = 1.0 / (len(G) - 1.0)
     centrality = {n: d * s for n, d in G.in_degree()}
     return centrality
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def out_degree_centrality(G):
     """Compute the out-degree centrality for nodes.
 
     The out-degree centrality for a node v is the fraction of nodes its
     outgoing edges are connected to.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/dispersion.py` & `networkx-3.3rc0/networkx/algorithms/centrality/dispersion.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from itertools import combinations
 
 import networkx as nx
 
 __all__ = ["dispersion"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def dispersion(G, u=None, v=None, normalized=True, alpha=1.0, b=0.0, c=0.0):
     r"""Calculate dispersion between `u` and `v` in `G`.
 
     A link between two actors (`u` and `v`) has a high dispersion when their
     mutual ties (`s` and `t`) are not well connected with each other.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/eigenvector.py` & `networkx-3.3rc0/networkx/algorithms/centrality/katz.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,341 +1,330 @@
-"""Functions for computing eigenvector centrality."""
+"""Katz centrality."""
 import math
 
 import networkx as nx
 from networkx.utils import not_implemented_for
 
-__all__ = ["eigenvector_centrality", "eigenvector_centrality_numpy"]
+__all__ = ["katz_centrality", "katz_centrality_numpy"]
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
-def eigenvector_centrality(G, max_iter=100, tol=1.0e-6, nstart=None, weight=None):
-    r"""Compute the eigenvector centrality for the graph G.
-
-    Eigenvector centrality computes the centrality for a node by adding
-    the centrality of its predecessors. The centrality for node $i$ is the
-    $i$-th element of a left eigenvector associated with the eigenvalue $\lambda$
-    of maximum modulus that is positive. Such an eigenvector $x$ is
-    defined up to a multiplicative constant by the equation
+@nx._dispatchable(edge_attrs="weight")
+def katz_centrality(
+    G,
+    alpha=0.1,
+    beta=1.0,
+    max_iter=1000,
+    tol=1.0e-6,
+    nstart=None,
+    normalized=True,
+    weight=None,
+):
+    r"""Compute the Katz centrality for the nodes of the graph G.
+
+    Katz centrality computes the centrality for a node based on the centrality
+    of its neighbors. It is a generalization of the eigenvector centrality. The
+    Katz centrality for node $i$ is
 
     .. math::
 
-         \lambda x^T = x^T A,
+        x_i = \alpha \sum_{j} A_{ij} x_j + \beta,
 
-    where $A$ is the adjacency matrix of the graph G. By definition of
-    row-column product, the equation above is equivalent to
+    where $A$ is the adjacency matrix of graph G with eigenvalues $\lambda$.
+
+    The parameter $\beta$ controls the initial centrality and
 
     .. math::
 
-        \lambda x_i = \sum_{j\to i}x_j.
+        \alpha < \frac{1}{\lambda_{\max}}.
 
-    That is, adding the eigenvector centralities of the predecessors of
-    $i$ one obtains the eigenvector centrality of $i$ multiplied by
-    $\lambda$. In the case of undirected graphs, $x$ also solves the familiar
-    right-eigenvector equation $Ax = \lambda x$.
-
-    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly
-    connected there is a unique eigenvector $x$, and all its entries
-    are strictly positive.
-
-    If G is not strongly connected there might be several left
-    eigenvectors associated with $\lambda$, and some of their elements
-    might be zero.
+    Katz centrality computes the relative influence of a node within a
+    network by measuring the number of the immediate neighbors (first
+    degree nodes) and also all other nodes in the network that connect
+    to the node under consideration through these immediate neighbors.
+
+    Extra weight can be provided to immediate neighbors through the
+    parameter $\beta$.  Connections made with distant neighbors
+    are, however, penalized by an attenuation factor $\alpha$ which
+    should be strictly less than the inverse largest eigenvalue of the
+    adjacency matrix in order for the Katz centrality to be computed
+    correctly. More information is provided in [1]_.
 
     Parameters
     ----------
     G : graph
-      A networkx graph.
+      A NetworkX graph.
+
+    alpha : float, optional (default=0.1)
+      Attenuation factor
+
+    beta : scalar or dictionary, optional (default=1.0)
+      Weight attributed to the immediate neighborhood. If not a scalar, the
+      dictionary must have a value for every node.
 
-    max_iter : integer, optional (default=100)
-      Maximum number of power iterations.
+    max_iter : integer, optional (default=1000)
+      Maximum number of iterations in power method.
 
     tol : float, optional (default=1.0e-6)
-      Error tolerance (in Euclidean norm) used to check convergence in
-      power iteration.
+      Error tolerance used to check convergence in power method iteration.
 
-    nstart : dictionary, optional (default=None)
-      Starting value of power iteration for each node. Must have a nonzero
-      projection on the desired eigenvector for the power method to converge.
-      If None, this implementation uses an all-ones vector, which is a safe
-      choice.
+    nstart : dictionary, optional
+      Starting value of Katz iteration for each node.
+
+    normalized : bool, optional (default=True)
+      If True normalize the resulting values.
 
     weight : None or string, optional (default=None)
-      If None, all edge weights are considered equal. Otherwise holds the
-      name of the edge attribute used as weight. In this measure the
-      weight is interpreted as the connection strength.
+      If None, all edge weights are considered equal.
+      Otherwise holds the name of the edge attribute used as weight.
+      In this measure the weight is interpreted as the connection strength.
 
     Returns
     -------
     nodes : dictionary
-       Dictionary of nodes with eigenvector centrality as the value. The
-       associated vector has unit Euclidian norm and the values are
-       nonegative.
-
-    Examples
-    --------
-    >>> G = nx.path_graph(4)
-    >>> centrality = nx.eigenvector_centrality(G)
-    >>> sorted((v, f"{c:0.2f}") for v, c in centrality.items())
-    [(0, '0.37'), (1, '0.60'), (2, '0.60'), (3, '0.37')]
+       Dictionary of nodes with Katz centrality as the value.
 
     Raises
     ------
-    NetworkXPointlessConcept
-        If the graph G is the null graph.
-
     NetworkXError
-        If each value in `nstart` is zero.
+       If the parameter `beta` is not a scalar but lacks a value for at least
+       one node
 
     PowerIterationFailedConvergence
         If the algorithm fails to converge to the specified tolerance
         within the specified number of iterations of the power iteration
         method.
 
+    Examples
+    --------
+    >>> import math
+    >>> G = nx.path_graph(4)
+    >>> phi = (1 + math.sqrt(5)) / 2.0  # largest eigenvalue of adj matrix
+    >>> centrality = nx.katz_centrality(G, 1 / phi - 0.01)
+    >>> for n, c in sorted(centrality.items()):
+    ...     print(f"{n} {c:.2f}")
+    0 0.37
+    1 0.60
+    2 0.60
+    3 0.37
+
     See Also
     --------
+    katz_centrality_numpy
+    eigenvector_centrality
     eigenvector_centrality_numpy
     :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
     :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
 
     Notes
     -----
-    Eigenvector centrality was introduced by Landau [2]_ for chess
-    tournaments. It was later rediscovered by Wei [3]_ and then
-    popularized by Kendall [4]_ in the context of sport ranking. Berge
-    introduced a general definition for graphs based on social connections
-    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made
-    it popular in link analysis.
-
-    This function computes the left dominant eigenvector, which corresponds
-    to adding the centrality of predecessors: this is the usual approach.
-    To add the centrality of successors first reverse the graph with
-    ``G.reverse()``.
-
-    The implementation uses power iteration [7]_ to compute a dominant
-    eigenvector starting from the provided vector `nstart`. Convergence is
-    guaranteed as long as `nstart` has a nonzero projection on a dominant
-    eigenvector, which certainly happens using the default value.
-
-    The method stops when the change in the computed vector between two
-    iterations is smaller than an error tolerance of ``G.number_of_nodes()
-    * tol`` or after ``max_iter`` iterations, but in the second case it
-    raises an exception.
-
-    This implementation uses $(A + I)$ rather than the adjacency matrix
-    $A$ because the change preserves eigenvectors, but it shifts the
-    spectrum, thus guaranteeing convergence even for networks with
-    negative eigenvalues of maximum modulus.
+    Katz centrality was introduced by [2]_.
+
+    This algorithm it uses the power method to find the eigenvector
+    corresponding to the largest eigenvalue of the adjacency matrix of ``G``.
+    The parameter ``alpha`` should be strictly less than the inverse of largest
+    eigenvalue of the adjacency matrix for the algorithm to converge.
+    You can use ``max(nx.adjacency_spectrum(G))`` to get $\lambda_{\max}$ the largest
+    eigenvalue of the adjacency matrix.
+    The iteration will stop after ``max_iter`` iterations or an error tolerance of
+    ``number_of_nodes(G) * tol`` has been reached.
+
+    For strongly connected graphs, as $\alpha \to 1/\lambda_{\max}$, and $\beta > 0$,
+    Katz centrality approaches the results for eigenvector centrality.
+
+    For directed graphs this finds "left" eigenvectors which corresponds
+    to the in-edges in the graph. For out-edges Katz centrality,
+    first reverse the graph with ``G.reverse()``.
 
     References
     ----------
-    .. [1] Abraham Berman and Robert J. Plemmons.
-       "Nonnegative Matrices in the Mathematical Sciences."
-       Classics in Applied Mathematics. SIAM, 1994.
-
-    .. [2] Edmund Landau.
-       "Zur relativen Wertbemessung der Turnierresultate."
-       Deutsches Wochenschach, 11:366–369, 1895.
-
-    .. [3] Teh-Hsing Wei.
-       "The Algebraic Foundations of Ranking Theory."
-       PhD thesis, University of Cambridge, 1952.
-
-    .. [4] Maurice G. Kendall.
-       "Further contributions to the theory of paired comparisons."
-       Biometrics, 11(1):43–62, 1955.
-       https://www.jstor.org/stable/3001479
-
-    .. [5] Claude Berge
-       "Théorie des graphes et ses applications."
-       Dunod, Paris, France, 1958.
-
-    .. [6] Phillip Bonacich.
-       "Technique for analyzing overlapping memberships."
-       Sociological Methodology, 4:176–185, 1972.
-       https://www.jstor.org/stable/270732
-
-    .. [7] Power iteration:: https://en.wikipedia.org/wiki/Power_iteration
-
+    .. [1] Mark E. J. Newman:
+       Networks: An Introduction.
+       Oxford University Press, USA, 2010, p. 720.
+    .. [2] Leo Katz:
+       A New Status Index Derived from Sociometric Index.
+       Psychometrika 18(1):39–43, 1953
+       https://link.springer.com/content/pdf/10.1007/BF02289026.pdf
     """
     if len(G) == 0:
-        raise nx.NetworkXPointlessConcept(
-            "cannot compute centrality for the null graph"
-        )
-    # If no initial vector is provided, start with the all-ones vector.
-    if nstart is None:
-        nstart = {v: 1 for v in G}
-    if all(v == 0 for v in nstart.values()):
-        raise nx.NetworkXError("initial vector cannot have all zero values")
-    # Normalize the initial vector so that each entry is in [0, 1]. This is
-    # guaranteed to never have a divide-by-zero error by the previous line.
-    nstart_sum = sum(nstart.values())
-    x = {k: v / nstart_sum for k, v in nstart.items()}
+        return {}
+
     nnodes = G.number_of_nodes()
+
+    if nstart is None:
+        # choose starting vector with entries of 0
+        x = {n: 0 for n in G}
+    else:
+        x = nstart
+
+    try:
+        b = dict.fromkeys(G, float(beta))
+    except (TypeError, ValueError, AttributeError) as err:
+        b = beta
+        if set(beta) != set(G):
+            raise nx.NetworkXError(
+                "beta dictionary must have a value for every node"
+            ) from err
+
     # make up to max_iter iterations
     for _ in range(max_iter):
         xlast = x
-        x = xlast.copy()  # Start with xlast times I to iterate with (A+I)
-        # do the multiplication y^T = x^T A (left eigenvector)
+        x = dict.fromkeys(xlast, 0)
+        # do the multiplication y^T = Alpha * x^T A + Beta
         for n in x:
             for nbr in G[n]:
-                w = G[n][nbr].get(weight, 1) if weight else 1
-                x[nbr] += xlast[n] * w
-        # Normalize the vector. The normalization denominator `norm`
-        # should never be zero by the Perron--Frobenius
-        # theorem. However, in case it is due to numerical error, we
-        # assume the norm to be one instead.
-        norm = math.hypot(*x.values()) or 1
-        x = {k: v / norm for k, v in x.items()}
-        # Check for convergence (in the L_1 norm).
-        if sum(abs(x[n] - xlast[n]) for n in x) < nnodes * tol:
+                x[nbr] += xlast[n] * G[n][nbr].get(weight, 1)
+        for n in x:
+            x[n] = alpha * x[n] + b[n]
+
+        # check convergence
+        error = sum(abs(x[n] - xlast[n]) for n in x)
+        if error < nnodes * tol:
+            if normalized:
+                # normalize vector
+                try:
+                    s = 1.0 / math.hypot(*x.values())
+                except ZeroDivisionError:
+                    s = 1.0
+            else:
+                s = 1
+            for n in x:
+                x[n] *= s
             return x
     raise nx.PowerIterationFailedConvergence(max_iter)
 
 
-@nx._dispatch(edge_attrs="weight")
-def eigenvector_centrality_numpy(G, weight=None, max_iter=50, tol=0):
-    r"""Compute the eigenvector centrality for the graph G.
-
-    Eigenvector centrality computes the centrality for a node by adding
-    the centrality of its predecessors. The centrality for node $i$ is the
-    $i$-th element of a left eigenvector associated with the eigenvalue $\lambda$
-    of maximum modulus that is positive. Such an eigenvector $x$ is
-    defined up to a multiplicative constant by the equation
+@not_implemented_for("multigraph")
+@nx._dispatchable(edge_attrs="weight")
+def katz_centrality_numpy(G, alpha=0.1, beta=1.0, normalized=True, weight=None):
+    r"""Compute the Katz centrality for the graph G.
+
+    Katz centrality computes the centrality for a node based on the centrality
+    of its neighbors. It is a generalization of the eigenvector centrality. The
+    Katz centrality for node $i$ is
 
     .. math::
 
-         \lambda x^T = x^T A,
+        x_i = \alpha \sum_{j} A_{ij} x_j + \beta,
 
-    where $A$ is the adjacency matrix of the graph G. By definition of
-    row-column product, the equation above is equivalent to
+    where $A$ is the adjacency matrix of graph G with eigenvalues $\lambda$.
+
+    The parameter $\beta$ controls the initial centrality and
 
     .. math::
 
-        \lambda x_i = \sum_{j\to i}x_j.
+        \alpha < \frac{1}{\lambda_{\max}}.
 
-    That is, adding the eigenvector centralities of the predecessors of
-    $i$ one obtains the eigenvector centrality of $i$ multiplied by
-    $\lambda$. In the case of undirected graphs, $x$ also solves the familiar
-    right-eigenvector equation $Ax = \lambda x$.
-
-    By virtue of the Perron–Frobenius theorem [1]_, if G is strongly
-    connected there is a unique eigenvector $x$, and all its entries
-    are strictly positive.
-
-    If G is not strongly connected there might be several left
-    eigenvectors associated with $\lambda$, and some of their elements
-    might be zero.
+    Katz centrality computes the relative influence of a node within a
+    network by measuring the number of the immediate neighbors (first
+    degree nodes) and also all other nodes in the network that connect
+    to the node under consideration through these immediate neighbors.
+
+    Extra weight can be provided to immediate neighbors through the
+    parameter $\beta$.  Connections made with distant neighbors
+    are, however, penalized by an attenuation factor $\alpha$ which
+    should be strictly less than the inverse largest eigenvalue of the
+    adjacency matrix in order for the Katz centrality to be computed
+    correctly. More information is provided in [1]_.
 
     Parameters
     ----------
     G : graph
-      A networkx graph.
-
-    max_iter : integer, optional (default=50)
-      Maximum number of Arnoldi update iterations allowed.
+      A NetworkX graph
 
-    tol : float, optional (default=0)
-      Relative accuracy for eigenvalues (stopping criterion).
-      The default value of 0 implies machine precision.
+    alpha : float
+      Attenuation factor
 
-    weight : None or string, optional (default=None)
-      If None, all edge weights are considered equal. Otherwise holds the
-      name of the edge attribute used as weight. In this measure the
-      weight is interpreted as the connection strength.
+    beta : scalar or dictionary, optional (default=1.0)
+      Weight attributed to the immediate neighborhood. If not a scalar the
+      dictionary must have an value for every node.
+
+    normalized : bool
+      If True normalize the resulting values.
+
+    weight : None or string, optional
+      If None, all edge weights are considered equal.
+      Otherwise holds the name of the edge attribute used as weight.
+      In this measure the weight is interpreted as the connection strength.
 
     Returns
     -------
     nodes : dictionary
-       Dictionary of nodes with eigenvector centrality as the value. The
-       associated vector has unit Euclidian norm and the values are
-       nonegative.
-
-    Examples
-    --------
-    >>> G = nx.path_graph(4)
-    >>> centrality = nx.eigenvector_centrality_numpy(G)
-    >>> print([f"{node} {centrality[node]:0.2f}" for node in centrality])
-    ['0 0.37', '1 0.60', '2 0.60', '3 0.37']
+       Dictionary of nodes with Katz centrality as the value.
 
     Raises
     ------
-    NetworkXPointlessConcept
-        If the graph G is the null graph.
+    NetworkXError
+       If the parameter `beta` is not a scalar but lacks a value for at least
+       one node
 
-    ArpackNoConvergence
-        When the requested convergence is not obtained. The currently
-        converged eigenvalues and eigenvectors can be found as
-        eigenvalues and eigenvectors attributes of the exception object.
+    Examples
+    --------
+    >>> import math
+    >>> G = nx.path_graph(4)
+    >>> phi = (1 + math.sqrt(5)) / 2.0  # largest eigenvalue of adj matrix
+    >>> centrality = nx.katz_centrality_numpy(G, 1 / phi)
+    >>> for n, c in sorted(centrality.items()):
+    ...     print(f"{n} {c:.2f}")
+    0 0.37
+    1 0.60
+    2 0.60
+    3 0.37
 
     See Also
     --------
-    :func:`scipy.sparse.linalg.eigs`
+    katz_centrality
+    eigenvector_centrality_numpy
     eigenvector_centrality
     :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
     :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
 
     Notes
     -----
-    Eigenvector centrality was introduced by Landau [2]_ for chess
-    tournaments. It was later rediscovered by Wei [3]_ and then
-    popularized by Kendall [4]_ in the context of sport ranking. Berge
-    introduced a general definition for graphs based on social connections
-    [5]_. Bonacich [6]_ reintroduced again eigenvector centrality and made
-    it popular in link analysis.
-
-    This function computes the left dominant eigenvector, which corresponds
-    to adding the centrality of predecessors: this is the usual approach.
-    To add the centrality of successors first reverse the graph with
-    ``G.reverse()``.
-
-    This implementation uses the
-    :func:`SciPy sparse eigenvalue solver<scipy.sparse.linalg.eigs>` (ARPACK)
-    to find the largest eigenvalue/eigenvector pair using Arnoldi iterations
-    [7]_.
+    Katz centrality was introduced by [2]_.
+
+    This algorithm uses a direct linear solver to solve the above equation.
+    The parameter ``alpha`` should be strictly less than the inverse of largest
+    eigenvalue of the adjacency matrix for there to be a solution.
+    You can use ``max(nx.adjacency_spectrum(G))`` to get $\lambda_{\max}$ the largest
+    eigenvalue of the adjacency matrix.
+
+    For strongly connected graphs, as $\alpha \to 1/\lambda_{\max}$, and $\beta > 0$,
+    Katz centrality approaches the results for eigenvector centrality.
+
+    For directed graphs this finds "left" eigenvectors which corresponds
+    to the in-edges in the graph. For out-edges Katz centrality,
+    first reverse the graph with ``G.reverse()``.
 
     References
     ----------
-    .. [1] Abraham Berman and Robert J. Plemmons.
-       "Nonnegative Matrices in the Mathematical Sciences."
-       Classics in Applied Mathematics. SIAM, 1994.
-
-    .. [2] Edmund Landau.
-       "Zur relativen Wertbemessung der Turnierresultate."
-       Deutsches Wochenschach, 11:366–369, 1895.
-
-    .. [3] Teh-Hsing Wei.
-       "The Algebraic Foundations of Ranking Theory."
-       PhD thesis, University of Cambridge, 1952.
-
-    .. [4] Maurice G. Kendall.
-       "Further contributions to the theory of paired comparisons."
-       Biometrics, 11(1):43–62, 1955.
-       https://www.jstor.org/stable/3001479
-
-    .. [5] Claude Berge
-       "Théorie des graphes et ses applications."
-       Dunod, Paris, France, 1958.
-
-    .. [6] Phillip Bonacich.
-       "Technique for analyzing overlapping memberships."
-       Sociological Methodology, 4:176–185, 1972.
-       https://www.jstor.org/stable/270732
-
-    .. [7] Arnoldi iteration:: https://en.wikipedia.org/wiki/Arnoldi_iteration
-
+    .. [1] Mark E. J. Newman:
+       Networks: An Introduction.
+       Oxford University Press, USA, 2010, p. 173.
+    .. [2] Leo Katz:
+       A New Status Index Derived from Sociometric Index.
+       Psychometrika 18(1):39–43, 1953
+       https://link.springer.com/content/pdf/10.1007/BF02289026.pdf
     """
     import numpy as np
-    import scipy as sp
 
     if len(G) == 0:
-        raise nx.NetworkXPointlessConcept(
-            "cannot compute centrality for the null graph"
-        )
-    M = nx.to_scipy_sparse_array(G, nodelist=list(G), weight=weight, dtype=float)
-    _, eigenvector = sp.sparse.linalg.eigs(
-        M.T, k=1, which="LR", maxiter=max_iter, tol=tol
-    )
-    largest = eigenvector.flatten().real
-    norm = np.sign(largest.sum()) * sp.linalg.norm(largest)
-    return dict(zip(G, largest / norm))
+        return {}
+    try:
+        nodelist = beta.keys()
+        if set(nodelist) != set(G):
+            raise nx.NetworkXError("beta dictionary must have a value for every node")
+        b = np.array(list(beta.values()), dtype=float)
+    except AttributeError:
+        nodelist = list(G)
+        try:
+            b = np.ones((len(nodelist), 1)) * beta
+        except (TypeError, ValueError, AttributeError) as err:
+            raise nx.NetworkXError("beta must be a number") from err
+
+    A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight).todense().T
+    n = A.shape[0]
+    centrality = np.linalg.solve(np.eye(n, n) - (alpha * A), b).squeeze()
+
+    # Normalize: rely on truediv to cast to float, then tolist to make Python numbers
+    norm = np.sign(sum(centrality)) * np.linalg.norm(centrality) if normalized else 1
+    return dict(zip(nodelist, (centrality / norm).tolist()))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/flow_matrix.py` & `networkx-3.3rc0/networkx/algorithms/centrality/flow_matrix.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # Helpers for current-flow betweenness and current-flow closeness
 # Lazy computations for inverse Laplacian and flow-matrix rows.
 import networkx as nx
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def flow_matrix_row(G, weight=None, dtype=float, solver="lu"):
     # Generate a row of the current-flow matrix
     import numpy as np
 
     solvername = {
         "full": FullInverseLaplacian,
         "lu": SuperLUInverseLaplacian,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/group.py` & `networkx-3.3rc0/networkx/algorithms/centrality/group.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
     "group_degree_centrality",
     "group_in_degree_centrality",
     "group_out_degree_centrality",
     "prominent_group",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def group_betweenness_centrality(G, C, normalized=True, weight=None, endpoints=False):
     r"""Compute the group betweenness centrality for a group of nodes.
 
     Group betweenness centrality of a group of nodes $C$ is the sum of the
     fraction of all-pairs shortest paths that pass through any vertex in $C$
 
     .. math::
@@ -232,15 +232,15 @@
                             * sigma[node][group_node1]
                             * sigma[group_node1][group_node2]
                             / sigma[node][group_node2]
                         )
     return PB, sigma, D
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def prominent_group(
     G, k, weight=None, C=None, endpoints=False, normalized=True, greedy=False
 ):
     r"""Find the prominent group of size $k$ in graph $G$. The prominence of the
     group is evaluated by the group betweenness centrality.
 
     Group betweenness centrality of a group of nodes $C$ is the sum of the
@@ -494,23 +494,23 @@
                 if D[added_node][y] == D[added_node][x] + D[x][y]:
                     dvxy = (
                         root_node["sigma"][added_node][x]
                         * root_node["sigma"][x][y]
                         / root_node["sigma"][added_node][y]
                     )
             DF_tree.nodes[node_p]["sigma"][x][y] = root_node["sigma"][x][y] * (1 - dxvy)
-            DF_tree.nodes[node_p]["betweenness"][x][y] = (
+            DF_tree.nodes[node_p]["betweenness"].loc[y, x] = (
                 root_node["betweenness"][x][y] - root_node["betweenness"][x][y] * dxvy
             )
             if y != added_node:
-                DF_tree.nodes[node_p]["betweenness"][x][y] -= (
+                DF_tree.nodes[node_p]["betweenness"].loc[y, x] -= (
                     root_node["betweenness"][x][added_node] * dxyv
                 )
             if x != added_node:
-                DF_tree.nodes[node_p]["betweenness"][x][y] -= (
+                DF_tree.nodes[node_p]["betweenness"].loc[y, x] -= (
                     root_node["betweenness"][added_node][y] * dvxy
                 )
 
     DF_tree.nodes[node_p]["CL"] = [
         node
         for _, node in sorted(
             zip(np.diag(DF_tree.nodes[node_p]["betweenness"]), nodes), reverse=True
@@ -539,15 +539,15 @@
             ]
     else:
         node_m = None
 
     return node_p, node_m, DF_tree
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def group_closeness_centrality(G, S, weight=None):
     r"""Compute the group closeness centrality for a group of nodes.
 
     Group closeness centrality of a group of nodes $S$ is a measure
     of how close the group is to the other nodes in the graph.
 
     .. math::
@@ -636,15 +636,15 @@
     try:
         closeness = len(V_S) / closeness
     except ZeroDivisionError:  # 1 / 0 assumed as 0
         closeness = 0
     return closeness
 
 
-@nx._dispatch
+@nx._dispatchable
 def group_degree_centrality(G, S):
     """Compute the group degree centrality for a group of nodes.
 
     Group degree centrality of a group of nodes $S$ is the fraction
     of non-group members connected to group members.
 
     Parameters
@@ -688,15 +688,15 @@
     """
     centrality = len(set().union(*[set(G.neighbors(i)) for i in S]) - set(S))
     centrality /= len(G.nodes()) - len(S)
     return centrality
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def group_in_degree_centrality(G, S):
     """Compute the group in-degree centrality for a group of nodes.
 
     Group in-degree centrality of a group of nodes $S$ is the fraction
     of non-group members connected to group members by incoming edges.
 
     Parameters
@@ -735,15 +735,15 @@
     `G.neighbors(i)` gives nodes with an outward edge from i, in a DiGraph,
     so for group in-degree centrality, the reverse graph is used.
     """
     return group_degree_centrality(G.reverse(), S)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def group_out_degree_centrality(G, S):
     """Compute the group out-degree centrality for a group of nodes.
 
     Group out-degree centrality of a group of nodes $S$ is the fraction
     of non-group members connected to group members by outgoing edges.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/harmonic.py` & `networkx-3.3rc0/networkx/algorithms/centrality/harmonic.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from functools import partial
 
 import networkx as nx
 
 __all__ = ["harmonic_centrality"]
 
 
-@nx._dispatch(edge_attrs="distance")
+@nx._dispatchable(edge_attrs="distance")
 def harmonic_centrality(G, nbunch=None, distance=None, sources=None):
     r"""Compute harmonic centrality for nodes.
 
     Harmonic centrality [1]_ of a node `u` is the sum of the reciprocal
     of the shortest path distances from all other nodes to `u`
 
     .. math::
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/katz.py` & `networkx-3.3rc0/networkx/algorithms/link_analysis/hits_alg.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,331 +1,337 @@
-"""Katz centrality."""
-import math
-
+"""Hubs and authorities analysis of graph structure.
+"""
 import networkx as nx
-from networkx.utils import not_implemented_for
-
-__all__ = ["katz_centrality", "katz_centrality_numpy"]
-
-
-@not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
-def katz_centrality(
-    G,
-    alpha=0.1,
-    beta=1.0,
-    max_iter=1000,
-    tol=1.0e-6,
-    nstart=None,
-    normalized=True,
-    weight=None,
-):
-    r"""Compute the Katz centrality for the nodes of the graph G.
-
-    Katz centrality computes the centrality for a node based on the centrality
-    of its neighbors. It is a generalization of the eigenvector centrality. The
-    Katz centrality for node $i$ is
 
-    .. math::
+__all__ = ["hits"]
 
-        x_i = \alpha \sum_{j} A_{ij} x_j + \beta,
 
-    where $A$ is the adjacency matrix of graph G with eigenvalues $\lambda$.
+@nx._dispatchable(preserve_edge_attrs={"G": {"weight": 1}})
+def hits(G, max_iter=100, tol=1.0e-8, nstart=None, normalized=True):
+    """Returns HITS hubs and authorities values for nodes.
 
-    The parameter $\beta$ controls the initial centrality and
-
-    .. math::
-
-        \alpha < \frac{1}{\lambda_{\max}}.
-
-    Katz centrality computes the relative influence of a node within a
-    network by measuring the number of the immediate neighbors (first
-    degree nodes) and also all other nodes in the network that connect
-    to the node under consideration through these immediate neighbors.
-
-    Extra weight can be provided to immediate neighbors through the
-    parameter $\beta$.  Connections made with distant neighbors
-    are, however, penalized by an attenuation factor $\alpha$ which
-    should be strictly less than the inverse largest eigenvalue of the
-    adjacency matrix in order for the Katz centrality to be computed
-    correctly. More information is provided in [1]_.
+    The HITS algorithm computes two numbers for a node.
+    Authorities estimates the node value based on the incoming links.
+    Hubs estimates the node value based on outgoing links.
 
     Parameters
     ----------
     G : graph
-      A NetworkX graph.
-
-    alpha : float
-      Attenuation factor
-
-    beta : scalar or dictionary, optional (default=1.0)
-      Weight attributed to the immediate neighborhood. If not a scalar, the
-      dictionary must have an value for every node.
+      A NetworkX graph
 
-    max_iter : integer, optional (default=1000)
+    max_iter : integer, optional
       Maximum number of iterations in power method.
 
-    tol : float, optional (default=1.0e-6)
+    tol : float, optional
       Error tolerance used to check convergence in power method iteration.
 
     nstart : dictionary, optional
-      Starting value of Katz iteration for each node.
-
-    normalized : bool, optional (default=True)
-      If True normalize the resulting values.
+      Starting value of each node for power method iteration.
 
-    weight : None or string, optional (default=None)
-      If None, all edge weights are considered equal.
-      Otherwise holds the name of the edge attribute used as weight.
-      In this measure the weight is interpreted as the connection strength.
+    normalized : bool (default=True)
+       Normalize results by the sum of all of the values.
 
     Returns
     -------
-    nodes : dictionary
-       Dictionary of nodes with Katz centrality as the value.
+    (hubs,authorities) : two-tuple of dictionaries
+       Two dictionaries keyed by node containing the hub and authority
+       values.
 
     Raises
     ------
-    NetworkXError
-       If the parameter `beta` is not a scalar but lacks a value for at least
-       one node
-
     PowerIterationFailedConvergence
         If the algorithm fails to converge to the specified tolerance
         within the specified number of iterations of the power iteration
         method.
 
     Examples
     --------
-    >>> import math
     >>> G = nx.path_graph(4)
-    >>> phi = (1 + math.sqrt(5)) / 2.0  # largest eigenvalue of adj matrix
-    >>> centrality = nx.katz_centrality(G, 1 / phi - 0.01)
-    >>> for n, c in sorted(centrality.items()):
-    ...     print(f"{n} {c:.2f}")
-    0 0.37
-    1 0.60
-    2 0.60
-    3 0.37
+    >>> h, a = nx.hits(G)
+
+    Notes
+    -----
+    The eigenvector calculation is done by the power iteration method
+    and has no guarantee of convergence.  The iteration will stop
+    after max_iter iterations or an error tolerance of
+    number_of_nodes(G)*tol has been reached.
+
+    The HITS algorithm was designed for directed graphs but this
+    algorithm does not check if the input graph is directed and will
+    execute on undirected graphs.
+
+    References
+    ----------
+    .. [1] A. Langville and C. Meyer,
+       "A survey of eigenvector methods of web information retrieval."
+       http://citeseer.ist.psu.edu/713792.html
+    .. [2] Jon Kleinberg,
+       Authoritative sources in a hyperlinked environment
+       Journal of the ACM 46 (5): 604-32, 1999.
+       doi:10.1145/324133.324140.
+       http://www.cs.cornell.edu/home/kleinber/auth.pdf.
+    """
+    import numpy as np
+    import scipy as sp
+
+    if len(G) == 0:
+        return {}, {}
+    A = nx.adjacency_matrix(G, nodelist=list(G), dtype=float)
+
+    if nstart is not None:
+        nstart = np.array(list(nstart.values()))
+    if max_iter <= 0:
+        raise nx.PowerIterationFailedConvergence(max_iter)
+    try:
+        _, _, vt = sp.sparse.linalg.svds(A, k=1, v0=nstart, maxiter=max_iter, tol=tol)
+    except sp.sparse.linalg.ArpackNoConvergence as exc:
+        raise nx.PowerIterationFailedConvergence(max_iter) from exc
+
+    a = vt.flatten().real
+    h = A @ a
+    if normalized:
+        h /= h.sum()
+        a /= a.sum()
+    hubs = dict(zip(G, map(float, h)))
+    authorities = dict(zip(G, map(float, a)))
+    return hubs, authorities
+
+
+def _hits_python(G, max_iter=100, tol=1.0e-8, nstart=None, normalized=True):
+    if isinstance(G, nx.MultiGraph | nx.MultiDiGraph):
+        raise Exception("hits() not defined for graphs with multiedges.")
+    if len(G) == 0:
+        return {}, {}
+    # choose fixed starting vector if not given
+    if nstart is None:
+        h = dict.fromkeys(G, 1.0 / G.number_of_nodes())
+    else:
+        h = nstart
+        # normalize starting vector
+        s = 1.0 / sum(h.values())
+        for k in h:
+            h[k] *= s
+    for _ in range(max_iter):  # power iteration: make up to max_iter iterations
+        hlast = h
+        h = dict.fromkeys(hlast.keys(), 0)
+        a = dict.fromkeys(hlast.keys(), 0)
+        # this "matrix multiply" looks odd because it is
+        # doing a left multiply a^T=hlast^T*G
+        for n in h:
+            for nbr in G[n]:
+                a[nbr] += hlast[n] * G[n][nbr].get("weight", 1)
+        # now multiply h=Ga
+        for n in h:
+            for nbr in G[n]:
+                h[n] += a[nbr] * G[n][nbr].get("weight", 1)
+        # normalize vector
+        s = 1.0 / max(h.values())
+        for n in h:
+            h[n] *= s
+        # normalize vector
+        s = 1.0 / max(a.values())
+        for n in a:
+            a[n] *= s
+        # check convergence, l1 norm
+        err = sum(abs(h[n] - hlast[n]) for n in h)
+        if err < tol:
+            break
+    else:
+        raise nx.PowerIterationFailedConvergence(max_iter)
+    if normalized:
+        s = 1.0 / sum(a.values())
+        for n in a:
+            a[n] *= s
+        s = 1.0 / sum(h.values())
+        for n in h:
+            h[n] *= s
+    return h, a
+
+
+def _hits_numpy(G, normalized=True):
+    """Returns HITS hubs and authorities values for nodes.
+
+    The HITS algorithm computes two numbers for a node.
+    Authorities estimates the node value based on the incoming links.
+    Hubs estimates the node value based on outgoing links.
+
+    Parameters
+    ----------
+    G : graph
+      A NetworkX graph
+
+    normalized : bool (default=True)
+       Normalize results by the sum of all of the values.
+
+    Returns
+    -------
+    (hubs,authorities) : two-tuple of dictionaries
+       Two dictionaries keyed by node containing the hub and authority
+       values.
 
-    See Also
+    Examples
     --------
-    katz_centrality_numpy
-    eigenvector_centrality
-    eigenvector_centrality_numpy
-    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
-    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
+    >>> G = nx.path_graph(4)
+
+    The `hubs` and `authorities` are given by the eigenvectors corresponding to the
+    maximum eigenvalues of the hubs_matrix and the authority_matrix, respectively.
+
+    The ``hubs`` and ``authority`` matrices are computed from the adjacency
+    matrix:
+
+    >>> adj_ary = nx.to_numpy_array(G)
+    >>> hubs_matrix = adj_ary @ adj_ary.T
+    >>> authority_matrix = adj_ary.T @ adj_ary
+
+    `_hits_numpy` maps the eigenvector corresponding to the maximum eigenvalue
+    of the respective matrices to the nodes in `G`:
+
+    >>> from networkx.algorithms.link_analysis.hits_alg import _hits_numpy
+    >>> hubs, authority = _hits_numpy(G)
 
     Notes
     -----
-    Katz centrality was introduced by [2]_.
+    The eigenvector calculation uses NumPy's interface to LAPACK.
 
-    This algorithm it uses the power method to find the eigenvector
-    corresponding to the largest eigenvalue of the adjacency matrix of ``G``.
-    The parameter ``alpha`` should be strictly less than the inverse of largest
-    eigenvalue of the adjacency matrix for the algorithm to converge.
-    You can use ``max(nx.adjacency_spectrum(G))`` to get $\lambda_{\max}$ the largest
-    eigenvalue of the adjacency matrix.
-    The iteration will stop after ``max_iter`` iterations or an error tolerance of
-    ``number_of_nodes(G) * tol`` has been reached.
-
-    When $\alpha = 1/\lambda_{\max}$ and $\beta=0$, Katz centrality is the same
-    as eigenvector centrality.
-
-    For directed graphs this finds "left" eigenvectors which corresponds
-    to the in-edges in the graph. For out-edges Katz centrality
-    first reverse the graph with ``G.reverse()``.
+    The HITS algorithm was designed for directed graphs but this
+    algorithm does not check if the input graph is directed and will
+    execute on undirected graphs.
 
     References
     ----------
-    .. [1] Mark E. J. Newman:
-       Networks: An Introduction.
-       Oxford University Press, USA, 2010, p. 720.
-    .. [2] Leo Katz:
-       A New Status Index Derived from Sociometric Index.
-       Psychometrika 18(1):39–43, 1953
-       https://link.springer.com/content/pdf/10.1007/BF02289026.pdf
+    .. [1] A. Langville and C. Meyer,
+       "A survey of eigenvector methods of web information retrieval."
+       http://citeseer.ist.psu.edu/713792.html
+    .. [2] Jon Kleinberg,
+       Authoritative sources in a hyperlinked environment
+       Journal of the ACM 46 (5): 604-32, 1999.
+       doi:10.1145/324133.324140.
+       http://www.cs.cornell.edu/home/kleinber/auth.pdf.
     """
+    import numpy as np
+
     if len(G) == 0:
-        return {}
+        return {}, {}
+    adj_ary = nx.to_numpy_array(G)
+    # Hub matrix
+    H = adj_ary @ adj_ary.T
+    e, ev = np.linalg.eig(H)
+    h = ev[:, np.argmax(e)]  # eigenvector corresponding to the maximum eigenvalue
+    # Authority matrix
+    A = adj_ary.T @ adj_ary
+    e, ev = np.linalg.eig(A)
+    a = ev[:, np.argmax(e)]  # eigenvector corresponding to the maximum eigenvalue
+    if normalized:
+        h /= h.sum()
+        a /= a.sum()
+    else:
+        h /= h.max()
+        a /= a.max()
+    hubs = dict(zip(G, map(float, h)))
+    authorities = dict(zip(G, map(float, a)))
+    return hubs, authorities
 
-    nnodes = G.number_of_nodes()
 
-    if nstart is None:
-        # choose starting vector with entries of 0
-        x = {n: 0 for n in G}
-    else:
-        x = nstart
+def _hits_scipy(G, max_iter=100, tol=1.0e-6, nstart=None, normalized=True):
+    """Returns HITS hubs and authorities values for nodes.
 
-    try:
-        b = dict.fromkeys(G, float(beta))
-    except (TypeError, ValueError, AttributeError) as err:
-        b = beta
-        if set(beta) != set(G):
-            raise nx.NetworkXError(
-                "beta dictionary " "must have a value for every node"
-            ) from err
 
-    # make up to max_iter iterations
-    for _ in range(max_iter):
-        xlast = x
-        x = dict.fromkeys(xlast, 0)
-        # do the multiplication y^T = Alpha * x^T A + Beta
-        for n in x:
-            for nbr in G[n]:
-                x[nbr] += xlast[n] * G[n][nbr].get(weight, 1)
-        for n in x:
-            x[n] = alpha * x[n] + b[n]
-
-        # check convergence
-        error = sum(abs(x[n] - xlast[n]) for n in x)
-        if error < nnodes * tol:
-            if normalized:
-                # normalize vector
-                try:
-                    s = 1.0 / math.hypot(*x.values())
-                # this should never be zero?
-                except ZeroDivisionError:
-                    s = 1.0
-            else:
-                s = 1
-            for n in x:
-                x[n] *= s
-            return x
-    raise nx.PowerIterationFailedConvergence(max_iter)
-
-
-@not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
-def katz_centrality_numpy(G, alpha=0.1, beta=1.0, normalized=True, weight=None):
-    r"""Compute the Katz centrality for the graph G.
-
-    Katz centrality computes the centrality for a node based on the centrality
-    of its neighbors. It is a generalization of the eigenvector centrality. The
-    Katz centrality for node $i$ is
-
-    .. math::
-
-        x_i = \alpha \sum_{j} A_{ij} x_j + \beta,
-
-    where $A$ is the adjacency matrix of graph G with eigenvalues $\lambda$.
-
-    The parameter $\beta$ controls the initial centrality and
-
-    .. math::
-
-        \alpha < \frac{1}{\lambda_{\max}}.
-
-    Katz centrality computes the relative influence of a node within a
-    network by measuring the number of the immediate neighbors (first
-    degree nodes) and also all other nodes in the network that connect
-    to the node under consideration through these immediate neighbors.
-
-    Extra weight can be provided to immediate neighbors through the
-    parameter $\beta$.  Connections made with distant neighbors
-    are, however, penalized by an attenuation factor $\alpha$ which
-    should be strictly less than the inverse largest eigenvalue of the
-    adjacency matrix in order for the Katz centrality to be computed
-    correctly. More information is provided in [1]_.
+    The HITS algorithm computes two numbers for a node.
+    Authorities estimates the node value based on the incoming links.
+    Hubs estimates the node value based on outgoing links.
 
     Parameters
     ----------
     G : graph
       A NetworkX graph
 
-    alpha : float
-      Attenuation factor
+    max_iter : integer, optional
+      Maximum number of iterations in power method.
 
-    beta : scalar or dictionary, optional (default=1.0)
-      Weight attributed to the immediate neighborhood. If not a scalar the
-      dictionary must have an value for every node.
-
-    normalized : bool
-      If True normalize the resulting values.
-
-    weight : None or string, optional
-      If None, all edge weights are considered equal.
-      Otherwise holds the name of the edge attribute used as weight.
-      In this measure the weight is interpreted as the connection strength.
+    tol : float, optional
+      Error tolerance used to check convergence in power method iteration.
+
+    nstart : dictionary, optional
+      Starting value of each node for power method iteration.
+
+    normalized : bool (default=True)
+       Normalize results by the sum of all of the values.
 
     Returns
     -------
-    nodes : dictionary
-       Dictionary of nodes with Katz centrality as the value.
-
-    Raises
-    ------
-    NetworkXError
-       If the parameter `beta` is not a scalar but lacks a value for at least
-       one node
+    (hubs,authorities) : two-tuple of dictionaries
+       Two dictionaries keyed by node containing the hub and authority
+       values.
 
     Examples
     --------
-    >>> import math
+    >>> from networkx.algorithms.link_analysis.hits_alg import _hits_scipy
     >>> G = nx.path_graph(4)
-    >>> phi = (1 + math.sqrt(5)) / 2.0  # largest eigenvalue of adj matrix
-    >>> centrality = nx.katz_centrality_numpy(G, 1 / phi)
-    >>> for n, c in sorted(centrality.items()):
-    ...     print(f"{n} {c:.2f}")
-    0 0.37
-    1 0.60
-    2 0.60
-    3 0.37
-
-    See Also
-    --------
-    katz_centrality
-    eigenvector_centrality_numpy
-    eigenvector_centrality
-    :func:`~networkx.algorithms.link_analysis.pagerank_alg.pagerank`
-    :func:`~networkx.algorithms.link_analysis.hits_alg.hits`
+    >>> h, a = _hits_scipy(G)
 
     Notes
     -----
-    Katz centrality was introduced by [2]_.
+    This implementation uses SciPy sparse matrices.
 
-    This algorithm uses a direct linear solver to solve the above equation.
-    The parameter ``alpha`` should be strictly less than the inverse of largest
-    eigenvalue of the adjacency matrix for there to be a solution.
-    You can use ``max(nx.adjacency_spectrum(G))`` to get $\lambda_{\max}$ the largest
-    eigenvalue of the adjacency matrix.
-
-    When $\alpha = 1/\lambda_{\max}$ and $\beta=0$, Katz centrality is the same
-    as eigenvector centrality.
-
-    For directed graphs this finds "left" eigenvectors which corresponds
-    to the in-edges in the graph. For out-edges Katz centrality
-    first reverse the graph with ``G.reverse()``.
+    The eigenvector calculation is done by the power iteration method
+    and has no guarantee of convergence.  The iteration will stop
+    after max_iter iterations or an error tolerance of
+    number_of_nodes(G)*tol has been reached.
+
+    The HITS algorithm was designed for directed graphs but this
+    algorithm does not check if the input graph is directed and will
+    execute on undirected graphs.
+
+    Raises
+    ------
+    PowerIterationFailedConvergence
+        If the algorithm fails to converge to the specified tolerance
+        within the specified number of iterations of the power iteration
+        method.
 
     References
     ----------
-    .. [1] Mark E. J. Newman:
-       Networks: An Introduction.
-       Oxford University Press, USA, 2010, p. 173.
-    .. [2] Leo Katz:
-       A New Status Index Derived from Sociometric Index.
-       Psychometrika 18(1):39–43, 1953
-       https://link.springer.com/content/pdf/10.1007/BF02289026.pdf
+    .. [1] A. Langville and C. Meyer,
+       "A survey of eigenvector methods of web information retrieval."
+       http://citeseer.ist.psu.edu/713792.html
+    .. [2] Jon Kleinberg,
+       Authoritative sources in a hyperlinked environment
+       Journal of the ACM 46 (5): 604-632, 1999.
+       doi:10.1145/324133.324140.
+       http://www.cs.cornell.edu/home/kleinber/auth.pdf.
     """
     import numpy as np
 
     if len(G) == 0:
-        return {}
-    try:
-        nodelist = beta.keys()
-        if set(nodelist) != set(G):
-            raise nx.NetworkXError("beta dictionary must have a value for every node")
-        b = np.array(list(beta.values()), dtype=float)
-    except AttributeError:
-        nodelist = list(G)
-        try:
-            b = np.ones((len(nodelist), 1)) * beta
-        except (TypeError, ValueError, AttributeError) as err:
-            raise nx.NetworkXError("beta must be a number") from err
-
-    A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight).todense().T
-    n = A.shape[0]
-    centrality = np.linalg.solve(np.eye(n, n) - (alpha * A), b).squeeze()
-
-    # Normalize: rely on truediv to cast to float
-    norm = np.sign(sum(centrality)) * np.linalg.norm(centrality) if normalized else 1
-    return dict(zip(nodelist, centrality / norm))
+        return {}, {}
+    A = nx.to_scipy_sparse_array(G, nodelist=list(G))
+    (n, _) = A.shape  # should be square
+    ATA = A.T @ A  # authority matrix
+    # choose fixed starting vector if not given
+    if nstart is None:
+        x = np.ones((n, 1)) / n
+    else:
+        x = np.array([nstart.get(n, 0) for n in list(G)], dtype=float)
+        x /= x.sum()
+
+    # power iteration on authority matrix
+    i = 0
+    while True:
+        xlast = x
+        x = ATA @ x
+        x /= x.max()
+        # check convergence, l1 norm
+        err = np.absolute(x - xlast).sum()
+        if err < tol:
+            break
+        if i > max_iter:
+            raise nx.PowerIterationFailedConvergence(max_iter)
+        i += 1
+
+    a = x.flatten()
+    h = A @ a
+    if normalized:
+        h /= h.sum()
+        a /= a.sum()
+    hubs = dict(zip(G, map(float, h)))
+    authorities = dict(zip(G, map(float, a)))
+    return hubs, authorities
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/laplacian.py` & `networkx-3.3rc0/networkx/algorithms/centrality/laplacian.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Laplacian centrality measures.
 """
 import networkx as nx
 
 __all__ = ["laplacian_centrality"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def laplacian_centrality(
     G, normalized=True, nodelist=None, weight="weight", walk_type=None, alpha=0.95
 ):
     r"""Compute the Laplacian centrality for nodes in the graph `G`.
 
     The Laplacian Centrality of a node ``i`` is measured by the drop in the
     Laplacian Energy after deleting node ``i`` from the graph. The Laplacian Energy
@@ -46,16 +46,19 @@
         Optional parameter `weight` to compute the Laplacian matrix.
         The edge data key used to compute each value in the matrix.
         If None, then each edge has weight 1.
 
     walk_type : string or None, optional (default=None)
         Optional parameter `walk_type` used when calling
         :func:`directed_laplacian_matrix <networkx.directed_laplacian_matrix>`.
-        If None, the transition matrix is selected depending on the properties
-        of the graph. Otherwise can be `random`, `lazy`, or `pagerank`.
+        One of ``"random"``, ``"lazy"``, or ``"pagerank"``. If ``walk_type=None``
+        (the default), then a value is selected according to the properties of `G`:
+        - ``walk_type="random"`` if `G` is strongly connected and aperiodic
+        - ``walk_type="lazy"`` if `G` is strongly connected but not aperiodic
+        - ``walk_type="pagerank"`` for all other cases.
 
     alpha : real (default = 0.95)
         Optional parameter `alpha` used when calling
         :func:`directed_laplacian_matrix <networkx.directed_laplacian_matrix>`.
         (1 - alpha) is the teleportation probability used with pagerank.
 
     Returns
@@ -137,10 +140,10 @@
         else:
             new_energy = 0.0
 
         lapl_cent = full_energy - new_energy
         if normalized:
             lapl_cent = lapl_cent / full_energy
 
-        laplace_centralities_dict[node] = lapl_cent
+        laplace_centralities_dict[node] = float(lapl_cent)
 
     return laplace_centralities_dict
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/load.py` & `networkx-3.3rc0/networkx/algorithms/centrality/load.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from operator import itemgetter
 
 import networkx as nx
 
 __all__ = ["load_centrality", "edge_load_centrality"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def newman_betweenness_centrality(G, v=None, cutoff=None, normalized=True, weight=None):
     """Compute load centrality for nodes.
 
     The load centrality of a node is the fraction of all shortest
     paths that pass through that node.
 
     Parameters
@@ -132,15 +132,15 @@
                 between[v] *= scale
     return between
 
 
 load_centrality = newman_betweenness_centrality
 
 
-@nx._dispatch
+@nx._dispatchable
 def edge_load_centrality(G, cutoff=False):
     """Compute edge load.
 
     WARNING: This concept of edge load has not been analysed
     or discussed outside of NetworkX that we know of.
     It is based loosely on load_centrality in the sense that
     it counts the number of shortest paths which cross each edge.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/percolation.py` & `networkx-3.3rc0/networkx/algorithms/centrality/percolation.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from networkx.algorithms.centrality.betweenness import (
     _single_source_shortest_path_basic as shortest_path,
 )
 
 __all__ = ["percolation_centrality"]
 
 
-@nx._dispatch(node_attrs="attribute", edge_attrs="weight")
+@nx._dispatchable(node_attrs="attribute", edge_attrs="weight")
 def percolation_centrality(G, attribute="percolation", states=None, weight=None):
     r"""Compute the percolation centrality for nodes.
 
     Percolation centrality of a node $v$, at a given time, is defined
     as the proportion of ‘percolated paths’ that go through that node.
 
     This measure quantifies relative impact of nodes based on their
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/reaching.py` & `networkx-3.3rc0/networkx/algorithms/centrality/reaching.py`

 * *Files 0% similar despite different names*

```diff
@@ -27,15 +27,15 @@
         return 0
     if weight is None:
         return 1 / path_length
     total_weight = sum(G.edges[i, j][weight] for i, j in pairwise(path))
     return total_weight / path_length
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def global_reaching_centrality(G, weight=None, normalized=True):
     """Returns the global reaching centrality of a directed graph.
 
     The *global reaching centrality* of a weighted directed graph is the
     average over all nodes of the difference between the local reaching
     centrality of the node and the greatest local reaching centrality of
     any node in the graph [1]_. For more information on the local
@@ -115,15 +115,15 @@
         for node, paths in shortest_paths.items()
     ]
 
     max_lrc = max(lrc)
     return sum(max_lrc - c for c in lrc) / (len(G) - 1)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def local_reaching_centrality(G, v, paths=None, weight=None, normalized=True):
     """Returns the local reaching centrality of a node in a directed
     graph.
 
     The *local reaching centrality* of a node in a directed graph is the
     proportion of other nodes reachable from that node [1]_.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/second_order.py` & `networkx-3.3rc0/networkx/algorithms/centrality/second_order.py`

 * *Files 1% similar despite different names*

```diff
@@ -35,15 +35,15 @@
 
 # Authors: Erwan Le Merrer (erwan.lemerrer@technicolor.com)
 
 __all__ = ["second_order_centrality"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def second_order_centrality(G, weight="weight"):
     """Compute the second order centrality for nodes of G.
 
     The second order centrality of a given node is the standard deviation of
     the return times to that node of a perpetual random walk on G:
 
     Parameters
@@ -130,9 +130,12 @@
 
     for i in range(n):
         M[:, i] = np.linalg.solve(
             np.identity(n) - _Qj(P, i), np.ones([n, 1])[:, 0]
         )  # eq 3
 
     return dict(
-        zip(G.nodes, [np.sqrt(2 * np.sum(M[:, i]) - n * (n + 1)) for i in range(n)])
+        zip(
+            G.nodes,
+            (float(np.sqrt(2 * np.sum(M[:, i]) - n * (n + 1))) for i in range(n)),
+        )
     )  # eq 6
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/subgraph_alg.py` & `networkx-3.3rc0/networkx/algorithms/centrality/subgraph_alg.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     "communicability_betweenness_centrality",
     "estrada_index",
 ]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def subgraph_centrality_exp(G):
     r"""Returns the subgraph centrality for each node of G.
 
     Subgraph centrality  of a node `n` is the sum of weighted closed
     walks of all lengths starting and ending at node `n`. The weights
     decrease with path length. Each closed walk is associated with a
     connected subgraph ([1]_).
@@ -94,15 +94,15 @@
     # convert diagonal to dictionary keyed by node
     sc = dict(zip(nodelist, map(float, expA.diagonal())))
     return sc
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def subgraph_centrality(G):
     r"""Returns subgraph centrality for each node in G.
 
     Subgraph centrality  of a node `n` is the sum of weighted closed
     walks of all lengths starting and ending at node `n`. The weights
     decrease with path length. Each closed walk is associated with a
     connected subgraph ([1]_).
@@ -185,15 +185,15 @@
     # convert vector dictionary keyed by node
     sc = dict(zip(nodelist, map(float, xg)))
     return sc
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def communicability_betweenness_centrality(G):
     r"""Returns subgraph communicability for all pairs of nodes in G.
 
     Communicability betweenness measure makes use of the number of walks
     connecting every pair of nodes as the basis of a betweenness centrality
     measure.
 
@@ -274,28 +274,27 @@
         A[i, :] = 0
         A[:, i] = 0
         B = (expA - sp.linalg.expm(A)) / expA
         # sum with row/col of node v and diag set to zero
         B[i, :] = 0
         B[:, i] = 0
         B -= np.diag(np.diag(B))
-        cbc[v] = B.sum()
+        cbc[v] = float(B.sum())
         # put row and col back
         A[i, :] = row
         A[:, i] = col
     # rescale when more than two nodes
     order = len(cbc)
     if order > 2:
         scale = 1.0 / ((order - 1.0) ** 2 - (order - 1.0))
-        for v in cbc:
-            cbc[v] *= scale
+        cbc = {node: value * scale for node, value in cbc.items()}
     return cbc
 
 
-@nx._dispatch
+@nx._dispatchable
 def estrada_index(G):
     r"""Returns the Estrada index of a the graph G.
 
     The Estrada Index is a topological index of folding or 3D "compactness" ([1]_).
 
     Parameters
     ----------
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality_subset.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_betweenness_centrality_subset.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_closeness_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_closeness_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_current_flow_closeness.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_current_flow_closeness.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_degree_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_degree_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_dispersion.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_dispersion.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_eigenvector_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_eigenvector_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_group.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_group.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_harmonic_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_harmonic_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_katz_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_katz_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_laplacian_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_laplacian_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_load_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_load_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_percolation_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_percolation_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_reaching.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_reaching.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_second_order_centrality.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_second_order_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_subgraph.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_subgraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_trophic.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_trophic.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/tests/test_voterank.py` & `networkx-3.3rc0/networkx/algorithms/centrality/tests/test_voterank.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/trophic.py` & `networkx-3.3rc0/networkx/algorithms/centrality/trophic.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["trophic_levels", "trophic_differences", "trophic_incoherence_parameter"]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def trophic_levels(G, weight="weight"):
     r"""Compute the trophic levels of nodes.
 
     The trophic level of a node $i$ is
 
     .. math::
 
@@ -72,21 +72,21 @@
     zero_node_ids = (node_id for node_id, degree in G.in_degree if degree == 0)
     for node_id in zero_node_ids:
         levels[node_id] = 1
 
     # all other nodes have levels as calculated
     nonzero_node_ids = (node_id for node_id, degree in G.in_degree if degree != 0)
     for i, node_id in enumerate(nonzero_node_ids):
-        levels[node_id] = y[i]
+        levels[node_id] = y.item(i)
 
     return levels
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def trophic_differences(G, weight="weight"):
     r"""Compute the trophic differences of the edges of a directed graph.
 
     The trophic difference $x_ij$ for each edge is defined in Johnson et al.
     [1]_ as:
 
     .. math::
@@ -113,15 +113,15 @@
     diffs = {}
     for u, v in G.edges:
         diffs[(u, v)] = levels[v] - levels[u]
     return diffs
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def trophic_incoherence_parameter(G, weight="weight", cannibalism=False):
     r"""Compute the trophic incoherence parameter of a graph.
 
     Trophic coherence is defined as the homogeneity of the distribution of
     trophic distances: the more similar, the more coherent. This is measured by
     the standard deviation of the trophic differences and referred to as the
     trophic incoherence parameter $q$ by [1].
@@ -155,8 +155,8 @@
             # Make a copy so we do not change G's edges in memory
             G_2 = G.copy()
             G_2.remove_edges_from(self_loops)
         else:
             # Avoid copy otherwise
             G_2 = G
         diffs = trophic_differences(G_2, weight=weight)
-    return np.std(list(diffs.values()))
+    return float(np.std(list(diffs.values())))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/centrality/voterank_alg.py` & `networkx-3.3rc0/networkx/algorithms/centrality/voterank_alg.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Algorithm to select influential nodes in a graph using VoteRank."""
 import networkx as nx
 
 __all__ = ["voterank"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def voterank(G, number_of_nodes=None):
     """Select a list of influential nodes in a graph using VoteRank algorithm
 
     VoteRank [1]_ computes a ranking of the nodes in a graph G based on a
-    voting scheme. With VoteRank, all nodes vote for each of its in-neighbours
+    voting scheme. With VoteRank, all nodes vote for each of its in-neighbors
     and the node with the highest votes is elected iteratively. The voting
     ability of out-neighbors of elected nodes is decreased in subsequent turns.
 
     Parameters
     ----------
     G : graph
         A NetworkX graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/chains.py` & `networkx-3.3rc0/networkx/algorithms/chains.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["chain_decomposition"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def chain_decomposition(G, root=None):
     """Returns the chain decomposition of a graph.
 
     The *chain decomposition* of a graph with respect a depth-first
     search tree is a set of cycles or paths derived from the set of
     fundamental cycles of the tree in the following manner. Consider
     each fundamental cycle with respect to the given tree, represented
```

### Comparing `networkx-3.2rc0/networkx/algorithms/chordal.py` & `networkx-3.3rc0/networkx/algorithms/chordal.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 class NetworkXTreewidthBoundExceeded(nx.NetworkXException):
     """Exception raised when a treewidth bound has been provided and it has
     been exceeded"""
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_chordal(G):
     """Checks whether G is a chordal graph.
 
     A graph is chordal if every cycle of length at least 4 has a chord
     (an edge joining two nodes not adjacent in the cycle).
 
     Parameters
@@ -84,15 +84,15 @@
        pp. 566–579.
     """
     if len(G.nodes) <= 3:
         return True
     return len(_find_chordality_breaker(G)) == 0
 
 
-@nx._dispatch
+@nx._dispatchable
 def find_induced_nodes(G, s, t, treewidth_bound=sys.maxsize):
     """Returns the set of induced nodes in the path from s to t.
 
     Parameters
     ----------
     G : graph
       A chordal NetworkX graph
@@ -164,15 +164,15 @@
         for u in G[s]:
             if len(induced_nodes & set(G[u])) == 2:
                 induced_nodes.add(u)
                 break
     return induced_nodes
 
 
-@nx._dispatch
+@nx._dispatchable
 def chordal_graph_cliques(G):
     """Returns all maximal cliques of a chordal graph.
 
     The algorithm breaks the graph in connected components and performs a
     maximum cardinality search in each component to get the cliques.
 
     Parameters
@@ -237,15 +237,15 @@
                         yield frozenset(clique_wanna_be)
                     clique_wanna_be = new_clique_wanna_be
                 else:
                     raise nx.NetworkXError("Input graph is not chordal.")
             yield frozenset(clique_wanna_be)
 
 
-@nx._dispatch
+@nx._dispatchable
 def chordal_graph_treewidth(G):
     """Returns the treewidth of the chordal graph G.
 
     Parameters
     ----------
     G : graph
       A NetworkX graph
@@ -335,14 +335,16 @@
     trying to find a non-chordal cycle.
 
     If it does find one, it returns (u,v,w) where u,v,w are the three
     nodes that together with s are involved in the cycle.
 
     It ignores any self loops.
     """
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept("Graph has no nodes.")
     unnumbered = set(G)
     if s is None:
         s = arbitrary_element(G)
     unnumbered.remove(s)
     numbered = {s}
     current_treewidth = -1
     while unnumbered:  # and current_treewidth <= treewidth_bound:
@@ -363,15 +365,15 @@
             # look for an edge that is not included in sg
             (u, w) = _find_missing_edge(sg)
             return (u, v, w)
     return ()
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def complete_to_chordal_graph(G):
     """Return a copy of G completed to a chordal graph
 
     Adds edges to a copy of G to create a chordal graph. A graph G=(V,E) is
     called chordal if for each cycle with length bigger than 3, there exist
     two non-adjacent nodes connected by an edge (called a chord).
```

### Comparing `networkx-3.2rc0/networkx/algorithms/clique.py` & `networkx-3.3rc0/networkx/algorithms/clique.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,26 +14,23 @@
 from networkx.utils import not_implemented_for
 
 __all__ = [
     "find_cliques",
     "find_cliques_recursive",
     "make_max_clique_graph",
     "make_clique_bipartite",
-    "graph_clique_number",
-    "graph_number_of_cliques",
     "node_clique_number",
     "number_of_cliques",
-    "cliques_containing_node",
     "enumerate_all_cliques",
     "max_weight_clique",
 ]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def enumerate_all_cliques(G):
     """Returns all cliques in an undirected graph.
 
     This function returns an iterator over cliques, each of which is a
     list of nodes. The iteration is ordered by cardinality of the
     cliques: first all cliques of size one, then all cliques of size
     two, etc.
@@ -97,15 +94,15 @@
                     chain(base, [u]),
                     filter(nbrs[u].__contains__, islice(cnbrs, i + 1, None)),
                 )
             )
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def find_cliques(G, nodes=None):
     """Returns all maximal cliques in an undirected graph.
 
     For each node *n*, a *maximal clique for n* is a largest complete
     subgraph containing *n*. The largest maximal clique is sometimes
     called the *maximum clique*.
 
@@ -293,15 +290,15 @@
                 Q.pop()
                 subg, cand, ext_u = stack.pop()
     except IndexError:
         pass
 
 
 # TODO Should this also be not implemented for directed graphs?
-@nx._dispatch
+@nx._dispatchable
 def find_cliques_recursive(G, nodes=None):
     """Returns all maximal cliques in a graph.
 
     For each node *v*, a *maximal clique for v* is a largest complete
     subgraph containing *v*. The largest maximal clique is sometimes
     called the *maximum clique*.
 
@@ -411,15 +408,15 @@
                 if cand_q:
                     yield from expand(subg_q, cand_q)
             Q.pop()
 
     return expand(subg_init, cand_init)
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def make_max_clique_graph(G, create_using=None):
     """Returns the maximal clique graph of the given graph.
 
     The nodes of the maximal clique graph of `G` are the cliques of
     `G` and an edge joins two cliques if the cliques are not disjoint.
 
     Parameters
@@ -436,16 +433,17 @@
         join two cliques if they are not disjoint.
 
     Notes
     -----
     This function behaves like the following code::
 
         import networkx as nx
+
         G = nx.make_clique_bipartite(G)
-        cliques = [v for v in G.nodes() if G.nodes[v]['bipartite'] == 0]
+        cliques = [v for v in G.nodes() if G.nodes[v]["bipartite"] == 0]
         G = nx.bipartite.projected_graph(G, cliques)
         G = nx.relabel_nodes(G, {-v: v - 1 for v in G})
 
     It should be faster, though, since it skips all the intermediate
     steps.
 
     """
@@ -458,15 +456,15 @@
     B.add_nodes_from(i for i, c in cliques)
     # Join cliques by an edge if they share a node.
     clique_pairs = combinations(cliques, 2)
     B.add_edges_from((i, j) for (i, c1), (j, c2) in clique_pairs if c1 & c2)
     return B
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def make_clique_bipartite(G, fpos=None, create_using=None, name=None):
     """Returns the bipartite clique graph corresponding to `G`.
 
     In the returned bipartite graph, the "bottom" nodes are the nodes of
     `G` and the "top" nodes represent the maximal cliques of `G`.
     There is an edge from node *v* to clique *C* in the returned graph
     if and only if *v* is an element of *C*.
@@ -507,115 +505,15 @@
         # nodes get negative numbers as labels.
         name = -i - 1
         B.add_node(name, bipartite=0)
         B.add_edges_from((v, name) for v in cl)
     return B
 
 
-def graph_clique_number(G, cliques=None):
-    """Returns the clique number of the graph.
-
-    The *clique number* of a graph is the size of the largest clique in
-    the graph.
-
-    .. deprecated:: 3.0
-
-       graph_clique_number is deprecated in NetworkX 3.0 and will be removed
-       in v3.2. The graph clique number can be computed directly with::
-
-           max(len(c) for c in nx.find_cliques(G))
-
-
-    Parameters
-    ----------
-    G : NetworkX graph
-        An undirected graph.
-
-    cliques : list
-        A list of cliques, each of which is itself a list of nodes. If
-        not specified, the list of all cliques will be computed, as by
-        :func:`find_cliques`.
-
-    Returns
-    -------
-    int
-        The size of the largest clique in `G`.
-
-    Notes
-    -----
-    You should provide `cliques` if you have already computed the list
-    of maximal cliques, in order to avoid an exponential time search for
-    maximal cliques.
-
-    """
-    import warnings
-
-    warnings.warn(
-        (
-            "\n\ngraph_clique_number is deprecated and will be removed.\n"
-            "Use: ``max(len(c) for c in nx.find_cliques(G))`` instead."
-        ),
-        DeprecationWarning,
-        stacklevel=2,
-    )
-    if len(G.nodes) < 1:
-        return 0
-    if cliques is None:
-        cliques = find_cliques(G)
-    return max([len(c) for c in cliques] or [1])
-
-
-def graph_number_of_cliques(G, cliques=None):
-    """Returns the number of maximal cliques in the graph.
-
-    .. deprecated:: 3.0
-
-       graph_number_of_cliques is deprecated and will be removed in v3.2.
-       The number of maximal cliques can be computed directly with::
-
-           sum(1 for _ in nx.find_cliques(G))
-
-    Parameters
-    ----------
-    G : NetworkX graph
-        An undirected graph.
-
-    cliques : list
-        A list of cliques, each of which is itself a list of nodes. If
-        not specified, the list of all cliques will be computed, as by
-        :func:`find_cliques`.
-
-    Returns
-    -------
-    int
-        The number of maximal cliques in `G`.
-
-    Notes
-    -----
-    You should provide `cliques` if you have already computed the list
-    of maximal cliques, in order to avoid an exponential time search for
-    maximal cliques.
-
-    """
-    import warnings
-
-    warnings.warn(
-        (
-            "\n\ngraph_number_of_cliques is deprecated and will be removed.\n"
-            "Use: ``sum(1 for _ in nx.find_cliques(G))`` instead."
-        ),
-        DeprecationWarning,
-        stacklevel=2,
-    )
-    if cliques is None:
-        cliques = list(find_cliques(G))
-    return len(cliques)
-
-
-@nx._dispatch
+@nx._dispatchable
 def node_clique_number(G, nodes=None, cliques=None, separate_nodes=False):
     """Returns the size of the largest maximal clique containing each given node.
 
     Returns a single or list depending on input nodes.
     An optional list of cliques can be input if already computed.
 
     Parameters
@@ -674,37 +572,17 @@
         return size_for_n
     return {n: size_for_n[n] for n in nodes}
 
 
 def number_of_cliques(G, nodes=None, cliques=None):
     """Returns the number of maximal cliques for each node.
 
-    .. deprecated:: 3.0
-
-       number_of_cliques is deprecated and will be removed in v3.2.
-       Use the result of `find_cliques` directly to compute the number of
-       cliques containing each node::
-
-           {n: sum(1 for c in nx.find_cliques(G) if n in c) for n in G}
-
     Returns a single or list depending on input nodes.
     Optional list of cliques can be input if already computed.
     """
-    import warnings
-
-    warnings.warn(
-        (
-            "\n\nnumber_of_cliques is deprecated and will be removed.\n"
-            "Use the result of find_cliques directly to compute the number\n"
-            "of cliques containing each node:\n\n"
-            "    {n: sum(1 for c in nx.find_cliques(G) if n in c) for n in G}\n\n"
-        ),
-        DeprecationWarning,
-        stacklevel=2,
-    )
     if cliques is None:
         cliques = list(find_cliques(G))
 
     if nodes is None:
         nodes = list(G.nodes())  # none, get entire graph
 
     if not isinstance(nodes, list):  # check for a list
@@ -714,57 +592,14 @@
     else:
         numcliq = {}
         for v in nodes:
             numcliq[v] = len([1 for c in cliques if v in c])
     return numcliq
 
 
-def cliques_containing_node(G, nodes=None, cliques=None):
-    """Returns a list of cliques containing the given node.
-
-    .. deprecated:: 3.0
-
-       cliques_containing_node is deprecated and will be removed in 3.2.
-       Use the result of `find_cliques` directly to compute the cliques that
-       contain each node::
-
-           {n: [c for c in nx.find_cliques(G) if n in c] for n in G}
-
-    Returns a single list or list of lists depending on input nodes.
-    Optional list of cliques can be input if already computed.
-    """
-    import warnings
-
-    warnings.warn(
-        (
-            "\n\ncliques_containing_node is deprecated and will be removed.\n"
-            "Use the result of find_cliques directly to compute maximal cliques\n"
-            "containing each node:\n\n"
-            "    {n: [c for c in nx.find_cliques(G) if n in c] for n in G}\n\n"
-        ),
-        DeprecationWarning,
-        stacklevel=2,
-    )
-    if cliques is None:
-        cliques = list(find_cliques(G))
-
-    if nodes is None:
-        nodes = list(G.nodes())  # none, get entire graph
-
-    if not isinstance(nodes, list):  # check for a list
-        v = nodes
-        # assume it is a single value
-        vcliques = [c for c in cliques if v in c]
-    else:
-        vcliques = {}
-        for v in nodes:
-            vcliques[v] = [c for c in cliques if v in c]
-    return vcliques
-
-
 class MaxWeightClique:
     """A class for the maximum weight clique algorithm.
 
     This class is a helper for the `max_weight_clique` function.  The class
     should not normally be used directly.
 
     Parameters
@@ -860,15 +695,15 @@
         # Sort nodes in reverse order of degree for speed
         nodes = sorted(self.G.nodes(), key=lambda v: self.G.degree(v), reverse=True)
         nodes = [v for v in nodes if self.node_weights[v] > 0]
         self.expand([], 0, nodes)
 
 
 @not_implemented_for("directed")
-@nx._dispatch(node_attrs="weight")
+@nx._dispatchable(node_attrs="weight")
 def max_weight_clique(G, weight="weight"):
     """Find a maximum weight clique in G.
 
     A *clique* in a graph is a set of nodes such that every two distinct nodes
     are adjacent.  The *weight* of a clique is the sum of the weights of its
     nodes.  A *maximum weight clique* of graph G is a clique C in G such that
     no clique in G has weight greater than the weight of C.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/cluster.py` & `networkx-3.3rc0/networkx/algorithms/coloring/greedy_coloring.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,605 +1,564 @@
-"""Algorithms to characterize the number of triangles in a graph."""
-
-from collections import Counter
-from itertools import chain, combinations
+"""
+Greedy graph coloring using various strategies.
+"""
+import itertools
+from collections import defaultdict, deque
 
 import networkx as nx
-from networkx.utils import not_implemented_for
+from networkx.utils import arbitrary_element, py_random_state
 
 __all__ = [
-    "triangles",
-    "average_clustering",
-    "clustering",
-    "transitivity",
-    "square_clustering",
-    "generalized_degree",
+    "greedy_color",
+    "strategy_connected_sequential",
+    "strategy_connected_sequential_bfs",
+    "strategy_connected_sequential_dfs",
+    "strategy_independent_set",
+    "strategy_largest_first",
+    "strategy_random_sequential",
+    "strategy_saturation_largest_first",
+    "strategy_smallest_last",
 ]
 
 
-@not_implemented_for("directed")
-@nx._dispatch
-def triangles(G, nodes=None):
-    """Compute the number of triangles.
-
-    Finds the number of triangles that include a node as one vertex.
-
-    Parameters
-    ----------
-    G : graph
-       A networkx graph
-
-    nodes : node, iterable of nodes, or None (default=None)
-        If a singleton node, return the number of triangles for that node.
-        If an iterable, compute the number of triangles for each of those nodes.
-        If `None` (the default) compute the number of triangles for all nodes in `G`.
-
-    Returns
-    -------
-    out : dict or int
-       If `nodes` is a container of nodes, returns number of triangles keyed by node (dict).
-       If `nodes` is a specific node, returns number of triangles for the node (int).
+def strategy_largest_first(G, colors):
+    """Returns a list of the nodes of ``G`` in decreasing order by
+    degree.
 
-    Examples
-    --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.triangles(G, 0))
-    6
-    >>> print(nx.triangles(G))
-    {0: 6, 1: 6, 2: 6, 3: 6, 4: 6}
-    >>> print(list(nx.triangles(G, [0, 1]).values()))
-    [6, 6]
-
-    Notes
-    -----
-    Self loops are ignored.
-
-    """
-    if nodes is not None:
-        # If `nodes` represents a single node, return only its number of triangles
-        if nodes in G:
-            return next(_triangles_and_degree_iter(G, nodes))[2] // 2
-
-        # if `nodes` is a container of nodes, then return a
-        # dictionary mapping node to number of triangles.
-        return {v: t // 2 for v, d, t, _ in _triangles_and_degree_iter(G, nodes)}
-
-    # if nodes is None, then compute triangles for the complete graph
-
-    # dict used to avoid visiting the same nodes twice
-    # this allows calculating/counting each triangle only once
-    later_neighbors = {}
-
-    # iterate over the nodes in a graph
-    for node, neighbors in G.adjacency():
-        later_neighbors[node] = {
-            n for n in neighbors if n not in later_neighbors and n is not node
-        }
-
-    # instantiate Counter for each node to include isolated nodes
-    # add 1 to the count if a nodes neighbor's neighbor is also a neighbor
-    triangle_counts = Counter(dict.fromkeys(G, 0))
-    for node1, neighbors in later_neighbors.items():
-        for node2 in neighbors:
-            third_nodes = neighbors & later_neighbors[node2]
-            m = len(third_nodes)
-            triangle_counts[node1] += m
-            triangle_counts[node2] += m
-            triangle_counts.update(third_nodes)
-
-    return dict(triangle_counts)
-
-
-@not_implemented_for("multigraph")
-def _triangles_and_degree_iter(G, nodes=None):
-    """Return an iterator of (node, degree, triangles, generalized degree).
-
-    This double counts triangles so you may want to divide by 2.
-    See degree(), triangles() and generalized_degree() for definitions
-    and details.
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
     """
-    if nodes is None:
-        nodes_nbrs = G.adj.items()
-    else:
-        nodes_nbrs = ((n, G[n]) for n in G.nbunch_iter(nodes))
-
-    for v, v_nbrs in nodes_nbrs:
-        vs = set(v_nbrs) - {v}
-        gen_degree = Counter(len(vs & (set(G[w]) - {w})) for w in vs)
-        ntriangles = sum(k * val for k, val in gen_degree.items())
-        yield (v, len(vs), ntriangles, gen_degree)
+    return sorted(G, key=G.degree, reverse=True)
 
 
-@not_implemented_for("multigraph")
-def _weighted_triangles_and_degree_iter(G, nodes=None, weight="weight"):
-    """Return an iterator of (node, degree, weighted_triangles).
+@py_random_state(2)
+def strategy_random_sequential(G, colors, seed=None):
+    """Returns a random permutation of the nodes of ``G`` as a list.
 
-    Used for weighted clustering.
-    Note: this returns the geometric average weight of edges in the triangle.
-    Also, each triangle is counted twice (each direction).
-    So you may want to divide by 2.
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
     """
-    import numpy as np
-
-    if weight is None or G.number_of_edges() == 0:
-        max_weight = 1
-    else:
-        max_weight = max(d.get(weight, 1) for u, v, d in G.edges(data=True))
-    if nodes is None:
-        nodes_nbrs = G.adj.items()
-    else:
-        nodes_nbrs = ((n, G[n]) for n in G.nbunch_iter(nodes))
-
-    def wt(u, v):
-        return G[u][v].get(weight, 1) / max_weight
+    nodes = list(G)
+    seed.shuffle(nodes)
+    return nodes
 
-    for i, nbrs in nodes_nbrs:
-        inbrs = set(nbrs) - {i}
-        weighted_triangles = 0
-        seen = set()
-        for j in inbrs:
-            seen.add(j)
-            # This avoids counting twice -- we double at the end.
-            jnbrs = set(G[j]) - seen
-            # Only compute the edge weight once, before the inner inner
-            # loop.
-            wij = wt(i, j)
-            weighted_triangles += sum(
-                np.cbrt([(wij * wt(j, k) * wt(k, i)) for k in inbrs & jnbrs])
-            )
-        yield (i, len(inbrs), 2 * weighted_triangles)
-
-
-@not_implemented_for("multigraph")
-def _directed_triangles_and_degree_iter(G, nodes=None):
-    """Return an iterator of
-    (node, total_degree, reciprocal_degree, directed_triangles).
-
-    Used for directed clustering.
-    Note that unlike `_triangles_and_degree_iter()`, this function counts
-    directed triangles so does not count triangles twice.
-
-    """
-    nodes_nbrs = ((n, G._pred[n], G._succ[n]) for n in G.nbunch_iter(nodes))
-
-    for i, preds, succs in nodes_nbrs:
-        ipreds = set(preds) - {i}
-        isuccs = set(succs) - {i}
-
-        directed_triangles = 0
-        for j in chain(ipreds, isuccs):
-            jpreds = set(G._pred[j]) - {j}
-            jsuccs = set(G._succ[j]) - {j}
-            directed_triangles += sum(
-                1
-                for k in chain(
-                    (ipreds & jpreds),
-                    (ipreds & jsuccs),
-                    (isuccs & jpreds),
-                    (isuccs & jsuccs),
-                )
-            )
-        dtotal = len(ipreds) + len(isuccs)
-        dbidirectional = len(ipreds & isuccs)
-        yield (i, dtotal, dbidirectional, directed_triangles)
-
-
-@not_implemented_for("multigraph")
-def _directed_weighted_triangles_and_degree_iter(G, nodes=None, weight="weight"):
-    """Return an iterator of
-    (node, total_degree, reciprocal_degree, directed_weighted_triangles).
-
-    Used for directed weighted clustering.
-    Note that unlike `_weighted_triangles_and_degree_iter()`, this function counts
-    directed triangles so does not count triangles twice.
 
-    """
-    import numpy as np
-
-    if weight is None or G.number_of_edges() == 0:
-        max_weight = 1
-    else:
-        max_weight = max(d.get(weight, 1) for u, v, d in G.edges(data=True))
+def strategy_smallest_last(G, colors):
+    """Returns a deque of the nodes of ``G``, "smallest" last.
 
-    nodes_nbrs = ((n, G._pred[n], G._succ[n]) for n in G.nbunch_iter(nodes))
+    Specifically, the degrees of each node are tracked in a bucket queue.
+    From this, the node of minimum degree is repeatedly popped from the
+    graph, updating its neighbors' degrees.
 
-    def wt(u, v):
-        return G[u][v].get(weight, 1) / max_weight
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
-    for i, preds, succs in nodes_nbrs:
-        ipreds = set(preds) - {i}
-        isuccs = set(succs) - {i}
-
-        directed_triangles = 0
-        for j in ipreds:
-            jpreds = set(G._pred[j]) - {j}
-            jsuccs = set(G._succ[j]) - {j}
-            directed_triangles += sum(
-                np.cbrt([(wt(j, i) * wt(k, i) * wt(k, j)) for k in ipreds & jpreds])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(j, i) * wt(k, i) * wt(j, k)) for k in ipreds & jsuccs])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(j, i) * wt(i, k) * wt(k, j)) for k in isuccs & jpreds])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(j, i) * wt(i, k) * wt(j, k)) for k in isuccs & jsuccs])
-            )
-
-        for j in isuccs:
-            jpreds = set(G._pred[j]) - {j}
-            jsuccs = set(G._succ[j]) - {j}
-            directed_triangles += sum(
-                np.cbrt([(wt(i, j) * wt(k, i) * wt(k, j)) for k in ipreds & jpreds])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(i, j) * wt(k, i) * wt(j, k)) for k in ipreds & jsuccs])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(i, j) * wt(i, k) * wt(k, j)) for k in isuccs & jpreds])
-            )
-            directed_triangles += sum(
-                np.cbrt([(wt(i, j) * wt(i, k) * wt(j, k)) for k in isuccs & jsuccs])
-            )
-
-        dtotal = len(ipreds) + len(isuccs)
-        dbidirectional = len(ipreds & isuccs)
-        yield (i, dtotal, dbidirectional, directed_triangles)
-
-
-@nx._dispatch(edge_attrs="weight")
-def average_clustering(G, nodes=None, weight=None, count_zeros=True):
-    r"""Compute the average clustering coefficient for the graph G.
+    This implementation of the strategy runs in $O(n + m)$ time
+    (ignoring polylogarithmic factors), where $n$ is the number of nodes
+    and $m$ is the number of edges.
 
-    The clustering coefficient for the graph is the average,
+    This strategy is related to :func:`strategy_independent_set`: if we
+    interpret each node removed as an independent set of size one, then
+    this strategy chooses an independent set of size one instead of a
+    maximal independent set.
 
-    .. math::
-
-       C = \frac{1}{n}\sum_{v \in G} c_v,
+    """
+    H = G.copy()
+    result = deque()
 
-    where :math:`n` is the number of nodes in `G`.
+    # Build initial degree list (i.e. the bucket queue data structure)
+    degrees = defaultdict(set)  # set(), for fast random-access removals
+    lbound = float("inf")
+    for node, d in H.degree():
+        degrees[d].add(node)
+        lbound = min(lbound, d)  # Lower bound on min-degree.
+
+    def find_min_degree():
+        # Save time by starting the iterator at `lbound`, not 0.
+        # The value that we find will be our new `lbound`, which we set later.
+        return next(d for d in itertools.count(lbound) if d in degrees)
+
+    for _ in G:
+        # Pop a min-degree node and add it to the list.
+        min_degree = find_min_degree()
+        u = degrees[min_degree].pop()
+        if not degrees[min_degree]:  # Clean up the degree list.
+            del degrees[min_degree]
+        result.appendleft(u)
+
+        # Update degrees of removed node's neighbors.
+        for v in H[u]:
+            degree = H.degree(v)
+            degrees[degree].remove(v)
+            if not degrees[degree]:  # Clean up the degree list.
+                del degrees[degree]
+            degrees[degree - 1].add(v)
+
+        # Finally, remove the node.
+        H.remove_node(u)
+        lbound = min_degree - 1  # Subtract 1 in case of tied neighbors.
+
+    return result
+
+
+def _maximal_independent_set(G):
+    """Returns a maximal independent set of nodes in ``G`` by repeatedly
+    choosing an independent node of minimum degree (with respect to the
+    subgraph of unchosen nodes).
 
-    Parameters
-    ----------
-    G : graph
+    """
+    result = set()
+    remaining = set(G)
+    while remaining:
+        G = G.subgraph(remaining)
+        v = min(remaining, key=G.degree)
+        result.add(v)
+        remaining -= set(G[v]) | {v}
+    return result
+
+
+def strategy_independent_set(G, colors):
+    """Uses a greedy independent set removal strategy to determine the
+    colors.
+
+    This function updates ``colors`` **in-place** and return ``None``,
+    unlike the other strategy functions in this module.
+
+    This algorithm repeatedly finds and removes a maximal independent
+    set, assigning each node in the set an unused color.
+
+    ``G`` is a NetworkX graph.
+
+    This strategy is related to :func:`strategy_smallest_last`: in that
+    strategy, an independent set of size one is chosen at each step
+    instead of a maximal independent set.
 
-    nodes : container of nodes, optional (default=all nodes in G)
-       Compute average clustering for nodes in this container.
+    """
+    remaining_nodes = set(G)
+    while len(remaining_nodes) > 0:
+        nodes = _maximal_independent_set(G.subgraph(remaining_nodes))
+        remaining_nodes -= nodes
+        yield from nodes
 
-    weight : string or None, optional (default=None)
-       The edge attribute that holds the numerical value used as a weight.
-       If None, then each edge has weight 1.
 
-    count_zeros : bool
-       If False include only the nodes with nonzero clustering in the average.
+def strategy_connected_sequential_bfs(G, colors):
+    """Returns an iterable over nodes in ``G`` in the order given by a
+    breadth-first traversal.
 
-    Returns
-    -------
-    avg : float
-       Average clustering
+    The generated sequence has the property that for each node except
+    the first, at least one neighbor appeared earlier in the sequence.
 
-    Examples
-    --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.average_clustering(G))
-    1.0
-
-    Notes
-    -----
-    This is a space saving routine; it might be faster
-    to use the clustering function to get a list and then take the average.
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
-    Self loops are ignored.
-
-    References
-    ----------
-    .. [1] Generalizations of the clustering coefficient to weighted
-       complex networks by J. Saramäki, M. Kivelä, J.-P. Onnela,
-       K. Kaski, and J. Kertész, Physical Review E, 75 027105 (2007).
-       http://jponnela.com/web_documents/a9.pdf
-    .. [2] Marcus Kaiser,  Mean clustering coefficients: the role of isolated
-       nodes and leafs on clustering measures for small-world networks.
-       https://arxiv.org/abs/0802.2512
     """
-    c = clustering(G, nodes, weight=weight).values()
-    if not count_zeros:
-        c = [v for v in c if abs(v) > 0]
-    return sum(c) / len(c)
-
-
-@nx._dispatch(edge_attrs="weight")
-def clustering(G, nodes=None, weight=None):
-    r"""Compute the clustering coefficient for nodes.
+    return strategy_connected_sequential(G, colors, "bfs")
 
-    For unweighted graphs, the clustering of a node :math:`u`
-    is the fraction of possible triangles through that node that exist,
 
-    .. math::
+def strategy_connected_sequential_dfs(G, colors):
+    """Returns an iterable over nodes in ``G`` in the order given by a
+    depth-first traversal.
 
-      c_u = \frac{2 T(u)}{deg(u)(deg(u)-1)},
+    The generated sequence has the property that for each node except
+    the first, at least one neighbor appeared earlier in the sequence.
 
-    where :math:`T(u)` is the number of triangles through node :math:`u` and
-    :math:`deg(u)` is the degree of :math:`u`.
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
-    For weighted graphs, there are several ways to define clustering [1]_.
-    the one used here is defined
-    as the geometric average of the subgraph edge weights [2]_,
+    """
+    return strategy_connected_sequential(G, colors, "dfs")
 
-    .. math::
 
-       c_u = \frac{1}{deg(u)(deg(u)-1))}
-             \sum_{vw} (\hat{w}_{uv} \hat{w}_{uw} \hat{w}_{vw})^{1/3}.
+def strategy_connected_sequential(G, colors, traversal="bfs"):
+    """Returns an iterable over nodes in ``G`` in the order given by a
+    breadth-first or depth-first traversal.
 
-    The edge weights :math:`\hat{w}_{uv}` are normalized by the maximum weight
-    in the network :math:`\hat{w}_{uv} = w_{uv}/\max(w)`.
+    ``traversal`` must be one of the strings ``'dfs'`` or ``'bfs'``,
+    representing depth-first traversal or breadth-first traversal,
+    respectively.
 
-    The value of :math:`c_u` is assigned to 0 if :math:`deg(u) < 2`.
+    The generated sequence has the property that for each node except
+    the first, at least one neighbor appeared earlier in the sequence.
 
-    Additionally, this weighted definition has been generalized to support negative edge weights [3]_.
+    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
-    For directed graphs, the clustering is similarly defined as the fraction
-    of all possible directed triangles or geometric average of the subgraph
-    edge weights for unweighted and weighted directed graph respectively [4]_.
+    """
+    if traversal == "bfs":
+        traverse = nx.bfs_edges
+    elif traversal == "dfs":
+        traverse = nx.dfs_edges
+    else:
+        raise nx.NetworkXError(
+            "Please specify one of the strings 'bfs' or"
+            " 'dfs' for connected sequential ordering"
+        )
+    for component in nx.connected_components(G):
+        source = arbitrary_element(component)
+        # Yield the source node, then all the nodes in the specified
+        # traversal order.
+        yield source
+        for _, end in traverse(G.subgraph(component), source):
+            yield end
+
+
+def strategy_saturation_largest_first(G, colors):
+    """Iterates over all the nodes of ``G`` in "saturation order" (also
+    known as "DSATUR").
 
-    .. math::
+    ``G`` is a NetworkX graph. ``colors`` is a dictionary mapping nodes of
+    ``G`` to colors, for those nodes that have already been colored.
 
-       c_u = \frac{T(u)}{2(deg^{tot}(u)(deg^{tot}(u)-1) - 2deg^{\leftrightarrow}(u))},
+    """
+    distinct_colors = {v: set() for v in G}
 
-    where :math:`T(u)` is the number of directed triangles through node
-    :math:`u`, :math:`deg^{tot}(u)` is the sum of in degree and out degree of
-    :math:`u` and :math:`deg^{\leftrightarrow}(u)` is the reciprocal degree of
-    :math:`u`.
+    # Add the node color assignments given in colors to the
+    # distinct colors set for each neighbor of that node
+    for node, color in colors.items():
+        for neighbor in G[node]:
+            distinct_colors[neighbor].add(color)
+
+    # Check that the color assignments in colors are valid
+    # i.e. no neighboring nodes have the same color
+    if len(colors) >= 2:
+        for node, color in colors.items():
+            if color in distinct_colors[node]:
+                raise nx.NetworkXError("Neighboring nodes must have different colors")
+
+    # If 0 nodes have been colored, simply choose the node of highest degree.
+    if not colors:
+        node = max(G, key=G.degree)
+        yield node
+        # Add the color 0 to the distinct colors set for each
+        # neighbor of that node.
+        for v in G[node]:
+            distinct_colors[v].add(0)
+
+    while len(G) != len(colors):
+        # Update the distinct color sets for the neighbors.
+        for node, color in colors.items():
+            for neighbor in G[node]:
+                distinct_colors[neighbor].add(color)
+
+        # Compute the maximum saturation and the set of nodes that
+        # achieve that saturation.
+        saturation = {v: len(c) for v, c in distinct_colors.items() if v not in colors}
+        # Yield the node with the highest saturation, and break ties by
+        # degree.
+        node = max(saturation, key=lambda v: (saturation[v], G.degree(v)))
+        yield node
+
+
+#: Dictionary mapping name of a strategy as a string to the strategy function.
+STRATEGIES = {
+    "largest_first": strategy_largest_first,
+    "random_sequential": strategy_random_sequential,
+    "smallest_last": strategy_smallest_last,
+    "independent_set": strategy_independent_set,
+    "connected_sequential_bfs": strategy_connected_sequential_bfs,
+    "connected_sequential_dfs": strategy_connected_sequential_dfs,
+    "connected_sequential": strategy_connected_sequential,
+    "saturation_largest_first": strategy_saturation_largest_first,
+    "DSATUR": strategy_saturation_largest_first,
+}
+
+
+@nx._dispatchable
+def greedy_color(G, strategy="largest_first", interchange=False):
+    """Color a graph using various strategies of greedy graph coloring.
+
+    Attempts to color a graph using as few colors as possible, where no
+    neighbors of a node can have same color as the node itself. The
+    given strategy determines the order in which nodes are colored.
 
+    The strategies are described in [1]_, and smallest-last is based on
+    [2]_.
 
     Parameters
     ----------
-    G : graph
+    G : NetworkX graph
 
-    nodes : node, iterable of nodes, or None (default=None)
-        If a singleton node, return the number of triangles for that node.
-        If an iterable, compute the number of triangles for each of those nodes.
-        If `None` (the default) compute the number of triangles for all nodes in `G`.
-
-    weight : string or None, optional (default=None)
-       The edge attribute that holds the numerical value used as a weight.
-       If None, then each edge has weight 1.
+    strategy : string or function(G, colors)
+       A function (or a string representing a function) that provides
+       the coloring strategy, by returning nodes in the ordering they
+       should be colored. ``G`` is the graph, and ``colors`` is a
+       dictionary of the currently assigned colors, keyed by nodes. The
+       function must return an iterable over all the nodes in ``G``.
+
+       If the strategy function is an iterator generator (that is, a
+       function with ``yield`` statements), keep in mind that the
+       ``colors`` dictionary will be updated after each ``yield``, since
+       this function chooses colors greedily.
+
+       If ``strategy`` is a string, it must be one of the following,
+       each of which represents one of the built-in strategy functions.
+
+       * ``'largest_first'``
+       * ``'random_sequential'``
+       * ``'smallest_last'``
+       * ``'independent_set'``
+       * ``'connected_sequential_bfs'``
+       * ``'connected_sequential_dfs'``
+       * ``'connected_sequential'`` (alias for the previous strategy)
+       * ``'saturation_largest_first'``
+       * ``'DSATUR'`` (alias for the previous strategy)
+
+    interchange: bool
+       Will use the color interchange algorithm described by [3]_ if set
+       to ``True``.
+
+       Note that ``saturation_largest_first`` and ``independent_set``
+       do not work with interchange. Furthermore, if you use
+       interchange with your own strategy function, you cannot rely
+       on the values in the ``colors`` argument.
 
     Returns
     -------
-    out : float, or dictionary
-       Clustering coefficient at specified nodes
+    A dictionary with keys representing nodes and values representing
+    corresponding coloring.
 
     Examples
     --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.clustering(G, 0))
-    1.0
-    >>> print(nx.clustering(G))
-    {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}
-
-    Notes
-    -----
-    Self loops are ignored.
-
-    References
-    ----------
-    .. [1] Generalizations of the clustering coefficient to weighted
-       complex networks by J. Saramäki, M. Kivelä, J.-P. Onnela,
-       K. Kaski, and J. Kertész, Physical Review E, 75 027105 (2007).
-       http://jponnela.com/web_documents/a9.pdf
-    .. [2] Intensity and coherence of motifs in weighted complex
-       networks by J. P. Onnela, J. Saramäki, J. Kertész, and K. Kaski,
-       Physical Review E, 71(6), 065103 (2005).
-    .. [3] Generalization of Clustering Coefficients to Signed Correlation Networks
-       by G. Costantini and M. Perugini, PloS one, 9(2), e88669 (2014).
-    .. [4] Clustering in complex directed networks by G. Fagiolo,
-       Physical Review E, 76(2), 026107 (2007).
-    """
-    if G.is_directed():
-        if weight is not None:
-            td_iter = _directed_weighted_triangles_and_degree_iter(G, nodes, weight)
-            clusterc = {
-                v: 0 if t == 0 else t / ((dt * (dt - 1) - 2 * db) * 2)
-                for v, dt, db, t in td_iter
-            }
-        else:
-            td_iter = _directed_triangles_and_degree_iter(G, nodes)
-            clusterc = {
-                v: 0 if t == 0 else t / ((dt * (dt - 1) - 2 * db) * 2)
-                for v, dt, db, t in td_iter
-            }
-    else:
-        # The formula 2*T/(d*(d-1)) from docs is t/(d*(d-1)) here b/c t==2*T
-        if weight is not None:
-            td_iter = _weighted_triangles_and_degree_iter(G, nodes, weight)
-            clusterc = {v: 0 if t == 0 else t / (d * (d - 1)) for v, d, t in td_iter}
-        else:
-            td_iter = _triangles_and_degree_iter(G, nodes)
-            clusterc = {v: 0 if t == 0 else t / (d * (d - 1)) for v, d, t, _ in td_iter}
-    if nodes in G:
-        # Return the value of the sole entry in the dictionary.
-        return clusterc[nodes]
-    return clusterc
-
-
-@nx._dispatch
-def transitivity(G):
-    r"""Compute graph transitivity, the fraction of all possible triangles
-    present in G.
-
-    Possible triangles are identified by the number of "triads"
-    (two edges with a shared vertex).
-
-    The transitivity is
-
-    .. math::
+    >>> G = nx.cycle_graph(4)
+    >>> d = nx.coloring.greedy_color(G, strategy="largest_first")
+    >>> d in [{0: 0, 1: 1, 2: 0, 3: 1}, {0: 1, 1: 0, 2: 1, 3: 0}]
+    True
 
-        T = 3\frac{\#triangles}{\#triads}.
+    Raises
+    ------
+    NetworkXPointlessConcept
+        If ``strategy`` is ``saturation_largest_first`` or
+        ``independent_set`` and ``interchange`` is ``True``.
 
-    Parameters
+    References
     ----------
-    G : graph
-
-    Returns
-    -------
-    out : float
-       Transitivity
+    .. [1] Adrian Kosowski, and Krzysztof Manuszewski,
+       Classical Coloring of Graphs, Graph Colorings, 2-19, 2004.
+       ISBN 0-8218-3458-4.
+    .. [2] David W. Matula, and Leland L. Beck, "Smallest-last
+       ordering and clustering and graph coloring algorithms." *J. ACM* 30,
+       3 (July 1983), 417–427. <https://doi.org/10.1145/2402.322385>
+    .. [3] Maciej M. Sysło, Narsingh Deo, Janusz S. Kowalik,
+       Discrete Optimization Algorithms with Pascal Programs, 415-424, 1983.
+       ISBN 0-486-45353-7.
 
-    Examples
-    --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.transitivity(G))
-    1.0
-    """
-    triangles_contri = [
-        (t, d * (d - 1)) for v, d, t, _ in _triangles_and_degree_iter(G)
-    ]
-    # If the graph is empty
-    if len(triangles_contri) == 0:
-        return 0
-    triangles, contri = map(sum, zip(*triangles_contri))
-    return 0 if triangles == 0 else triangles / contri
-
-
-@nx._dispatch
-def square_clustering(G, nodes=None):
-    r"""Compute the squares clustering coefficient for nodes.
-
-    For each node return the fraction of possible squares that exist at
-    the node [1]_
-
-    .. math::
-       C_4(v) = \frac{ \sum_{u=1}^{k_v}
-       \sum_{w=u+1}^{k_v} q_v(u,w) }{ \sum_{u=1}^{k_v}
-       \sum_{w=u+1}^{k_v} [a_v(u,w) + q_v(u,w)]},
-
-    where :math:`q_v(u,w)` are the number of common neighbors of :math:`u` and
-    :math:`w` other than :math:`v` (ie squares), and :math:`a_v(u,w) = (k_u -
-    (1+q_v(u,w)+\theta_{uv})) + (k_w - (1+q_v(u,w)+\theta_{uw}))`, where
-    :math:`\theta_{uw} = 1` if :math:`u` and :math:`w` are connected and 0
-    otherwise. [2]_
+    """
+    if len(G) == 0:
+        return {}
+    # Determine the strategy provided by the caller.
+    strategy = STRATEGIES.get(strategy, strategy)
+    if not callable(strategy):
+        raise nx.NetworkXError(
+            f"strategy must be callable or a valid string. {strategy} not valid."
+        )
+    # Perform some validation on the arguments before executing any
+    # strategy functions.
+    if interchange:
+        if strategy is strategy_independent_set:
+            msg = "interchange cannot be used with independent_set"
+            raise nx.NetworkXPointlessConcept(msg)
+        if strategy is strategy_saturation_largest_first:
+            msg = "interchange cannot be used with" " saturation_largest_first"
+            raise nx.NetworkXPointlessConcept(msg)
+    colors = {}
+    nodes = strategy(G, colors)
+    if interchange:
+        return _greedy_coloring_with_interchange(G, nodes)
+    for u in nodes:
+        # Set to keep track of colors of neighbors
+        nbr_colors = {colors[v] for v in G[u] if v in colors}
+        # Find the first unused color.
+        for color in itertools.count():
+            if color not in nbr_colors:
+                break
+        # Assign the new color to the current node.
+        colors[u] = color
+    return colors
+
+
+# Tools for coloring with interchanges
+class _Node:
+    __slots__ = ["node_id", "color", "adj_list", "adj_color"]
+
+    def __init__(self, node_id, n):
+        self.node_id = node_id
+        self.color = -1
+        self.adj_list = None
+        self.adj_color = [None for _ in range(n)]
+
+    def __repr__(self):
+        return (
+            f"Node_id: {self.node_id}, Color: {self.color}, "
+            f"Adj_list: ({self.adj_list}), adj_color: ({self.adj_color})"
+        )
+
+    def assign_color(self, adj_entry, color):
+        adj_entry.col_prev = None
+        adj_entry.col_next = self.adj_color[color]
+        self.adj_color[color] = adj_entry
+        if adj_entry.col_next is not None:
+            adj_entry.col_next.col_prev = adj_entry
+
+    def clear_color(self, adj_entry, color):
+        if adj_entry.col_prev is None:
+            self.adj_color[color] = adj_entry.col_next
+        else:
+            adj_entry.col_prev.col_next = adj_entry.col_next
+        if adj_entry.col_next is not None:
+            adj_entry.col_next.col_prev = adj_entry.col_prev
+
+    def iter_neighbors(self):
+        adj_node = self.adj_list
+        while adj_node is not None:
+            yield adj_node
+            adj_node = adj_node.next
+
+    def iter_neighbors_color(self, color):
+        adj_color_node = self.adj_color[color]
+        while adj_color_node is not None:
+            yield adj_color_node.node_id
+            adj_color_node = adj_color_node.col_next
+
+
+class _AdjEntry:
+    __slots__ = ["node_id", "next", "mate", "col_next", "col_prev"]
+
+    def __init__(self, node_id):
+        self.node_id = node_id
+        self.next = None
+        self.mate = None
+        self.col_next = None
+        self.col_prev = None
+
+    def __repr__(self):
+        col_next = None if self.col_next is None else self.col_next.node_id
+        col_prev = None if self.col_prev is None else self.col_prev.node_id
+        return (
+            f"Node_id: {self.node_id}, Next: ({self.next}), "
+            f"Mate: ({self.mate.node_id}), "
+            f"col_next: ({col_next}), col_prev: ({col_prev})"
+        )
+
+
+def _greedy_coloring_with_interchange(G, nodes):
+    """Return a coloring for `original_graph` using interchange approach
+
+    This procedure is an adaption of the algorithm described by [1]_,
+    and is an implementation of coloring with interchange. Please be
+    advised, that the datastructures used are rather complex because
+    they are optimized to minimize the time spent identifying
+    subcomponents of the graph, which are possible candidates for color
+    interchange.
 
     Parameters
     ----------
-    G : graph
+    G : NetworkX graph
+        The graph to be colored
 
-    nodes : container of nodes, optional (default=all nodes in G)
-       Compute clustering for nodes in this container.
+    nodes : list
+        nodes ordered using the strategy of choice
 
     Returns
     -------
-    c4 : dictionary
-       A dictionary keyed by node with the square clustering coefficient value.
-
-    Examples
-    --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.square_clustering(G, 0))
-    1.0
-    >>> print(nx.square_clustering(G))
-    {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}
-
-    Notes
-    -----
-    While :math:`C_3(v)` (triangle clustering) gives the probability that
-    two neighbors of node v are connected with each other, :math:`C_4(v)` is
-    the probability that two neighbors of node v share a common
-    neighbor different from v. This algorithm can be applied to both
-    bipartite and unipartite networks.
+    dict :
+        A dictionary keyed by node to a color value
 
     References
     ----------
-    .. [1] Pedro G. Lind, Marta C. González, and Hans J. Herrmann. 2005
-        Cycles and clustering in bipartite networks.
-        Physical Review E (72) 056127.
-    .. [2] Zhang, Peng et al. Clustering Coefficient and Community Structure of
-        Bipartite Networks. Physica A: Statistical Mechanics and its Applications 387.27 (2008): 6869–6875.
-        https://arxiv.org/abs/0710.0117v1
+    .. [1] Maciej M. Syslo, Narsingh Deo, Janusz S. Kowalik,
+       Discrete Optimization Algorithms with Pascal Programs, 415-424, 1983.
+       ISBN 0-486-45353-7.
     """
-    if nodes is None:
-        node_iter = G
-    else:
-        node_iter = G.nbunch_iter(nodes)
-    clustering = {}
-    for v in node_iter:
-        clustering[v] = 0
-        potential = 0
-        for u, w in combinations(G[v], 2):
-            squares = len((set(G[u]) & set(G[w])) - {v})
-            clustering[v] += squares
-            degm = squares + 1
-            if w in G[u]:
-                degm += 1
-            potential += (len(G[u]) - degm) + (len(G[w]) - degm) + squares
-        if potential > 0:
-            clustering[v] /= potential
-    if nodes in G:
-        # Return the value of the sole entry in the dictionary.
-        return clustering[nodes]
-    return clustering
-
-
-@not_implemented_for("directed")
-@nx._dispatch
-def generalized_degree(G, nodes=None):
-    r"""Compute the generalized degree for nodes.
-
-    For each node, the generalized degree shows how many edges of given
-    triangle multiplicity the node is connected to. The triangle multiplicity
-    of an edge is the number of triangles an edge participates in. The
-    generalized degree of node :math:`i` can be written as a vector
-    :math:`\mathbf{k}_i=(k_i^{(0)}, \dotsc, k_i^{(N-2)})` where
-    :math:`k_i^{(j)}` is the number of edges attached to node :math:`i` that
-    participate in :math:`j` triangles.
+    n = len(G)
 
-    Parameters
-    ----------
-    G : graph
-
-    nodes : container of nodes, optional (default=all nodes in G)
-       Compute the generalized degree for nodes in this container.
+    graph = {node: _Node(node, n) for node in G}
 
-    Returns
-    -------
-    out : Counter, or dictionary of Counters
-       Generalized degree of specified nodes. The Counter is keyed by edge
-       triangle multiplicity.
+    for node1, node2 in G.edges():
+        adj_entry1 = _AdjEntry(node2)
+        adj_entry2 = _AdjEntry(node1)
+        adj_entry1.mate = adj_entry2
+        adj_entry2.mate = adj_entry1
+        node1_head = graph[node1].adj_list
+        adj_entry1.next = node1_head
+        graph[node1].adj_list = adj_entry1
+        node2_head = graph[node2].adj_list
+        adj_entry2.next = node2_head
+        graph[node2].adj_list = adj_entry2
+
+    k = 0
+    for node in nodes:
+        # Find the smallest possible, unused color
+        neighbors = graph[node].iter_neighbors()
+        col_used = {graph[adj_node.node_id].color for adj_node in neighbors}
+        col_used.discard(-1)
+        k1 = next(itertools.dropwhile(lambda x: x in col_used, itertools.count()))
+
+        # k1 is now the lowest available color
+        if k1 > k:
+            connected = True
+            visited = set()
+            col1 = -1
+            col2 = -1
+            while connected and col1 < k:
+                col1 += 1
+                neighbor_cols = graph[node].iter_neighbors_color(col1)
+                col1_adj = list(neighbor_cols)
+
+                col2 = col1
+                while connected and col2 < k:
+                    col2 += 1
+                    visited = set(col1_adj)
+                    frontier = list(col1_adj)
+                    i = 0
+                    while i < len(frontier):
+                        search_node = frontier[i]
+                        i += 1
+                        col_opp = col2 if graph[search_node].color == col1 else col1
+                        neighbor_cols = graph[search_node].iter_neighbors_color(col_opp)
+
+                        for neighbor in neighbor_cols:
+                            if neighbor not in visited:
+                                visited.add(neighbor)
+                                frontier.append(neighbor)
+
+                    # Search if node is not adj to any col2 vertex
+                    connected = (
+                        len(
+                            visited.intersection(graph[node].iter_neighbors_color(col2))
+                        )
+                        > 0
+                    )
+
+            # If connected is false then we can swap !!!
+            if not connected:
+                # Update all the nodes in the component
+                for search_node in visited:
+                    graph[search_node].color = (
+                        col2 if graph[search_node].color == col1 else col1
+                    )
+                    col2_adj = graph[search_node].adj_color[col2]
+                    graph[search_node].adj_color[col2] = graph[search_node].adj_color[
+                        col1
+                    ]
+                    graph[search_node].adj_color[col1] = col2_adj
+
+                # Update all the neighboring nodes
+                for search_node in visited:
+                    col = graph[search_node].color
+                    col_opp = col1 if col == col2 else col2
+                    for adj_node in graph[search_node].iter_neighbors():
+                        if graph[adj_node.node_id].color != col_opp:
+                            # Direct reference to entry
+                            adj_mate = adj_node.mate
+                            graph[adj_node.node_id].clear_color(adj_mate, col_opp)
+                            graph[adj_node.node_id].assign_color(adj_mate, col)
+                k1 = col1
+
+        # We can color this node color k1
+        graph[node].color = k1
+        k = max(k1, k)
+
+        # Update the neighbors of this node
+        for adj_node in graph[node].iter_neighbors():
+            adj_mate = adj_node.mate
+            graph[adj_node.node_id].assign_color(adj_mate, k1)
 
-    Examples
-    --------
-    >>> G = nx.complete_graph(5)
-    >>> print(nx.generalized_degree(G, 0))
-    Counter({3: 4})
-    >>> print(nx.generalized_degree(G))
-    {0: Counter({3: 4}), 1: Counter({3: 4}), 2: Counter({3: 4}), 3: Counter({3: 4}), 4: Counter({3: 4})}
-
-    To recover the number of triangles attached to a node:
-
-    >>> k1 = nx.generalized_degree(G, 0)
-    >>> sum([k * v for k, v in k1.items()]) / 2 == nx.triangles(G, 0)
-    True
-
-    Notes
-    -----
-    In a network of N nodes, the highest triangle multiplicity an edge can have
-    is N-2.
-
-    The return value does not include a `zero` entry if no edges of a
-    particular triangle multiplicity are present.
-
-    The number of triangles node :math:`i` is attached to can be recovered from
-    the generalized degree :math:`\mathbf{k}_i=(k_i^{(0)}, \dotsc,
-    k_i^{(N-2)})` by :math:`(k_i^{(1)}+2k_i^{(2)}+\dotsc +(N-2)k_i^{(N-2)})/2`.
-
-    References
-    ----------
-    .. [1] Networks with arbitrary edge multiplicities by V. Zlatić,
-        D. Garlaschelli and G. Caldarelli, EPL (Europhysics Letters),
-        Volume 97, Number 2 (2012).
-        https://iopscience.iop.org/article/10.1209/0295-5075/97/28005
-    """
-    if nodes in G:
-        return next(_triangles_and_degree_iter(G, nodes))[3]
-    return {v: gd for v, d, t, gd in _triangles_and_degree_iter(G, nodes)}
+    return {node.node_id: node.color for node in graph.values()}
```

### Comparing `networkx-3.2rc0/networkx/algorithms/coloring/equitable_coloring.py` & `networkx-3.3rc0/networkx/algorithms/coloring/equitable_coloring.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,22 +5,22 @@
 from collections import defaultdict
 
 import networkx as nx
 
 __all__ = ["equitable_color"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_coloring(G, coloring):
     """Determine if the coloring is a valid coloring for the graph G."""
     # Verify that the coloring is valid.
     return all(coloring[s] != coloring[d] for s, d in G.edges)
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_equitable(G, coloring, num_colors=None):
     """Determines if the coloring is valid and equitable for the graph G."""
 
     if not is_coloring(G, coloring):
         return False
 
     # Verify whether it is equitable.
@@ -108,15 +108,15 @@
         Y = T_cal[X]
         # Move _any_ witness from X to Y = T_cal[X]
         w = next(x for x in C[X] if N[(x, Y)] == 0)
         change_color(w, X, Y, N=N, H=H, F=F, C=C, L=L)
         X = Y
 
 
-@nx._dispatch
+@nx._dispatchable(mutates_input=True)
 def pad_graph(G, num_colors):
     """Add a disconnected complete clique K_p such that the number of nodes in
     the graph becomes a multiple of `num_colors`.
 
     Assumes that the graph's nodes are labelled using integers.
 
     Returns the number of nodes with each color.
@@ -382,15 +382,15 @@
                         "of two vertices in B_cal_prime."
                     )
 
             if made_equitable:
                 break
 
 
-@nx._dispatch
+@nx._dispatchable
 def equitable_color(G, num_colors):
     """Provides an equitable coloring for nodes of `G`.
 
     Attempts to color a graph using `num_colors` colors, where no neighbors of
     a node can have same color as the node itself and the number of nodes with
     each color differ by at most 1. `num_colors` must be greater than the
     maximum degree of `G`. The algorithm is described in [1]_ and has
```

### Comparing `networkx-3.2rc0/networkx/algorithms/coloring/greedy_coloring.py` & `networkx-3.3rc0/networkx/algorithms/summarization.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,572 +1,563 @@
 """
-Greedy graph coloring using various strategies.
+Graph summarization finds smaller representations of graphs resulting in faster
+runtime of algorithms, reduced storage needs, and noise reduction.
+Summarization has applications in areas such as visualization, pattern mining,
+clustering and community detection, and more.  Core graph summarization
+techniques are grouping/aggregation, bit-compression,
+simplification/sparsification, and influence based. Graph summarization
+algorithms often produce either summary graphs in the form of supergraphs or
+sparsified graphs, or a list of independent structures. Supergraphs are the
+most common product, which consist of supernodes and original nodes and are
+connected by edges and superedges, which represent aggregate edges between
+nodes and supernodes.
+
+Grouping/aggregation based techniques compress graphs by representing
+close/connected nodes and edges in a graph by a single node/edge in a
+supergraph. Nodes can be grouped together into supernodes based on their
+structural similarities or proximity within a graph to reduce the total number
+of nodes in a graph. Edge-grouping techniques group edges into lossy/lossless
+nodes called compressor or virtual nodes to reduce the total number of edges in
+a graph. Edge-grouping techniques can be lossless, meaning that they can be
+used to re-create the original graph, or techniques can be lossy, requiring
+less space to store the summary graph, but at the expense of lower
+reconstruction accuracy of the original graph.
+
+Bit-compression techniques minimize the amount of information needed to
+describe the original graph, while revealing structural patterns in the
+original graph.  The two-part minimum description length (MDL) is often used to
+represent the model and the original graph in terms of the model.  A key
+difference between graph compression and graph summarization is that graph
+summarization focuses on finding structural patterns within the original graph,
+whereas graph compression focuses on compressions the original graph to be as
+small as possible.  **NOTE**: Some bit-compression methods exist solely to
+compress a graph without creating a summary graph or finding comprehensible
+structural patterns.
+
+Simplification/Sparsification techniques attempt to create a sparse
+representation of a graph by removing unimportant nodes and edges from the
+graph.  Sparsified graphs differ from supergraphs created by
+grouping/aggregation by only containing a subset of the original nodes and
+edges of the original graph.
+
+Influence based techniques aim to find a high-level description of influence
+propagation in a large graph.  These methods are scarce and have been mostly
+applied to social graphs.
+
+*dedensification* is a grouping/aggregation based technique to compress the
+neighborhoods around high-degree nodes in unweighted graphs by adding
+compressor nodes that summarize multiple edges of the same type to
+high-degree nodes (nodes with a degree greater than a given threshold).
+Dedensification was developed for the purpose of increasing performance of
+query processing around high-degree nodes in graph databases and enables direct
+operations on the compressed graph.  The structural patterns surrounding
+high-degree nodes in the original is preserved while using fewer edges and
+adding a small number of compressor nodes.  The degree of nodes present in the
+original graph is also preserved. The current implementation of dedensification
+supports graphs with one edge type.
+
+For more information on graph summarization, see `Graph Summarization Methods
+and Applications: A Survey <https://dl.acm.org/doi/abs/10.1145/3186727>`_
 """
-import itertools
-from collections import defaultdict, deque
+from collections import Counter, defaultdict
 
 import networkx as nx
-from networkx.utils import arbitrary_element, py_random_state
-
-__all__ = [
-    "greedy_color",
-    "strategy_connected_sequential",
-    "strategy_connected_sequential_bfs",
-    "strategy_connected_sequential_dfs",
-    "strategy_independent_set",
-    "strategy_largest_first",
-    "strategy_random_sequential",
-    "strategy_saturation_largest_first",
-    "strategy_smallest_last",
-]
-
-
-@nx._dispatch
-def strategy_largest_first(G, colors):
-    """Returns a list of the nodes of ``G`` in decreasing order by
-    degree.
-
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
-
-    """
-    return sorted(G, key=G.degree, reverse=True)
 
-
-@py_random_state(2)
-@nx._dispatch
-def strategy_random_sequential(G, colors, seed=None):
-    """Returns a random permutation of the nodes of ``G`` as a list.
-
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
-
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-    """
-    nodes = list(G)
-    seed.shuffle(nodes)
-    return nodes
+__all__ = ["dedensify", "snap_aggregation"]
 
 
-@nx._dispatch
-def strategy_smallest_last(G, colors):
-    """Returns a deque of the nodes of ``G``, "smallest" last.
+@nx._dispatchable(mutates_input={"not copy": 3}, returns_graph=True)
+def dedensify(G, threshold, prefix=None, copy=True):
+    """Compresses neighborhoods around high-degree nodes
+
+    Reduces the number of edges to high-degree nodes by adding compressor nodes
+    that summarize multiple edges of the same type to high-degree nodes (nodes
+    with a degree greater than a given threshold).  Dedensification also has
+    the added benefit of reducing the number of edges around high-degree nodes.
+    The implementation currently supports graphs with a single edge type.
 
-    Specifically, the degrees of each node are tracked in a bucket queue.
-    From this, the node of minimum degree is repeatedly popped from the
-    graph, updating its neighbors' degrees.
+    Parameters
+    ----------
+    G: graph
+       A networkx graph
+    threshold: int
+       Minimum degree threshold of a node to be considered a high degree node.
+       The threshold must be greater than or equal to 2.
+    prefix: str or None, optional (default: None)
+       An optional prefix for denoting compressor nodes
+    copy: bool, optional (default: True)
+       Indicates if dedensification should be done inplace
 
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
+    Returns
+    -------
+    dedensified networkx graph : (graph, set)
+        2-tuple of the dedensified graph and set of compressor nodes
 
-    This implementation of the strategy runs in $O(n + m)$ time
-    (ignoring polylogarithmic factors), where $n$ is the number of nodes
-    and $m$ is the number of edges.
+    Notes
+    -----
+    According to the algorithm in [1]_, removes edges in a graph by
+    compressing/decompressing the neighborhoods around high degree nodes by
+    adding compressor nodes that summarize multiple edges of the same type
+    to high-degree nodes.  Dedensification will only add a compressor node when
+    doing so will reduce the total number of edges in the given graph. This
+    implementation currently supports graphs with a single edge type.
 
-    This strategy is related to :func:`strategy_independent_set`: if we
-    interpret each node removed as an independent set of size one, then
-    this strategy chooses an independent set of size one instead of a
-    maximal independent set.
+    Examples
+    --------
+    Dedensification will only add compressor nodes when doing so would result
+    in fewer edges::
 
-    """
-    H = G.copy()
-    result = deque()
+        >>> original_graph = nx.DiGraph()
+        >>> original_graph.add_nodes_from(
+        ...     ["1", "2", "3", "4", "5", "6", "A", "B", "C"]
+        ... )
+        >>> original_graph.add_edges_from(
+        ...     [
+        ...         ("1", "C"), ("1", "B"),
+        ...         ("2", "C"), ("2", "B"), ("2", "A"),
+        ...         ("3", "B"), ("3", "A"), ("3", "6"),
+        ...         ("4", "C"), ("4", "B"), ("4", "A"),
+        ...         ("5", "B"), ("5", "A"),
+        ...         ("6", "5"),
+        ...         ("A", "6")
+        ...     ]
+        ... )
+        >>> c_graph, c_nodes = nx.dedensify(original_graph, threshold=2)
+        >>> original_graph.number_of_edges()
+        15
+        >>> c_graph.number_of_edges()
+        14
+
+    A dedensified, directed graph can be "densified" to reconstruct the
+    original graph::
+
+        >>> original_graph = nx.DiGraph()
+        >>> original_graph.add_nodes_from(
+        ...     ["1", "2", "3", "4", "5", "6", "A", "B", "C"]
+        ... )
+        >>> original_graph.add_edges_from(
+        ...     [
+        ...         ("1", "C"), ("1", "B"),
+        ...         ("2", "C"), ("2", "B"), ("2", "A"),
+        ...         ("3", "B"), ("3", "A"), ("3", "6"),
+        ...         ("4", "C"), ("4", "B"), ("4", "A"),
+        ...         ("5", "B"), ("5", "A"),
+        ...         ("6", "5"),
+        ...         ("A", "6")
+        ...     ]
+        ... )
+        >>> c_graph, c_nodes = nx.dedensify(original_graph, threshold=2)
+        >>> # re-densifies the compressed graph into the original graph
+        >>> for c_node in c_nodes:
+        ...     all_neighbors = set(nx.all_neighbors(c_graph, c_node))
+        ...     out_neighbors = set(c_graph.neighbors(c_node))
+        ...     for out_neighbor in out_neighbors:
+        ...         c_graph.remove_edge(c_node, out_neighbor)
+        ...     in_neighbors = all_neighbors - out_neighbors
+        ...     for in_neighbor in in_neighbors:
+        ...         c_graph.remove_edge(in_neighbor, c_node)
+        ...         for out_neighbor in out_neighbors:
+        ...             c_graph.add_edge(in_neighbor, out_neighbor)
+        ...     c_graph.remove_node(c_node)
+        ...
+        >>> nx.is_isomorphic(original_graph, c_graph)
+        True
 
-    # Build initial degree list (i.e. the bucket queue data structure)
-    degrees = defaultdict(set)  # set(), for fast random-access removals
-    lbound = float("inf")
-    for node, d in H.degree():
-        degrees[d].add(node)
-        lbound = min(lbound, d)  # Lower bound on min-degree.
-
-    def find_min_degree():
-        # Save time by starting the iterator at `lbound`, not 0.
-        # The value that we find will be our new `lbound`, which we set later.
-        return next(d for d in itertools.count(lbound) if d in degrees)
-
-    for _ in G:
-        # Pop a min-degree node and add it to the list.
-        min_degree = find_min_degree()
-        u = degrees[min_degree].pop()
-        if not degrees[min_degree]:  # Clean up the degree list.
-            del degrees[min_degree]
-        result.appendleft(u)
-
-        # Update degrees of removed node's neighbors.
-        for v in H[u]:
-            degree = H.degree(v)
-            degrees[degree].remove(v)
-            if not degrees[degree]:  # Clean up the degree list.
-                del degrees[degree]
-            degrees[degree - 1].add(v)
-
-        # Finally, remove the node.
-        H.remove_node(u)
-        lbound = min_degree - 1  # Subtract 1 in case of tied neighbors.
-
-    return result
-
-
-def _maximal_independent_set(G):
-    """Returns a maximal independent set of nodes in ``G`` by repeatedly
-    choosing an independent node of minimum degree (with respect to the
-    subgraph of unchosen nodes).
+    References
+    ----------
+    .. [1] Maccioni, A., & Abadi, D. J. (2016, August).
+       Scalable pattern matching over compressed graphs via dedensification.
+       In Proceedings of the 22nd ACM SIGKDD International Conference on
+       Knowledge Discovery and Data Mining (pp. 1755-1764).
+       http://www.cs.umd.edu/~abadi/papers/graph-dedense.pdf
+    """
+    if threshold < 2:
+        raise nx.NetworkXError("The degree threshold must be >= 2")
+
+    degrees = G.in_degree if G.is_directed() else G.degree
+    # Group nodes based on degree threshold
+    high_degree_nodes = {n for n, d in degrees if d > threshold}
+    low_degree_nodes = G.nodes() - high_degree_nodes
+
+    auxiliary = {}
+    for node in G:
+        high_degree_nbrs = frozenset(high_degree_nodes & set(G[node]))
+        if high_degree_nbrs:
+            if high_degree_nbrs in auxiliary:
+                auxiliary[high_degree_nbrs].add(node)
+            else:
+                auxiliary[high_degree_nbrs] = {node}
+
+    if copy:
+        G = G.copy()
+
+    compressor_nodes = set()
+    for index, (high_degree_nodes, low_degree_nodes) in enumerate(auxiliary.items()):
+        low_degree_node_count = len(low_degree_nodes)
+        high_degree_node_count = len(high_degree_nodes)
+        old_edges = high_degree_node_count * low_degree_node_count
+        new_edges = high_degree_node_count + low_degree_node_count
+        if old_edges <= new_edges:
+            continue
+        compression_node = "".join(str(node) for node in high_degree_nodes)
+        if prefix:
+            compression_node = str(prefix) + compression_node
+        for node in low_degree_nodes:
+            for high_node in high_degree_nodes:
+                if G.has_edge(node, high_node):
+                    G.remove_edge(node, high_node)
+
+            G.add_edge(node, compression_node)
+        for node in high_degree_nodes:
+            G.add_edge(compression_node, node)
+        compressor_nodes.add(compression_node)
+    return G, compressor_nodes
+
+
+def _snap_build_graph(
+    G,
+    groups,
+    node_attributes,
+    edge_attributes,
+    neighbor_info,
+    edge_types,
+    prefix,
+    supernode_attribute,
+    superedge_attribute,
+):
+    """
+    Build the summary graph from the data structures produced in the SNAP aggregation algorithm
+
+    Used in the SNAP aggregation algorithm to build the output summary graph and supernode
+    lookup dictionary.  This process uses the original graph and the data structures to
+    create the supernodes with the correct node attributes, and the superedges with the correct
+    edge attributes
 
-    """
-    result = set()
-    remaining = set(G)
-    while remaining:
-        G = G.subgraph(remaining)
-        v = min(remaining, key=G.degree)
-        result.add(v)
-        remaining -= set(G[v]) | {v}
-    return result
-
-
-@nx._dispatch
-def strategy_independent_set(G, colors):
-    """Uses a greedy independent set removal strategy to determine the
-    colors.
-
-    This function updates ``colors`` **in-place** and return ``None``,
-    unlike the other strategy functions in this module.
-
-    This algorithm repeatedly finds and removes a maximal independent
-    set, assigning each node in the set an unused color.
-
-    ``G`` is a NetworkX graph.
-
-    This strategy is related to :func:`strategy_smallest_last`: in that
-    strategy, an independent set of size one is chosen at each step
-    instead of a maximal independent set.
+    Parameters
+    ----------
+    G: networkx.Graph
+        the original graph to be summarized
+    groups: dict
+        A dictionary of unique group IDs and their corresponding node groups
+    node_attributes: iterable
+        An iterable of the node attributes considered in the summarization process
+    edge_attributes: iterable
+        An iterable of the edge attributes considered in the summarization process
+    neighbor_info: dict
+        A data structure indicating the number of edges a node has with the
+        groups in the current summarization of each edge type
+    edge_types: dict
+        dictionary of edges in the graph and their corresponding attributes recognized
+        in the summarization
+    prefix: string
+        The prefix to be added to all supernodes
+    supernode_attribute: str
+        The node attribute for recording the supernode groupings of nodes
+    superedge_attribute: str
+        The edge attribute for recording the edge types represented by superedges
 
+    Returns
+    -------
+    summary graph: Networkx graph
     """
-    remaining_nodes = set(G)
-    while len(remaining_nodes) > 0:
-        nodes = _maximal_independent_set(G.subgraph(remaining_nodes))
-        remaining_nodes -= nodes
-        yield from nodes
-
-
-@nx._dispatch
-def strategy_connected_sequential_bfs(G, colors):
-    """Returns an iterable over nodes in ``G`` in the order given by a
-    breadth-first traversal.
+    output = G.__class__()
+    node_label_lookup = {}
+    for index, group_id in enumerate(groups):
+        group_set = groups[group_id]
+        supernode = f"{prefix}{index}"
+        node_label_lookup[group_id] = supernode
+        supernode_attributes = {
+            attr: G.nodes[next(iter(group_set))][attr] for attr in node_attributes
+        }
+        supernode_attributes[supernode_attribute] = group_set
+        output.add_node(supernode, **supernode_attributes)
+
+    for group_id in groups:
+        group_set = groups[group_id]
+        source_supernode = node_label_lookup[group_id]
+        for other_group, group_edge_types in neighbor_info[
+            next(iter(group_set))
+        ].items():
+            if group_edge_types:
+                target_supernode = node_label_lookup[other_group]
+                summary_graph_edge = (source_supernode, target_supernode)
+
+                edge_types = [
+                    dict(zip(edge_attributes, edge_type))
+                    for edge_type in group_edge_types
+                ]
+
+                has_edge = output.has_edge(*summary_graph_edge)
+                if output.is_multigraph():
+                    if not has_edge:
+                        for edge_type in edge_types:
+                            output.add_edge(*summary_graph_edge, **edge_type)
+                    elif not output.is_directed():
+                        existing_edge_data = output.get_edge_data(*summary_graph_edge)
+                        for edge_type in edge_types:
+                            if edge_type not in existing_edge_data.values():
+                                output.add_edge(*summary_graph_edge, **edge_type)
+                else:
+                    superedge_attributes = {superedge_attribute: edge_types}
+                    output.add_edge(*summary_graph_edge, **superedge_attributes)
+
+    return output
 
-    The generated sequence has the property that for each node except
-    the first, at least one neighbor appeared earlier in the sequence.
-
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
 
+def _snap_eligible_group(G, groups, group_lookup, edge_types):
     """
-    return strategy_connected_sequential(G, colors, "bfs")
-
+    Determines if a group is eligible to be split.
 
-@nx._dispatch
-def strategy_connected_sequential_dfs(G, colors):
-    """Returns an iterable over nodes in ``G`` in the order given by a
-    depth-first traversal.
+    A group is eligible to be split if all nodes in the group have edges of the same type(s)
+    with the same other groups.
 
-    The generated sequence has the property that for each node except
-    the first, at least one neighbor appeared earlier in the sequence.
-
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
+    Parameters
+    ----------
+    G: graph
+        graph to be summarized
+    groups: dict
+        A dictionary of unique group IDs and their corresponding node groups
+    group_lookup: dict
+        dictionary of nodes and their current corresponding group ID
+    edge_types: dict
+        dictionary of edges in the graph and their corresponding attributes recognized
+        in the summarization
 
+    Returns
+    -------
+    tuple: group ID to split, and neighbor-groups participation_counts data structure
     """
-    return strategy_connected_sequential(G, colors, "dfs")
-
-
-@nx._dispatch
-def strategy_connected_sequential(G, colors, traversal="bfs"):
-    """Returns an iterable over nodes in ``G`` in the order given by a
-    breadth-first or depth-first traversal.
-
-    ``traversal`` must be one of the strings ``'dfs'`` or ``'bfs'``,
-    representing depth-first traversal or breadth-first traversal,
-    respectively.
+    nbr_info = {node: {gid: Counter() for gid in groups} for node in group_lookup}
+    for group_id in groups:
+        current_group = groups[group_id]
+
+        # build nbr_info for nodes in group
+        for node in current_group:
+            nbr_info[node] = {group_id: Counter() for group_id in groups}
+            edges = G.edges(node, keys=True) if G.is_multigraph() else G.edges(node)
+            for edge in edges:
+                neighbor = edge[1]
+                edge_type = edge_types[edge]
+                neighbor_group_id = group_lookup[neighbor]
+                nbr_info[node][neighbor_group_id][edge_type] += 1
+
+        # check if group_id is eligible to be split
+        group_size = len(current_group)
+        for other_group_id in groups:
+            edge_counts = Counter()
+            for node in current_group:
+                edge_counts.update(nbr_info[node][other_group_id].keys())
+
+            if not all(count == group_size for count in edge_counts.values()):
+                # only the nbr_info of the returned group_id is required for handling group splits
+                return group_id, nbr_info
+
+    # if no eligible groups, complete nbr_info is calculated
+    return None, nbr_info
+
+
+def _snap_split(groups, neighbor_info, group_lookup, group_id):
+    """
+    Splits a group based on edge types and updates the groups accordingly
+
+    Splits the group with the given group_id based on the edge types
+    of the nodes so that each new grouping will all have the same
+    edges with other nodes.
 
-    The generated sequence has the property that for each node except
-    the first, at least one neighbor appeared earlier in the sequence.
-
-    ``G`` is a NetworkX graph. ``colors`` is ignored.
+    Parameters
+    ----------
+    groups: dict
+        A dictionary of unique group IDs and their corresponding node groups
+    neighbor_info: dict
+        A data structure indicating the number of edges a node has with the
+        groups in the current summarization of each edge type
+    edge_types: dict
+        dictionary of edges in the graph and their corresponding attributes recognized
+        in the summarization
+    group_lookup: dict
+        dictionary of nodes and their current corresponding group ID
+    group_id: object
+        ID of group to be split
 
+    Returns
+    -------
+    dict
+        The updated groups based on the split
     """
-    if traversal == "bfs":
-        traverse = nx.bfs_edges
-    elif traversal == "dfs":
-        traverse = nx.dfs_edges
-    else:
-        raise nx.NetworkXError(
-            "Please specify one of the strings 'bfs' or"
-            " 'dfs' for connected sequential ordering"
+    new_group_mappings = defaultdict(set)
+    for node in groups[group_id]:
+        signature = tuple(
+            frozenset(edge_types) for edge_types in neighbor_info[node].values()
         )
-    for component in nx.connected_components(G):
-        source = arbitrary_element(component)
-        # Yield the source node, then all the nodes in the specified
-        # traversal order.
-        yield source
-        for _, end in traverse(G.subgraph(component), source):
-            yield end
-
-
-@nx._dispatch
-def strategy_saturation_largest_first(G, colors):
-    """Iterates over all the nodes of ``G`` in "saturation order" (also
-    known as "DSATUR").
-
-    ``G`` is a NetworkX graph. ``colors`` is a dictionary mapping nodes of
-    ``G`` to colors, for those nodes that have already been colored.
-
-    """
-    distinct_colors = {v: set() for v in G}
-
-    # Add the node color assignments given in colors to the
-    # distinct colors set for each neighbor of that node
-    for node, color in colors.items():
-        for neighbor in G[node]:
-            distinct_colors[neighbor].add(color)
-
-    # Check that the color assignments in colors are valid
-    # i.e. no neighboring nodes have the same color
-    if len(colors) >= 2:
-        for node, color in colors.items():
-            if color in distinct_colors[node]:
-                raise nx.NetworkXError("Neighboring nodes must have different colors")
-
-    # If 0 nodes have been colored, simply choose the node of highest degree.
-    if not colors:
-        node = max(G, key=G.degree)
-        yield node
-        # Add the color 0 to the distinct colors set for each
-        # neighbor of that node.
-        for v in G[node]:
-            distinct_colors[v].add(0)
-
-    while len(G) != len(colors):
-        # Update the distinct color sets for the neighbors.
-        for node, color in colors.items():
-            for neighbor in G[node]:
-                distinct_colors[neighbor].add(color)
-
-        # Compute the maximum saturation and the set of nodes that
-        # achieve that saturation.
-        saturation = {v: len(c) for v, c in distinct_colors.items() if v not in colors}
-        # Yield the node with the highest saturation, and break ties by
-        # degree.
-        node = max(saturation, key=lambda v: (saturation[v], G.degree(v)))
-        yield node
-
-
-#: Dictionary mapping name of a strategy as a string to the strategy function.
-STRATEGIES = {
-    "largest_first": strategy_largest_first,
-    "random_sequential": strategy_random_sequential,
-    "smallest_last": strategy_smallest_last,
-    "independent_set": strategy_independent_set,
-    "connected_sequential_bfs": strategy_connected_sequential_bfs,
-    "connected_sequential_dfs": strategy_connected_sequential_dfs,
-    "connected_sequential": strategy_connected_sequential,
-    "saturation_largest_first": strategy_saturation_largest_first,
-    "DSATUR": strategy_saturation_largest_first,
-}
-
-
-@nx._dispatch
-def greedy_color(G, strategy="largest_first", interchange=False):
-    """Color a graph using various strategies of greedy graph coloring.
-
-    Attempts to color a graph using as few colors as possible, where no
-    neighbours of a node can have same color as the node itself. The
-    given strategy determines the order in which nodes are colored.
+        new_group_mappings[signature].add(node)
 
-    The strategies are described in [1]_, and smallest-last is based on
-    [2]_.
+    # leave the biggest new_group as the original group
+    new_groups = sorted(new_group_mappings.values(), key=len)
+    for new_group in new_groups[:-1]:
+        # Assign unused integer as the new_group_id
+        # ids are tuples, so will not interact with the original group_ids
+        new_group_id = len(groups)
+        groups[new_group_id] = new_group
+        groups[group_id] -= new_group
+        for node in new_group:
+            group_lookup[node] = new_group_id
+
+    return groups
+
+
+@nx._dispatchable(
+    node_attrs="[node_attributes]", edge_attrs="[edge_attributes]", returns_graph=True
+)
+def snap_aggregation(
+    G,
+    node_attributes,
+    edge_attributes=(),
+    prefix="Supernode-",
+    supernode_attribute="group",
+    superedge_attribute="types",
+):
+    """Creates a summary graph based on attributes and connectivity.
+
+    This function uses the Summarization by Grouping Nodes on Attributes
+    and Pairwise edges (SNAP) algorithm for summarizing a given
+    graph by grouping nodes by node attributes and their edge attributes
+    into supernodes in a summary graph.  This name SNAP should not be
+    confused with the Stanford Network Analysis Project (SNAP).
+
+    Here is a high-level view of how this algorithm works:
+
+    1) Group nodes by node attribute values.
+
+    2) Iteratively split groups until all nodes in each group have edges
+    to nodes in the same groups. That is, until all the groups are homogeneous
+    in their member nodes' edges to other groups.  For example,
+    if all the nodes in group A only have edge to nodes in group B, then the
+    group is homogeneous and does not need to be split. If all nodes in group B
+    have edges with nodes in groups {A, C}, but some also have edges with other
+    nodes in B, then group B is not homogeneous and needs to be split into
+    groups have edges with {A, C} and a group of nodes having
+    edges with {A, B, C}.  This way, viewers of the summary graph can
+    assume that all nodes in the group have the exact same node attributes and
+    the exact same edges.
+
+    3) Build the output summary graph, where the groups are represented by
+    super-nodes. Edges represent the edges shared between all the nodes in each
+    respective groups.
+
+    A SNAP summary graph can be used to visualize graphs that are too large to display
+    or visually analyze, or to efficiently identify sets of similar nodes with similar connectivity
+    patterns to other sets of similar nodes based on specified node and/or edge attributes in a graph.
 
     Parameters
     ----------
-    G : NetworkX graph
-
-    strategy : string or function(G, colors)
-       A function (or a string representing a function) that provides
-       the coloring strategy, by returning nodes in the ordering they
-       should be colored. ``G`` is the graph, and ``colors`` is a
-       dictionary of the currently assigned colors, keyed by nodes. The
-       function must return an iterable over all the nodes in ``G``.
-
-       If the strategy function is an iterator generator (that is, a
-       function with ``yield`` statements), keep in mind that the
-       ``colors`` dictionary will be updated after each ``yield``, since
-       this function chooses colors greedily.
-
-       If ``strategy`` is a string, it must be one of the following,
-       each of which represents one of the built-in strategy functions.
-
-       * ``'largest_first'``
-       * ``'random_sequential'``
-       * ``'smallest_last'``
-       * ``'independent_set'``
-       * ``'connected_sequential_bfs'``
-       * ``'connected_sequential_dfs'``
-       * ``'connected_sequential'`` (alias for the previous strategy)
-       * ``'saturation_largest_first'``
-       * ``'DSATUR'`` (alias for the previous strategy)
-
-    interchange: bool
-       Will use the color interchange algorithm described by [3]_ if set
-       to ``True``.
-
-       Note that ``saturation_largest_first`` and ``independent_set``
-       do not work with interchange. Furthermore, if you use
-       interchange with your own strategy function, you cannot rely
-       on the values in the ``colors`` argument.
+    G: graph
+        Networkx Graph to be summarized
+    node_attributes: iterable, required
+        An iterable of the node attributes used to group nodes in the summarization process. Nodes
+        with the same values for these attributes will be grouped together in the summary graph.
+    edge_attributes: iterable, optional
+        An iterable of the edge attributes considered in the summarization process.  If provided, unique
+        combinations of the attribute values found in the graph are used to
+        determine the edge types in the graph.  If not provided, all edges
+        are considered to be of the same type.
+    prefix: str
+        The prefix used to denote supernodes in the summary graph. Defaults to 'Supernode-'.
+    supernode_attribute: str
+        The node attribute for recording the supernode groupings of nodes. Defaults to 'group'.
+    superedge_attribute: str
+        The edge attribute for recording the edge types of multiple edges. Defaults to 'types'.
 
     Returns
     -------
-    A dictionary with keys representing nodes and values representing
-    corresponding coloring.
+    networkx.Graph: summary graph
 
     Examples
     --------
-    >>> G = nx.cycle_graph(4)
-    >>> d = nx.coloring.greedy_color(G, strategy="largest_first")
-    >>> d in [{0: 0, 1: 1, 2: 0, 3: 1}, {0: 1, 1: 0, 2: 1, 3: 0}]
-    True
-
-    Raises
-    ------
-    NetworkXPointlessConcept
-        If ``strategy`` is ``saturation_largest_first`` or
-        ``independent_set`` and ``interchange`` is ``True``.
+    SNAP aggregation takes a graph and summarizes it in the context of user-provided
+    node and edge attributes such that a viewer can more easily extract and
+    analyze the information represented by the graph
+
+    >>> nodes = {
+    ...     "A": dict(color="Red"),
+    ...     "B": dict(color="Red"),
+    ...     "C": dict(color="Red"),
+    ...     "D": dict(color="Red"),
+    ...     "E": dict(color="Blue"),
+    ...     "F": dict(color="Blue"),
+    ... }
+    >>> edges = [
+    ...     ("A", "E", "Strong"),
+    ...     ("B", "F", "Strong"),
+    ...     ("C", "E", "Weak"),
+    ...     ("D", "F", "Weak"),
+    ... ]
+    >>> G = nx.Graph()
+    >>> for node in nodes:
+    ...     attributes = nodes[node]
+    ...     G.add_node(node, **attributes)
+    >>> for source, target, type in edges:
+    ...     G.add_edge(source, target, type=type)
+    >>> node_attributes = ("color",)
+    >>> edge_attributes = ("type",)
+    >>> summary_graph = nx.snap_aggregation(
+    ...     G, node_attributes=node_attributes, edge_attributes=edge_attributes
+    ... )
+
+    Notes
+    -----
+    The summary graph produced is called a maximum Attribute-edge
+    compatible (AR-compatible) grouping.  According to [1]_, an
+    AR-compatible grouping means that all nodes in each group have the same
+    exact node attribute values and the same exact edges and
+    edge types to one or more nodes in the same groups.  The maximal
+    AR-compatible grouping is the grouping with the minimal cardinality.
+
+    The AR-compatible grouping is the most detailed grouping provided by
+    any of the SNAP algorithms.
 
     References
     ----------
-    .. [1] Adrian Kosowski, and Krzysztof Manuszewski,
-       Classical Coloring of Graphs, Graph Colorings, 2-19, 2004.
-       ISBN 0-8218-3458-4.
-    .. [2] David W. Matula, and Leland L. Beck, "Smallest-last
-       ordering and clustering and graph coloring algorithms." *J. ACM* 30,
-       3 (July 1983), 417–427. <https://doi.org/10.1145/2402.322385>
-    .. [3] Maciej M. Sysło, Narsingh Deo, Janusz S. Kowalik,
-       Discrete Optimization Algorithms with Pascal Programs, 415-424, 1983.
-       ISBN 0-486-45353-7.
-
-    """
-    if len(G) == 0:
-        return {}
-    # Determine the strategy provided by the caller.
-    strategy = STRATEGIES.get(strategy, strategy)
-    if not callable(strategy):
-        raise nx.NetworkXError(
-            "strategy must be callable or a valid string. " f"{strategy} not valid."
-        )
-    # Perform some validation on the arguments before executing any
-    # strategy functions.
-    if interchange:
-        if strategy is strategy_independent_set:
-            msg = "interchange cannot be used with independent_set"
-            raise nx.NetworkXPointlessConcept(msg)
-        if strategy is strategy_saturation_largest_first:
-            msg = "interchange cannot be used with" " saturation_largest_first"
-            raise nx.NetworkXPointlessConcept(msg)
-    colors = {}
-    nodes = strategy(G, colors)
-    if interchange:
-        return _greedy_coloring_with_interchange(G, nodes)
-    for u in nodes:
-        # Set to keep track of colors of neighbours
-        neighbour_colors = {colors[v] for v in G[u] if v in colors}
-        # Find the first unused color.
-        for color in itertools.count():
-            if color not in neighbour_colors:
-                break
-        # Assign the new color to the current node.
-        colors[u] = color
-    return colors
-
-
-# Tools for coloring with interchanges
-class _Node:
-    __slots__ = ["node_id", "color", "adj_list", "adj_color"]
-
-    def __init__(self, node_id, n):
-        self.node_id = node_id
-        self.color = -1
-        self.adj_list = None
-        self.adj_color = [None for _ in range(n)]
-
-    def __repr__(self):
-        return (
-            f"Node_id: {self.node_id}, Color: {self.color}, "
-            f"Adj_list: ({self.adj_list}), adj_color: ({self.adj_color})"
-        )
-
-    def assign_color(self, adj_entry, color):
-        adj_entry.col_prev = None
-        adj_entry.col_next = self.adj_color[color]
-        self.adj_color[color] = adj_entry
-        if adj_entry.col_next is not None:
-            adj_entry.col_next.col_prev = adj_entry
-
-    def clear_color(self, adj_entry, color):
-        if adj_entry.col_prev is None:
-            self.adj_color[color] = adj_entry.col_next
+    .. [1] Y. Tian, R. A. Hankins, and J. M. Patel. Efficient aggregation
+       for graph summarization. In Proc. 2008 ACM-SIGMOD Int. Conf.
+       Management of Data (SIGMOD’08), pages 567–580, Vancouver, Canada,
+       June 2008.
+    """
+    edge_types = {
+        edge: tuple(attrs.get(attr) for attr in edge_attributes)
+        for edge, attrs in G.edges.items()
+    }
+    if not G.is_directed():
+        if G.is_multigraph():
+            # list is needed to avoid mutating while iterating
+            edges = [((v, u, k), etype) for (u, v, k), etype in edge_types.items()]
         else:
-            adj_entry.col_prev.col_next = adj_entry.col_next
-        if adj_entry.col_next is not None:
-            adj_entry.col_next.col_prev = adj_entry.col_prev
-
-    def iter_neighbors(self):
-        adj_node = self.adj_list
-        while adj_node is not None:
-            yield adj_node
-            adj_node = adj_node.next
-
-    def iter_neighbors_color(self, color):
-        adj_color_node = self.adj_color[color]
-        while adj_color_node is not None:
-            yield adj_color_node.node_id
-            adj_color_node = adj_color_node.col_next
-
-
-class _AdjEntry:
-    __slots__ = ["node_id", "next", "mate", "col_next", "col_prev"]
-
-    def __init__(self, node_id):
-        self.node_id = node_id
-        self.next = None
-        self.mate = None
-        self.col_next = None
-        self.col_prev = None
-
-    def __repr__(self):
-        col_next = None if self.col_next is None else self.col_next.node_id
-        col_prev = None if self.col_prev is None else self.col_prev.node_id
-        return (
-            f"Node_id: {self.node_id}, Next: ({self.next}), "
-            f"Mate: ({self.mate.node_id}), "
-            f"col_next: ({col_next}), col_prev: ({col_prev})"
+            # list is needed to avoid mutating while iterating
+            edges = [((v, u), etype) for (u, v), etype in edge_types.items()]
+        edge_types.update(edges)
+
+    group_lookup = {
+        node: tuple(attrs[attr] for attr in node_attributes)
+        for node, attrs in G.nodes.items()
+    }
+    groups = defaultdict(set)
+    for node, node_type in group_lookup.items():
+        groups[node_type].add(node)
+
+    eligible_group_id, nbr_info = _snap_eligible_group(
+        G, groups, group_lookup, edge_types
+    )
+    while eligible_group_id:
+        groups = _snap_split(groups, nbr_info, group_lookup, eligible_group_id)
+        eligible_group_id, nbr_info = _snap_eligible_group(
+            G, groups, group_lookup, edge_types
         )
-
-
-def _greedy_coloring_with_interchange(G, nodes):
-    """Return a coloring for `original_graph` using interchange approach
-
-    This procedure is an adaption of the algorithm described by [1]_,
-    and is an implementation of coloring with interchange. Please be
-    advised, that the datastructures used are rather complex because
-    they are optimized to minimize the time spent identifying
-    subcomponents of the graph, which are possible candidates for color
-    interchange.
-
-    Parameters
-    ----------
-    G : NetworkX graph
-        The graph to be colored
-
-    nodes : list
-        nodes ordered using the strategy of choice
-
-    Returns
-    -------
-    dict :
-        A dictionary keyed by node to a color value
-
-    References
-    ----------
-    .. [1] Maciej M. Syslo, Narsingh Deo, Janusz S. Kowalik,
-       Discrete Optimization Algorithms with Pascal Programs, 415-424, 1983.
-       ISBN 0-486-45353-7.
-    """
-    n = len(G)
-
-    graph = {node: _Node(node, n) for node in G}
-
-    for node1, node2 in G.edges():
-        adj_entry1 = _AdjEntry(node2)
-        adj_entry2 = _AdjEntry(node1)
-        adj_entry1.mate = adj_entry2
-        adj_entry2.mate = adj_entry1
-        node1_head = graph[node1].adj_list
-        adj_entry1.next = node1_head
-        graph[node1].adj_list = adj_entry1
-        node2_head = graph[node2].adj_list
-        adj_entry2.next = node2_head
-        graph[node2].adj_list = adj_entry2
-
-    k = 0
-    for node in nodes:
-        # Find the smallest possible, unused color
-        neighbors = graph[node].iter_neighbors()
-        col_used = {graph[adj_node.node_id].color for adj_node in neighbors}
-        col_used.discard(-1)
-        k1 = next(itertools.dropwhile(lambda x: x in col_used, itertools.count()))
-
-        # k1 is now the lowest available color
-        if k1 > k:
-            connected = True
-            visited = set()
-            col1 = -1
-            col2 = -1
-            while connected and col1 < k:
-                col1 += 1
-                neighbor_cols = graph[node].iter_neighbors_color(col1)
-                col1_adj = list(neighbor_cols)
-
-                col2 = col1
-                while connected and col2 < k:
-                    col2 += 1
-                    visited = set(col1_adj)
-                    frontier = list(col1_adj)
-                    i = 0
-                    while i < len(frontier):
-                        search_node = frontier[i]
-                        i += 1
-                        col_opp = col2 if graph[search_node].color == col1 else col1
-                        neighbor_cols = graph[search_node].iter_neighbors_color(col_opp)
-
-                        for neighbor in neighbor_cols:
-                            if neighbor not in visited:
-                                visited.add(neighbor)
-                                frontier.append(neighbor)
-
-                    # Search if node is not adj to any col2 vertex
-                    connected = (
-                        len(
-                            visited.intersection(graph[node].iter_neighbors_color(col2))
-                        )
-                        > 0
-                    )
-
-            # If connected is false then we can swap !!!
-            if not connected:
-                # Update all the nodes in the component
-                for search_node in visited:
-                    graph[search_node].color = (
-                        col2 if graph[search_node].color == col1 else col1
-                    )
-                    col2_adj = graph[search_node].adj_color[col2]
-                    graph[search_node].adj_color[col2] = graph[search_node].adj_color[
-                        col1
-                    ]
-                    graph[search_node].adj_color[col1] = col2_adj
-
-                # Update all the neighboring nodes
-                for search_node in visited:
-                    col = graph[search_node].color
-                    col_opp = col1 if col == col2 else col2
-                    for adj_node in graph[search_node].iter_neighbors():
-                        if graph[adj_node.node_id].color != col_opp:
-                            # Direct reference to entry
-                            adj_mate = adj_node.mate
-                            graph[adj_node.node_id].clear_color(adj_mate, col_opp)
-                            graph[adj_node.node_id].assign_color(adj_mate, col)
-                k1 = col1
-
-        # We can color this node color k1
-        graph[node].color = k1
-        k = max(k1, k)
-
-        # Update the neighbors of this node
-        for adj_node in graph[node].iter_neighbors():
-            adj_mate = adj_node.mate
-            graph[adj_node.node_id].assign_color(adj_mate, k1)
-
-    return {node.node_id: node.color for node in graph.values()}
+    return _snap_build_graph(
+        G,
+        groups,
+        node_attributes,
+        edge_attributes,
+        nbr_info,
+        edge_types,
+        prefix,
+        supernode_attribute,
+        superedge_attribute,
+    )
```

### Comparing `networkx-3.2rc0/networkx/algorithms/coloring/tests/test_coloring.py` & `networkx-3.3rc0/networkx/algorithms/coloring/tests/test_coloring.py`

 * *Files 0% similar despite different names*

```diff
@@ -442,21 +442,21 @@
             aux_colored_nodes = colored_nodes.copy()
 
             node_iterator = nx.algorithms.coloring.greedy_coloring.strategy_saturation_largest_first(
                 G, aux_colored_nodes
             )
 
             for u in node_iterator:
-                # Set to keep track of colors of neighbours
-                neighbour_colors = {
+                # Set to keep track of colors of neighbors
+                nbr_colors = {
                     aux_colored_nodes[v] for v in G[u] if v in aux_colored_nodes
                 }
                 # Find the first unused color.
                 for color in itertools.count():
-                    if color not in neighbour_colors:
+                    if color not in nbr_colors:
                         break
                 aux_colored_nodes[u] = color
                 color_assignments.append((u, color))
 
                 # Color nodes between iterations
                 for i in range(nodes_to_add_between_calls - 1):
                     if not len(color_assignments) + len(colored_nodes) >= len(
```

### Comparing `networkx-3.2rc0/networkx/algorithms/communicability_alg.py` & `networkx-3.3rc0/networkx/algorithms/communicability_alg.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["communicability", "communicability_exp"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def communicability(G):
     r"""Returns communicability between all pairs of nodes in G.
 
     The communicability between pairs of nodes in G is the sum of
     walks of different lengths starting at node u and ending at node v.
 
     Parameters
@@ -87,15 +87,15 @@
                 s += vec[:, j][p] * vec[:, j][q] * expw[j]
             c[u][v] = float(s)
     return c
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def communicability_exp(G):
     r"""Returns communicability between all pairs of nodes in G.
 
     Communicability between pair of node (u,v) of node in G is the sum of
     walks of different lengths starting at node u and ending at node v.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/__init__.py` & `networkx-3.3rc0/networkx/algorithms/community/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -10,14 +10,15 @@
     >>> next_level_communities = next(communities_generator)
     >>> sorted(map(sorted, next_level_communities))
     [[0, 1, 2, 3, 4], [5], [6, 7, 8, 9, 10]]
 
 """
 from networkx.algorithms.community.asyn_fluid import *
 from networkx.algorithms.community.centrality import *
+from networkx.algorithms.community.divisive import *
 from networkx.algorithms.community.kclique import *
 from networkx.algorithms.community.kernighan_lin import *
 from networkx.algorithms.community.label_propagation import *
 from networkx.algorithms.community.lukes import *
 from networkx.algorithms.community.modularity_max import *
 from networkx.algorithms.community.quality import *
 from networkx.algorithms.community.community_utils import *
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/asyn_fluid.py` & `networkx-3.3rc0/networkx/algorithms/community/asyn_fluid.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,29 +6,30 @@
 from networkx.algorithms.components import is_connected
 from networkx.exception import NetworkXError
 from networkx.utils import groups, not_implemented_for, py_random_state
 
 __all__ = ["asyn_fluidc"]
 
 
-@not_implemented_for("directed", "multigraph")
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable
 def asyn_fluidc(G, k, max_iter=100, seed=None):
     """Returns communities in `G` as detected by Fluid Communities algorithm.
 
     The asynchronous fluid communities algorithm is described in
     [1]_. The algorithm is based on the simple idea of fluids interacting
     in an environment, expanding and pushing each other. Its initialization is
     random, so found communities may vary on different executions.
 
     The algorithm proceeds as follows. First each of the initial k communities
     is initialized in a random vertex in the graph. Then the algorithm iterates
     over all vertices in a random order, updating the community of each vertex
-    based on its own community and the communities of its neighbours. This
+    based on its own community and the communities of its neighbors. This
     process is performed several times until convergence.
     At all times, each community has a total density of 1, which is equally
     distributed among the vertices it contains. If a vertex changes of
     community, vertex densities of affected communities are adjusted
     immediately. When a complete iteration over all vertices is done, such that
     no vertex changes the community it belongs to, the algorithm has converged
     and returns.
@@ -98,15 +99,15 @@
             # Updating rule
             com_counter = Counter()
             # Take into account self vertex community
             try:
                 com_counter.update({communities[vertex]: density[communities[vertex]]})
             except KeyError:
                 pass
-            # Gather neighbour vertex communities
+            # Gather neighbor vertex communities
             for v in G[vertex]:
                 try:
                     com_counter.update({communities[v]: density[communities[v]]})
                 except KeyError:
                     continue
             # Check which is the community with highest density
             new_com = -1
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/centrality.py` & `networkx-3.3rc0/networkx/algorithms/community/centrality.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Functions for computing communities based on centrality notions."""
 
 import networkx as nx
 
 __all__ = ["girvan_newman"]
 
 
-@nx._dispatch(preserve_edge_attrs="most_valuable_edge")
+@nx._dispatchable(preserve_edge_attrs="most_valuable_edge")
 def girvan_newman(G, most_valuable_edge=None):
     """Finds communities in a graph using the Girvan–Newman method.
 
     Parameters
     ----------
     G : NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/community_utils.py` & `networkx-3.3rc0/networkx/algorithms/community/community_utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Helper functions for community-finding algorithms."""
 import networkx as nx
 
 __all__ = ["is_partition"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_partition(G, communities):
     """Returns *True* if `communities` is a partition of the nodes of `G`.
 
     A partition of a universe set is a family of pairwise disjoint sets
     whose union is the entire universe set.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/kclique.py` & `networkx-3.3rc0/networkx/algorithms/community/kclique.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from collections import defaultdict
 
 import networkx as nx
 
 __all__ = ["k_clique_communities"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def k_clique_communities(G, k, cliques=None):
     """Find k-clique communities in graph using the percolation method.
 
     A k-clique community is the union of all cliques of size k that
     can be reached through adjacent (sharing k-1 nodes) k-cliques.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/kernighan_lin.py` & `networkx-3.3rc0/networkx/algorithms/community/kernighan_lin.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,15 +38,15 @@
         totcost += cost_u + cost_v
         i += 1
         yield totcost, i, (u, v)
 
 
 @not_implemented_for("directed")
 @py_random_state(4)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def kernighan_lin_bisection(G, partition=None, max_iter=10, weight="weight", seed=None):
     """Partition a graph into two blocks using the Kernighan–Lin
     algorithm.
 
     This algorithm partitions a network into two sets by iteratively
     swapping pairs of nodes to reduce the edge cut between the two sets.  The
     pairs are chosen according to a modified form of Kernighan-Lin [1]_, which
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/label_propagation.py` & `networkx-3.3rc0/networkx/algorithms/community/label_propagation.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     "label_propagation_communities",
     "asyn_lpa_communities",
     "fast_label_propagation_communities",
 ]
 
 
 @py_random_state("seed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def fast_label_propagation_communities(G, *, weight=None, seed=None):
     """Returns communities in `G` as detected by fast label propagation.
 
     The fast label propagation algorithm is described in [1]_. The algorithm is
     probabilistic and the found communities may vary in different executions.
 
     The algorithm operates as follows. First, the community label of each node is
@@ -31,40 +31,40 @@
     are removed from the queue one by one and processed. If a node updates its label,
     all its neighbors that have a different label are added to the queue (if not
     already in the queue). The algorithm stops when the queue is empty.
 
     Parameters
     ----------
     G : Graph, DiGraph, MultiGraph, or MultiDiGraph
-      Any NetworkX graph.
+        Any NetworkX graph.
 
     weight : string, or None (default)
-      The edge attribute representing a non-negative weight of an edge. If None,
-      each edge is assumed to have weight one. The weight of an edge is used in
-      determining the frequency with which a label appears among the neighbors of
-      a node (edge with weight `w` is equivalent to `w` unweighted edges).
+        The edge attribute representing a non-negative weight of an edge. If None,
+        each edge is assumed to have weight one. The weight of an edge is used in
+        determining the frequency with which a label appears among the neighbors of
+        a node (edge with weight `w` is equivalent to `w` unweighted edges).
 
     seed : integer, random_state, or None (default)
-      Indicator of random number generation state. See :ref:`Randomness<randomness>`.
+        Indicator of random number generation state. See :ref:`Randomness<randomness>`.
 
     Returns
     -------
     communities : iterable
-      Iterable of communities given as sets of nodes.
+        Iterable of communities given as sets of nodes.
 
     Notes
     -----
     Edge directions are ignored for directed graphs.
     Edge weights must be non-negative numbers.
 
     References
     ----------
     .. [1] Vincent A. Traag & Lovro Šubelj. "Large network community detection by
-    fast label propagation." Scientific Reports 13 (2023): 2701.
-    https://doi.org/10.1038/s41598-023-29610-z
+       fast label propagation." Scientific Reports 13 (2023): 2701.
+       https://doi.org/10.1038/s41598-023-29610-z
     """
 
     # Queue of nodes to be processed.
     nodes_queue = deque(G)
     seed.shuffle(nodes_queue)
 
     # Set of nodes in the queue.
@@ -133,15 +133,15 @@
             for nbr, _, w in G.in_edges(node, data=weight, default=1):
                 label_freqs[comms[nbr]] += w
 
     return label_freqs
 
 
 @py_random_state(2)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def asyn_lpa_communities(G, weight=None, seed=None):
     """Returns communities in `G` as detected by asynchronous label
     propagation.
 
     The asynchronous label propagation algorithm is described in
     [1]_. The algorithm is probabilistic and the found communities may
     vary on different executions.
@@ -229,15 +229,15 @@
                 labels[node] = seed.choice(best_labels)
                 cont = True
 
     yield from groups(labels).values()
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def label_propagation_communities(G):
     """Generates community sets determined by label propagation
 
     Finds communities in `G` using a semi-synchronous label propagation
     method [1]_. This method combines the advantages of both the synchronous
     and asynchronous models. Not implemented for directed graphs.
 
@@ -312,15 +312,15 @@
     Input `labeling` should be a dict keyed by node to labels.
     """
     if not G[node]:
         # Nodes with no neighbors are themselves a community and are labeled
         # accordingly, hence the immediate if statement.
         return {labeling[node]}
 
-    # Compute the frequencies of all neighbours of node
+    # Compute the frequencies of all neighbors of node
     freqs = Counter(labeling[q] for q in G[node])
     max_freq = max(freqs.values())
     return {label for label, freq in freqs.items() if freq == max_freq}
 
 
 def _update_label(node, labeling, G):
     """Updates the label of a node using the Prec-Max tie breaking algorithm
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/louvain.py` & `networkx-3.3rc0/networkx/algorithms/community/louvain.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,24 @@
 """Function for detecting communities based on Louvain Community Detection
 Algorithm"""
 
+import itertools
 from collections import defaultdict, deque
 
 import networkx as nx
 from networkx.algorithms.community import modularity
 from networkx.utils import py_random_state
 
 __all__ = ["louvain_communities", "louvain_partitions"]
 
 
 @py_random_state("seed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def louvain_communities(
-    G, weight="weight", resolution=1, threshold=0.0000001, seed=None
+    G, weight="weight", resolution=1, threshold=0.0000001, max_level=None, seed=None
 ):
     r"""Find the best partition of a graph using the Louvain Community Detection
     Algorithm.
 
     Louvain Community Detection Algorithm is a simple method to extract the community
     structure of a network. This is a heuristic method based on modularity optimization. [1]_
 
@@ -52,15 +53,15 @@
     The second phase consists in building a new network whose nodes are now the communities
     found in the first phase. To do so, the weights of the links between the new nodes are given by
     the sum of the weight of the links between nodes in the corresponding two communities. Once this
     phase is complete it is possible to reapply the first phase creating bigger communities with
     increased modularity.
 
     The above two phases are executed until no modularity gain is achieved (or is less than
-    the `threshold`).
+    the `threshold`, or until `max_levels` is reached).
 
     Be careful with self-loops in the input graph. These are treated as
     previously reduced communities -- as if the process had been started
     in the middle of the algorithm. Large self-loop edge weights thus
     represent strong communities and in practice may be hard to add
     other nodes to.  If your input graph edge weights for self-loops
     do not represent already reduced communities you may want to remove
@@ -75,14 +76,18 @@
     resolution : float, optional (default=1)
         If resolution is less than 1, the algorithm favors larger communities.
         Greater than 1 favors smaller communities
     threshold : float, optional (default=0.0000001)
         Modularity gain threshold for each level. If the gain of modularity
         between 2 levels of the algorithm is less than the given threshold
         then the algorithm stops and returns the resulting communities.
+    max_level : int or None, optional (default=None)
+        The maximum number of levels (steps of the algorithm) to compute.
+        Must be a positive integer or None. If None, then there is no max
+        level and the threshold parameter determines the stopping condition.
     seed : integer, random_state, or None (default)
         Indicator of random number generation state.
         See :ref:`Randomness<randomness>`.
 
     Returns
     -------
     list
@@ -111,21 +116,25 @@
         [Research Report] Université d’Orléans. 2015. hal-01231784. https://hal.archives-ouvertes.fr/hal-01231784
 
     See Also
     --------
     louvain_partitions
     """
 
-    d = louvain_partitions(G, weight, resolution, threshold, seed)
-    q = deque(d, maxlen=1)
-    return q.pop()
+    partitions = louvain_partitions(G, weight, resolution, threshold, seed)
+    if max_level is not None:
+        if max_level <= 0:
+            raise ValueError("max_level argument must be a positive integer or None")
+        partitions = itertools.islice(partitions, max_level)
+    final_partition = deque(partitions, maxlen=1)
+    return final_partition.pop()
 
 
 @py_random_state("seed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def louvain_partitions(
     G, weight="weight", resolution=1, threshold=0.0000001, seed=None
 ):
     """Yields partitions for each level of the Louvain Community Detection Algorithm
 
     Louvain Community Detection Algorithm is a simple method to extract the community
     structure of a network. This is a heuristic method based on modularity optimization. [1]_
@@ -236,15 +245,15 @@
     node2com = {u: i for i, u in enumerate(G.nodes())}
     inner_partition = [{u} for u in G.nodes()]
     if is_directed:
         in_degrees = dict(G.in_degree(weight="weight"))
         out_degrees = dict(G.out_degree(weight="weight"))
         Stot_in = list(in_degrees.values())
         Stot_out = list(out_degrees.values())
-        # Calculate weights for both in and out neighbours without considering self-loops
+        # Calculate weights for both in and out neighbors without considering self-loops
         nbrs = {}
         for u in G:
             nbrs[u] = defaultdict(float)
             for _, n, wt in G.out_edges(u, data="weight"):
                 if u != n:
                     nbrs[u][n] += wt
             for n, _, wt in G.in_edges(u, data="weight"):
@@ -323,15 +332,15 @@
 
 def _neighbor_weights(nbrs, node2com):
     """Calculate weights between node and its neighbor communities.
 
     Parameters
     ----------
     nbrs : dictionary
-           Dictionary with nodes' neighbours as keys and their edge weight as value.
+           Dictionary with nodes' neighbors as keys and their edge weight as value.
     node2com : dictionary
            Dictionary with all graph's nodes as keys and their community index as value.
 
     """
     weights = defaultdict(float)
     for nbr, wt in nbrs.items():
         weights[node2com[nbr]] += wt
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/lukes.py` & `networkx-3.3rc0/networkx/algorithms/community/lukes.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     # splits j in two parts of which the first is at least
     # the second argument
     assert n >= min_size_of_first_part
     for p1 in range(min_size_of_first_part, n + 1):
         yield p1, n - p1
 
 
-@nx._dispatch(node_attrs="node_weight", edge_attrs="edge_weight")
+@nx._dispatchable(node_attrs="node_weight", edge_attrs="edge_weight")
 def lukes_partitioning(G, max_size, node_weight=None, edge_weight=None):
     """Optimal partitioning of a weighted tree using the Lukes algorithm.
 
     This algorithm partitions a connected, acyclic graph featuring integer
     node weights and float edge weights. The resulting clusters are such
     that the total weight of the nodes in each cluster does not exceed
     max_size and that the weight of the edges that are cut by the partition
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/modularity_max.py` & `networkx-3.3rc0/networkx/algorithms/community/modularity_max.py`

 * *Files 1% similar despite different names*

```diff
@@ -219,15 +219,15 @@
         if directed:
             b[v] += b[u]
             b[u] = 0
 
         yield communities.values()
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def greedy_modularity_communities(
     G,
     weight=None,
     resolution=1,
     cutoff=1,
     best_n=None,
 ):
@@ -305,14 +305,17 @@
        "Finding community structure in very large networks."
        Physical Review E 70(6), 2004.
     .. [3] Reichardt and Bornholdt "Statistical Mechanics of Community
        Detection" Phys. Rev. E74, 2006.
     .. [4] Newman, M. E. J."Analysis of weighted networks"
        Physical Review E 70(5 Pt 2):056131, 2004.
     """
+    if not G.size():
+        return [{n} for n in G]
+
     if (cutoff < 1) or (cutoff > G.number_of_nodes()):
         raise ValueError(f"cutoff must be between 1 and {len(G)}. Got {cutoff}.")
     if best_n is not None:
         if (best_n < 1) or (best_n > G.number_of_nodes()):
             raise ValueError(f"best_n must be between 1 and {len(G)}. Got {best_n}.")
         if best_n < cutoff:
             raise ValueError(f"Must have best_n >= cutoff. Got {best_n} < {cutoff}")
@@ -349,15 +352,15 @@
         communities = next(community_gen)
 
     return sorted(communities, key=len, reverse=True)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def naive_greedy_modularity_communities(G, resolution=1, weight=None):
     r"""Find communities in G using greedy modularity maximization.
 
     This implementation is O(n^4), much slower than alternatives, but it is
     provided as an easy-to-understand reference implementation.
 
     Greedy modularity maximization begins with each node in its own community
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/quality.py` & `networkx-3.3rc0/networkx/algorithms/community/quality.py`

 * *Files 5% similar despite different names*

```diff
@@ -54,15 +54,15 @@
         return G, partition
     raise nx.NetworkXError("`partition` is not a valid partition of the nodes of G")
 
 
 require_partition = argmap(_require_partition, (0, 1))
 
 
-@nx._dispatch
+@nx._dispatchable
 def intra_community_edges(G, partition):
     """Returns the number of intra-community edges for a partition of `G`.
 
     Parameters
     ----------
     G : NetworkX graph.
 
@@ -72,15 +72,15 @@
     The "intra-community edges" are those edges joining a pair of nodes
     in the same block of the partition.
 
     """
     return sum(G.subgraph(block).size() for block in partition)
 
 
-@nx._dispatch
+@nx._dispatchable
 def inter_community_edges(G, partition):
     """Returns the number of inter-community edges for a partition of `G`.
     according to the given
     partition of the nodes of `G`.
 
     Parameters
     ----------
@@ -104,15 +104,15 @@
     #                                    for block in partition))
     #     return sum(1 for u, v in G.edges() if aff[u] != aff[v])
     #
     MG = nx.MultiDiGraph if G.is_directed() else nx.MultiGraph
     return nx.quotient_graph(G, partition, create_using=MG).size()
 
 
-@nx._dispatch
+@nx._dispatchable
 def inter_community_non_edges(G, partition):
     """Returns the number of inter-community non-edges according to the
     given partition of the nodes of `G`.
 
     Parameters
     ----------
     G : NetworkX graph.
@@ -137,27 +137,28 @@
     #     aff = dict(chain.from_iterable(((v, block) for v in block)
     #                                    for block in partition))
     #     return sum(1 for u, v in nx.non_edges(G) if aff[u] != aff[v])
     #
     return inter_community_edges(nx.complement(G), partition)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def modularity(G, communities, weight="weight", resolution=1):
     r"""Returns the modularity of the given partition of the graph.
 
     Modularity is defined in [1]_ as
 
     .. math::
         Q = \frac{1}{2m} \sum_{ij} \left( A_{ij} - \gamma\frac{k_ik_j}{2m}\right)
             \delta(c_i,c_j)
 
-    where $m$ is the number of edges, $A$ is the adjacency matrix of `G`,
-    $k_i$ is the degree of $i$, $\gamma$ is the resolution parameter,
-    and $\delta(c_i, c_j)$ is 1 if $i$ and $j$ are in the same community else 0.
+    where $m$ is the number of edges (or sum of all edge weights as in [5]_),
+    $A$ is the adjacency matrix of `G`, $k_i$ is the (weighted) degree of $i$,
+    $\gamma$ is the resolution parameter, and $\delta(c_i, c_j)$ is 1 if $i$ and
+    $j$ are in the same community else 0.
 
     According to [2]_ (and verified by some algebra) this can be reduced to
 
     .. math::
        Q = \sum_{c=1}^{n}
        \left[ \frac{L_c}{m} - \gamma\left( \frac{k_c}{2m} \right) ^2 \right]
 
@@ -217,15 +218,17 @@
        "Finding community structure in very large networks."
        Phys. Rev. E 70.6 (2004). <https://arxiv.org/abs/cond-mat/0408187>
     .. [3] Reichardt and Bornholdt "Statistical Mechanics of Community Detection"
        Phys. Rev. E 74, 016110, 2006. https://doi.org/10.1103/PhysRevE.74.016110
     .. [4] M. E. J. Newman, "Equivalence between modularity optimization and
        maximum likelihood methods for community detection"
        Phys. Rev. E 94, 052315, 2016. https://doi.org/10.1103/PhysRevE.94.052315
-
+    .. [5] Blondel, V.D. et al. "Fast unfolding of communities in large
+       networks" J. Stat. Mech 10008, 1-12 (2008).
+       https://doi.org/10.1088/1742-5468/2008/10/P10008
     """
     if not isinstance(communities, list):
         communities = list(communities)
     if not is_partition(G, communities):
         raise NotAPartition(G, communities)
 
     directed = G.is_directed()
@@ -249,15 +252,15 @@
 
         return L_c / m - resolution * out_degree_sum * in_degree_sum * norm
 
     return sum(map(community_contribution, communities))
 
 
 @require_partition
-@nx._dispatch
+@nx._dispatchable
 def partition_quality(G, partition):
     """Returns the coverage and performance of a partition of G.
 
     The *coverage* of a partition is the ratio of the number of
     intra-community edges to the total number of edges in the graph.
 
     The *performance* of a partition is the number of
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_asyn_fluid.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_asyn_fluid.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,21 @@
 import pytest
 
 import networkx as nx
 from networkx import Graph, NetworkXError
 from networkx.algorithms.community import asyn_fluidc
 
 
+@pytest.mark.parametrize("graph_constructor", (nx.DiGraph, nx.MultiGraph))
+def test_raises_on_directed_and_multigraphs(graph_constructor):
+    G = graph_constructor([(0, 1), (1, 2)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.community.asyn_fluidc(G, 1)
+
+
 def test_exceptions():
     test = Graph()
     test.add_node("a")
     pytest.raises(NetworkXError, asyn_fluidc, test, "hi")
     pytest.raises(NetworkXError, asyn_fluidc, test, -1)
     pytest.raises(NetworkXError, asyn_fluidc, test, 3)
     test.add_node("b")
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_centrality.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_centrality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_kclique.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_kclique.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_kernighan_lin.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_kernighan_lin.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_label_propagation.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_label_propagation.py`

 * *Files 2% similar despite different names*

```diff
@@ -159,15 +159,15 @@
         self._check_communities(G, ground_truth)
 
 
 class TestFastLabelPropagationCommunities:
     N = 100  # number of nodes
     K = 15  # average node degree
 
-    def _check_communities(self, G, truth, weight=None, seed=None):
+    def _check_communities(self, G, truth, weight=None, seed=42):
         C = nx.community.fast_label_propagation_communities(G, weight=weight, seed=seed)
         assert {frozenset(c) for c in C} == truth
 
     def test_null_graph(self):
         G = nx.null_graph()
         truth = set()
         self._check_communities(G, truth)
@@ -189,32 +189,31 @@
 
     def test_bipartite_graph(self):
         G = nx.complete_bipartite_graph(self.N // 2, self.N // 2)
         truth = {frozenset(G)}
         self._check_communities(G, truth)
 
     def test_random_graph(self):
-        G = nx.gnm_random_graph(self.N, self.N * self.K // 2)
+        G = nx.gnm_random_graph(self.N, self.N * self.K // 2, seed=42)
         truth = {frozenset(G)}
         self._check_communities(G, truth)
 
     def test_disjoin_cliques(self):
         G = nx.Graph(["ab", "AB", "AC", "BC", "12", "13", "14", "23", "24", "34"])
         truth = {frozenset("ab"), frozenset("ABC"), frozenset("1234")}
         self._check_communities(G, truth)
 
     def test_ring_of_cliques(self):
-        G = nx.ring_of_cliques(self.N, self.K)
-        truth = {
-            frozenset([self.K * i + k for k in range(self.K)]) for i in range(self.N)
-        }
+        N, K = self.N, self.K
+        G = nx.ring_of_cliques(N, K)
+        truth = {frozenset([K * i + k for k in range(K)]) for i in range(N)}
         self._check_communities(G, truth)
 
     def test_larger_graph(self):
-        G = nx.gnm_random_graph(100 * self.N, 50 * self.N * self.K)
+        G = nx.gnm_random_graph(100 * self.N, 50 * self.N * self.K, seed=42)
         nx.community.fast_label_propagation_communities(G)
 
     def test_graph_type(self):
         G1 = nx.complete_graph(self.N, nx.MultiDiGraph())
         G2 = nx.MultiGraph(G1)
         G3 = nx.DiGraph(G1)
         G4 = nx.Graph(G1)
@@ -234,7 +233,9 @@
         self._check_communities(G, truth, weight="weight")
 
     def test_seed_argument(self):
         G = nx.karate_club_graph()
         C = nx.community.fast_label_propagation_communities(G, seed=2023)
         truth = {frozenset(c) for c in C}
         self._check_communities(G, truth, seed=2023)
+        # smoke test that seed=None works
+        C = nx.community.fast_label_propagation_communities(G, seed=None)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_louvain.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_louvain.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+import pytest
+
 import networkx as nx
 
 
 def test_modularity_increase():
     G = nx.LFR_benchmark_graph(
         250, 3, 1.5, 0.009, average_degree=5, min_community=20, seed=10
     )
@@ -61,15 +63,15 @@
     assert expected_partition == part
 
     G.add_weighted_edges_from([(i, i, i * 1000) for i in range(9)])
     # large self-loop weight impacts partition
     partition = nx.community.louvain_communities(G, seed=2, weight="weight")
     assert part != partition
 
-    # small self-loop weights arent enough to impact partition in this graph
+    # small self-loop weights aren't enough to impact partition in this graph
     partition = nx.community.louvain_communities(G, seed=2, weight=None)
     assert part == partition
 
 
 def test_directed_selfloops():
     G = nx.DiGraph()
     G.add_nodes_from(range(11))
@@ -90,15 +92,15 @@
     G_expected_partition = nx.community.louvain_communities(G, seed=123, weight=None)
 
     G.add_weighted_edges_from([(i, i, i * 1000) for i in range(3)])
     # large self-loop weight impacts partition
     G_partition = nx.community.louvain_communities(G, seed=123, weight="weight")
     assert G_partition != G_expected_partition
 
-    # small self-loop weights arent enough to impact partition in this graph
+    # small self-loop weights aren't enough to impact partition in this graph
     G_partition = nx.community.louvain_communities(G, seed=123, weight=None)
     assert G_partition == G_expected_partition
 
 
 def test_directed_partition():
     """
     Test 2 cases that were looping infinitely
@@ -230,15 +232,33 @@
         250, 3, 1.5, 0.009, average_degree=5, min_community=20, seed=10
     )
     partition1 = nx.community.louvain_communities(G, threshold=0.3, seed=2)
     partition2 = nx.community.louvain_communities(G, seed=2)
     mod1 = nx.community.modularity(G, partition1)
     mod2 = nx.community.modularity(G, partition2)
 
-    assert mod1 < mod2
+    assert mod1 <= mod2
 
 
 def test_empty_graph():
     G = nx.Graph()
     G.add_nodes_from(range(5))
     expected = [{0}, {1}, {2}, {3}, {4}]
     assert nx.community.louvain_communities(G) == expected
+
+
+def test_max_level():
+    G = nx.LFR_benchmark_graph(
+        250, 3, 1.5, 0.009, average_degree=5, min_community=20, seed=10
+    )
+    parts_iter = nx.community.louvain_partitions(G, seed=42)
+    for max_level, expected in enumerate(parts_iter, 1):
+        partition = nx.community.louvain_communities(G, max_level=max_level, seed=42)
+        assert partition == expected
+    assert max_level > 1  # Ensure we are actually testing max_level
+    # max_level is an upper limit; it's okay if we stop before it's hit.
+    partition = nx.community.louvain_communities(G, max_level=max_level + 1, seed=42)
+    assert partition == expected
+    with pytest.raises(
+        ValueError, match="max_level argument must be a positive integer"
+    ):
+        nx.community.louvain_communities(G, max_level=0)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_lukes.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_lukes.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_modularity_max.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_modularity_max.py`

 * *Files 2% similar despite different names*

```diff
@@ -327,7 +327,14 @@
     expected = [frozenset(range(8)), frozenset(range(8, 13))]
     assert greedy_modularity_communities(G, best_n=best_n) == expected
 
     # Two additional merging steps:
     best_n = 1
     expected = [frozenset(range(13))]
     assert greedy_modularity_communities(G, best_n=best_n) == expected
+
+
+def test_greedy_modularity_communities_corner_cases():
+    G = nx.empty_graph()
+    assert nx.community.greedy_modularity_communities(G) == []
+    G.add_nodes_from(range(3))
+    assert nx.community.greedy_modularity_communities(G) == [{0}, {1}, {2}]
```

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_quality.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_quality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/community/tests/test_utils.py` & `networkx-3.3rc0/networkx/algorithms/community/tests/test_utils.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/components/attracting.py` & `networkx-3.3rc0/networkx/algorithms/components/attracting.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,15 +6,15 @@
     "number_attracting_components",
     "attracting_components",
     "is_attracting_component",
 ]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def attracting_components(G):
     """Generates the attracting components in `G`.
 
     An attracting component in a directed graph `G` is a strongly connected
     component with the property that a random walker on the graph will never
     leave the component, once it enters the component.
 
@@ -50,15 +50,15 @@
     cG = nx.condensation(G, scc)
     for n in cG:
         if cG.out_degree(n) == 0:
             yield scc[n]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def number_attracting_components(G):
     """Returns the number of attracting components in `G`.
 
     Parameters
     ----------
     G : DiGraph, MultiDiGraph
         The graph to be analyzed.
@@ -79,15 +79,15 @@
     is_attracting_component
 
     """
     return sum(1 for ac in attracting_components(G))
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_attracting_component(G):
     """Returns True if `G` consists of a single attracting component.
 
     Parameters
     ----------
     G : DiGraph, MultiDiGraph
         The graph to be analyzed.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/biconnected.py` & `networkx-3.3rc0/networkx/algorithms/components/biconnected.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     "biconnected_component_edges",
     "is_biconnected",
     "articulation_points",
 ]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def is_biconnected(G):
     """Returns True if the graph is biconnected, False otherwise.
 
     A graph is biconnected if, and only if, it cannot be disconnected by
     removing only one node (and all edges incident on that node).  If
     removing a node increases the number of disconnected components
     in the graph, that node is called an articulation point, or cut
@@ -90,15 +90,15 @@
         return len(bcc) == len(G)
     else:
         # Multiple bicomponents
         return False
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def biconnected_component_edges(G):
     """Returns a generator of lists of edges, one list for each biconnected
     component of the input graph.
 
     Biconnected components are maximal subgraphs such that the removal of a
     node (and all edges incident on that node) will not disconnect the
     subgraph.  Note that nodes may be part of more than one biconnected
@@ -163,15 +163,15 @@
            Communications of the ACM 16: 372–378. doi:10.1145/362248.362272
 
     """
     yield from _biconnected_dfs(G, components=True)
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def biconnected_components(G):
     """Returns a generator of sets of nodes, one set for each biconnected
     component of the graph
 
     Biconnected components are maximal subgraphs such that the removal of a
     node (and all edges incident on that node) will not disconnect the
     subgraph. Note that nodes may be part of more than one biconnected
@@ -256,15 +256,15 @@
 
     """
     for comp in _biconnected_dfs(G, components=True):
         yield set(chain.from_iterable(comp))
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def articulation_points(G):
     """Yield the articulation points, or cut vertices, of a graph.
 
     An articulation point or cut vertex is any node whose removal (along with
     all its incident edges) increases the number of connected components of
     a graph.  An undirected connected graph without articulation points is
     biconnected. Articulation points belong to more than one biconnected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/connected.py` & `networkx-3.3rc0/networkx/algorithms/components/connected.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     "connected_components",
     "is_connected",
     "node_connected_component",
 ]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def connected_components(G):
     """Generate connected components.
 
     Parameters
     ----------
     G : NetworkX graph
        An undirected graph
@@ -64,28 +64,34 @@
     for v in G:
         if v not in seen:
             c = _plain_bfs(G, v)
             seen.update(c)
             yield c
 
 
-@nx._dispatch
+@not_implemented_for("directed")
+@nx._dispatchable
 def number_connected_components(G):
     """Returns the number of connected components.
 
     Parameters
     ----------
     G : NetworkX graph
        An undirected graph.
 
     Returns
     -------
     n : integer
        Number of connected components
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If G is directed.
+
     Examples
     --------
     >>> G = nx.Graph([(0, 1), (1, 2), (5, 6), (3, 4)])
     >>> nx.number_connected_components(G)
     3
 
     See Also
@@ -99,15 +105,15 @@
     For undirected graphs only.
 
     """
     return sum(1 for cc in connected_components(G))
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def is_connected(G):
     """Returns True if the graph is connected, False otherwise.
 
     Parameters
     ----------
     G : NetworkX Graph
        An undirected graph.
@@ -139,21 +145,21 @@
     Notes
     -----
     For undirected graphs only.
 
     """
     if len(G) == 0:
         raise nx.NetworkXPointlessConcept(
-            "Connectivity is undefined ", "for the null graph."
+            "Connectivity is undefined for the null graph."
         )
     return sum(1 for node in _plain_bfs(G, arbitrary_element(G))) == len(G)
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def node_connected_component(G, n):
     """Returns the set of nodes in the component of graph containing node n.
 
     Parameters
     ----------
     G : NetworkX Graph
        An undirected graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/semiconnected.py` & `networkx-3.3rc0/networkx/algorithms/components/semiconnected.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for, pairwise
 
 __all__ = ["is_semiconnected"]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_semiconnected(G):
     r"""Returns True if the graph is semiconnected, False otherwise.
 
     A graph is semiconnected if and only if for any pair of nodes, either one
     is reachable from the other, or they are mutually reachable.
 
     This function uses a theorem that states that a DAG is semiconnected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/strongly_connected.py` & `networkx-3.3rc0/networkx/algorithms/components/strongly_connected.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     "strongly_connected_components_recursive",
     "kosaraju_strongly_connected_components",
     "condensation",
 ]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def strongly_connected_components(G):
     """Generate nodes in strongly connected components of graph.
 
     Parameters
     ----------
     G : NetworkX Graph
         A directed graph.
@@ -35,18 +35,15 @@
 
     Examples
     --------
     Generate a sorted list of strongly connected components, largest first.
 
     >>> G = nx.cycle_graph(4, create_using=nx.DiGraph())
     >>> nx.add_cycle(G, [10, 11, 12])
-    >>> [
-    ...     len(c)
-    ...     for c in sorted(nx.strongly_connected_components(G), key=len, reverse=True)
-    ... ]
+    >>> [len(c) for c in sorted(nx.strongly_connected_components(G), key=len, reverse=True)]
     [4, 3]
 
     If you only want the largest component, it's more efficient to
     use max instead of sort.
 
     >>> largest = max(nx.strongly_connected_components(G), key=len)
 
@@ -108,15 +105,15 @@
                         scc_found.update(scc)
                         yield scc
                     else:
                         scc_queue.append(v)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def kosaraju_strongly_connected_components(G, source=None):
     """Generate nodes in strongly connected components of graph.
 
     Parameters
     ----------
     G : NetworkX Graph
         A directed graph.
@@ -170,15 +167,15 @@
         c = nx.dfs_preorder_nodes(G, r)
         new = {v for v in c if v not in seen}
         seen.update(new)
         yield new
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def strongly_connected_components_recursive(G):
     """Generate nodes in strongly connected components of graph.
 
     .. deprecated:: 3.2
 
        This function is deprecated and will be removed in a future version of
        NetworkX. Use `strongly_connected_components` instead.
@@ -252,15 +249,15 @@
         stacklevel=2,
     )
 
     yield from strongly_connected_components(G)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def number_strongly_connected_components(G):
     """Returns number of strongly connected components in graph.
 
     Parameters
     ----------
     G : NetworkX graph
        A directed graph.
@@ -273,15 +270,17 @@
     Raises
     ------
     NetworkXNotImplemented
         If G is undirected.
 
     Examples
     --------
-    >>> G = nx.DiGraph([(0, 1), (1, 2), (2, 0), (2, 3), (4, 5), (3, 4), (5, 6), (6, 3), (6, 7)])
+    >>> G = nx.DiGraph(
+    ...     [(0, 1), (1, 2), (2, 0), (2, 3), (4, 5), (3, 4), (5, 6), (6, 3), (6, 7)]
+    ... )
     >>> nx.number_strongly_connected_components(G)
     3
 
     See Also
     --------
     strongly_connected_components
     number_connected_components
@@ -291,15 +290,15 @@
     -----
     For directed graphs only.
     """
     return sum(1 for scc in strongly_connected_components(G))
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_strongly_connected(G):
     """Test directed graph for strong connectivity.
 
     A directed graph is strongly connected if and only if every vertex in
     the graph is reachable from every other vertex.
 
     Parameters
@@ -343,15 +342,15 @@
             """Connectivity is undefined for the null graph."""
         )
 
     return len(next(strongly_connected_components(G))) == len(G)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def condensation(G, scc=None):
     """Returns the condensation of G.
 
     The condensation of G is the graph with each of the strongly connected
     components contracted into a single node.
 
     Parameters
@@ -387,15 +386,15 @@
 
     >>> G = nx.barbell_graph(4, 0)
     >>> G.remove_edge(3, 4)
     >>> G = nx.DiGraph(G)
     >>> H = nx.condensation(G)
     >>> H.nodes.data()
     NodeDataView({0: {'members': {0, 1, 2, 3}}, 1: {'members': {4, 5, 6, 7}}})
-    >>> H.graph['mapping']
+    >>> H.graph["mapping"]
     {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1}
 
     Contracting a complete graph into one single SCC.
 
     >>> G = nx.complete_graph(7, create_using=nx.DiGraph)
     >>> H = nx.condensation(G)
     >>> H.nodes
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_attracting.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_attracting.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_biconnected.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_biconnected.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_connected.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_connected.py`

 * *Files 1% similar despite different names*

```diff
@@ -57,15 +57,15 @@
         C = [[0, 1, 2], [3, 4]]
         cls.gc.append((G, C))
 
         G = nx.DiGraph()
         C = []
         cls.gc.append((G, C))
 
-    # This additionally tests the @nx._dispatch mechanism, treating
+    # This additionally tests the @nx._dispatchable mechanism, treating
     # nx.connected_components as if it were a re-implementation from another package
     @pytest.mark.parametrize("wrapper", [lambda x: x, dispatch_interface.convert])
     def test_connected_components(self, wrapper):
         cc = nx.connected_components
         G = wrapper(self.G)
         C = {
             frozenset([0, 1, 2, 3]),
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_semiconnected.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_semiconnected.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_strongly_connected.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_strongly_connected.py`

 * *Files 1% similar despite different names*

```diff
@@ -179,20 +179,16 @@
     def test_connected_raise(self):
         G = nx.Graph()
         with pytest.raises(NetworkXNotImplemented):
             next(nx.strongly_connected_components(G))
         with pytest.raises(NetworkXNotImplemented):
             next(nx.kosaraju_strongly_connected_components(G))
         with pytest.raises(NetworkXNotImplemented):
-            with pytest.deprecated_call():
-                next(nx.strongly_connected_components_recursive(G))
+            next(nx.strongly_connected_components_recursive(G))
         pytest.raises(NetworkXNotImplemented, nx.is_strongly_connected, G)
-        pytest.raises(
-            nx.NetworkXPointlessConcept, nx.is_strongly_connected, nx.DiGraph()
-        )
         pytest.raises(NetworkXNotImplemented, nx.condensation, G)
 
     strong_cc_methods = (
         nx.strongly_connected_components,
         nx.kosaraju_strongly_connected_components,
     )
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/tests/test_weakly_connected.py` & `networkx-3.3rc0/networkx/algorithms/components/tests/test_weakly_connected.py`

 * *Files 9% similar despite different names*

```diff
@@ -84,7 +84,13 @@
         DG = nx.path_graph(5, create_using=nx.DiGraph)
         G = nx.disjoint_union(DG, DG)
         seen = set()
         for component in nx.weakly_connected_components(G):
             assert len(seen & component) == 0
             seen.update(component)
             component.clear()
+
+
+def test_is_weakly_connected_empty_graph_raises():
+    G = nx.DiGraph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="Connectivity is undefined"):
+        nx.is_weakly_connected(G)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/components/weakly_connected.py` & `networkx-3.3rc0/networkx/algorithms/components/weakly_connected.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,15 +6,15 @@
     "number_weakly_connected_components",
     "weakly_connected_components",
     "is_weakly_connected",
 ]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def weakly_connected_components(G):
     """Generate weakly connected components of G.
 
     Parameters
     ----------
     G : NetworkX graph
         A directed graph
@@ -32,18 +32,15 @@
 
     Examples
     --------
     Generate a sorted list of weakly connected components, largest first.
 
     >>> G = nx.path_graph(4, create_using=nx.DiGraph())
     >>> nx.add_path(G, [10, 11, 12])
-    >>> [
-    ...     len(c)
-    ...     for c in sorted(nx.weakly_connected_components(G), key=len, reverse=True)
-    ... ]
+    >>> [len(c) for c in sorted(nx.weakly_connected_components(G), key=len, reverse=True)]
     [4, 3]
 
     If you only want the largest component, it's more efficient to
     use max instead of sort:
 
     >>> largest_cc = max(nx.weakly_connected_components(G), key=len)
 
@@ -62,15 +59,15 @@
         if v not in seen:
             c = set(_plain_bfs(G, v))
             seen.update(c)
             yield c
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def number_weakly_connected_components(G):
     """Returns the number of weakly connected components in G.
 
     Parameters
     ----------
     G : NetworkX graph
         A directed graph.
@@ -102,15 +99,15 @@
     For directed graphs only.
 
     """
     return sum(1 for wcc in weakly_connected_components(G))
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_weakly_connected(G):
     """Test directed graph for weak connectivity.
 
     A directed graph is weakly connected if and only if the graph
     is connected when the direction of the edge between nodes is ignored.
 
     Note that if a graph is strongly connected (i.e. the graph is connected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/connectivity.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/connectivity.py`

 * *Files 0% similar despite different names*

```diff
@@ -27,15 +27,15 @@
     "node_connectivity",
     "local_edge_connectivity",
     "edge_connectivity",
     "all_pairs_node_connectivity",
 ]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 4, "residual?": 5},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"auxiliary", "residual"},
 )
 def local_node_connectivity(
     G, s, t, flow_func=None, auxiliary=None, residual=None, cutoff=None
 ):
@@ -114,28 +114,26 @@
     all pairs of nodes of the platonic icosahedral graph reusing
     the data structures.
 
     >>> import itertools
     >>> # You also have to explicitly import the function for
     >>> # building the auxiliary digraph from the connectivity package
     >>> from networkx.algorithms.connectivity import build_auxiliary_node_connectivity
-    ...
     >>> H = build_auxiliary_node_connectivity(G)
     >>> # And the function for building the residual network from the
     >>> # flow package
     >>> from networkx.algorithms.flow import build_residual_network
     >>> # Note that the auxiliary digraph has an edge attribute named capacity
     >>> R = build_residual_network(H, "capacity")
     >>> result = dict.fromkeys(G, dict())
     >>> # Reuse the auxiliary digraph and the residual network by passing them
     >>> # as parameters
     >>> for u, v in itertools.combinations(G, 2):
     ...     k = local_node_connectivity(G, u, v, auxiliary=H, residual=R)
     ...     result[u][v] = k
-    ...
     >>> all(result[u][v] == 5 for u, v in itertools.combinations(G, 2))
     True
 
     You can also use alternative flow algorithms for computing node
     connectivity. For instance, in dense networks the algorithm
     :meth:`shortest_augmenting_path` will usually perform better than
     the default :meth:`edmonds_karp` which is faster for sparse
@@ -210,15 +208,15 @@
         kwargs["cutoff"] = cutoff
     elif flow_func is boykov_kolmogorov:
         kwargs["cutoff"] = cutoff
 
     return nx.maximum_flow_value(H, f"{mapping[s]}B", f"{mapping[t]}A", **kwargs)
 
 
-@nx._dispatch
+@nx._dispatchable
 def node_connectivity(G, s=None, t=None, flow_func=None):
     r"""Returns node connectivity for a graph or digraph G.
 
     Node connectivity is equal to the minimum number of nodes that
     must be removed to disconnect G or render it trivial. If source
     and target nodes are provided, this function returns the local node
     connectivity: the minimum number of nodes that must be removed to break
@@ -351,15 +349,15 @@
             continue
         kwargs["cutoff"] = K
         K = min(K, local_node_connectivity(G, x, y, **kwargs))
 
     return K
 
 
-@nx._dispatch
+@nx._dispatchable
 def average_node_connectivity(G, flow_func=None):
     r"""Returns the average connectivity of a graph G.
 
     The average connectivity `\bar{\kappa}` of a graph G is the average
     of local node connectivity over all pairs of nodes of G [1]_ .
 
     .. math::
@@ -420,15 +418,15 @@
         den += 1
 
     if den == 0:  # Null Graph
         return 0
     return num / den
 
 
-@nx._dispatch
+@nx._dispatchable
 def all_pairs_node_connectivity(G, nbunch=None, flow_func=None):
     """Compute node connectivity between all pairs of nodes of G.
 
     Parameters
     ----------
     G : NetworkX graph
         Undirected graph
@@ -488,15 +486,15 @@
         all_pairs[u][v] = K
         if not directed:
             all_pairs[v][u] = K
 
     return all_pairs
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 4, "residual?": 5},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
 )
 def local_edge_connectivity(
     G, s, t, flow_func=None, auxiliary=None, residual=None, cutoff=None
 ):
@@ -654,15 +652,15 @@
         kwargs["cutoff"] = cutoff
     elif flow_func is boykov_kolmogorov:
         kwargs["cutoff"] = cutoff
 
     return nx.maximum_flow_value(H, s, t, **kwargs)
 
 
-@nx._dispatch
+@nx._dispatchable
 def edge_connectivity(G, s=None, t=None, flow_func=None, cutoff=None):
     r"""Returns the edge connectivity of the graph or digraph G.
 
     The edge connectivity is equal to the minimum number of edges that
     must be removed to disconnect G or render it trivial. If source
     and target nodes are provided, this function returns the local edge
     connectivity: the minimum number of edges that must be removed to
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/cuts.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/cuts.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     "minimum_st_node_cut",
     "minimum_node_cut",
     "minimum_st_edge_cut",
     "minimum_edge_cut",
 ]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 4, "residual?": 5},
     preserve_edge_attrs={
         "auxiliary": {"capacity": float("inf")},
         "residual": {"capacity": float("inf")},
     },
     preserve_graph_attrs={"auxiliary", "residual"},
 )
@@ -157,15 +157,15 @@
     cutset = set()
     for u, nbrs in ((n, G[n]) for n in reachable):
         cutset.update((u, v) for v in nbrs if v in non_reachable)
 
     return cutset
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 4, "residual?": 5},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_node_attrs={"auxiliary": {"id": None}},
     preserve_graph_attrs={"auxiliary", "residual"},
 )
 def minimum_st_node_cut(G, s, t, flow_func=None, auxiliary=None, residual=None):
     r"""Returns a set of nodes of minimum cardinality that disconnect source
@@ -301,15 +301,15 @@
     # original graph.
     edge_cut = minimum_st_edge_cut(H, f"{mapping[s]}B", f"{mapping[t]}A", **kwargs)
     # Each node in the original graph maps to two nodes of the auxiliary graph
     node_cut = {H.nodes[node]["id"] for edge in edge_cut for node in edge}
     return node_cut - {s, t}
 
 
-@nx._dispatch
+@nx._dispatchable
 def minimum_node_cut(G, s=None, t=None, flow_func=None):
     r"""Returns a set of nodes of minimum cardinality that disconnects G.
 
     If source and target nodes are provided, this function returns the
     set of nodes of minimum cardinality that, if removed, would destroy
     all paths among source and target in G. If not, it returns a set
     of nodes of minimum cardinality that disconnects G.
@@ -447,15 +447,15 @@
         this_cut = minimum_st_node_cut(G, x, y, **kwargs)
         if len(min_cut) >= len(this_cut):
             min_cut = this_cut
 
     return min_cut
 
 
-@nx._dispatch
+@nx._dispatchable
 def minimum_edge_cut(G, s=None, t=None, flow_func=None):
     r"""Returns a set of edges of minimum cardinality that disconnects G.
 
     If source and target nodes are provided, this function returns the
     set of edges of minimum cardinality that, if removed, would break
     all paths among source and target in G. If not, it returns a set of
     edges of minimum cardinality that disconnects G.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/disjoint_paths.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/disjoint_paths.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 # Functions to build auxiliary data structures.
 from .utils import build_auxiliary_edge_connectivity, build_auxiliary_node_connectivity
 
 __all__ = ["edge_disjoint_paths", "node_disjoint_paths"]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 5, "residual?": 6},
     preserve_edge_attrs={
         "auxiliary": {"capacity": float("inf")},
         "residual": {"capacity": float("inf")},
     },
     preserve_graph_attrs={"residual"},
 )
@@ -230,15 +230,15 @@
                 break
         else:
             path.append(t)
             yield path
             paths_found += 1
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "auxiliary?": 5, "residual?": 6},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_node_attrs={"auxiliary": {"id": None}},
     preserve_graph_attrs={"auxiliary", "residual"},
 )
 def node_disjoint_paths(
     G, s, t, flow_func=None, cutoff=None, auxiliary=None, residual=None
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/edge_augmentation.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/edge_augmentation.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 from networkx.utils import not_implemented_for, py_random_state
 
 __all__ = ["k_edge_augmentation", "is_k_edge_connected", "is_locally_k_edge_connected"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_k_edge_connected(G, k):
     """Tests to see if a graph is k-edge-connected.
 
     Is it impossible to disconnect the graph by removing fewer than k edges?
     If so, then G is k-edge-connected.
 
     Parameters
@@ -64,22 +64,22 @@
     elif any(d < k for n, d in G.degree()):
         return False
     else:
         # Otherwise perform the full check
         if k == 1:
             return nx.is_connected(G)
         elif k == 2:
-            return not nx.has_bridges(G)
+            return nx.is_connected(G) and not nx.has_bridges(G)
         else:
             return nx.edge_connectivity(G, cutoff=k) >= k
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_locally_k_edge_connected(G, s, t, k):
     """Tests to see if an edge in a graph is locally k-edge-connected.
 
     Is it impossible to disconnect s and t by removing fewer than k edges?
     If so, then s and t are locally k-edge-connected in G.
 
     Parameters
@@ -129,15 +129,15 @@
         else:
             localk = nx.connectivity.local_edge_connectivity(G, s, t, cutoff=k)
             return localk >= k
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def k_edge_augmentation(G, k, avail=None, weight=None, partial=False):
     """Finds set of edges to k-edge-connect G.
 
     Adding edges from the augmentation to G make it impossible to disconnect G
     unless k or more edges are removed. This function uses the most efficient
     function available (depending on the value of k and if the problem is
     weighted or unweighted) to search for a minimum weight subset of available
@@ -280,15 +280,15 @@
                     G, k=k, avail=avail, weight=weight
                 )
             yield from aug_edges
         else:
             raise
 
 
-@nx._dispatch
+@nx._dispatchable
 def partial_k_edge_augmentation(G, k, avail, weight=None):
     """Finds augmentation that k-edge-connects as much of the graph as possible.
 
     When a k-edge-augmentation is not possible, we can still try to find a
     small set of edges that partially k-edge-connects as much of the graph as
     possible. All possible edges are generated between remaining parts.
     This minimizes the number of k-edge-connected subgraphs in the resulting
@@ -383,15 +383,15 @@
             edge = d.get("generator", None)
             if edge is not None:
                 yield edge
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def one_edge_augmentation(G, avail=None, weight=None, partial=False):
     """Finds minimum weight set of edges to connect G.
 
     Equivalent to :func:`k_edge_augmentation` when k=1. Adding the resulting
     edges to G will make it 1-edge-connected. The solution is optimal for both
     weighted and non-weighted variants.
 
@@ -438,15 +438,15 @@
         return weighted_one_edge_augmentation(
             G, avail=avail, weight=weight, partial=partial
         )
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def bridge_augmentation(G, avail=None, weight=None):
     """Finds the a set of edges that bridge connects G.
 
     Equivalent to :func:`k_edge_augmentation` when k=2, and partial=False.
     Adding the resulting edges to G will make it 2-edge-connected.  If no
     constraints are specified the returned set of edges is minimum an optimal,
     otherwise the solution is approximated.
@@ -574,15 +574,15 @@
         # Ignore available edges within the same meta-node
         if mu != mv:
             # Choose the lightest available edge belonging to each meta-edge
             w, u, v = min(choices_wuv)
             yield MetaEdge((mu, mv), (u, v), w)
 
 
-@nx._dispatch
+@nx._dispatchable
 def unconstrained_one_edge_augmentation(G):
     """Finds the smallest set of edges to connect G.
 
     This is a variant of the unweighted MST problem.
     If G is not empty, a feasible solution always exists.
 
     Parameters
@@ -617,15 +617,15 @@
     inverse = defaultdict(list)
     for k, v in C.graph["mapping"].items():
         inverse[v].append(k)
     for mu, mv in meta_aug:
         yield (inverse[mu][0], inverse[mv][0])
 
 
-@nx._dispatch
+@nx._dispatchable
 def weighted_one_edge_augmentation(G, avail, weight=None, partial=False):
     """Finds the minimum weight set of edges to connect G if one exists.
 
     This is a variant of the weighted MST problem.
 
     Parameters
     ----------
@@ -686,15 +686,15 @@
     # Yield the edge that generated the meta-edge
     for mu, mv, d in meta_mst.edges(data=True):
         if "generator" in d:
             edge = d["generator"]
             yield edge
 
 
-@nx._dispatch
+@nx._dispatchable
 def unconstrained_bridge_augmentation(G):
     """Finds an optimal 2-edge-augmentation of G using the fewest edges.
 
     This is an implementation of the algorithm detailed in [1]_.
     The basic idea is to construct a meta-graph of bridge-ccs, connect leaf
     nodes of the trees to connect the entire graph, and finally connect the
     leafs of the tree in dfs-preorder to bridge connect the entire graph.
@@ -841,15 +841,15 @@
         for u, v in it.product(inverse[mu], inverse[mv]):
             if not G2.has_edge(u, v):
                 G2.add_edge(u, v)
                 yield u, v
                 break
 
 
-@nx._dispatch
+@nx._dispatchable
 def weighted_bridge_augmentation(G, avail, weight=None):
     """Finds an approximate min-weight 2-edge-augmentation of G.
 
     This is an implementation of the approximation algorithm detailed in [1]_.
     It chooses a set of edges from avail to add to G that renders it
     2-edge-connected if such a subset exists.  This is done by finding a
     minimum spanning arborescence of a specially constructed metagraph.
@@ -1036,15 +1036,15 @@
     # root the graph by removing all predecessors to `root`.
     rooted.remove_edges_from([(u, root) for u in D.predecessors(root)])
     # Then compute the branching / arborescence.
     A = nx.minimum_spanning_arborescence(rooted)
     return A
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def collapse(G, grouped_nodes):
     """Collapses each group of nodes into a single node.
 
     This is similar to condensation, but works on undirected graphs.
 
     Parameters
     ----------
@@ -1108,15 +1108,15 @@
     # Add a list of members (ie original nodes) to each node (ie scc) in C.
     nx.set_node_attributes(C, name="members", values=members)
     # Add mapping dict as graph attribute
     C.graph["mapping"] = mapping
     return C
 
 
-@nx._dispatch
+@nx._dispatchable
 def complement_edges(G):
     """Returns only the edges in the complement of G
 
     Parameters
     ----------
     G : NetworkX Graph
 
@@ -1154,15 +1154,15 @@
     """wrapper around rng.shuffle for python 2 compatibility reasons"""
     rng.shuffle(input)
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
 @py_random_state(4)
-@nx._dispatch
+@nx._dispatchable
 def greedy_k_edge_augmentation(G, k, avail=None, weight=None, seed=None):
     """Greedy algorithm for finding a k-edge-augmentation
 
     Parameters
     ----------
     G : NetworkX graph
        An undirected graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/edge_kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/edge_kcomponents.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     "k_edge_subgraphs",
     "bridge_components",
     "EdgeComponentAuxGraph",
 ]
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def k_edge_components(G, k):
     """Generates nodes in each maximal k-edge-connected component in G.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -103,15 +103,15 @@
             return bridge_components(G)
         else:
             aux_graph = EdgeComponentAuxGraph.construct(G)
             return aux_graph.k_edge_components(k)
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def k_edge_subgraphs(G, k):
     """Generates nodes in each maximal k-edge-connected subgraph in G.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -192,15 +192,15 @@
     """
     for C in general_k_edge_subgraphs(G, k):
         yield set(C.nodes())
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def bridge_components(G):
     """Finds all bridge-connected components G.
 
     Parameters
     ----------
     G : NetworkX undirected graph
 
@@ -499,36 +499,43 @@
     # Note: remaining connected components may not be k-edge-connected
     if G.is_directed():
         yield from nx.strongly_connected_components(H)
     else:
         yield from nx.connected_components(H)
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def general_k_edge_subgraphs(G, k):
-    """General algorithm to find all maximal k-edge-connected subgraphs in G.
+    """General algorithm to find all maximal k-edge-connected subgraphs in `G`.
 
-    Returns
-    -------
-    k_edge_subgraphs : a generator of nx.Graphs that are k-edge-subgraphs
-        Each k-edge-subgraph is a maximal set of nodes that defines a subgraph
-        of G that is k-edge-connected.
+    Parameters
+    ----------
+    G : nx.Graph
+       Graph in which all maximal k-edge-connected subgraphs will be found.
+
+    k : int
+
+    Yields
+    ------
+    k_edge_subgraphs : Graph instances that are k-edge-subgraphs
+        Each k-edge-subgraph contains a maximal set of nodes that defines a
+        subgraph of `G` that is k-edge-connected.
 
     Notes
     -----
-    Implementation of the basic algorithm from _[1].  The basic idea is to find
+    Implementation of the basic algorithm from [1]_.  The basic idea is to find
     a global minimum cut of the graph. If the cut value is at least k, then the
     graph is a k-edge-connected subgraph and can be added to the results.
     Otherwise, the cut is used to split the graph in two and the procedure is
     applied recursively. If the graph is just a single node, then it is also
     added to the results. At the end, each result is either guaranteed to be
     a single node or a subgraph of G that is k-edge-connected.
 
     This implementation contains optimizations for reducing the number of calls
-    to max-flow, but there are other optimizations in _[1] that could be
+    to max-flow, but there are other optimizations in [1]_ that could be
     implemented.
 
     References
     ----------
     .. [1] Zhou, Liu, et al. (2012) Finding maximal k-edge-connected subgraphs
         from a large graph.  ACM International Conference on Extending Database
         Technology 2012 480-–491.
@@ -543,15 +550,15 @@
     ...     # connect the cliques with high degree but low connectivity
     ...     (50, 13),
     ...     (12, 50, 22),
     ...     (13, 102, 23),
     ...     (14, 101, 24),
     ... ]
     >>> G = nx.Graph(it.chain(*[pairwise(path) for path in paths]))
-    >>> sorted(map(len, k_edge_subgraphs(G, k=3)))
+    >>> sorted(len(k_sg) for k_sg in k_edge_subgraphs(G, k=3))
     [1, 1, 1, 4, 4]
     """
     if k < 1:
         raise ValueError("k cannot be less than 1")
 
     # Node pruning optimization (incorporates early return)
     # find_ccs is either connected_components/strongly_connected_components
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/kcomponents.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 
 default_flow_func = edmonds_karp
 
 __all__ = ["k_components"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def k_components(G, flow_func=None):
     r"""Returns the k-component structure of a graph G.
 
     A `k`-component is a maximal subgraph of a graph G that has, at least,
     node connectivity `k`: we need to remove at least `k` nodes to break it
     into more components. `k`-components have an inherent hierarchical
     structure because they are nested in terms of connectivity: a connected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/kcutsets.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/kcutsets.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 
 default_flow_func = edmonds_karp
 
 
 __all__ = ["all_node_cuts"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def all_node_cuts(G, k=None, flow_func=None):
     r"""Returns all minimum k cutsets of an undirected graph G.
 
     This implementation is based on Kanevsky's algorithm [1]_ for finding all
     minimum-size node cut-sets of an undirected graph G; ie the set (or sets)
     of nodes of cardinality equal to the node connectivity of G. Thus if
     removed, would break G into two or more connected components.
@@ -89,18 +89,19 @@
 
     """
     if not nx.is_connected(G):
         raise nx.NetworkXError("Input graph is disconnected.")
 
     # Address some corner cases first.
     # For complete Graphs
+
     if nx.density(G) == 1:
-        for cut_set in combinations(G, len(G) - 1):
-            yield set(cut_set)
+        yield from ()
         return
+
     # Initialize data structures.
     # Keep track of the cuts already computed so we do not repeat them.
     seen = []
     # Even-Tarjan reduction is what we call auxiliary digraph
     # for node connectivity.
     H = build_auxiliary_node_connectivity(G)
     H_nodes = H.nodes  # for speed
@@ -126,15 +127,15 @@
     if _is_separating_set(G, X):
         seen.append(X)
         yield X
 
     for x in X:
         # step 3: Compute local connectivity flow of x with all other
         # non adjacent nodes in G
-        non_adjacent = set(G) - X - set(G[x])
+        non_adjacent = set(G) - {x} - set(G[x])
         for v in non_adjacent:
             # step 4: compute maximum flow in an Even-Tarjan reduction H of G
             # and step 5: build the associated residual network R
             R = flow_func(H, f"{mapping[x]}B", f"{mapping[v]}A", **kwargs)
             flow_value = R.graph["flow_value"]
 
             if flow_value == k:
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/stoerwagner.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/stoerwagner.py`

 * *Files 0% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 from ...utils import BinaryHeap, arbitrary_element, not_implemented_for
 
 __all__ = ["stoer_wagner"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def stoer_wagner(G, weight="weight", heap=BinaryHeap):
     r"""Returns the weighted minimum edge cut using the Stoer-Wagner algorithm.
 
     Determine the minimum edge cut of a connected graph using the
     Stoer-Wagner algorithm. In weighted cases, all weights must be
     nonnegative.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_connectivity.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_connectivity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_cuts.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_cuts.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_disjoint_paths.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_disjoint_paths.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_edge_augmentation.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_edge_augmentation.py`

 * *Files 2% similar despite different names*

```diff
@@ -71,14 +71,19 @@
 
     G = nx.complete_graph(5)
     assert is_k_edge_connected(G, k=1)
     assert is_k_edge_connected(G, k=2)
     assert is_k_edge_connected(G, k=3)
     assert is_k_edge_connected(G, k=4)
 
+    G = nx.compose(nx.complete_graph([0, 1, 2]), nx.complete_graph([3, 4, 5]))
+    assert not is_k_edge_connected(G, k=1)
+    assert not is_k_edge_connected(G, k=2)
+    assert not is_k_edge_connected(G, k=3)
+
 
 def test_is_k_edge_connected_exceptions():
     pytest.raises(
         nx.NetworkXNotImplemented, is_locally_k_edge_connected, nx.DiGraph(), 1, 2, k=0
     )
     pytest.raises(
         nx.NetworkXNotImplemented,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_edge_kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_edge_kcomponents.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_kcomponents.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_kcomponents.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_kcutsets.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_kcutsets.py`

 * *Files 2% similar despite different names*

```diff
@@ -255,12 +255,19 @@
     assert len(solution) == len(cuts)
     for cut in cuts:
         assert cut in solution
 
 
 def test_complete_graph():
     G = nx.complete_graph(5)
-    solution = [{0, 1, 2, 3}, {0, 1, 2, 4}, {0, 1, 3, 4}, {0, 2, 3, 4}, {1, 2, 3, 4}]
-    cuts = list(nx.all_node_cuts(G))
-    assert len(solution) == len(cuts)
-    for cut in cuts:
-        assert cut in solution
+    assert nx.node_connectivity(G) == 4
+    assert list(nx.all_node_cuts(G)) == []
+
+
+def test_all_node_cuts_simple_case():
+    G = nx.complete_graph(5)
+    G.remove_edges_from([(0, 1), (3, 4)])
+    expected = [{0, 1, 2}, {2, 3, 4}]
+    actual = list(nx.all_node_cuts(G))
+    assert len(actual) == len(expected)
+    for cut in actual:
+        assert cut in expected
```

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/tests/test_stoer_wagner.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/tests/test_stoer_wagner.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/connectivity/utils.py` & `networkx-3.3rc0/networkx/algorithms/connectivity/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Utilities for connectivity package
 """
 import networkx as nx
 
 __all__ = ["build_auxiliary_node_connectivity", "build_auxiliary_edge_connectivity"]
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def build_auxiliary_node_connectivity(G):
     r"""Creates a directed graph D from an undirected graph G to compute flow
     based node connectivity.
 
     For an undirected graph G having `n` nodes and `m` edges we derive a
     directed graph D with `2n` nodes and `2m+n` arcs by replacing each
     original node `v` with two nodes `vA`, `vB` linked by an (internal)
@@ -55,15 +55,15 @@
     H.add_edges_from(edges, capacity=1)
 
     # Store mapping as graph attribute
     H.graph["mapping"] = mapping
     return H
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def build_auxiliary_edge_connectivity(G):
     """Auxiliary digraph for computing flow based edge connectivity
 
     If the input graph is undirected, we replace each edge (`u`,`v`) with
     two reciprocal arcs (`u`, `v`) and (`v`, `u`) and then we set the attribute
     'capacity' for each arc to 1. If the input graph is directed we simply
     add the 'capacity' attribute. Part of algorithm 1 in [1]_ .
```

### Comparing `networkx-3.2rc0/networkx/algorithms/core.py` & `networkx-3.3rc0/networkx/algorithms/triads.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,545 +1,604 @@
-"""
-Find the k-cores of a graph.
+# See https://github.com/networkx/networkx/pull/1474
+# Copyright 2011 Reya Group <http://www.reyagroup.com>
+# Copyright 2011 Alex Levenson <alex@isnotinvain.com>
+# Copyright 2011 Diederik van Liere <diederik.vanliere@rotman.utoronto.ca>
+"""Functions for analyzing triads of a graph."""
 
-The k-core is found by recursively pruning nodes with degrees less than k.
+from collections import defaultdict
+from itertools import combinations, permutations
 
-See the following references for details:
-
-An O(m) Algorithm for Cores Decomposition of Networks
-Vladimir Batagelj and Matjaz Zaversnik, 2003.
-https://arxiv.org/abs/cs.DS/0310049
-
-Generalized Cores
-Vladimir Batagelj and Matjaz Zaversnik, 2002.
-https://arxiv.org/pdf/cs/0202039
-
-For directed graphs a more general notion is that of D-cores which
-looks at (k, l) restrictions on (in, out) degree. The (k, k) D-core
-is the k-core.
-
-D-cores: Measuring Collaboration of Directed Graphs Based on Degeneracy
-Christos Giatsidis, Dimitrios M. Thilikos, Michalis Vazirgiannis, ICDM 2011.
-http://www.graphdegeneracy.org/dcores_ICDM_2011.pdf
-
-Multi-scale structure and topological anomaly detection via a new network \
-statistic: The onion decomposition
-L. Hébert-Dufresne, J. A. Grochow, and A. Allard
-Scientific Reports 6, 31708 (2016)
-http://doi.org/10.1038/srep31708
-
-"""
 import networkx as nx
-from networkx.exception import NetworkXError
-from networkx.utils import not_implemented_for
+from networkx.utils import not_implemented_for, py_random_state
 
 __all__ = [
-    "core_number",
-    "k_core",
-    "k_shell",
-    "k_crust",
-    "k_corona",
-    "k_truss",
-    "onion_layers",
+    "triadic_census",
+    "is_triad",
+    "all_triplets",
+    "all_triads",
+    "triads_by_type",
+    "triad_type",
+    "random_triad",
 ]
 
+#: The integer codes representing each type of triad.
+#:
+#: Triads that are the same up to symmetry have the same code.
+TRICODES = (
+    1,
+    2,
+    2,
+    3,
+    2,
+    4,
+    6,
+    8,
+    2,
+    6,
+    5,
+    7,
+    3,
+    8,
+    7,
+    11,
+    2,
+    6,
+    4,
+    8,
+    5,
+    9,
+    9,
+    13,
+    6,
+    10,
+    9,
+    14,
+    7,
+    14,
+    12,
+    15,
+    2,
+    5,
+    6,
+    7,
+    6,
+    9,
+    10,
+    14,
+    4,
+    9,
+    9,
+    12,
+    8,
+    13,
+    14,
+    15,
+    3,
+    7,
+    8,
+    11,
+    7,
+    12,
+    14,
+    15,
+    8,
+    14,
+    13,
+    15,
+    11,
+    15,
+    15,
+    16,
+)
+
+#: The names of each type of triad. The order of the elements is
+#: important: it corresponds to the tricodes given in :data:`TRICODES`.
+TRIAD_NAMES = (
+    "003",
+    "012",
+    "102",
+    "021D",
+    "021U",
+    "021C",
+    "111D",
+    "111U",
+    "030T",
+    "030C",
+    "201",
+    "120D",
+    "120U",
+    "120C",
+    "210",
+    "300",
+)
+
+
+#: A dictionary mapping triad code to triad name.
+TRICODE_TO_NAME = {i: TRIAD_NAMES[code - 1] for i, code in enumerate(TRICODES)}
+
+
+def _tricode(G, v, u, w):
+    """Returns the integer code of the given triad.
+
+    This is some fancy magic that comes from Batagelj and Mrvar's paper. It
+    treats each edge joining a pair of `v`, `u`, and `w` as a bit in
+    the binary representation of an integer.
 
-@not_implemented_for("multigraph")
-@nx._dispatch
-def core_number(G):
-    """Returns the core number for each vertex.
+    """
+    combos = ((v, u, 1), (u, v, 2), (v, w, 4), (w, v, 8), (u, w, 16), (w, u, 32))
+    return sum(x for u, v, x in combos if v in G[u])
 
-    A k-core is a maximal subgraph that contains nodes of degree k or more.
 
-    The core number of a node is the largest value k of a k-core containing
-    that node.
+@not_implemented_for("undirected")
+@nx._dispatchable
+def triadic_census(G, nodelist=None):
+    """Determines the triadic census of a directed graph.
+
+    The triadic census is a count of how many of the 16 possible types of
+    triads are present in a directed graph. If a list of nodes is passed, then
+    only those triads are taken into account which have elements of nodelist in them.
 
     Parameters
     ----------
-    G : NetworkX graph
-       A graph or directed graph
+    G : digraph
+       A NetworkX DiGraph
+    nodelist : list
+        List of nodes for which you want to calculate triadic census
 
     Returns
     -------
-    core_number : dictionary
-       A dictionary keyed by node to the core number.
+    census : dict
+       Dictionary with triad type as keys and number of occurrences as values.
 
-    Raises
-    ------
-    NetworkXError
-        The k-core is not implemented for graphs with self loops
-        or parallel edges.
+    Examples
+    --------
+    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1), (3, 4), (4, 1), (4, 2)])
+    >>> triadic_census = nx.triadic_census(G)
+    >>> for key, value in triadic_census.items():
+    ...     print(f"{key}: {value}")
+    003: 0
+    012: 0
+    102: 0
+    021D: 0
+    021U: 0
+    021C: 0
+    111D: 0
+    111U: 0
+    030T: 2
+    030C: 2
+    201: 0
+    120D: 0
+    120U: 0
+    120C: 0
+    210: 0
+    300: 0
 
     Notes
     -----
-    Not implemented for graphs with parallel edges or self loops.
-
-    For directed graphs the node degree is defined to be the
-    in-degree + out-degree.
+    This algorithm has complexity $O(m)$ where $m$ is the number of edges in
+    the graph.
 
-    References
-    ----------
-    .. [1] An O(m) Algorithm for Cores Decomposition of Networks
-       Vladimir Batagelj and Matjaz Zaversnik, 2003.
-       https://arxiv.org/abs/cs.DS/0310049
-    """
-    if nx.number_of_selfloops(G) > 0:
-        msg = (
-            "Input graph has self loops which is not permitted; "
-            "Consider using G.remove_edges_from(nx.selfloop_edges(G))."
-        )
-        raise NetworkXError(msg)
-    degrees = dict(G.degree())
-    # Sort nodes by degree.
-    nodes = sorted(degrees, key=degrees.get)
-    bin_boundaries = [0]
-    curr_degree = 0
-    for i, v in enumerate(nodes):
-        if degrees[v] > curr_degree:
-            bin_boundaries.extend([i] * (degrees[v] - curr_degree))
-            curr_degree = degrees[v]
-    node_pos = {v: pos for pos, v in enumerate(nodes)}
-    # The initial guess for the core number of a node is its degree.
-    core = degrees
-    nbrs = {v: list(nx.all_neighbors(G, v)) for v in G}
-    for v in nodes:
-        for u in nbrs[v]:
-            if core[u] > core[v]:
-                nbrs[u].remove(v)
-                pos = node_pos[u]
-                bin_start = bin_boundaries[core[u]]
-                node_pos[u] = bin_start
-                node_pos[nodes[bin_start]] = pos
-                nodes[bin_start], nodes[pos] = nodes[pos], nodes[bin_start]
-                bin_boundaries[core[u]] += 1
-                core[u] -= 1
-    return core
+    For undirected graphs, the triadic census can be computed by first converting
+    the graph into a directed graph using the ``G.to_directed()`` method.
+    After this conversion, only the triad types 003, 102, 201 and 300 will be
+    present in the undirected scenario.
 
+    Raises
+    ------
+    ValueError
+        If `nodelist` contains duplicate nodes or nodes not in `G`.
+        If you want to ignore this you can preprocess with `set(nodelist) & G.nodes`
 
-def _core_subgraph(G, k_filter, k=None, core=None):
-    """Returns the subgraph induced by nodes passing filter `k_filter`.
+    See also
+    --------
+    triad_graph
 
-    Parameters
+    References
     ----------
-    G : NetworkX graph
-       The graph or directed graph to process
-    k_filter : filter function
-       This function filters the nodes chosen. It takes three inputs:
-       A node of G, the filter's cutoff, and the core dict of the graph.
-       The function should return a Boolean value.
-    k : int, optional
-      The order of the core. If not specified use the max core number.
-      This value is used as the cutoff for the filter.
-    core : dict, optional
-      Precomputed core numbers keyed by node for the graph `G`.
-      If not specified, the core numbers will be computed from `G`.
+    .. [1] Vladimir Batagelj and Andrej Mrvar, A subquadratic triad census
+        algorithm for large sparse networks with small maximum degree,
+        University of Ljubljana,
+        http://vlado.fmf.uni-lj.si/pub/networks/doc/triads/triads.pdf
 
     """
-    if core is None:
-        core = core_number(G)
-    if k is None:
-        k = max(core.values())
-    nodes = (v for v in core if k_filter(v, k, core))
-    return G.subgraph(nodes).copy()
-
-
-@nx._dispatch(preserve_all_attrs=True)
-def k_core(G, k=None, core_number=None):
-    """Returns the k-core of G.
-
-    A k-core is a maximal subgraph that contains nodes of degree k or more.
+    nodeset = set(G.nbunch_iter(nodelist))
+    if nodelist is not None and len(nodelist) != len(nodeset):
+        raise ValueError("nodelist includes duplicate nodes or nodes not in G")
+
+    N = len(G)
+    Nnot = N - len(nodeset)  # can signal special counting for subset of nodes
+
+    # create an ordering of nodes with nodeset nodes first
+    m = {n: i for i, n in enumerate(nodeset)}
+    if Nnot:
+        # add non-nodeset nodes later in the ordering
+        not_nodeset = G.nodes - nodeset
+        m.update((n, i + N) for i, n in enumerate(not_nodeset))
+
+    # build all_neighbor dicts for easy counting
+    # After Python 3.8 can leave off these keys(). Speedup also using G._pred
+    # nbrs = {n: G._pred[n].keys() | G._succ[n].keys() for n in G}
+    nbrs = {n: G.pred[n].keys() | G.succ[n].keys() for n in G}
+    dbl_nbrs = {n: G.pred[n].keys() & G.succ[n].keys() for n in G}
+
+    if Nnot:
+        sgl_nbrs = {n: G.pred[n].keys() ^ G.succ[n].keys() for n in not_nodeset}
+        # find number of edges not incident to nodes in nodeset
+        sgl = sum(1 for n in not_nodeset for nbr in sgl_nbrs[n] if nbr not in nodeset)
+        sgl_edges_outside = sgl // 2
+        dbl = sum(1 for n in not_nodeset for nbr in dbl_nbrs[n] if nbr not in nodeset)
+        dbl_edges_outside = dbl // 2
+
+    # Initialize the count for each triad to be zero.
+    census = {name: 0 for name in TRIAD_NAMES}
+    # Main loop over nodes
+    for v in nodeset:
+        vnbrs = nbrs[v]
+        dbl_vnbrs = dbl_nbrs[v]
+        if Nnot:
+            # set up counts of edges attached to v.
+            sgl_unbrs_bdy = sgl_unbrs_out = dbl_unbrs_bdy = dbl_unbrs_out = 0
+        for u in vnbrs:
+            if m[u] <= m[v]:
+                continue
+            unbrs = nbrs[u]
+            neighbors = (vnbrs | unbrs) - {u, v}
+            # Count connected triads.
+            for w in neighbors:
+                if m[u] < m[w] or (m[v] < m[w] < m[u] and v not in nbrs[w]):
+                    code = _tricode(G, v, u, w)
+                    census[TRICODE_TO_NAME[code]] += 1
+
+            # Use a formula for dyadic triads with edge incident to v
+            if u in dbl_vnbrs:
+                census["102"] += N - len(neighbors) - 2
+            else:
+                census["012"] += N - len(neighbors) - 2
+
+            # Count edges attached to v. Subtract later to get triads with v isolated
+            # _out are (u,unbr) for unbrs outside boundary of nodeset
+            # _bdy are (u,unbr) for unbrs on boundary of nodeset (get double counted)
+            if Nnot and u not in nodeset:
+                sgl_unbrs = sgl_nbrs[u]
+                sgl_unbrs_bdy += len(sgl_unbrs & vnbrs - nodeset)
+                sgl_unbrs_out += len(sgl_unbrs - vnbrs - nodeset)
+                dbl_unbrs = dbl_nbrs[u]
+                dbl_unbrs_bdy += len(dbl_unbrs & vnbrs - nodeset)
+                dbl_unbrs_out += len(dbl_unbrs - vnbrs - nodeset)
+        # if nodeset == G.nodes, skip this b/c we will find the edge later.
+        if Nnot:
+            # Count edges outside nodeset not connected with v (v isolated triads)
+            census["012"] += sgl_edges_outside - (sgl_unbrs_out + sgl_unbrs_bdy // 2)
+            census["102"] += dbl_edges_outside - (dbl_unbrs_out + dbl_unbrs_bdy // 2)
+
+    # calculate null triads: "003"
+    # null triads = total number of possible triads - all found triads
+    total_triangles = (N * (N - 1) * (N - 2)) // 6
+    triangles_without_nodeset = (Nnot * (Nnot - 1) * (Nnot - 2)) // 6
+    total_census = total_triangles - triangles_without_nodeset
+    census["003"] = total_census - sum(census.values())
+
+    return census
+
+
+@nx._dispatchable
+def is_triad(G):
+    """Returns True if the graph G is a triad, else False.
 
     Parameters
     ----------
-    G : NetworkX graph
-      A graph or directed graph
-    k : int, optional
-      The order of the core.  If not specified return the main core.
-    core_number : dictionary, optional
-      Precomputed core numbers for the graph G.
+    G : graph
+       A NetworkX Graph
 
     Returns
     -------
-    G : NetworkX graph
-      The k-core subgraph
+    istriad : boolean
+       Whether G is a valid triad
 
-    Raises
-    ------
-    NetworkXError
-      The k-core is not defined for graphs with self loops or parallel edges.
-
-    Notes
-    -----
-    The main core is the core with the largest degree.
-
-    Not implemented for graphs with parallel edges or self loops.
-
-    For directed graphs the node degree is defined to be the
-    in-degree + out-degree.
-
-    Graph, node, and edge attributes are copied to the subgraph.
-
-    See Also
+    Examples
     --------
-    core_number
-
-    References
-    ----------
-    .. [1] An O(m) Algorithm for Cores Decomposition of Networks
-       Vladimir Batagelj and Matjaz Zaversnik,  2003.
-       https://arxiv.org/abs/cs.DS/0310049
+    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1)])
+    >>> nx.is_triad(G)
+    True
+    >>> G.add_edge(0, 1)
+    >>> nx.is_triad(G)
+    False
     """
+    if isinstance(G, nx.Graph):
+        if G.order() == 3 and nx.is_directed(G):
+            if not any((n, n) in G.edges() for n in G.nodes()):
+                return True
+    return False
 
-    def k_filter(v, k, c):
-        return c[v] >= k
 
-    return _core_subgraph(G, k_filter, k, core_number)
+@not_implemented_for("undirected")
+@nx._dispatchable
+def all_triplets(G):
+    """Returns a generator of all possible sets of 3 nodes in a DiGraph.
 
+    .. deprecated:: 3.3
 
-@nx._dispatch(preserve_all_attrs=True)
-def k_shell(G, k=None, core_number=None):
-    """Returns the k-shell of G.
+       all_triplets is deprecated and will be removed in NetworkX version 3.5.
+       Use `itertools.combinations` instead::
 
-    The k-shell is the subgraph induced by nodes with core number k.
-    That is, nodes in the k-core that are not in the (k+1)-core.
+          all_triplets = itertools.combinations(G, 3)
 
     Parameters
     ----------
-    G : NetworkX graph
-      A graph or directed graph.
-    k : int, optional
-      The order of the shell. If not specified return the outer shell.
-    core_number : dictionary, optional
-      Precomputed core numbers for the graph G.
-
+    G : digraph
+       A NetworkX DiGraph
 
     Returns
     -------
-    G : NetworkX graph
-       The k-shell subgraph
-
-    Raises
-    ------
-    NetworkXError
-        The k-shell is not implemented for graphs with self loops
-        or parallel edges.
-
-    Notes
-    -----
-    This is similar to k_corona but in that case only neighbors in the
-    k-core are considered.
-
-    Not implemented for graphs with parallel edges or self loops.
-
-    For directed graphs the node degree is defined to be the
-    in-degree + out-degree.
-
-    Graph, node, and edge attributes are copied to the subgraph.
+    triplets : generator of 3-tuples
+       Generator of tuples of 3 nodes
 
-    See Also
+    Examples
     --------
-    core_number
-    k_corona
+    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 4)])
+    >>> list(nx.all_triplets(G))
+    [(1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4)]
 
-
-    References
-    ----------
-    .. [1] A model of Internet topology using k-shell decomposition
-       Shai Carmi, Shlomo Havlin, Scott Kirkpatrick, Yuval Shavitt,
-       and Eran Shir, PNAS  July 3, 2007   vol. 104  no. 27  11150-11154
-       http://www.pnas.org/content/104/27/11150.full
     """
+    import warnings
 
-    def k_filter(v, k, c):
-        return c[v] == k
-
-    return _core_subgraph(G, k_filter, k, core_number)
-
-
-@nx._dispatch(preserve_all_attrs=True)
-def k_crust(G, k=None, core_number=None):
-    """Returns the k-crust of G.
-
-    The k-crust is the graph G with the edges of the k-core removed
-    and isolated nodes found after the removal of edges are also removed.
+    warnings.warn(
+        (
+            "\n\nall_triplets is deprecated and will be rmoved in v3.5.\n"
+            "Use `itertools.combinations(G, 3)` instead."
+        ),
+        category=DeprecationWarning,
+        stacklevel=4,
+    )
+    triplets = combinations(G.nodes(), 3)
+    return triplets
+
+
+@not_implemented_for("undirected")
+@nx._dispatchable(returns_graph=True)
+def all_triads(G):
+    """A generator of all possible triads in G.
 
     Parameters
     ----------
-    G : NetworkX graph
-       A graph or directed graph.
-    k : int, optional
-      The order of the shell.  If not specified return the main crust.
-    core_number : dictionary, optional
-      Precomputed core numbers for the graph G.
+    G : digraph
+       A NetworkX DiGraph
 
     Returns
     -------
-    G : NetworkX graph
-       The k-crust subgraph
-
-    Raises
-    ------
-    NetworkXError
-        The k-crust is not implemented for graphs with self loops
-        or parallel edges.
-
-    Notes
-    -----
-    This definition of k-crust is different than the definition in [1]_.
-    The k-crust in [1]_ is equivalent to the k+1 crust of this algorithm.
-
-    Not implemented for graphs with parallel edges or self loops.
+    all_triads : generator of DiGraphs
+       Generator of triads (order-3 DiGraphs)
 
-    For directed graphs the node degree is defined to be the
-    in-degree + out-degree.
-
-    Graph, node, and edge attributes are copied to the subgraph.
-
-    See Also
+    Examples
     --------
-    core_number
+    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1), (3, 4), (4, 1), (4, 2)])
+    >>> for triad in nx.all_triads(G):
+    ...     print(triad.edges)
+    [(1, 2), (2, 3), (3, 1)]
+    [(1, 2), (4, 1), (4, 2)]
+    [(3, 1), (3, 4), (4, 1)]
+    [(2, 3), (3, 4), (4, 2)]
 
-    References
-    ----------
-    .. [1] A model of Internet topology using k-shell decomposition
-       Shai Carmi, Shlomo Havlin, Scott Kirkpatrick, Yuval Shavitt,
-       and Eran Shir, PNAS  July 3, 2007   vol. 104  no. 27  11150-11154
-       http://www.pnas.org/content/104/27/11150.full
     """
-    # Default for k is one less than in _core_subgraph, so just inline.
-    #    Filter is c[v] <= k
-    if core_number is None:
-        core_number = nx.core_number(G)
-    if k is None:
-        k = max(core_number.values()) - 1
-    nodes = (v for v in core_number if core_number[v] <= k)
-    return G.subgraph(nodes).copy()
-
-
-@nx._dispatch(preserve_all_attrs=True)
-def k_corona(G, k, core_number=None):
-    """Returns the k-corona of G.
+    triplets = combinations(G.nodes(), 3)
+    for triplet in triplets:
+        yield G.subgraph(triplet).copy()
+
+
+@not_implemented_for("undirected")
+@nx._dispatchable
+def triads_by_type(G):
+    """Returns a list of all triads for each triad type in a directed graph.
+    There are exactly 16 different types of triads possible. Suppose 1, 2, 3 are three
+    nodes, they will be classified as a particular triad type if their connections
+    are as follows:
+
+    - 003: 1, 2, 3
+    - 012: 1 -> 2, 3
+    - 102: 1 <-> 2, 3
+    - 021D: 1 <- 2 -> 3
+    - 021U: 1 -> 2 <- 3
+    - 021C: 1 -> 2 -> 3
+    - 111D: 1 <-> 2 <- 3
+    - 111U: 1 <-> 2 -> 3
+    - 030T: 1 -> 2 -> 3, 1 -> 3
+    - 030C: 1 <- 2 <- 3, 1 -> 3
+    - 201: 1 <-> 2 <-> 3
+    - 120D: 1 <- 2 -> 3, 1 <-> 3
+    - 120U: 1 -> 2 <- 3, 1 <-> 3
+    - 120C: 1 -> 2 -> 3, 1 <-> 3
+    - 210: 1 -> 2 <-> 3, 1 <-> 3
+    - 300: 1 <-> 2 <-> 3, 1 <-> 3
 
-    The k-corona is the subgraph of nodes in the k-core which have
-    exactly k neighbours in the k-core.
+    Refer to the :doc:`example gallery </auto_examples/graph/plot_triad_types>`
+    for visual examples of the triad types.
 
     Parameters
     ----------
-    G : NetworkX graph
-       A graph or directed graph
-    k : int
-       The order of the corona.
-    core_number : dictionary, optional
-       Precomputed core numbers for the graph G.
+    G : digraph
+       A NetworkX DiGraph
 
     Returns
     -------
-    G : NetworkX graph
-       The k-corona subgraph
-
-    Raises
-    ------
-    NetworkXError
-        The k-corona is not defined for graphs with self loops or
-        parallel edges.
-
-    Notes
-    -----
-    Not implemented for graphs with parallel edges or self loops.
-
-    For directed graphs the node degree is defined to be the
-    in-degree + out-degree.
+    tri_by_type : dict
+       Dictionary with triad types as keys and lists of triads as values.
 
-    Graph, node, and edge attributes are copied to the subgraph.
-
-    See Also
+    Examples
     --------
-    core_number
+    >>> G = nx.DiGraph([(1, 2), (1, 3), (2, 3), (3, 1), (5, 6), (5, 4), (6, 7)])
+    >>> dict = nx.triads_by_type(G)
+    >>> dict["120C"][0].edges()
+    OutEdgeView([(1, 2), (1, 3), (2, 3), (3, 1)])
+    >>> dict["012"][0].edges()
+    OutEdgeView([(1, 2)])
 
     References
     ----------
-    .. [1]  k -core (bootstrap) percolation on complex networks:
-       Critical phenomena and nonlocal effects,
-       A. V. Goltsev, S. N. Dorogovtsev, and J. F. F. Mendes,
-       Phys. Rev. E 73, 056101 (2006)
-       http://link.aps.org/doi/10.1103/PhysRevE.73.056101
+    .. [1] Snijders, T. (2012). "Transitivity and triads." University of
+        Oxford.
+        https://web.archive.org/web/20170830032057/http://www.stats.ox.ac.uk/~snijders/Trans_Triads_ha.pdf
     """
-
-    def func(v, k, c):
-        return c[v] == k and k == sum(1 for w in G[v] if c[w] >= k)
-
-    return _core_subgraph(G, func, k, core_number)
+    # num_triads = o * (o - 1) * (o - 2) // 6
+    # if num_triads > TRIAD_LIMIT: print(WARNING)
+    all_tri = all_triads(G)
+    tri_by_type = defaultdict(list)
+    for triad in all_tri:
+        name = triad_type(triad)
+        tri_by_type[name].append(triad)
+    return tri_by_type
 
 
-@not_implemented_for("directed")
-@not_implemented_for("multigraph")
-@nx._dispatch(preserve_all_attrs=True)
-def k_truss(G, k):
-    """Returns the k-truss of `G`.
-
-    The k-truss is the maximal induced subgraph of `G` which contains at least
-    three vertices where every edge is incident to at least `k-2` triangles.
+@not_implemented_for("undirected")
+@nx._dispatchable
+def triad_type(G):
+    """Returns the sociological triad type for a triad.
 
     Parameters
     ----------
-    G : NetworkX graph
-      An undirected graph
-    k : int
-      The order of the truss
+    G : digraph
+       A NetworkX DiGraph with 3 nodes
 
     Returns
     -------
-    H : NetworkX graph
-      The k-truss subgraph
-
-    Raises
-    ------
-    NetworkXError
+    triad_type : str
+       A string identifying the triad type
 
-      The k-truss is not defined for graphs with self loops, directed graphs
-      and multigraphs.
+    Examples
+    --------
+    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1)])
+    >>> nx.triad_type(G)
+    '030C'
+    >>> G.add_edge(1, 3)
+    >>> nx.triad_type(G)
+    '120C'
 
     Notes
     -----
-    A k-clique is a (k-2)-truss and a k-truss is a (k+1)-core.
-
-    Not implemented for digraphs or graphs with parallel edges or self loops.
-
-    Graph, node, and edge attributes are copied to the subgraph.
-
-    K-trusses were originally defined in [2] which states that the k-truss
-    is the maximal induced subgraph where each edge belongs to at least
-    `k-2` triangles. A more recent paper, [1], uses a slightly different
-    definition requiring that each edge belong to at least `k` triangles.
-    This implementation uses the original definition of `k-2` triangles.
+    There can be 6 unique edges in a triad (order-3 DiGraph) (so 2^^6=64 unique
+    triads given 3 nodes). These 64 triads each display exactly 1 of 16
+    topologies of triads (topologies can be permuted). These topologies are
+    identified by the following notation:
+
+    {m}{a}{n}{type} (for example: 111D, 210, 102)
+
+    Here:
+
+    {m}     = number of mutual ties (takes 0, 1, 2, 3); a mutual tie is (0,1)
+              AND (1,0)
+    {a}     = number of asymmetric ties (takes 0, 1, 2, 3); an asymmetric tie
+              is (0,1) BUT NOT (1,0) or vice versa
+    {n}     = number of null ties (takes 0, 1, 2, 3); a null tie is NEITHER
+              (0,1) NOR (1,0)
+    {type}  = a letter (takes U, D, C, T) corresponding to up, down, cyclical
+              and transitive. This is only used for topologies that can have
+              more than one form (eg: 021D and 021U).
 
     References
     ----------
-    .. [1] Bounds and Algorithms for k-truss. Paul Burkhardt, Vance Faber,
-       David G. Harris, 2018. https://arxiv.org/abs/1806.05523v2
-    .. [2] Trusses: Cohesive Subgraphs for Social Network Analysis. Jonathan
-       Cohen, 2005.
+    .. [1] Snijders, T. (2012). "Transitivity and triads." University of
+        Oxford.
+        https://web.archive.org/web/20170830032057/http://www.stats.ox.ac.uk/~snijders/Trans_Triads_ha.pdf
     """
-    if nx.number_of_selfloops(G) > 0:
-        msg = (
-            "Input graph has self loops which is not permitted; "
-            "Consider using G.remove_edges_from(nx.selfloop_edges(G))."
-        )
-        raise NetworkXError(msg)
+    if not is_triad(G):
+        raise nx.NetworkXAlgorithmError("G is not a triad (order-3 DiGraph)")
+    num_edges = len(G.edges())
+    if num_edges == 0:
+        return "003"
+    elif num_edges == 1:
+        return "012"
+    elif num_edges == 2:
+        e1, e2 = G.edges()
+        if set(e1) == set(e2):
+            return "102"
+        elif e1[0] == e2[0]:
+            return "021D"
+        elif e1[1] == e2[1]:
+            return "021U"
+        elif e1[1] == e2[0] or e2[1] == e1[0]:
+            return "021C"
+    elif num_edges == 3:
+        for e1, e2, e3 in permutations(G.edges(), 3):
+            if set(e1) == set(e2):
+                if e3[0] in e1:
+                    return "111U"
+                # e3[1] in e1:
+                return "111D"
+            elif set(e1).symmetric_difference(set(e2)) == set(e3):
+                if {e1[0], e2[0], e3[0]} == {e1[0], e2[0], e3[0]} == set(G.nodes()):
+                    return "030C"
+                # e3 == (e1[0], e2[1]) and e2 == (e1[1], e3[1]):
+                return "030T"
+    elif num_edges == 4:
+        for e1, e2, e3, e4 in permutations(G.edges(), 4):
+            if set(e1) == set(e2):
+                # identify pair of symmetric edges (which necessarily exists)
+                if set(e3) == set(e4):
+                    return "201"
+                if {e3[0]} == {e4[0]} == set(e3).intersection(set(e4)):
+                    return "120D"
+                if {e3[1]} == {e4[1]} == set(e3).intersection(set(e4)):
+                    return "120U"
+                if e3[1] == e4[0]:
+                    return "120C"
+    elif num_edges == 5:
+        return "210"
+    elif num_edges == 6:
+        return "300"
+
+
+@not_implemented_for("undirected")
+@py_random_state(1)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
+def random_triad(G, seed=None):
+    """Returns a random triad from a directed graph.
+
+    .. deprecated:: 3.3
 
-    H = G.copy()
+       random_triad is deprecated and will be removed in version 3.5.
+       Use random sampling directly instead::
 
-    n_dropped = 1
-    while n_dropped > 0:
-        n_dropped = 0
-        to_drop = []
-        seen = set()
-        for u in H:
-            nbrs_u = set(H[u])
-            seen.add(u)
-            new_nbrs = [v for v in nbrs_u if v not in seen]
-            for v in new_nbrs:
-                if len(nbrs_u & set(H[v])) < (k - 2):
-                    to_drop.append((u, v))
-        H.remove_edges_from(to_drop)
-        n_dropped = len(to_drop)
-        H.remove_nodes_from(list(nx.isolates(H)))
-
-    return H
-
-
-@not_implemented_for("multigraph")
-@not_implemented_for("directed")
-@nx._dispatch
-def onion_layers(G):
-    """Returns the layer of each vertex in an onion decomposition of the graph.
-
-    The onion decomposition refines the k-core decomposition by providing
-    information on the internal organization of each k-shell. It is usually
-    used alongside the `core numbers`.
+          G.subgraph(random.sample(list(G), 3))
 
     Parameters
     ----------
-    G : NetworkX graph
-        A simple graph without self loops or parallel edges
+    G : digraph
+       A NetworkX DiGraph
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
     Returns
     -------
-    od_layers : dictionary
-        A dictionary keyed by vertex to the onion layer. The layers are
-        contiguous integers starting at 1.
+    G2 : subgraph
+       A randomly selected triad (order-3 NetworkX DiGraph)
 
     Raises
     ------
     NetworkXError
-        The onion decomposition is not implemented for graphs with self loops
-        or parallel edges or for directed graphs.
-
-    Notes
-    -----
-    Not implemented for graphs with parallel edges or self loops.
-
-    Not implemented for directed graphs.
+        If the input Graph has less than 3 nodes.
 
-    See Also
+    Examples
     --------
-    core_number
+    >>> G = nx.DiGraph([(1, 2), (1, 3), (2, 3), (3, 1), (5, 6), (5, 4), (6, 7)])
+    >>> triad = nx.random_triad(G, seed=1)
+    >>> triad.edges
+    OutEdgeView([(1, 2)])
 
-    References
-    ----------
-    .. [1] Multi-scale structure and topological anomaly detection via a new
-       network statistic: The onion decomposition
-       L. Hébert-Dufresne, J. A. Grochow, and A. Allard
-       Scientific Reports 6, 31708 (2016)
-       http://doi.org/10.1038/srep31708
-    .. [2] Percolation and the effective structure of complex networks
-       A. Allard and L. Hébert-Dufresne
-       Physical Review X 9, 011023 (2019)
-       http://doi.org/10.1103/PhysRevX.9.011023
     """
-    if nx.number_of_selfloops(G) > 0:
-        msg = (
-            "Input graph contains self loops which is not permitted; "
-            "Consider using G.remove_edges_from(nx.selfloop_edges(G))."
+    import warnings
+
+    warnings.warn(
+        (
+            "\n\nrandom_triad is deprecated and will be removed in NetworkX v3.5.\n"
+            "Use random.sample instead, e.g.::\n\n"
+            "\tG.subgraph(random.sample(list(G), 3))\n"
+        ),
+        category=DeprecationWarning,
+        stacklevel=5,
+    )
+    if len(G) < 3:
+        raise nx.NetworkXError(
+            f"G needs at least 3 nodes to form a triad; (it has {len(G)} nodes)"
         )
-        raise NetworkXError(msg)
-    # Dictionaries to register the k-core/onion decompositions.
-    od_layers = {}
-    # Adjacency list
-    neighbors = {v: list(nx.all_neighbors(G, v)) for v in G}
-    # Effective degree of nodes.
-    degrees = dict(G.degree())
-    # Performs the onion decomposition.
-    current_core = 1
-    current_layer = 1
-    # Sets vertices of degree 0 to layer 1, if any.
-    isolated_nodes = list(nx.isolates(G))
-    if len(isolated_nodes) > 0:
-        for v in isolated_nodes:
-            od_layers[v] = current_layer
-            degrees.pop(v)
-        current_layer = 2
-    # Finds the layer for the remaining nodes.
-    while len(degrees) > 0:
-        # Sets the order for looking at nodes.
-        nodes = sorted(degrees, key=degrees.get)
-        # Sets properly the current core.
-        min_degree = degrees[nodes[0]]
-        if min_degree > current_core:
-            current_core = min_degree
-        # Identifies vertices in the current layer.
-        this_layer = []
-        for n in nodes:
-            if degrees[n] > current_core:
-                break
-            this_layer.append(n)
-        # Identifies the core/layer of the vertices in the current layer.
-        for v in this_layer:
-            od_layers[v] = current_layer
-            for n in neighbors[v]:
-                neighbors[n].remove(v)
-                degrees[n] = degrees[n] - 1
-            degrees.pop(v)
-        # Updates the layer count.
-        current_layer = current_layer + 1
-    # Returns the dictionaries containing the onion layer of each vertices.
-    return od_layers
+    nodes = seed.sample(list(G.nodes()), 3)
+    G2 = G.subgraph(nodes)
+    return G2
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `networkx-3.2rc0/networkx/algorithms/covering.py` & `networkx-3.3rc0/networkx/algorithms/covering.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from networkx.utils import arbitrary_element, not_implemented_for
 
 __all__ = ["min_edge_cover", "is_edge_cover"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def min_edge_cover(G, matching_algorithm=None):
     """Returns the min cardinality edge cover of the graph as a set of edges.
 
     A smallest edge cover can be found in polynomial time by finding
     a maximum matching and extending it greedily so that all nodes
     are covered. This function follows that process. A maximum matching
     algorithm can be specified for the first step of the algorithm.
@@ -72,15 +72,15 @@
     :func:`~networkx.algorithms.bipartite.matching.hopcraft_karp_matching`
     """
     if len(G) == 0:
         return set()
     if nx.number_of_isolates(G) > 0:
         # ``min_cover`` does not exist as there is an isolated node
         raise nx.NetworkXException(
-            "Graph has a node with no edge incident on it, " "so no edge cover exists."
+            "Graph has a node with no edge incident on it, so no edge cover exists."
         )
     if matching_algorithm is None:
         matching_algorithm = partial(nx.max_weight_matching, maxcardinality=True)
     maximum_matching = matching_algorithm(G)
     # ``min_cover`` is superset of ``maximum_matching``
     try:
         # bipartite matching algs return dict so convert if needed
@@ -102,15 +102,15 @@
         min_cover.add((u, v))
         if bipartite_cover:
             min_cover.add((v, u))
     return min_cover
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def is_edge_cover(G, cover):
     """Decides whether a set of edges is a valid edge cover of the graph.
 
     Given a set of edges, whether it is an edge covering can
     be decided if we just check whether all nodes of the graph
     has an edge from the set, incident on it.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/cuts.py` & `networkx-3.3rc0/networkx/algorithms/cuts.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     "volume",
 ]
 
 
 # TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def cut_size(G, S, T=None, weight=None):
     """Returns the size of the cut between two sets of nodes.
 
     A *cut* is a partition of the nodes of a graph into two sets. The
     *cut size* is the sum of the weights of the edges "between" the two
     sets of nodes.
 
@@ -80,15 +80,15 @@
     """
     edges = nx.edge_boundary(G, S, T, data=weight, default=1)
     if G.is_directed():
         edges = chain(edges, nx.edge_boundary(G, T, S, data=weight, default=1))
     return sum(weight for u, v, weight in edges)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def volume(G, S, weight=None):
     """Returns the volume of a set of nodes.
 
     The *volume* of a set *S* is the sum of the (out-)degrees of nodes
     in *S* (taking into account parallel edges in multigraphs). [1]
 
     Parameters
@@ -123,15 +123,15 @@
            <https://www.cs.purdue.edu/homes/dgleich/publications/Gleich%202005%20-%20hierarchical%20directed%20spectral.pdf>
 
     """
     degree = G.out_degree if G.is_directed() else G.degree
     return sum(d for v, d in degree(S, weight=weight))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def normalized_cut_size(G, S, T=None, weight=None):
     """Returns the normalized size of the cut between two sets of nodes.
 
     The *normalized cut size* is the cut size times the sum of the
     reciprocal sizes of the volumes of the two sets. [1]
 
     Parameters
@@ -176,15 +176,15 @@
         T = set(G) - set(S)
     num_cut_edges = cut_size(G, S, T=T, weight=weight)
     volume_S = volume(G, S, weight=weight)
     volume_T = volume(G, T, weight=weight)
     return num_cut_edges * ((1 / volume_S) + (1 / volume_T))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def conductance(G, S, T=None, weight=None):
     """Returns the conductance of two sets of nodes.
 
     The *conductance* is the quotient of the cut size and the smaller of
     the volumes of the two sets. [1]
 
     Parameters
@@ -224,15 +224,15 @@
         T = set(G) - set(S)
     num_cut_edges = cut_size(G, S, T, weight=weight)
     volume_S = volume(G, S, weight=weight)
     volume_T = volume(G, T, weight=weight)
     return num_cut_edges / min(volume_S, volume_T)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def edge_expansion(G, S, T=None, weight=None):
     """Returns the edge expansion between two node sets.
 
     The *edge expansion* is the quotient of the cut size and the smaller
     of the cardinalities of the two sets. [1]
 
     Parameters
@@ -271,15 +271,15 @@
     """
     if T is None:
         T = set(G) - set(S)
     num_cut_edges = cut_size(G, S, T=T, weight=weight)
     return num_cut_edges / min(len(S), len(T))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def mixing_expansion(G, S, T=None, weight=None):
     """Returns the mixing expansion between two node sets.
 
     The *mixing expansion* is the quotient of the cut size and twice the
     number of edges in the graph. [1]
 
     Parameters
@@ -319,15 +319,15 @@
     num_cut_edges = cut_size(G, S, T=T, weight=weight)
     num_total_edges = G.number_of_edges()
     return num_cut_edges / (2 * num_total_edges)
 
 
 # TODO What is the generalization to two arguments, S and T? Does the
 # denominator become `min(len(S), len(T))`?
-@nx._dispatch
+@nx._dispatchable
 def node_expansion(G, S):
     """Returns the node expansion of the set `S`.
 
     The *node expansion* is the quotient of the size of the node
     boundary of *S* and the cardinality of *S*. [1]
 
     Parameters
@@ -359,15 +359,15 @@
     """
     neighborhood = set(chain.from_iterable(G.neighbors(v) for v in S))
     return len(neighborhood) / len(S)
 
 
 # TODO What is the generalization to two arguments, S and T? Does the
 # denominator become `min(len(S), len(T))`?
-@nx._dispatch
+@nx._dispatchable
 def boundary_expansion(G, S):
     """Returns the boundary expansion of the set `S`.
 
     The *boundary expansion* is the quotient of the size
     of the node boundary and the cardinality of *S*. [1]
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/cycles.py` & `networkx-3.3rc0/networkx/algorithms/cycles.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
     "chordless_cycles",
     "girth",
 ]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def cycle_basis(G, root=None):
     """Returns a list of cycles which form a basis for cycles of G.
 
     A basis for cycles of a network is a minimal collection of
     cycles such that any cycle in the network can be written
     as a sum of cycles in the basis.  Here summation of cycles
     is defined as "exclusive or" of the edges. Cycle bases are
@@ -62,14 +62,15 @@
     ----------
     .. [1] Paton, K. An algorithm for finding a fundamental set of
        cycles of a graph. Comm. ACM 12, 9 (Sept 1969), 514-518.
 
     See Also
     --------
     simple_cycles
+    minimum_cycle_basis
     """
     gnodes = dict.fromkeys(G)  # set-like object that maintains node order
     cycles = []
     while gnodes:  # loop over connected components
         if root is None:
             root = gnodes.popitem()[0]
         stack = [root]
@@ -97,15 +98,15 @@
                     used[nbr].add(z)
         for node in pred:
             gnodes.pop(node, None)
         root = None
     return cycles
 
 
-@nx._dispatch
+@nx._dispatchable
 def simple_cycles(G, length_bound=None):
     """Find simple cycles (elementary circuits) of a graph.
 
     A `simple cycle`, or `elementary circuit`, is a closed path where
     no node appears twice.  In a directed graph, two simple cycles are distinct
     if they are not cyclic permutations of each other.  In an undirected graph,
     two simple cycles are distinct if they are not cyclic permutations of each
@@ -470,15 +471,15 @@
                         lock[u] = length_bound - bl + 1
                         relax_stack.extend((bl + 1, w) for w in B[u].difference(path))
             else:
                 for w in G[v]:
                     B[w].add(v)
 
 
-@nx._dispatch
+@nx._dispatchable
 def chordless_cycles(G, length_bound=None):
     """Find simple chordless cycles of a graph.
 
     A `simple cycle` is a closed path where no node appears twice.  In a simple
     cycle, a `chord` is an additional edge between two nodes in the cycle.  A
     `chordless cycle` is a simple cycle without chords.  Said differently, a
     chordless cycle is a cycle C in a graph G where the number of edges in the
@@ -759,15 +760,15 @@
         else:
             stack.pop()
             for v in B[path.pop()]:
                 blocked[v] -= 1
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def recursive_simple_cycles(G):
     """Find simple cycles (elementary circuits) of a directed graph.
 
     A `simple cycle`, or `elementary circuit`, is a closed path where
     no node appears twice. Two elementary circuits are distinct if they
     are not cyclic permutations of each other.
 
@@ -869,15 +870,15 @@
             for node in component:
                 blocked[node] = False
                 B[node][:] = []
             dummy = circuit(startnode, startnode, component)
     return result
 
 
-@nx._dispatch
+@nx._dispatchable
 def find_cycle(G, source=None, orientation=None):
     """Returns a cycle found via depth-first traversal.
 
     The cycle is a list of edges indicating the cyclic path.
     Orientation of directed edges is controlled by `orientation`.
 
     Parameters
@@ -1031,15 +1032,15 @@
             break
 
     return cycle[i:]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def minimum_cycle_basis(G, weight=None):
     """Returns a minimum weight cycle basis for G
 
     Minimum weight means a cycle basis for which the total weight
     (length for unweighted graphs) of all the cycles is minimum.
 
     Parameters
@@ -1161,15 +1162,15 @@
             edgeset.remove(e[::-1])
 
     return min_edgelist
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def girth(G):
     """Returns the girth of the graph.
 
     The girth of a graph is the length of its shortest cycle, or infinity if
     the graph is acyclic. The algorithm follows the description given on the
     Wikipedia page [1]_, and runs in time O(mn) on a graph with m edges and n
     nodes.
@@ -1198,15 +1199,15 @@
     >>> nx.girth(nx.pappus_graph())
     6
     >>> nx.girth(nx.path_graph(5))
     inf
 
     References
     ----------
-    .. [1] https://en.wikipedia.org/wiki/Girth_(graph_theory)
+    .. [1] `Wikipedia: Girth <https://en.wikipedia.org/wiki/Girth_(graph_theory)>`_
 
     """
     girth = depth_limit = inf
     tree_edge = nx.algorithms.traversal.breadth_first_search.TREE_EDGE
     level_edge = nx.algorithms.traversal.breadth_first_search.LEVEL_EDGE
     for n in G:
         # run a BFS from source n, keeping track of distances; since we want
```

### Comparing `networkx-3.2rc0/networkx/algorithms/d_separation.py` & `networkx-3.3rc0/networkx/generators/line.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,457 +1,499 @@
-"""
-Algorithm for testing d-separation in DAGs.
+"""Functions for generating line graphs."""
+from collections import defaultdict
+from functools import partial
+from itertools import combinations
 
-*d-separation* is a test for conditional independence in probability
-distributions that can be factorized using DAGs.  It is a purely
-graphical test that uses the underlying graph and makes no reference
-to the actual distribution parameters.  See [1]_ for a formal
-definition.
-
-The implementation is based on the conceptually simple linear time
-algorithm presented in [2]_.  Refer to [3]_, [4]_ for a couple of
-alternative algorithms.
-
-Here, we provide a brief overview of d-separation and related concepts that
-are relevant for understanding it:
-
-Blocking paths
---------------
-
-Before we overview, we introduce the following terminology to describe paths:
-
-- "open" path: A path between two nodes that can be traversed
-- "blocked" path: A path between two nodes that cannot be traversed
-
-A **collider** is a triplet of nodes along a path that is like the following:
-``... u -> c <- v ...``), where 'c' is a common successor of ``u`` and ``v``. A path
-through a collider is considered "blocked". When
-a node that is a collider, or a descendant of a collider is included in
-the d-separating set, then the path through that collider node is "open". If the
-path through the collider node is open, then we will call this node an open collider.
-
-The d-separation set blocks the paths between ``u`` and ``v``. If you include colliders,
-or their descendant nodes in the d-separation set, then those colliders will open up,
-enabling a path to be traversed if it is not blocked some other way.
-
-Illustration of D-separation with examples
-------------------------------------------
-
-For a pair of two nodes, ``u`` and ``v``, all paths are considered open if
-there is a path between ``u`` and ``v`` that is not blocked. That means, there is an open
-path between ``u`` and ``v`` that does not encounter a collider, or a variable in the
-d-separating set.
-
-For example, if the d-separating set is the empty set, then the following paths are
-unblocked between ``u`` and ``v``:
-
-- u <- z -> v
-- u -> w -> ... -> z -> v
-
-If for example, 'z' is in the d-separating set, then 'z' blocks those paths
-between ``u`` and ``v``.
-
-Colliders block a path by default if they and their descendants are not included
-in the d-separating set. An example of a path that is blocked when the d-separating
-set is empty is:
-
-- u -> w -> ... -> z <- v
-
-because 'z' is a collider in this path and 'z' is not in the d-separating set. However,
-if 'z' or a descendant of 'z' is included in the d-separating set, then the path through
-the collider at 'z' (... -> z <- ...) is now "open". 
-
-D-separation is concerned with blocking all paths between u and v. Therefore, a
-d-separating set between ``u`` and ``v`` is one where all paths are blocked.
-
-D-separation and its applications in probability
-------------------------------------------------
-
-D-separation is commonly used in probabilistic graphical models. D-separation
-connects the idea of probabilistic "dependence" with separation in a graph. If
-one assumes the causal Markov condition [5]_, then d-separation implies conditional
-independence in probability distributions.
-
-Examples
---------
-
->>>
->>> # HMM graph with five states and observation nodes
-... g = nx.DiGraph()
->>> g.add_edges_from(
-...     [
-...         ("S1", "S2"),
-...         ("S2", "S3"),
-...         ("S3", "S4"),
-...         ("S4", "S5"),
-...         ("S1", "O1"),
-...         ("S2", "O2"),
-...         ("S3", "O3"),
-...         ("S4", "O4"),
-...         ("S5", "O5"),
-...     ]
-... )
->>>
->>> # states/obs before 'S3' are d-separated from states/obs after 'S3'
-... nx.d_separated(g, {"S1", "S2", "O1", "O2"}, {"S4", "S5", "O4", "O5"}, {"S3"})
-True
-
-
-References
-----------
-
-.. [1] Pearl, J.  (2009).  Causality.  Cambridge: Cambridge University Press.
-
-.. [2] Darwiche, A.  (2009).  Modeling and reasoning with Bayesian networks. 
-   Cambridge: Cambridge University Press.
-
-.. [3] Shachter, R.  D.  (1998).
-   Bayes-ball: rational pastime (for determining irrelevance and requisite
-   information in belief networks and influence diagrams).
-   In , Proceedings of the Fourteenth Conference on Uncertainty in Artificial
-   Intelligence (pp.  480–487).
-   San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
-
-.. [4] Koller, D., & Friedman, N. (2009).
-   Probabilistic graphical models: principles and techniques. The MIT Press.
+import networkx as nx
+from networkx.utils import arbitrary_element
+from networkx.utils.decorators import not_implemented_for
 
-.. [5] https://en.wikipedia.org/wiki/Causal_Markov_condition
+__all__ = ["line_graph", "inverse_line_graph"]
 
-"""
 
-from collections import deque
+@nx._dispatchable(returns_graph=True)
+def line_graph(G, create_using=None):
+    r"""Returns the line graph of the graph or digraph `G`.
 
-import networkx as nx
-from networkx.utils import UnionFind, not_implemented_for
+    The line graph of a graph `G` has a node for each edge in `G` and an
+    edge joining those nodes if the two edges in `G` share a common node. For
+    directed graphs, nodes are adjacent exactly when the edges they represent
+    form a directed path of length two.
 
-__all__ = ["d_separated", "minimal_d_separator", "is_minimal_d_separator"]
+    The nodes of the line graph are 2-tuples of nodes in the original graph (or
+    3-tuples for multigraphs, with the key of the edge as the third element).
 
-
-@not_implemented_for("undirected")
-@nx._dispatch
-def d_separated(G, x, y, z):
-    """
-    Return whether node sets ``x`` and ``y`` are d-separated by ``z``.
+    For information about self-loops and more discussion, see the **Notes**
+    section below.
 
     Parameters
     ----------
     G : graph
-        A NetworkX DAG.
-
-    x : set
-        First set of nodes in ``G``.
-
-    y : set
-        Second set of nodes in ``G``.
-
-    z : set
-        Set of conditioning nodes in ``G``. Can be empty set.
+        A NetworkX Graph, DiGraph, MultiGraph, or MultiDigraph.
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+       Graph type to create. If graph instance, then cleared before populated.
 
     Returns
     -------
-    b : bool
-        A boolean that is true if ``x`` is d-separated from ``y`` given ``z`` in ``G``.
+    L : graph
+        The line graph of G.
 
-    Raises
-    ------
-    NetworkXError
-        The *d-separation* test is commonly used with directed
-        graphical models which are acyclic.  Accordingly, the algorithm
-        raises a :exc:`NetworkXError` if the input graph is not a DAG.
-
-    NodeNotFound
-        If any of the input nodes are not found in the graph,
-        a :exc:`NodeNotFound` exception is raised.
+    Examples
+    --------
+    >>> G = nx.star_graph(3)
+    >>> L = nx.line_graph(G)
+    >>> print(sorted(map(sorted, L.edges())))  # makes a 3-clique, K3
+    [[(0, 1), (0, 2)], [(0, 1), (0, 3)], [(0, 2), (0, 3)]]
+
+    Edge attributes from `G` are not copied over as node attributes in `L`, but
+    attributes can be copied manually:
+
+    >>> G = nx.path_graph(4)
+    >>> G.add_edges_from((u, v, {"tot": u + v}) for u, v in G.edges)
+    >>> G.edges(data=True)
+    EdgeDataView([(0, 1, {'tot': 1}), (1, 2, {'tot': 3}), (2, 3, {'tot': 5})])
+    >>> H = nx.line_graph(G)
+    >>> H.add_nodes_from((node, G.edges[node]) for node in H)
+    >>> H.nodes(data=True)
+    NodeDataView({(0, 1): {'tot': 1}, (2, 3): {'tot': 5}, (1, 2): {'tot': 3}})
 
     Notes
     -----
-    A d-separating set in a DAG is a set of nodes that
-    blocks all paths between the two sets. Nodes in `z`
-    block a path if they are part of the path and are not a collider,
-    or a descendant of a collider. A collider structure along a path
-    is ``... -> c <- ...`` where ``c`` is the collider node.
+    Graph, node, and edge data are not propagated to the new graph. For
+    undirected graphs, the nodes in G must be sortable, otherwise the
+    constructed line graph may not be correct.
+
+    *Self-loops in undirected graphs*
+
+    For an undirected graph `G` without multiple edges, each edge can be
+    written as a set `\{u, v\}`.  Its line graph `L` has the edges of `G` as
+    its nodes. If `x` and `y` are two nodes in `L`, then `\{x, y\}` is an edge
+    in `L` if and only if the intersection of `x` and `y` is nonempty. Thus,
+    the set of all edges is determined by the set of all pairwise intersections
+    of edges in `G`.
+
+    Trivially, every edge in G would have a nonzero intersection with itself,
+    and so every node in `L` should have a self-loop. This is not so
+    interesting, and the original context of line graphs was with simple
+    graphs, which had no self-loops or multiple edges. The line graph was also
+    meant to be a simple graph and thus, self-loops in `L` are not part of the
+    standard definition of a line graph. In a pairwise intersection matrix,
+    this is analogous to excluding the diagonal entries from the line graph
+    definition.
+
+    Self-loops and multiple edges in `G` add nodes to `L` in a natural way, and
+    do not require any fundamental changes to the definition. It might be
+    argued that the self-loops we excluded before should now be included.
+    However, the self-loops are still "trivial" in some sense and thus, are
+    usually excluded.
+
+    *Self-loops in directed graphs*
+
+    For a directed graph `G` without multiple edges, each edge can be written
+    as a tuple `(u, v)`. Its line graph `L` has the edges of `G` as its
+    nodes. If `x` and `y` are two nodes in `L`, then `(x, y)` is an edge in `L`
+    if and only if the tail of `x` matches the head of `y`, for example, if `x
+    = (a, b)` and `y = (b, c)` for some vertices `a`, `b`, and `c` in `G`.
+
+    Due to the directed nature of the edges, it is no longer the case that
+    every edge in `G` should have a self-loop in `L`. Now, the only time
+    self-loops arise is if a node in `G` itself has a self-loop.  So such
+    self-loops are no longer "trivial" but instead, represent essential
+    features of the topology of `G`. For this reason, the historical
+    development of line digraphs is such that self-loops are included. When the
+    graph `G` has multiple edges, once again only superficial changes are
+    required to the definition.
+
+    References
+    ----------
+    * Harary, Frank, and Norman, Robert Z., "Some properties of line digraphs",
+      Rend. Circ. Mat. Palermo, II. Ser. 9 (1960), 161--168.
+    * Hemminger, R. L.; Beineke, L. W. (1978), "Line graphs and line digraphs",
+      in Beineke, L. W.; Wilson, R. J., Selected Topics in Graph Theory,
+      Academic Press Inc., pp. 271--305.
 
-    https://en.wikipedia.org/wiki/Bayesian_network#d-separation
     """
+    if G.is_directed():
+        L = _lg_directed(G, create_using=create_using)
+    else:
+        L = _lg_undirected(G, selfloops=False, create_using=create_using)
+    return L
 
-    if not nx.is_directed_acyclic_graph(G):
-        raise nx.NetworkXError("graph should be directed acyclic")
 
-    union_xyz = x.union(y).union(z)
+def _lg_directed(G, create_using=None):
+    """Returns the line graph L of the (multi)digraph G.
 
-    if any(n not in G.nodes for n in union_xyz):
-        raise nx.NodeNotFound("one or more specified nodes not found in the graph")
+    Edges in G appear as nodes in L, represented as tuples of the form (u,v)
+    or (u,v,key) if G is a multidigraph. A node in L corresponding to the edge
+    (u,v) is connected to every node corresponding to an edge (v,w).
 
-    G_copy = G.copy()
-
-    # transform the graph by removing leaves that are not in x | y | z
-    # until no more leaves can be removed.
-    leaves = deque([n for n in G_copy.nodes if G_copy.out_degree[n] == 0])
-    while len(leaves) > 0:
-        leaf = leaves.popleft()
-        if leaf not in union_xyz:
-            for p in G_copy.predecessors(leaf):
-                if G_copy.out_degree[p] == 1:
-                    leaves.append(p)
-            G_copy.remove_node(leaf)
-
-    # transform the graph by removing outgoing edges from the
-    # conditioning set.
-    edges_to_remove = list(G_copy.out_edges(z))
-    G_copy.remove_edges_from(edges_to_remove)
-
-    # use disjoint-set data structure to check if any node in `x`
-    # occurs in the same weakly connected component as a node in `y`.
-    disjoint_set = UnionFind(G_copy.nodes())
-    for component in nx.weakly_connected_components(G_copy):
-        disjoint_set.union(*component)
-    disjoint_set.union(*x)
-    disjoint_set.union(*y)
+    Parameters
+    ----------
+    G : digraph
+        A directed graph or directed multigraph.
+    create_using : NetworkX graph constructor, optional
+       Graph type to create. If graph instance, then cleared before populated.
+       Default is to use the same graph class as `G`.
 
-    if x and y and disjoint_set[next(iter(x))] == disjoint_set[next(iter(y))]:
-        return False
-    else:
-        return True
+    """
+    L = nx.empty_graph(0, create_using, default=G.__class__)
 
+    # Create a graph specific edge function.
+    get_edges = partial(G.edges, keys=True) if G.is_multigraph() else G.edges
 
-@not_implemented_for("undirected")
-@nx._dispatch
-def minimal_d_separator(G, u, v):
-    """Compute a minimal d-separating set between 'u' and 'v'.
-
-    A d-separating set in a DAG is a set of nodes that blocks all paths
-    between the two nodes, 'u' and 'v'. This function
-    constructs a d-separating set that is "minimal", meaning it is the smallest
-    d-separating set for 'u' and 'v'. This is not necessarily
-    unique. For more details, see Notes.
+    for from_node in get_edges():
+        # from_node is: (u,v) or (u,v,key)
+        L.add_node(from_node)
+        for to_node in get_edges(from_node[1]):
+            L.add_edge(from_node, to_node)
 
-    Parameters
-    ----------
-    G : graph
-        A networkx DAG.
-    u : node
-        A node in the graph, G.
-    v : node
-        A node in the graph, G.
+    return L
 
-    Raises
-    ------
-    NetworkXError
-        Raises a :exc:`NetworkXError` if the input graph is not a DAG.
 
-    NodeNotFound
-        If any of the input nodes are not found in the graph,
-        a :exc:`NodeNotFound` exception is raised.
+def _lg_undirected(G, selfloops=False, create_using=None):
+    """Returns the line graph L of the (multi)graph G.
 
-    References
+    Edges in G appear as nodes in L, represented as sorted tuples of the form
+    (u,v), or (u,v,key) if G is a multigraph. A node in L corresponding to
+    the edge {u,v} is connected to every node corresponding to an edge that
+    involves u or v.
+
+    Parameters
     ----------
-    .. [1] Tian, J., & Paz, A. (1998). Finding Minimal D-separators.
+    G : graph
+        An undirected graph or multigraph.
+    selfloops : bool
+        If `True`, then self-loops are included in the line graph. If `False`,
+        they are excluded.
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+       Graph type to create. If graph instance, then cleared before populated.
 
     Notes
     -----
-    This function only finds ``a`` minimal d-separator. It does not guarantee
-    uniqueness, since in a DAG there may be more than one minimal d-separator
-    between two nodes. Moreover, this only checks for minimal separators
-    between two nodes, not two sets. Finding minimal d-separators between
-    two sets of nodes is not supported.
-
-    Uses the algorithm presented in [1]_. The complexity of the algorithm
-    is :math:`O(|E_{An}^m|)`, where :math:`|E_{An}^m|` stands for the
-    number of edges in the moralized graph of the sub-graph consisting
-    of only the ancestors of 'u' and 'v'. For full details, see [1]_.
-
-    The algorithm works by constructing the moral graph consisting of just
-    the ancestors of `u` and `v`. Then it constructs a candidate for
-    a separating set  ``Z'`` from the predecessors of `u` and `v`.
-    Then BFS is run starting from `u` and marking nodes
-    found from ``Z'`` and calling those nodes ``Z''``.
-    Then BFS is run again starting from `v` and marking nodes if they are
-    present in ``Z''``. Those marked nodes are the returned minimal
-    d-separating set.
+    The standard algorithm for line graphs of undirected graphs does not
+    produce self-loops.
 
-    https://en.wikipedia.org/wiki/Bayesian_network#d-separation
     """
-    if not nx.is_directed_acyclic_graph(G):
-        raise nx.NetworkXError("graph should be directed acyclic")
-
-    union_uv = {u, v}
-
-    if any(n not in G.nodes for n in union_uv):
-        raise nx.NodeNotFound("one or more specified nodes not found in the graph")
+    L = nx.empty_graph(0, create_using, default=G.__class__)
 
-    # first construct the set of ancestors of X and Y
-    x_anc = nx.ancestors(G, u)
-    y_anc = nx.ancestors(G, v)
-    D_anc_xy = x_anc.union(y_anc)
-    D_anc_xy.update((u, v))
+    # Graph specific functions for edges.
+    get_edges = partial(G.edges, keys=True) if G.is_multigraph() else G.edges
 
-    # second, construct the moralization of the subgraph of Anc(X,Y)
-    moral_G = nx.moral_graph(G.subgraph(D_anc_xy))
+    # Determine if we include self-loops or not.
+    shift = 0 if selfloops else 1
 
-    # find a separating set Z' in moral_G
-    Z_prime = set(G.predecessors(u)).union(set(G.predecessors(v)))
+    # Introduce numbering of nodes
+    node_index = {n: i for i, n in enumerate(G)}
+
+    # Lift canonical representation of nodes to edges in line graph
+    edge_key_function = lambda edge: (node_index[edge[0]], node_index[edge[1]])
+
+    edges = set()
+    for u in G:
+        # Label nodes as a sorted tuple of nodes in original graph.
+        # Decide on representation of {u, v} as (u, v) or (v, u) depending on node_index.
+        # -> This ensures a canonical representation and avoids comparing values of different types.
+        nodes = [tuple(sorted(x[:2], key=node_index.get)) + x[2:] for x in get_edges(u)]
+
+        if len(nodes) == 1:
+            # Then the edge will be an isolated node in L.
+            L.add_node(nodes[0])
+
+        # Add a clique of `nodes` to graph. To prevent double adding edges,
+        # especially important for multigraphs, we store the edges in
+        # canonical form in a set.
+        for i, a in enumerate(nodes):
+            edges.update(
+                [
+                    tuple(sorted((a, b), key=edge_key_function))
+                    for b in nodes[i + shift :]
+                ]
+            )
 
-    # perform BFS on the graph from 'x' to mark
-    Z_dprime = _bfs_with_marks(moral_G, u, Z_prime)
-    Z = _bfs_with_marks(moral_G, v, Z_dprime)
-    return Z
+    L.add_edges_from(edges)
+    return L
 
 
-@not_implemented_for("undirected")
-@nx._dispatch
-def is_minimal_d_separator(G, u, v, z):
-    """Determine if a d-separating set is minimal.
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
+@nx._dispatchable(returns_graph=True)
+def inverse_line_graph(G):
+    """Returns the inverse line graph of graph G.
 
-    A d-separating set, `z`, in a DAG is a set of nodes that blocks
-    all paths between the two nodes, `u` and `v`. This function
-    verifies that a set is "minimal", meaning there is no smaller
-    d-separating set between the two nodes.
+    If H is a graph, and G is the line graph of H, such that G = L(H).
+    Then H is the inverse line graph of G.
 
-    Note: This function checks whether `z` is a d-separator AND is minimal.
-    One can use the function `d_separated` to only check if `z` is a d-separator.
-    See examples below.
+    Not all graphs are line graphs and these do not have an inverse line graph.
+    In these cases this function raises a NetworkXError.
 
     Parameters
     ----------
-    G : nx.DiGraph
-        The graph.
-    u : node
-        A node in the graph.
-    v : node
-        A node in the graph.
-    z : Set of nodes
-        The set of nodes to check if it is a minimal d-separating set.
-        The function :func:`d_separated` is called inside this function
-        to verify that `z` is in fact a d-separator.
+    G : graph
+        A NetworkX Graph
 
     Returns
     -------
-    bool
-        Whether or not the set `z` is a d-separator and is also minimal.
-
-    Examples
-    --------
-    >>> G = nx.path_graph([0, 1, 2, 3], create_using=nx.DiGraph)
-    >>> G.add_node(4)
-    >>> nx.is_minimal_d_separator(G, 0, 2, {1})
-    True
-    >>> # since {1} is the minimal d-separator, {1, 3, 4} is not minimal
-    >>> nx.is_minimal_d_separator(G, 0, 2, {1, 3, 4})
-    False
-    >>> # alternatively, if we only want to check that {1, 3, 4} is a d-separator
-    >>> nx.d_separated(G, {0}, {4}, {1, 3, 4})
-    True
+    H : graph
+        The inverse line graph of G.
 
     Raises
     ------
+    NetworkXNotImplemented
+        If G is directed or a multigraph
+
     NetworkXError
-        Raises a :exc:`NetworkXError` if the input graph is not a DAG.
+        If G is not a line graph
 
-    NodeNotFound
-        If any of the input nodes are not found in the graph,
-        a :exc:`NodeNotFound` exception is raised.
+    Notes
+    -----
+    This is an implementation of the Roussopoulos algorithm[1]_.
+
+    If G consists of multiple components, then the algorithm doesn't work.
+    You should invert every component separately:
+
+    >>> K5 = nx.complete_graph(5)
+    >>> P4 = nx.Graph([("a", "b"), ("b", "c"), ("c", "d")])
+    >>> G = nx.union(K5, P4)
+    >>> root_graphs = []
+    >>> for comp in nx.connected_components(G):
+    ...     root_graphs.append(nx.inverse_line_graph(G.subgraph(comp)))
+    >>> len(root_graphs)
+    2
 
     References
     ----------
-    .. [1] Tian, J., & Paz, A. (1998). Finding Minimal D-separators.
+    .. [1] Roussopoulos, N.D. , "A max {m, n} algorithm for determining the graph H from
+       its line graph G", Information Processing Letters 2, (1973), 108--112, ISSN 0020-0190,
+       `DOI link <https://doi.org/10.1016/0020-0190(73)90029-X>`_
+
+    """
+    if G.number_of_nodes() == 0:
+        return nx.empty_graph(1)
+    elif G.number_of_nodes() == 1:
+        v = arbitrary_element(G)
+        a = (v, 0)
+        b = (v, 1)
+        H = nx.Graph([(a, b)])
+        return H
+    elif G.number_of_nodes() > 1 and G.number_of_edges() == 0:
+        msg = (
+            "inverse_line_graph() doesn't work on an edgeless graph. "
+            "Please use this function on each component separately."
+        )
+        raise nx.NetworkXError(msg)
+
+    if nx.number_of_selfloops(G) != 0:
+        msg = (
+            "A line graph as generated by NetworkX has no selfloops, so G has no "
+            "inverse line graph. Please remove the selfloops from G and try again."
+        )
+        raise nx.NetworkXError(msg)
+
+    starting_cell = _select_starting_cell(G)
+    P = _find_partition(G, starting_cell)
+    # count how many times each vertex appears in the partition set
+    P_count = {u: 0 for u in G.nodes}
+    for p in P:
+        for u in p:
+            P_count[u] += 1
+
+    if max(P_count.values()) > 2:
+        msg = "G is not a line graph (vertex found in more than two partition cells)"
+        raise nx.NetworkXError(msg)
+    W = tuple((u,) for u in P_count if P_count[u] == 1)
+    H = nx.Graph()
+    H.add_nodes_from(P)
+    H.add_nodes_from(W)
+    for a, b in combinations(H.nodes, 2):
+        if any(a_bit in b for a_bit in a):
+            H.add_edge(a, b)
+    return H
+
+
+def _triangles(G, e):
+    """Return list of all triangles containing edge e"""
+    u, v = e
+    if u not in G:
+        raise nx.NetworkXError(f"Vertex {u} not in graph")
+    if v not in G[u]:
+        raise nx.NetworkXError(f"Edge ({u}, {v}) not in graph")
+    triangle_list = []
+    for x in G[u]:
+        if x in G[v]:
+            triangle_list.append((u, v, x))
+    return triangle_list
+
+
+def _odd_triangle(G, T):
+    """Test whether T is an odd triangle in G
+
+    Parameters
+    ----------
+    G : NetworkX Graph
+    T : 3-tuple of vertices forming triangle in G
+
+    Returns
+    -------
+    True is T is an odd triangle
+    False otherwise
+
+    Raises
+    ------
+    NetworkXError
+        T is not a triangle in G
 
     Notes
     -----
-    This function only works on verifying a d-separating set is minimal
-    between two nodes. To verify that a d-separating set is minimal between
-    two sets of nodes is not supported.
-
-    Uses algorithm 2 presented in [1]_. The complexity of the algorithm
-    is :math:`O(|E_{An}^m|)`, where :math:`|E_{An}^m|` stands for the
-    number of edges in the moralized graph of the sub-graph consisting
-    of only the ancestors of ``u`` and ``v``.
-
-    The algorithm works by constructing the moral graph consisting of just
-    the ancestors of `u` and `v`. First, it performs BFS on the moral graph
-    starting from `u` and marking any nodes it encounters that are part of
-    the separating set, `z`. If a node is marked, then it does not continue
-    along that path. In the second stage, BFS with markings is repeated on the
-    moral graph starting from `v`. If at any stage, any node in `z` is
-    not marked, then `z` is considered not minimal. If the end of the algorithm
-    is reached, then `z` is minimal.
+    An odd triangle is one in which there exists another vertex in G which is
+    adjacent to either exactly one or exactly all three of the vertices in the
+    triangle.
 
-    For full details, see [1]_.
-
-    https://en.wikipedia.org/wiki/Bayesian_network#d-separation
     """
-    if not nx.d_separated(G, {u}, {v}, z):
-        return False
+    for u in T:
+        if u not in G.nodes():
+            raise nx.NetworkXError(f"Vertex {u} not in graph")
+    for e in list(combinations(T, 2)):
+        if e[0] not in G[e[1]]:
+            raise nx.NetworkXError(f"Edge ({e[0]}, {e[1]}) not in graph")
+
+    T_nbrs = defaultdict(int)
+    for t in T:
+        for v in G[t]:
+            if v not in T:
+                T_nbrs[v] += 1
+    return any(T_nbrs[v] in [1, 3] for v in T_nbrs)
 
-    x_anc = nx.ancestors(G, u)
-    y_anc = nx.ancestors(G, v)
-    xy_anc = x_anc.union(y_anc)
-
-    # if Z contains any node which is not in ancestors of X or Y
-    # then it is definitely not minimal
-    if any(node not in xy_anc for node in z):
-        return False
-
-    D_anc_xy = x_anc.union(y_anc)
-    D_anc_xy.update((u, v))
-
-    # second, construct the moralization of the subgraph
-    moral_G = nx.moral_graph(G.subgraph(D_anc_xy))
-
-    # start BFS from X
-    marks = _bfs_with_marks(moral_G, u, z)
-
-    # if not all the Z is marked, then the set is not minimal
-    if any(node not in marks for node in z):
-        return False
-
-    # similarly, start BFS from Y and check the marks
-    marks = _bfs_with_marks(moral_G, v, z)
-    # if not all the Z is marked, then the set is not minimal
-    if any(node not in marks for node in z):
-        return False
 
-    return True
+def _find_partition(G, starting_cell):
+    """Find a partition of the vertices of G into cells of complete graphs
 
+    Parameters
+    ----------
+    G : NetworkX Graph
+    starting_cell : tuple of vertices in G which form a cell
+
+    Returns
+    -------
+    List of tuples of vertices of G
+
+    Raises
+    ------
+    NetworkXError
+        If a cell is not a complete subgraph then G is not a line graph
+    """
+    G_partition = G.copy()
+    P = [starting_cell]  # partition set
+    G_partition.remove_edges_from(list(combinations(starting_cell, 2)))
+    # keep list of partitioned nodes which might have an edge in G_partition
+    partitioned_vertices = list(starting_cell)
+    while G_partition.number_of_edges() > 0:
+        # there are still edges left and so more cells to be made
+        u = partitioned_vertices.pop()
+        deg_u = len(G_partition[u])
+        if deg_u != 0:
+            # if u still has edges then we need to find its other cell
+            # this other cell must be a complete subgraph or else G is
+            # not a line graph
+            new_cell = [u] + list(G_partition[u])
+            for u in new_cell:
+                for v in new_cell:
+                    if (u != v) and (v not in G_partition[u]):
+                        msg = (
+                            "G is not a line graph "
+                            "(partition cell not a complete subgraph)"
+                        )
+                        raise nx.NetworkXError(msg)
+            P.append(tuple(new_cell))
+            G_partition.remove_edges_from(list(combinations(new_cell, 2)))
+            partitioned_vertices += new_cell
+    return P
 
-@not_implemented_for("directed")
-def _bfs_with_marks(G, start_node, check_set):
-    """Breadth-first-search with markings.
 
-    Performs BFS starting from ``start_node`` and whenever a node
-    inside ``check_set`` is met, it is "marked". Once a node is marked,
-    BFS does not continue along that path. The resulting marked nodes
-    are returned.
+def _select_starting_cell(G, starting_edge=None):
+    """Select a cell to initiate _find_partition
 
     Parameters
     ----------
-    G : nx.Graph
-        An undirected graph.
-    start_node : node
-        The start of the BFS.
-    check_set : set
-        The set of nodes to check against.
+    G : NetworkX Graph
+    starting_edge: an edge to build the starting cell from
 
     Returns
     -------
-    marked : set
-        A set of nodes that were marked.
+    Tuple of vertices in G
+
+    Raises
+    ------
+    NetworkXError
+        If it is determined that G is not a line graph
+
+    Notes
+    -----
+    If starting edge not specified then pick an arbitrary edge - doesn't
+    matter which. However, this function may call itself requiring a
+    specific starting edge. Note that the r, s notation for counting
+    triangles is the same as in the Roussopoulos paper cited above.
     """
-    visited = {}
-    marked = set()
-    queue = []
-
-    visited[start_node] = None
-    queue.append(start_node)
-    while queue:
-        m = queue.pop(0)
-
-        for nbr in G.neighbors(m):
-            if nbr not in visited:
-                # memoize where we visited so far
-                visited[nbr] = None
-
-                # mark the node in Z' and do not continue along that path
-                if nbr in check_set:
-                    marked.add(nbr)
-                else:
-                    queue.append(nbr)
-    return marked
+    if starting_edge is None:
+        e = arbitrary_element(G.edges())
+    else:
+        e = starting_edge
+        if e[0] not in G.nodes():
+            raise nx.NetworkXError(f"Vertex {e[0]} not in graph")
+        if e[1] not in G[e[0]]:
+            msg = f"starting_edge ({e[0]}, {e[1]}) is not in the Graph"
+            raise nx.NetworkXError(msg)
+    e_triangles = _triangles(G, e)
+    r = len(e_triangles)
+    if r == 0:
+        # there are no triangles containing e, so the starting cell is just e
+        starting_cell = e
+    elif r == 1:
+        # there is exactly one triangle, T, containing e. If other 2 edges
+        # of T belong only to this triangle then T is starting cell
+        T = e_triangles[0]
+        a, b, c = T
+        # ab was original edge so check the other 2 edges
+        ac_edges = len(_triangles(G, (a, c)))
+        bc_edges = len(_triangles(G, (b, c)))
+        if ac_edges == 1:
+            if bc_edges == 1:
+                starting_cell = T
+            else:
+                return _select_starting_cell(G, starting_edge=(b, c))
+        else:
+            return _select_starting_cell(G, starting_edge=(a, c))
+    else:
+        # r >= 2 so we need to count the number of odd triangles, s
+        s = 0
+        odd_triangles = []
+        for T in e_triangles:
+            if _odd_triangle(G, T):
+                s += 1
+                odd_triangles.append(T)
+        if r == 2 and s == 0:
+            # in this case either triangle works, so just use T
+            starting_cell = T
+        elif r - 1 <= s <= r:
+            # check if odd triangles containing e form complete subgraph
+            triangle_nodes = set()
+            for T in odd_triangles:
+                for x in T:
+                    triangle_nodes.add(x)
+
+            for u in triangle_nodes:
+                for v in triangle_nodes:
+                    if u != v and (v not in G[u]):
+                        msg = (
+                            "G is not a line graph (odd triangles "
+                            "do not form complete subgraph)"
+                        )
+                        raise nx.NetworkXError(msg)
+            # otherwise then we can use this as the starting cell
+            starting_cell = tuple(triangle_nodes)
+
+        else:
+            msg = (
+                "G is not a line graph (incorrect number of "
+                "odd triangles around starting edge)"
+            )
+            raise nx.NetworkXError(msg)
+    return starting_cell
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `networkx-3.2rc0/networkx/algorithms/dag.py` & `networkx-3.3rc0/networkx/algorithms/dag.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     "dag_to_branching",
     "compute_v_structures",
 ]
 
 chaini = chain.from_iterable
 
 
-@nx._dispatch
+@nx._dispatchable
 def descendants(G, source):
     """Returns all nodes reachable from `source` in `G`.
 
     Parameters
     ----------
     G : NetworkX Graph
     source : node in `G`
@@ -69,15 +69,15 @@
     See also
     --------
     ancestors
     """
     return {child for parent, child in nx.bfs_edges(G, source)}
 
 
-@nx._dispatch
+@nx._dispatchable
 def ancestors(G, source):
     """Returns all nodes having a path to `source` in `G`.
 
     Parameters
     ----------
     G : NetworkX Graph
     source : node in `G`
@@ -106,27 +106,27 @@
     See also
     --------
     descendants
     """
     return {child for parent, child in nx.bfs_edges(G, source, reverse=True)}
 
 
-@nx._dispatch
+@nx._dispatchable
 def has_cycle(G):
     """Decides whether the directed graph has a cycle."""
     try:
         # Feed the entire iterator into a zero-length deque.
         deque(topological_sort(G), maxlen=0)
     except nx.NetworkXUnfeasible:
         return True
     else:
         return False
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_directed_acyclic_graph(G):
     """Returns True if the graph `G` is a directed acyclic graph (DAG) or
     False if not.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -159,15 +159,15 @@
     See also
     --------
     topological_sort
     """
     return G.is_directed() and not has_cycle(G)
 
 
-@nx._dispatch
+@nx._dispatchable
 def topological_generations(G):
     """Stratifies a DAG into generations.
 
     A topological generation is node collection in which ancestors of a node in each
     generation are guaranteed to be in a previous generation, and any descendants of
     a node are guaranteed to be in a following generation. Nodes are guaranteed to
     be in the earliest possible generation that they can belong to.
@@ -237,15 +237,15 @@
 
     if indegree_map:
         raise nx.NetworkXUnfeasible(
             "Graph contains a cycle or graph changed during iteration"
         )
 
 
-@nx._dispatch
+@nx._dispatchable
 def topological_sort(G):
     """Returns a generator of nodes in topologically sorted order.
 
     A topological sort is a nonunique permutation of the nodes of a
     directed graph such that an edge from u to v implies that u
     appears before v in the topological sort order. This ordering is
     valid only if the graph has no directed cycles.
@@ -306,15 +306,15 @@
     .. [1] Manber, U. (1989).
        *Introduction to Algorithms - A Creative Approach.* Addison-Wesley.
     """
     for generation in nx.topological_generations(G):
         yield from generation
 
 
-@nx._dispatch
+@nx._dispatchable
 def lexicographical_topological_sort(G, key=None):
     """Generate the nodes in the unique lexicographical topological sort order.
 
     Generates a unique ordering of nodes by first sorting topologically (for which there are often
     multiple valid orderings) and then additionally by sorting lexicographically.
 
     A topological sort arranges the nodes of a directed graph so that the
@@ -373,15 +373,15 @@
     [2, 1, 3, 5, 4]
     >>> list(nx.lexicographical_topological_sort(DG, key=lambda x: -x))
     [2, 5, 1, 4, 3]
 
     The sort will fail for any graph with integer and string nodes. Comparison of integer to strings
     is not defined in python.  Is 3 greater or less than 'red'?
 
-    >>> DG = nx.DiGraph([(1, 'red'), (3, 'red'), (1, 'green'), (2, 'blue')])
+    >>> DG = nx.DiGraph([(1, "red"), (3, "red"), (1, "green"), (2, "blue")])
     >>> list(nx.lexicographical_topological_sort(DG))
     Traceback (most recent call last):
     ...
     TypeError: '<' not supported between instances of 'str' and 'int'
     ...
 
     Incomparable nodes can be resolved using a `key` function. This example function
@@ -449,15 +449,15 @@
 
     if indegree_map:
         msg = "Graph contains a cycle or graph changed during iteration"
         raise nx.NetworkXUnfeasible(msg)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def all_topological_sorts(G):
     """Returns a generator of _all_ topological sorts of the directed graph G.
 
     A topological sort is a nonunique permutation of the nodes such that an
     edge from u to v implies that u appears before v in the topological sort
     order.
 
@@ -568,15 +568,15 @@
             if len(bases) < len(current_sort):
                 bases.append(q)
 
         if len(bases) == 0:
             break
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_aperiodic(G):
     """Returns True if `G` is aperiodic.
 
     A directed graph is aperiodic if there is no integer k > 1 that
     divides the length of every cycle in the graph.
 
     Parameters
@@ -637,15 +637,16 @@
     .. [1] Jarvis, J. P.; Shier, D. R. (1996),
        "Graph-theoretic analysis of finite Markov chains,"
        in Shier, D. R.; Wallenius, K. T., Applied Mathematical Modeling:
        A Multidisciplinary Approach, CRC Press.
     """
     if not G.is_directed():
         raise nx.NetworkXError("is_aperiodic not defined for undirected graphs")
-
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept("Graph has no nodes.")
     s = arbitrary_element(G)
     levels = {s: 0}
     this_level = [s]
     g = 0
     lev = 1
     while this_level:
         next_level = []
@@ -660,15 +661,15 @@
         lev += 1
     if len(levels) == len(G):  # All nodes in tree
         return g == 1
     else:
         return g == 1 and nx.is_aperiodic(G.subgraph(set(G) - set(levels)))
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def transitive_closure(G, reflexive=False):
     """Returns transitive closure of a graph
 
     The transitive closure of G = (V,E) is a graph G+ = (V,E+) such that
     for all v, w in V there is an edge (v, w) in E+ if and only if there
     is a path from v to w in G.
 
@@ -753,15 +754,15 @@
         elif reflexive is False:
             TC.add_edges_from((v, e[1]) for e in nx.edge_bfs(G, v) if e[1] not in TC[v])
 
     return TC
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def transitive_closure_dag(G, topo_order=None):
     """Returns the transitive closure of a directed acyclic graph.
 
     This function is faster than the function `transitive_closure`, but fails
     if the graph has a cycle.
 
     The transitive closure of G = (V,E) is a graph G+ = (V,E+) such that
@@ -810,15 +811,15 @@
     for v in reversed(topo_order):
         TC.add_edges_from((v, u) for u in nx.descendants_at_distance(TC, v, 2))
 
     return TC
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def transitive_reduction(G):
     """Returns transitive reduction of a directed graph
 
     The transitive reduction of G = (V,E) is a graph G- = (V,E-) such that
     for all v,w in V there is an edge (v,w) in E- if and only if (v,w) is
     in E and there is no path from v to w in G with length greater than 1.
 
@@ -848,15 +849,15 @@
     [(1, 2), (2, 3)]
 
     To avoid unnecessary data copies, this implementation does not return a
     DiGraph with node/edge data.
     To perform transitive reduction on a DiGraph and transfer node/edge data:
 
     >>> DG = nx.DiGraph()
-    >>> DG.add_edges_from([(1, 2), (2, 3), (1, 3)], color='red')
+    >>> DG.add_edges_from([(1, 2), (2, 3), (1, 3)], color="red")
     >>> TR = nx.transitive_reduction(DG)
     >>> TR.add_nodes_from(DG.nodes(data=True))
     >>> TR.add_edges_from((u, v, DG.edges[u, v]) for u, v in TR.edges)
     >>> list(TR.edges(data=True))
     [(1, 2, {'color': 'red'}), (2, 3, {'color': 'red'})]
 
     References
@@ -883,15 +884,15 @@
             if check_count[v] == 0:
                 del descendants[v]
         TR.add_edges_from((u, v) for v in u_nbrs)
     return TR
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def antichains(G, topo_order=None):
     """Generates antichains from a directed acyclic graph (DAG).
 
     An antichain is a subset of a partially ordered set such that any
     two elements in the subset are incomparable.
 
     Parameters
@@ -950,15 +951,15 @@
             x = stack.pop()
             new_antichain = antichain + [x]
             new_stack = [t for t in stack if not ((t in TC[x]) or (x in TC[t]))]
             antichains_stacks.append((new_antichain, new_stack))
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs={"weight": "default_weight"})
+@nx._dispatchable(edge_attrs={"weight": "default_weight"})
 def dag_longest_path(G, weight="weight", default_weight=1, topo_order=None):
     """Returns the longest path in a directed acyclic graph (DAG).
 
     If `G` has edges with `weight` attribute the edge data are used as
     weight values.
 
     Parameters
@@ -983,15 +984,15 @@
     Raises
     ------
     NetworkXNotImplemented
         If `G` is not directed
 
     Examples
     --------
-    >>> DG = nx.DiGraph([(0, 1, {'cost':1}), (1, 2, {'cost':1}), (0, 2, {'cost':42})])
+    >>> DG = nx.DiGraph([(0, 1, {"cost": 1}), (1, 2, {"cost": 1}), (0, 2, {"cost": 42})])
     >>> list(nx.all_simple_paths(DG, 0, 2))
     [[0, 1, 2], [0, 2]]
     >>> nx.dag_longest_path(DG)
     [0, 1, 2]
     >>> nx.dag_longest_path(DG, weight="cost")
     [0, 2]
 
@@ -1046,15 +1047,15 @@
         v = dist[v][1]
 
     path.reverse()
     return path
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs={"weight": "default_weight"})
+@nx._dispatchable(edge_attrs={"weight": "default_weight"})
 def dag_longest_path_length(G, weight="weight", default_weight=1):
     """Returns the longest path length in a DAG
 
     Parameters
     ----------
     G : NetworkX DiGraph
         A directed acyclic graph (DAG)
@@ -1073,15 +1074,15 @@
     Raises
     ------
     NetworkXNotImplemented
         If `G` is not directed
 
     Examples
     --------
-    >>> DG = nx.DiGraph([(0, 1, {'cost':1}), (1, 2, {'cost':1}), (0, 2, {'cost':42})])
+    >>> DG = nx.DiGraph([(0, 1, {"cost": 1}), (1, 2, {"cost": 1}), (0, 2, {"cost": 42})])
     >>> list(nx.all_simple_paths(DG, 0, 2))
     [[0, 1, 2], [0, 2]]
     >>> nx.dag_longest_path_length(DG)
     2
     >>> nx.dag_longest_path_length(DG, weight="cost")
     42
 
@@ -1098,15 +1099,15 @@
     else:
         for u, v in pairwise(path):
             path_length += G[u][v].get(weight, default_weight)
 
     return path_length
 
 
-@nx._dispatch
+@nx._dispatchable
 def root_to_leaf_paths(G):
     """Yields root-to-leaf paths in a directed acyclic graph.
 
     `G` must be a directed acyclic graph. If not, the behavior of this
     function is undefined. A "root" in this graph is a node of in-degree
     zero and a "leaf" a node of out-degree zero.
 
@@ -1119,15 +1120,15 @@
     all_paths = partial(nx.all_simple_paths, G)
     # TODO In Python 3, this would be better as `yield from ...`.
     return chaini(starmap(all_paths, product(roots, leaves)))
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def dag_to_branching(G):
     """Returns a branching representing all (overlapping) paths from
     root nodes to leaf nodes in the given directed acyclic graph.
 
     As described in :mod:`networkx.algorithms.tree.recognition`, a
     *branching* is a directed forest in which each node has at most one
     parent. In other words, a branching is a disjoint union of
@@ -1217,15 +1218,15 @@
     # Remove the synthetic `root`(0) and `NIL`(-1) nodes from the tree
     B.remove_node(0)
     B.remove_node(-1)
     return B
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def compute_v_structures(G):
     """Iterate through the graph to compute all v-structures.
 
     V-structures are triples in the directed graph where
     two parent nodes point to the same child and the two parent nodes
     are not adjacent.
 
@@ -1245,14 +1246,14 @@
     >>> G = nx.DiGraph()
     >>> G.add_edges_from([(1, 2), (0, 5), (3, 1), (2, 4), (3, 1), (4, 5), (1, 5)])
     >>> sorted(nx.compute_v_structures(G))
     [(0, 5, 1), (0, 5, 4), (1, 5, 4)]
 
     Notes
     -----
-    https://en.wikipedia.org/wiki/Collider_(statistics)
+    `Wikipedia: Collider in causal graphs <https://en.wikipedia.org/wiki/Collider_(statistics)>`_
     """
     for collider, preds in G.pred.items():
         for common_parents in combinations(preds, r=2):
             # ensure that the colliders are the same
             common_parents = sorted(common_parents)
             yield (common_parents[0], collider, common_parents[1])
```

### Comparing `networkx-3.2rc0/networkx/algorithms/distance_measures.py` & `networkx-3.3rc0/networkx/algorithms/distance_measures.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,14 +8,15 @@
     "diameter",
     "radius",
     "periphery",
     "center",
     "barycenter",
     "resistance_distance",
     "kemeny_constant",
+    "effective_graph_resistance",
 ]
 
 
 def _extrema_bounding(G, compute="diameter", weight=None):
     """Compute requested extreme distance metric of undirected graph G
 
     Computation is based on smart lower and upper bounds, and in practice
@@ -232,15 +233,15 @@
         c = [v for v in G if ecc_upper[v] == minupper]
         return c
     if compute == "eccentricities":
         return ecc_lower
     return None
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def eccentricity(G, v=None, sp=None, weight=None):
     """Returns the eccentricity of nodes in G.
 
     The eccentricity of a node v is the maximum distance from v to
     all other nodes in G.
 
     Parameters
@@ -321,15 +322,15 @@
         e[n] = max(length.values())
 
     if v in G:
         return e[v]  # return single value
     return e
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def diameter(G, e=None, usebounds=False, weight=None):
     """Returns the diameter of the graph G.
 
     The diameter is the maximum eccentricity.
 
     Parameters
     ----------
@@ -377,15 +378,15 @@
     if usebounds is True and e is None and not G.is_directed():
         return _extrema_bounding(G, compute="diameter", weight=weight)
     if e is None:
         e = eccentricity(G, weight=weight)
     return max(e.values())
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def periphery(G, e=None, usebounds=False, weight=None):
     """Returns the periphery of the graph G.
 
     The periphery is the set of nodes with eccentricity equal to the diameter.
 
     Parameters
     ----------
@@ -436,15 +437,15 @@
     if e is None:
         e = eccentricity(G, weight=weight)
     diameter = max(e.values())
     p = [v for v in e if e[v] == diameter]
     return p
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def radius(G, e=None, usebounds=False, weight=None):
     """Returns the radius of the graph G.
 
     The radius is the minimum eccentricity.
 
     Parameters
     ----------
@@ -489,15 +490,15 @@
     if usebounds is True and e is None and not G.is_directed():
         return _extrema_bounding(G, compute="radius", weight=weight)
     if e is None:
         e = eccentricity(G, weight=weight)
     return min(e.values())
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def center(G, e=None, usebounds=False, weight=None):
     """Returns the center of the graph G.
 
     The center is the set of nodes with eccentricity equal to radius.
 
     Parameters
     ----------
@@ -548,15 +549,15 @@
     if e is None:
         e = eccentricity(G, weight=weight)
     radius = min(e.values())
     p = [v for v in e if e[v] == radius]
     return p
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight", mutates_input={"attr": 2})
 def barycenter(G, weight=None, attr=None, sp=None):
     r"""Calculate barycenter of a connected graph, optionally with edge weights.
 
     The :dfn:`barycenter` a
     :func:`connected <networkx.algorithms.components.is_connected>` graph
     :math:`G` is the subgraph induced by the set of its nodes :math:`v`
     minimizing the objective function
@@ -627,32 +628,18 @@
             smallest = barycentricity
             barycenter_vertices = [v]
         elif barycentricity == smallest:
             barycenter_vertices.append(v)
     return barycenter_vertices
 
 
-def _count_lu_permutations(perm_array):
-    """Counts the number of permutations in SuperLU perm_c or perm_r"""
-    perm_cnt = 0
-    arr = perm_array.tolist()
-    for i in range(len(arr)):
-        if i != arr[i]:
-            perm_cnt += 1
-            n = arr.index(i)
-            arr[n] = arr[i]
-            arr[i] = i
-
-    return perm_cnt
-
-
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def resistance_distance(G, nodeA=None, nodeB=None, weight=None, invert_weight=True):
-    """Returns the resistance distance between every pair of nodes on graph G.
+    """Returns the resistance distance between pairs of nodes in graph G.
 
     The resistance distance between two nodes of a graph is akin to treating
     the graph as a grid of resistors with a resistance equal to the provided
     weight [1]_, [2]_.
 
     If weight is not provided, then a weight of 1 is used for all edges.
 
@@ -744,82 +731,138 @@
     L = nx.laplacian_matrix(G, weight=weight).todense()
     Linv = np.linalg.pinv(L, hermitian=True)
 
     # Return relevant distances
     if nodeA is not None and nodeB is not None:
         i = node_list.index(nodeA)
         j = node_list.index(nodeB)
-        return Linv[i, i] + Linv[j, j] - Linv[i, j] - Linv[j, i]
+        return Linv.item(i, i) + Linv.item(j, j) - Linv.item(i, j) - Linv.item(j, i)
 
     elif nodeA is not None:
         i = node_list.index(nodeA)
         d = {}
         for n in G:
             j = node_list.index(n)
-            d[n] = Linv[i, i] + Linv[j, j] - Linv[i, j] - Linv[j, i]
+            d[n] = Linv.item(i, i) + Linv.item(j, j) - Linv.item(i, j) - Linv.item(j, i)
         return d
 
     elif nodeB is not None:
         j = node_list.index(nodeB)
         d = {}
         for n in G:
             i = node_list.index(n)
-            d[n] = Linv[i, i] + Linv[j, j] - Linv[i, j] - Linv[j, i]
+            d[n] = Linv.item(i, i) + Linv.item(j, j) - Linv.item(i, j) - Linv.item(j, i)
         return d
 
     else:
         d = {}
         for n in G:
             i = node_list.index(n)
             d[n] = {}
             for n2 in G:
                 j = node_list.index(n2)
-                d[n][n2] = Linv[i, i] + Linv[j, j] - Linv[i, j] - Linv[j, i]
+                d[n][n2] = (
+                    Linv.item(i, i)
+                    + Linv.item(j, j)
+                    - Linv.item(i, j)
+                    - Linv.item(j, i)
+                )
         return d
-    # Replace with collapsing topology or approximated zero?
 
-    # Using determinants to compute the effective resistance is more memory
-    # efficient than directly calculating the pseudo-inverse
-    L = nx.laplacian_matrix(G, node_list, weight=weight).asformat("csc")
-    indices = list(range(L.shape[0]))
-    # w/ nodeA removed
-    indices.remove(node_list.index(nodeA))
-    L_a = L[indices, :][:, indices]
-    # Both nodeA and nodeB removed
-    indices.remove(node_list.index(nodeB))
-    L_ab = L[indices, :][:, indices]
-
-    # Factorize Laplacian submatrixes and extract diagonals
-    # Order the diagonals to minimize the likelihood over overflows
-    # during computing the determinant
-    lu_a = sp.sparse.linalg.splu(L_a, options={"SymmetricMode": True})
-    LdiagA = lu_a.U.diagonal()
-    LdiagA_s = np.prod(np.sign(LdiagA)) * np.prod(lu_a.L.diagonal())
-    LdiagA_s *= (-1) ** _count_lu_permutations(lu_a.perm_r)
-    LdiagA_s *= (-1) ** _count_lu_permutations(lu_a.perm_c)
-    LdiagA = np.absolute(LdiagA)
-    LdiagA = np.sort(LdiagA)
-
-    lu_ab = sp.sparse.linalg.splu(L_ab, options={"SymmetricMode": True})
-    LdiagAB = lu_ab.U.diagonal()
-    LdiagAB_s = np.prod(np.sign(LdiagAB)) * np.prod(lu_ab.L.diagonal())
-    LdiagAB_s *= (-1) ** _count_lu_permutations(lu_ab.perm_r)
-    LdiagAB_s *= (-1) ** _count_lu_permutations(lu_ab.perm_c)
-    LdiagAB = np.absolute(LdiagAB)
-    LdiagAB = np.sort(LdiagAB)
-
-    # Calculate the ratio of determinant, rd = det(L_ab)/det(L_a)
-    Ldet = np.prod(np.divide(np.append(LdiagAB, [1]), LdiagA))
-    rd = Ldet * LdiagAB_s / LdiagA_s
 
-    return rd
+@not_implemented_for("directed")
+@nx._dispatchable(edge_attrs="weight")
+def effective_graph_resistance(G, weight=None, invert_weight=True):
+    """Returns the Effective graph resistance of G.
+
+    Also known as the Kirchhoff index.
+
+    The effective graph resistance is defined as the sum
+    of the resistance distance of every node pair in G [1]_.
+
+    If weight is not provided, then a weight of 1 is used for all edges.
+
+    The effective graph resistance of a disconnected graph is infinite.
+
+    Parameters
+    ----------
+    G : NetworkX graph
+       A graph
+
+    weight : string or None, optional (default=None)
+       The edge data key used to compute the effective graph resistance.
+       If None, then each edge has weight 1.
+
+    invert_weight : boolean (default=True)
+        Proper calculation of resistance distance requires building the
+        Laplacian matrix with the reciprocal of the weight. Not required
+        if the weight is already inverted. Weight cannot be zero.
+
+    Returns
+    -------
+    RG : float
+        The effective graph resistance of `G`.
+
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a directed graph.
+
+    NetworkXError
+        If `G` does not contain any nodes.
+
+    Examples
+    --------
+    >>> G = nx.Graph([(1, 2), (1, 3), (1, 4), (3, 4), (3, 5), (4, 5)])
+    >>> round(nx.effective_graph_resistance(G), 10)
+    10.25
+
+    Notes
+    -----
+    The implementation is based on Theorem 2.2 in [2]_. Self-loops are ignored.
+    Multi-edges are contracted in one edge with weight equal to the harmonic sum of the weights.
+
+    References
+    ----------
+    .. [1] Wolfram
+       "Kirchhoff Index."
+       https://mathworld.wolfram.com/KirchhoffIndex.html
+    .. [2] W. Ellens, F. M. Spieksma, P. Van Mieghem, A. Jamakovic, R. E. Kooij.
+        Effective graph resistance.
+        Lin. Alg. Appl. 435:2491-2506, 2011.
+    """
+    import numpy as np
+
+    if len(G) == 0:
+        raise nx.NetworkXError("Graph G must contain at least one node.")
+
+    # Disconnected graphs have infinite Effective graph resistance
+    if not nx.is_connected(G):
+        return float("inf")
+
+    # Invert weights
+    G = G.copy()
+    if invert_weight and weight is not None:
+        if G.is_multigraph():
+            for u, v, k, d in G.edges(keys=True, data=True):
+                d[weight] = 1 / d[weight]
+        else:
+            for u, v, d in G.edges(data=True):
+                d[weight] = 1 / d[weight]
+
+    # Get Laplacian eigenvalues
+    mu = np.sort(nx.laplacian_spectrum(G, weight=weight))
+
+    # Compute Effective graph resistance based on spectrum of the Laplacian
+    # Self-loops are ignored
+    return float(np.sum(1 / mu[1:]) * G.number_of_nodes())
 
 
 @nx.utils.not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def kemeny_constant(G, *, weight=None):
     """Returns the Kemeny constant of the given graph.
 
     The *Kemeny constant* (or Kemeny's constant) of a graph `G`
     can be computed by regarding the graph as a Markov chain.
     The Kemeny constant is then the expected number of time steps
     to transition from a starting state i to a random destination state
@@ -840,15 +883,15 @@
 
     weight : string or None, optional (default=None)
        The edge data key used to compute the Kemeny constant.
        If None, then each edge has weight 1.
 
     Returns
     -------
-    K : float
+    float
         The Kemeny constant of the graph `G`.
 
     Raises
     ------
     NetworkXNotImplemented
         If the graph `G` is directed.
 
@@ -899,8 +942,8 @@
     DH = sp.sparse.csr_array(sp.sparse.spdiags(diags_sqrt, 0, m, n, format="csr"))
     H = DH @ (A @ DH)
 
     # Compute eigenvalues of H
     eig = np.sort(sp.linalg.eigvalsh(H.todense()))
 
     # Compute the Kemeny constant
-    return np.sum(1 / (1 - eig[:-1]))
+    return float(np.sum(1 / (1 - eig[:-1])))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/distance_regular.py` & `networkx-3.3rc0/networkx/algorithms/distance_regular.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     "is_distance_regular",
     "is_strongly_regular",
     "intersection_array",
     "global_parameters",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_distance_regular(G):
     """Returns True if the graph is distance regular, False otherwise.
 
     A connected graph G is distance-regular if for any nodes x,y
     and any integers i,j=0,1,...,d (where d is the graph
     diameter), the number of vertices at distance i from x and
     distance j from y depends only on i,j and the graph distance
@@ -105,16 +105,17 @@
     See Also
     --------
     intersection_array
     """
     return ((y, b[0] - x - y, x) for x, y in zip(b + [0], [0] + c))
 
 
-@not_implemented_for("directed", "multigraph")
-@nx._dispatch
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
+@nx._dispatchable
 def intersection_array(G):
     """Returns the intersection array of a distance-regular graph.
 
     Given a distance-regular graph G with integers b_i, c_i,i = 0,....,d
     such that for any 2 vertices x,y in G at a distance i=d(x,y), there
     are exactly c_i neighbors of y at a distance of i-1 from x and b_i
     neighbors of y at a distance of i+1 from x.
@@ -143,14 +144,16 @@
        http://mathworld.wolfram.com/IntersectionArray.html
 
     See Also
     --------
     global_parameters
     """
     # test for regular graph (all degrees must be equal)
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept("Graph has no nodes.")
     degree = iter(G.degree())
     (_, k) = next(degree)
     for _, knext in degree:
         if knext != k:
             raise nx.NetworkXError("Graph is not distance regular.")
         k = knext
     path_length = dict(nx.all_pairs_shortest_path_length(G))
@@ -175,16 +178,17 @@
     return (
         [bint.get(j, 0) for j in range(diameter)],
         [cint.get(j + 1, 0) for j in range(diameter)],
     )
 
 
 # TODO There is a definition for directed strongly regular graphs.
-@not_implemented_for("directed", "multigraph")
-@nx._dispatch
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
+@nx._dispatchable
 def is_strongly_regular(G):
     """Returns True if and only if the given graph is strongly
     regular.
 
     An undirected graph is *strongly regular* if
 
     * it is regular,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/dominance.py` & `networkx-3.3rc0/networkx/algorithms/dominance.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["immediate_dominators", "dominance_frontiers"]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def immediate_dominators(G, start):
     """Returns the immediate dominators of all nodes of a directed graph.
 
     Parameters
     ----------
     G : a DiGraph or MultiDiGraph
         The graph where dominance is to be computed.
@@ -80,15 +80,15 @@
             if u not in idom or idom[u] != new_idom:
                 idom[u] = new_idom
                 changed = True
 
     return idom
 
 
-@nx._dispatch
+@nx._dispatchable
 def dominance_frontiers(G, start):
     """Returns the dominance frontiers of all nodes of a directed graph.
 
     Parameters
     ----------
     G : a DiGraph or MultiDiGraph
         The graph where dominance is to be computed.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/dominating.py` & `networkx-3.3rc0/networkx/algorithms/dominating.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import networkx as nx
 from networkx.utils import arbitrary_element
 
 __all__ = ["dominating_set", "is_dominating_set"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def dominating_set(G, start_with=None):
     r"""Finds a dominating set for the graph G.
 
     A *dominating set* for a graph with node set *V* is a subset *D* of
     *V* such that every node not in *D* is adjacent to at least one
     member of *D* [1]_.
 
@@ -51,25 +51,25 @@
         raise nx.NetworkXError(f"node {start_with} is not in G")
     dominating_set = {start_with}
     dominated_nodes = set(G[start_with])
     remaining_nodes = all_nodes - dominated_nodes - dominating_set
     while remaining_nodes:
         # Choose an arbitrary node and determine its undominated neighbors.
         v = remaining_nodes.pop()
-        undominated_neighbors = set(G[v]) - dominating_set
+        undominated_nbrs = set(G[v]) - dominating_set
         # Add the node to the dominating set and the neighbors to the
         # dominated set. Finally, remove all of those nodes from the set
         # of remaining nodes.
         dominating_set.add(v)
-        dominated_nodes |= undominated_neighbors
-        remaining_nodes -= undominated_neighbors
+        dominated_nodes |= undominated_nbrs
+        remaining_nodes -= undominated_nbrs
     return dominating_set
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_dominating_set(G, nbunch):
     """Checks if `nbunch` is a dominating set for `G`.
 
     A *dominating set* for a graph with node set *V* is a subset *D* of
     *V* such that every node not in *D* is adjacent to at least one
     member of *D* [1]_.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/efficiency_measures.py` & `networkx-3.3rc0/networkx/algorithms/efficiency_measures.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 
 from ..utils import not_implemented_for
 
 __all__ = ["efficiency", "local_efficiency", "global_efficiency"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def efficiency(G, u, v):
     """Returns the efficiency of a pair of nodes in a graph.
 
     The *efficiency* of a pair of nodes is the multiplicative inverse of the
     shortest path distance between the nodes [1]_. Returns 0 if no path
     between nodes.
 
@@ -56,15 +56,15 @@
         eff = 1 / nx.shortest_path_length(G, u, v)
     except NetworkXNoPath:
         eff = 0
     return eff
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def global_efficiency(G):
     """Returns the average global efficiency of the graph.
 
     The *efficiency* of a pair of nodes in a graph is the multiplicative
     inverse of the shortest path distance between the nodes. The *average
     global efficiency* of a graph is the average efficiency of all pairs of
     nodes [1]_.
@@ -117,15 +117,15 @@
         g_eff = 0
     # TODO This can be made more efficient by computing all pairs shortest
     # path lengths in parallel.
     return g_eff
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def local_efficiency(G):
     """Returns the average local efficiency of the graph.
 
     The *efficiency* of a pair of nodes in a graph is the multiplicative
     inverse of the shortest path distance between the nodes. The *local
     efficiency* of a node in the graph is the average global efficiency of the
     subgraph induced by the neighbors of the node. The *average local
```

### Comparing `networkx-3.2rc0/networkx/algorithms/euler.py` & `networkx-3.3rc0/networkx/algorithms/euler.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     "eulerize",
     "is_semieulerian",
     "has_eulerian_path",
     "eulerian_path",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_eulerian(G):
     """Returns True if and only if `G` is Eulerian.
 
     A graph is *Eulerian* if it has an Eulerian circuit. An *Eulerian
     circuit* is a closed walk that includes each edge of a graph exactly
     once.
 
@@ -65,15 +65,15 @@
             G.in_degree(n) == G.out_degree(n) for n in G
         ) and nx.is_strongly_connected(G)
     # An undirected Eulerian graph has no vertices of odd degree and
     # must be connected.
     return all(d % 2 == 0 for v, d in G.degree()) and nx.is_connected(G)
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_semieulerian(G):
     """Return True iff `G` is semi-Eulerian.
 
     G is semi-Eulerian if it has an Eulerian path but no Eulerian circuit.
 
     See Also
     --------
@@ -150,15 +150,15 @@
         else:
             triple = arbitrary_element(edges(current_vertex, keys=True))
             _, next_vertex, next_key = triple
             vertex_stack.append((next_vertex, next_key))
             G.remove_edge(current_vertex, next_vertex, next_key)
 
 
-@nx._dispatch
+@nx._dispatchable
 def eulerian_circuit(G, source=None, keys=False):
     """Returns an iterator over the edges of an Eulerian circuit in `G`.
 
     An *Eulerian circuit* is a closed walk that includes each edge of a
     graph exactly once.
 
     Parameters
@@ -231,15 +231,15 @@
                 yield u, v, k
             else:
                 yield u, v
     else:
         yield from _simplegraph_eulerian_circuit(G, source)
 
 
-@nx._dispatch
+@nx._dispatchable
 def has_eulerian_path(G, source=None):
     """Return True iff `G` has an Eulerian path.
 
     An Eulerian path is a path in a graph which uses each edge of a graph
     exactly once. If `source` is specified, then this function checks
     whether an Eulerian path that starts at node `source` exists.
 
@@ -326,15 +326,15 @@
         if source is not None and G.degree[source] % 2 != 1:
             return False
 
         # Sum is 2 since we know it is not eulerian (which implies sum is 0)
         return sum(d % 2 == 1 for v, d in G.degree()) == 2 and nx.is_connected(G)
 
 
-@nx._dispatch
+@nx._dispatchable
 def eulerian_path(G, source=None, keys=False):
     """Return an iterator over the edges of an Eulerian path in `G`.
 
     Parameters
     ----------
     G : NetworkX Graph
         The graph in which to look for an eulerian path.
@@ -382,15 +382,15 @@
         else:
             yield from reversed(
                 [(v, u) for u, v in _simplegraph_eulerian_circuit(G, source)]
             )
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def eulerize(G):
     """Transforms a graph into an Eulerian graph.
 
     If `G` is Eulerian the result is `G` as a MultiGraph, otherwise the result is a smallest
     (in terms of the number of edges) multigraph whose underlying simple graph is `G`.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/boykovkolmogorov.py` & `networkx-3.3rc0/networkx/algorithms/flow/boykovkolmogorov.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,19 +6,20 @@
 
 import networkx as nx
 from networkx.algorithms.flow.utils import build_residual_network
 
 __all__ = ["boykov_kolmogorov"]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "residual?": 4},
     edge_attrs={"capacity": float("inf")},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
+    returns_graph=True,
 )
 def boykov_kolmogorov(
     G, s, t, capacity="capacity", residual=None, value_only=False, cutoff=None
 ):
     r"""Find a maximum single-commodity flow using Boykov-Kolmogorov algorithm.
 
     This function returns the residual network resulting after computing
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/capacityscaling.py` & `networkx-3.3rc0/networkx/algorithms/flow/capacityscaling.py`

 * *Files 1% similar despite different names*

```diff
@@ -145,15 +145,17 @@
                 for v, es in R[u].items()
                 for e in es.values()
                 if e["flow"] > 0
             )
     return flow_dict
 
 
-@nx._dispatch(node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0})
+@nx._dispatchable(
+    node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0}
+)
 def capacity_scaling(
     G, demand="demand", capacity="capacity", weight="weight", heap=BinaryHeap
 ):
     r"""Find a minimum cost flow satisfying all demands in digraph G.
 
     This is a capacity scaling successive shortest augmenting path algorithm.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/dinitz_alg.py` & `networkx-3.3rc0/networkx/algorithms/flow/dinitz_alg.py`

 * *Files 13% similar despite different names*

```diff
@@ -6,19 +6,20 @@
 import networkx as nx
 from networkx.algorithms.flow.utils import build_residual_network
 from networkx.utils import pairwise
 
 __all__ = ["dinitz"]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "residual?": 4},
     edge_attrs={"capacity": float("inf")},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
+    returns_graph=True,
 )
 def dinitz(G, s, t, capacity="capacity", residual=None, value_only=False, cutoff=None):
     """Find a maximum single-commodity flow using Dinitz' algorithm.
 
     This function returns the residual network resulting after computing
     the maximum flow. See below for details about the conventions
     NetworkX uses for defining residual networks.
@@ -169,43 +170,67 @@
         cutoff = INF
 
     R_succ = R.succ
     R_pred = R.pred
 
     def breath_first_search():
         parents = {}
-        queue = deque([s])
+        vertex_dist = {s: 0}
+        queue = deque([(s, 0)])
+        # Record all the potential edges of shortest augmenting paths
         while queue:
             if t in parents:
                 break
-            u = queue.popleft()
-            for v in R_succ[u]:
-                attr = R_succ[u][v]
-                if v not in parents and attr["capacity"] - attr["flow"] > 0:
-                    parents[v] = u
-                    queue.append(v)
+            u, dist = queue.popleft()
+            for v, attr in R_succ[u].items():
+                if attr["capacity"] - attr["flow"] > 0:
+                    if v in parents:
+                        if vertex_dist[v] == dist + 1:
+                            parents[v].append(u)
+                    else:
+                        parents[v] = deque([u])
+                        vertex_dist[v] = dist + 1
+                        queue.append((v, dist + 1))
         return parents
 
     def depth_first_search(parents):
+        # DFS to find all the shortest augmenting paths
         """Build a path using DFS starting from the sink"""
-        path = []
+        total_flow = 0
         u = t
-        flow = INF
-        while u != s:
-            path.append(u)
-            v = parents[u]
-            flow = min(flow, R_pred[u][v]["capacity"] - R_pred[u][v]["flow"])
+        # path also functions as a stack
+        path = [u]
+        # The loop ends with no augmenting path left in the layered graph
+        while True:
+            if len(parents[u]) > 0:
+                v = parents[u][0]
+                path.append(v)
+            else:
+                path.pop()
+                if len(path) == 0:
+                    break
+                v = path[-1]
+                parents[v].popleft()
+            # Augment the flow along the path found
+            if v == s:
+                flow = INF
+                for u, v in pairwise(path):
+                    flow = min(flow, R_pred[u][v]["capacity"] - R_pred[u][v]["flow"])
+                for u, v in pairwise(reversed(path)):
+                    R_pred[v][u]["flow"] += flow
+                    R_pred[u][v]["flow"] -= flow
+                    # Find the proper node to continue the search
+                    if R_pred[v][u]["capacity"] - R_pred[v][u]["flow"] == 0:
+                        parents[v].popleft()
+                        while path[-1] != v:
+                            path.pop()
+                total_flow += flow
+                v = path[-1]
             u = v
-        path.append(s)
-        # Augment the flow along the path found
-        if flow > 0:
-            for u, v in pairwise(path):
-                R_pred[u][v]["flow"] += flow
-                R_pred[v][u]["flow"] -= flow
-        return flow
+        return total_flow
 
     flow_value = 0
     while flow_value < cutoff:
         parents = breath_first_search()
         if t not in parents:
             break
         this_flow = depth_first_search(parents)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/edmondskarp.py` & `networkx-3.3rc0/networkx/algorithms/flow/edmondskarp.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,18 +4,19 @@
 
 import networkx as nx
 from networkx.algorithms.flow.utils import build_residual_network
 
 __all__ = ["edmonds_karp"]
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs="R",
     preserve_edge_attrs={"R": {"capacity": float("inf"), "flow": 0}},
     preserve_graph_attrs=True,
+    mutates_input=True,
 )
 def edmonds_karp_core(R, s, t, cutoff):
     """Implementation of the Edmonds-Karp algorithm."""
     R_nodes = R.nodes
     R_pred = R.pred
     R_succ = R.succ
 
@@ -118,19 +119,20 @@
     if cutoff is None:
         cutoff = float("inf")
     R.graph["flow_value"] = edmonds_karp_core(R, s, t, cutoff)
 
     return R
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "residual?": 4},
     edge_attrs={"capacity": float("inf")},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
+    returns_graph=True,
 )
 def edmonds_karp(
     G, s, t, capacity="capacity", residual=None, value_only=False, cutoff=None
 ):
     """Find a maximum single-commodity flow using the Edmonds-Karp algorithm.
 
     This function returns the residual network resulting after computing
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/gomory_hu.py` & `networkx-3.3rc0/networkx/algorithms/flow/gomory_hu.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 default_flow_func = edmonds_karp
 
 __all__ = ["gomory_hu_tree"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(edge_attrs={"capacity": float("inf")}, returns_graph=True)
 def gomory_hu_tree(G, capacity="capacity", flow_func=None):
     r"""Returns the Gomory-Hu tree of an undirected graph G.
 
     A Gomory-Hu tree of an undirected graph with capacities is a
     weighted tree that represents the minimum s-t cuts for all s-t
     pairs in the graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/maxflow.py` & `networkx-3.3rc0/networkx/algorithms/flow/maxflow.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 # Define the default flow function for computing maximum flow.
 default_flow_func = preflow_push
 
 __all__ = ["maximum_flow", "maximum_flow_value", "minimum_cut", "minimum_cut_value"]
 
 
-@nx._dispatch(graphs="flowG", edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(graphs="flowG", edge_attrs={"capacity": float("inf")})
 def maximum_flow(flowG, _s, _t, capacity="capacity", flow_func=None, **kwargs):
     """Find a maximum single-commodity flow.
 
     Parameters
     ----------
     flowG : NetworkX graph
         Edges of the graph are expected to have an attribute called
@@ -136,17 +136,15 @@
     >>> print(flow_dict["x"]["b"])
     1.0
 
     You can also use alternative algorithms for computing the
     maximum flow by using the flow_func parameter.
 
     >>> from networkx.algorithms.flow import shortest_augmenting_path
-    >>> flow_value == nx.maximum_flow(G, "x", "y", flow_func=shortest_augmenting_path)[
-    ...     0
-    ... ]
+    >>> flow_value == nx.maximum_flow(G, "x", "y", flow_func=shortest_augmenting_path)[0]
     True
 
     """
     if flow_func is None:
         if kwargs:
             raise nx.NetworkXError(
                 "You have to explicitly set a flow_func if"
@@ -159,15 +157,15 @@
 
     R = flow_func(flowG, _s, _t, capacity=capacity, value_only=False, **kwargs)
     flow_dict = build_flow_dict(flowG, R)
 
     return (R.graph["flow_value"], flow_dict)
 
 
-@nx._dispatch(graphs="flowG", edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(graphs="flowG", edge_attrs={"capacity": float("inf")})
 def maximum_flow_value(flowG, _s, _t, capacity="capacity", flow_func=None, **kwargs):
     """Find the value of maximum single-commodity flow.
 
     Parameters
     ----------
     flowG : NetworkX graph
         Edges of the graph are expected to have an attribute called
@@ -277,17 +275,15 @@
     >>> flow_value
     3.0
 
     You can also use alternative algorithms for computing the
     maximum flow by using the flow_func parameter.
 
     >>> from networkx.algorithms.flow import shortest_augmenting_path
-    >>> flow_value == nx.maximum_flow_value(
-    ...     G, "x", "y", flow_func=shortest_augmenting_path
-    ... )
+    >>> flow_value == nx.maximum_flow_value(G, "x", "y", flow_func=shortest_augmenting_path)
     True
 
     """
     if flow_func is None:
         if kwargs:
             raise nx.NetworkXError(
                 "You have to explicitly set a flow_func if"
@@ -299,15 +295,15 @@
         raise nx.NetworkXError("flow_func has to be callable.")
 
     R = flow_func(flowG, _s, _t, capacity=capacity, value_only=True, **kwargs)
 
     return R.graph["flow_value"]
 
 
-@nx._dispatch(graphs="flowG", edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(graphs="flowG", edge_attrs={"capacity": float("inf")})
 def minimum_cut(flowG, _s, _t, capacity="capacity", flow_func=None, **kwargs):
     """Compute the value and the node partition of a minimum (s, t)-cut.
 
     Use the max-flow min-cut theorem, i.e., the capacity of a minimum
     capacity cut is equal to the flow value of a maximum flow.
 
     Parameters
@@ -463,15 +459,15 @@
     # Finally add again cutset edges to the residual network to make
     # sure that it is reusable.
     if cutset is not None:
         R.add_edges_from(cutset)
     return (R.graph["flow_value"], partition)
 
 
-@nx._dispatch(graphs="flowG", edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(graphs="flowG", edge_attrs={"capacity": float("inf")})
 def minimum_cut_value(flowG, _s, _t, capacity="capacity", flow_func=None, **kwargs):
     """Compute the value of a minimum (s, t)-cut.
 
     Use the max-flow min-cut theorem, i.e., the capacity of a minimum
     capacity cut is equal to the flow value of a maximum flow.
 
     Parameters
@@ -578,17 +574,15 @@
     >>> cut_value
     3.0
 
     You can also use alternative algorithms for computing the
     minimum cut by using the flow_func parameter.
 
     >>> from networkx.algorithms.flow import shortest_augmenting_path
-    >>> cut_value == nx.minimum_cut_value(
-    ...     G, "x", "y", flow_func=shortest_augmenting_path
-    ... )
+    >>> cut_value == nx.minimum_cut_value(G, "x", "y", flow_func=shortest_augmenting_path)
     True
 
     """
     if flow_func is None:
         if kwargs:
             raise nx.NetworkXError(
                 "You have to explicitly set a flow_func if"
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/mincost.py` & `networkx-3.3rc0/networkx/algorithms/flow/mincost.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,17 @@
 """
 
 __all__ = ["min_cost_flow_cost", "min_cost_flow", "cost_of_flow", "max_flow_min_cost"]
 
 import networkx as nx
 
 
-@nx._dispatch(node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0})
+@nx._dispatchable(
+    node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0}
+)
 def min_cost_flow_cost(G, demand="demand", capacity="capacity", weight="weight"):
     r"""Find the cost of a minimum cost flow satisfying all demands in digraph G.
 
     G is a digraph with edge costs and capacities and in which nodes
     have demand, i.e., they want to send or receive some amount of
     flow. A negative demand means that the node wants to send flow, a
     positive demand means that the node want to receive flow. A flow on
@@ -93,15 +95,17 @@
     >>> flowCost = nx.min_cost_flow_cost(G)
     >>> flowCost
     24
     """
     return nx.network_simplex(G, demand=demand, capacity=capacity, weight=weight)[0]
 
 
-@nx._dispatch(node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0})
+@nx._dispatchable(
+    node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0}
+)
 def min_cost_flow(G, demand="demand", capacity="capacity", weight="weight"):
     r"""Returns a minimum cost flow satisfying all demands in digraph G.
 
     G is a digraph with edge costs and capacities and in which nodes
     have demand, i.e., they want to send or receive some amount of
     flow. A negative demand means that the node wants to send flow, a
     positive demand means that the node want to receive flow. A flow on
@@ -178,19 +182,21 @@
     >>> G.add_node("a", demand=-5)
     >>> G.add_node("d", demand=5)
     >>> G.add_edge("a", "b", weight=3, capacity=4)
     >>> G.add_edge("a", "c", weight=6, capacity=10)
     >>> G.add_edge("b", "d", weight=1, capacity=9)
     >>> G.add_edge("c", "d", weight=2, capacity=5)
     >>> flowDict = nx.min_cost_flow(G)
+    >>> flowDict
+    {'a': {'b': 4, 'c': 1}, 'd': {}, 'b': {'d': 4}, 'c': {'d': 1}}
     """
     return nx.network_simplex(G, demand=demand, capacity=capacity, weight=weight)[1]
 
 
-@nx._dispatch(edge_attrs={"weight": 0})
+@nx._dispatchable(edge_attrs={"weight": 0})
 def cost_of_flow(G, flowDict, weight="weight"):
     """Compute the cost of the flow given by flowDict on graph G.
 
     Note that this function does not check for the validity of the
     flow flowDict. This function will fail if the graph G and the
     flow don't have the same edge set.
 
@@ -223,19 +229,34 @@
     Notes
     -----
     This algorithm is not guaranteed to work if edge weights or demands
     are floating point numbers (overflows and roundoff errors can
     cause problems). As a workaround you can use integer numbers by
     multiplying the relevant edge attributes by a convenient
     constant factor (eg 100).
+
+    Examples
+    --------
+    >>> G = nx.DiGraph()
+    >>> G.add_node("a", demand=-5)
+    >>> G.add_node("d", demand=5)
+    >>> G.add_edge("a", "b", weight=3, capacity=4)
+    >>> G.add_edge("a", "c", weight=6, capacity=10)
+    >>> G.add_edge("b", "d", weight=1, capacity=9)
+    >>> G.add_edge("c", "d", weight=2, capacity=5)
+    >>> flowDict = nx.min_cost_flow(G)
+    >>> flowDict
+    {'a': {'b': 4, 'c': 1}, 'd': {}, 'b': {'d': 4}, 'c': {'d': 1}}
+    >>> nx.cost_of_flow(G, flowDict)
+    24
     """
     return sum((flowDict[u][v] * d.get(weight, 0) for u, v, d in G.edges(data=True)))
 
 
-@nx._dispatch(edge_attrs={"capacity": float("inf"), "weight": 0})
+@nx._dispatchable(edge_attrs={"capacity": float("inf"), "weight": 0})
 def max_flow_min_cost(G, s, t, capacity="capacity", weight="weight"):
     """Returns a maximum (s, t)-flow of minimum cost.
 
     G is a digraph with edge costs and capacities. There is a source
     node s and a sink node t. This function finds a maximum flow from
     s to t whose total cost is minimized.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/networksimplex.py` & `networkx-3.3rc0/networkx/algorithms/flow/networksimplex.py`

 * *Files 0% similar despite different names*

```diff
@@ -322,15 +322,17 @@
             key=lambda i_p: self.residual_capacity(*i_p),
         )
         t = self.edge_targets[j] if self.edge_sources[j] == s else self.edge_sources[j]
         return j, s, t
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0})
+@nx._dispatchable(
+    node_attrs="demand", edge_attrs={"capacity": float("inf"), "weight": 0}
+)
 def network_simplex(G, demand="demand", capacity="capacity", weight="weight"):
     r"""Find a minimum cost flow satisfying all demands in digraph G.
 
     This is a primal network simplex algorithm that uses the leaving
     arc rule to prevent cycling.
 
     G is a digraph with edge costs and capacities and in which nodes
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/preflowpush.py` & `networkx-3.3rc0/networkx/algorithms/flow/preflowpush.py`

 * *Files 0% similar despite different names*

```diff
@@ -284,19 +284,20 @@
                 height = global_relabel(False)
                 grt.clear_work()
 
     R.graph["flow_value"] = R_nodes[t]["excess"]
     return R
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "residual?": 4},
     edge_attrs={"capacity": float("inf")},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
+    returns_graph=True,
 )
 def preflow_push(
     G, s, t, capacity="capacity", residual=None, global_relabel_freq=1, value_only=False
 ):
     r"""Find a maximum single-commodity flow using the highest-label
     preflow-push algorithm.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/shortestaugmentingpath.py` & `networkx-3.3rc0/networkx/algorithms/flow/shortestaugmentingpath.py`

 * *Files 1% similar despite different names*

```diff
@@ -159,19 +159,20 @@
     # Phase 2: Look for shortest augmenting paths using breadth-first search.
     flow_value += edmonds_karp_core(R, s, t, cutoff - flow_value)
 
     R.graph["flow_value"] = flow_value
     return R
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G": 0, "residual?": 4},
     edge_attrs={"capacity": float("inf")},
     preserve_edge_attrs={"residual": {"capacity": float("inf")}},
     preserve_graph_attrs={"residual"},
+    returns_graph=True,
 )
 def shortest_augmenting_path(
     G,
     s,
     t,
     capacity="capacity",
     residual=None,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/gl1.gpickle.bz2` & `networkx-3.3rc0/networkx/algorithms/flow/tests/gl1.gpickle.bz2`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/gw1.gpickle.bz2` & `networkx-3.3rc0/networkx/algorithms/flow/tests/gw1.gpickle.bz2`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/netgen-2.gpickle.bz2` & `networkx-3.3rc0/networkx/algorithms/flow/tests/netgen-2.gpickle.bz2`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/test_gomory_hu.py` & `networkx-3.3rc0/networkx/algorithms/flow/tests/test_gomory_hu.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/test_maxflow.py` & `networkx-3.3rc0/networkx/algorithms/flow/tests/test_maxflow.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/test_maxflow_large_graph.py` & `networkx-3.3rc0/networkx/algorithms/flow/tests/test_maxflow_large_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/test_mincost.py` & `networkx-3.3rc0/networkx/algorithms/flow/tests/test_mincost.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/test_networksimplex.py` & `networkx-3.3rc0/networkx/algorithms/flow/tests/test_networksimplex.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/tests/wlm3.gpickle.bz2` & `networkx-3.3rc0/networkx/algorithms/flow/tests/wlm3.gpickle.bz2`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/flow/utils.py` & `networkx-3.3rc0/networkx/algorithms/flow/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -68,15 +68,15 @@
     def is_reached(self):
         return self._work >= self._threshold
 
     def clear_work(self):
         self._work = 0
 
 
-@nx._dispatch(edge_attrs={"capacity": float("inf")})
+@nx._dispatchable(edge_attrs={"capacity": float("inf")}, returns_graph=True)
 def build_residual_network(G, capacity):
     """Build a residual network and initialize a zero flow.
 
     The residual network :samp:`R` from an input graph :samp:`G` has the
     same nodes as :samp:`G`. :samp:`R` is a DiGraph that contains a pair
     of edges :samp:`(u, v)` and :samp:`(v, u)` iff :samp:`(u, v)` is not a
     self-loop, and at least one of :samp:`(u, v)` and :samp:`(v, u)` exists
@@ -150,15 +150,15 @@
 
     # Record the value simulating infinity.
     R.graph["inf"] = inf
 
     return R
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs="R",
     preserve_edge_attrs={"R": {"capacity": float("inf")}},
     preserve_graph_attrs=True,
 )
 def detect_unboundedness(R, s, t):
     """Detect an infinite-capacity s-t path in R."""
     q = deque([s])
@@ -172,15 +172,15 @@
                     raise nx.NetworkXUnbounded(
                         "Infinite capacity path, flow unbounded above."
                     )
                 seen.add(v)
                 q.append(v)
 
 
-@nx._dispatch(graphs={"G": 0, "R": 1}, preserve_edge_attrs={"R": {"flow": None}})
+@nx._dispatchable(graphs={"G": 0, "R": 1}, preserve_edge_attrs={"R": {"flow": None}})
 def build_flow_dict(G, R):
     """Build a flow dictionary from a residual network."""
     flow_dict = {}
     for u in G:
         flow_dict[u] = {v: 0 for v in G[u]}
         flow_dict[u].update(
             (v, attr["flow"]) for v, attr in R[u].items() if attr["flow"] > 0
```

### Comparing `networkx-3.2rc0/networkx/algorithms/graph_hashing.py` & `networkx-3.3rc0/networkx/algorithms/graph_hashing.py`

 * *Files 11% similar despite different names*

```diff
@@ -33,46 +33,46 @@
     label_list = []
     for nbr in G.neighbors(node):
         prefix = "" if edge_attr is None else str(G[node][nbr][edge_attr])
         label_list.append(prefix + node_labels[nbr])
     return node_labels[node] + "".join(sorted(label_list))
 
 
-@nx._dispatch(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
+@nx._dispatchable(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
 def weisfeiler_lehman_graph_hash(
     G, edge_attr=None, node_attr=None, iterations=3, digest_size=16
 ):
     """Return Weisfeiler Lehman (WL) graph hash.
 
-    The function iteratively aggregates and hashes neighbourhoods of each node.
+    The function iteratively aggregates and hashes neighborhoods of each node.
     After each node's neighbors are hashed to obtain updated node labels,
     a hashed histogram of resulting labels is returned as the final hash.
 
     Hashes are identical for isomorphic graphs and strong guarantees that
     non-isomorphic graphs will get different hashes. See [1]_ for details.
 
     If no node or edge attributes are provided, the degree of each node
     is used as its initial label.
     Otherwise, node and/or edge labels are used to compute the hash.
 
     Parameters
     ----------
-    G: graph
+    G : graph
         The graph to be hashed.
         Can have node and/or edge attributes. Can also have no attributes.
-    edge_attr: string, default=None
+    edge_attr : string, optional (default=None)
         The key in edge attribute dictionary to be used for hashing.
         If None, edge labels are ignored.
-    node_attr: string, default=None
+    node_attr: string, optional (default=None)
         The key in node attribute dictionary to be used for hashing.
         If None, and no edge_attr given, use the degrees of the nodes as labels.
-    iterations: int, default=3
+    iterations: int, optional (default=3)
         Number of neighbor aggregations to perform.
         Should be larger for larger graphs.
-    digest_size: int, default=16
+    digest_size: int, optional (default=16)
         Size (in bits) of blake2b hash digest to use for hashing node labels.
 
     Returns
     -------
     h : string
         Hexadecimal string corresponding to hash of the input graph.
 
@@ -156,45 +156,51 @@
         # sort the counter, extend total counts
         subgraph_hash_counts.extend(sorted(counter.items(), key=lambda x: x[0]))
 
     # hash the final counter
     return _hash_label(str(tuple(subgraph_hash_counts)), digest_size)
 
 
-@nx._dispatch(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
+@nx._dispatchable(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
 def weisfeiler_lehman_subgraph_hashes(
-    G, edge_attr=None, node_attr=None, iterations=3, digest_size=16
+    G,
+    edge_attr=None,
+    node_attr=None,
+    iterations=3,
+    digest_size=16,
+    include_initial_labels=False,
 ):
     """
     Return a dictionary of subgraph hashes by node.
 
     Dictionary keys are nodes in `G`, and values are a list of hashes.
     Each hash corresponds to a subgraph rooted at a given node u in `G`.
     Lists of subgraph hashes are sorted in increasing order of depth from
     their root node, with the hash at index i corresponding to a subgraph
     of nodes at most i edges distance from u. Thus, each list will contain
-    ``iterations + 1`` elements - a hash for a subgraph at each depth, and
-    additionally a hash of the initial node label (or equivalently a
-    subgraph of depth 0)
+    `iterations` elements - a hash for a subgraph at each depth. If
+    `include_initial_labels` is set to `True`, each list will additionally
+    have contain a hash of the initial node label (or equivalently a
+    subgraph of depth 0) prepended, totalling ``iterations + 1`` elements.
 
-    The function iteratively aggregates and hashes neighbourhoods of each node.
+    The function iteratively aggregates and hashes neighborhoods of each node.
     This is achieved for each step by replacing for each node its label from
     the previous iteration with its hashed 1-hop neighborhood aggregate.
     The new node label is then appended to a list of node labels for each
     node.
 
-    To aggregate neighborhoods at each step for a node $n$, all labels of
-    nodes adjacent to $n$ are concatenated. If the `edge_attr` parameter is set,
+    To aggregate neighborhoods for a node $u$ at each step, all labels of
+    nodes adjacent to $u$ are concatenated. If the `edge_attr` parameter is set,
     labels for each neighboring node are prefixed with the value of this attribute
-    along the connecting edge from this neighbor to node $n$. The resulting string
+    along the connecting edge from this neighbor to node $u$. The resulting string
     is then hashed to compress this information into a fixed digest size.
 
     Thus, at the $i$-th iteration, nodes within $i$ hops influence any given
-    hashed node label. We can therefore say that at depth $i$ for node $n$
-    we have a hash for a subgraph induced by the $2i$-hop neighborhood of $n$.
+    hashed node label. We can therefore say that at depth $i$ for node $u$
+    we have a hash for a subgraph induced by the $i$-hop neighborhood of $u$.
 
     The output can be used to to create general Weisfeiler-Lehman graph kernels,
     or generate features for graphs or nodes - for example to generate 'words' in
     a graph as seen in the 'graph2vec' algorithm.
     See [1]_ & [2]_ respectively for details.
 
     Hashes are identical for isomorphic subgraphs and there exist strong
@@ -203,66 +209,64 @@
 
     If no node or edge attributes are provided, the degree of each node
     is used as its initial label.
     Otherwise, node and/or edge labels are used to compute the hash.
 
     Parameters
     ----------
-    G: graph
+    G : graph
         The graph to be hashed.
         Can have node and/or edge attributes. Can also have no attributes.
-    edge_attr: string, default=None
+    edge_attr : string, optional (default=None)
         The key in edge attribute dictionary to be used for hashing.
         If None, edge labels are ignored.
-    node_attr: string, default=None
+    node_attr : string, optional (default=None)
         The key in node attribute dictionary to be used for hashing.
         If None, and no edge_attr given, use the degrees of the nodes as labels.
-    iterations: int, default=3
+        If None, and edge_attr is given, each node starts with an identical label.
+    iterations : int, optional (default=3)
         Number of neighbor aggregations to perform.
         Should be larger for larger graphs.
-    digest_size: int, default=16
+    digest_size : int, optional (default=16)
         Size (in bits) of blake2b hash digest to use for hashing node labels.
-        The default size is 16 bits
+        The default size is 16 bits.
+    include_initial_labels : bool, optional (default=False)
+        If True, include the hashed initial node label as the first subgraph
+        hash for each node.
 
     Returns
     -------
     node_subgraph_hashes : dict
         A dictionary with each key given by a node in G, and each value given
         by the subgraph hashes in order of depth from the key node.
 
     Examples
     --------
     Finding similar nodes in different graphs:
 
     >>> G1 = nx.Graph()
-    >>> G1.add_edges_from([
-    ...     (1, 2), (2, 3), (2, 4), (3, 5), (4, 6), (5, 7), (6, 7)
-    ... ])
+    >>> G1.add_edges_from([(1, 2), (2, 3), (2, 4), (3, 5), (4, 6), (5, 7), (6, 7)])
     >>> G2 = nx.Graph()
-    >>> G2.add_edges_from([
-    ...     (1, 3), (2, 3), (1, 6), (1, 5), (4, 6)
-    ... ])
+    >>> G2.add_edges_from([(1, 3), (2, 3), (1, 6), (1, 5), (4, 6)])
     >>> g1_hashes = nx.weisfeiler_lehman_subgraph_hashes(G1, iterations=3, digest_size=8)
     >>> g2_hashes = nx.weisfeiler_lehman_subgraph_hashes(G2, iterations=3, digest_size=8)
 
     Even though G1 and G2 are not isomorphic (they have different numbers of edges),
     the hash sequence of depth 3 for node 1 in G1 and node 5 in G2 are similar:
 
     >>> g1_hashes[1]
     ['a93b64973cfc8897', 'db1b43ae35a1878f', '57872a7d2059c1c0']
     >>> g2_hashes[5]
     ['a93b64973cfc8897', 'db1b43ae35a1878f', '1716d2a4012fa4bc']
 
     The first 2 WL subgraph hashes match. From this we can conclude that it's very
-    likely the neighborhood of 4 hops around these nodes are isomorphic: each
-    iteration aggregates 1-hop neighbourhoods meaning hashes at depth $n$ are influenced
-    by every node within $2n$ hops.
+    likely the neighborhood of 2 hops around these nodes are isomorphic.
 
-    However the neighborhood of 6 hops is no longer isomorphic since their 3rd hash does
-    not match.
+    However the 3-hop neighborhoods of ``G1`` and ``G2`` are not isomorphic since the
+    3rd hashes in the lists above are not equal.
 
     These nodes may be candidates to be classified together since their local topology
     is similar.
 
     Notes
     -----
     To hash the full graph when subgraph hashes are not needed, use
@@ -299,15 +303,20 @@
             label = _neighborhood_aggregate(G, node, labels, edge_attr=edge_attr)
             hashed_label = _hash_label(label, digest_size)
             new_labels[node] = hashed_label
             node_subgraph_hashes[node].append(hashed_label)
         return new_labels
 
     node_labels = _init_node_labels(G, edge_attr, node_attr)
+    if include_initial_labels:
+        node_subgraph_hashes = {
+            k: [_hash_label(v, digest_size)] for k, v in node_labels.items()
+        }
+    else:
+        node_subgraph_hashes = defaultdict(list)
 
-    node_subgraph_hashes = defaultdict(list)
     for _ in range(iterations):
         node_labels = weisfeiler_lehman_step(
             G, node_labels, node_subgraph_hashes, edge_attr
         )
 
     return dict(node_subgraph_hashes)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/graphical.py` & `networkx-3.3rc0/networkx/algorithms/graphical.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     "is_pseudographical",
     "is_digraphical",
     "is_valid_degree_sequence_erdos_gallai",
     "is_valid_degree_sequence_havel_hakimi",
 ]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_graphical(sequence, method="eg"):
     """Returns True if sequence is a valid degree sequence.
 
     A degree sequence is valid if some graph can realize it.
 
     Parameters
     ----------
@@ -89,15 +89,15 @@
             num_degs[d] += 1
     # Reject sequence if it has odd sum or is oversaturated
     if dsum % 2 or dsum > n * (n - 1):
         raise nx.NetworkXUnfeasible
     return dmax, dmin, dsum, n, num_degs
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_valid_degree_sequence_havel_hakimi(deg_sequence):
     r"""Returns True if deg_sequence can be realized by a simple graph.
 
     The validation proceeds using the Havel-Hakimi theorem
     [havel1955]_, [hakimi1962]_, [CL1996]_.
     Worst-case run time is $O(s)$ where $s$ is the sum of the sequence.
 
@@ -179,15 +179,15 @@
         # Add back to the list any non-zero stubs that were removed
         for i in range(mslen):
             stub = modstubs[i]
             num_degs[stub], n = num_degs[stub] + 1, n + 1
     return True
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_valid_degree_sequence_erdos_gallai(deg_sequence):
     r"""Returns True if deg_sequence can be realized by a simple graph.
 
     The validation is done using the Erdős-Gallai theorem [EG1960]_.
 
     Parameters
     ----------
@@ -270,15 +270,15 @@
                 sum_jnj += (k + v) * num_degs[k + v]
             k += run_size
             if sum_deg > k * (n - 1) - k * sum_nj + sum_jnj:
                 return False
     return True
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_multigraphical(sequence):
     """Returns True if some multigraph can realize the sequence.
 
     Parameters
     ----------
     sequence : list
         A list of integers
@@ -321,15 +321,15 @@
             return False
         dsum, dmax = dsum + d, max(dmax, d)
     if dsum % 2 or dsum < 2 * dmax:
         return False
     return True
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_pseudographical(sequence):
     """Returns True if some pseudograph can realize the sequence.
 
     Every nonnegative integer sequence with an even sum is pseudographical
     (see [1]_).
 
     Parameters
@@ -368,15 +368,15 @@
     try:
         deg_sequence = nx.utils.make_list_of_ints(sequence)
     except nx.NetworkXError:
         return False
     return sum(deg_sequence) % 2 == 0 and min(deg_sequence) >= 0
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def is_digraphical(in_sequence, out_sequence):
     r"""Returns True if some directed graph can realize the in- and out-degree
     sequences.
 
     Parameters
     ----------
     in_sequence : list or iterable container
```

### Comparing `networkx-3.2rc0/networkx/algorithms/hierarchy.py` & `networkx-3.3rc0/networkx/algorithms/hierarchy.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Flow Hierarchy.
 """
 import networkx as nx
 
 __all__ = ["flow_hierarchy"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def flow_hierarchy(G, weight=None):
     """Returns the flow hierarchy of a directed network.
 
     Flow hierarchy is defined as the fraction of edges not participating
     in cycles in a directed graph [1]_.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/hybrid.py` & `networkx-3.3rc0/networkx/algorithms/hybrid.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import copy
 
 import networkx as nx
 
 __all__ = ["kl_connected_subgraph", "is_kl_connected"]
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def kl_connected_subgraph(G, k, l, low_memory=False, same_as_graph=False):
     """Returns the maximum locally `(k, l)`-connected subgraph of `G`.
 
     A graph is locally `(k, l)`-connected if for each edge `(u, v)` in the
     graph there are at least `l` edge-disjoint paths of length at most `k`
     joining `u` to `v`.
 
@@ -111,15 +111,15 @@
     # We looked through all edges and removed none of them.
     # So, H is the maximal (k,l)-connected subgraph of G
     if same_as_graph:
         return (H, graphOK)
     return H
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_kl_connected(G, k, l, low_memory=False):
     """Returns True if and only if `G` is locally `(k, l)`-connected.
 
     A graph is locally `(k, l)`-connected if for each edge `(u, v)` in the
     graph there are at least `l` edge-disjoint paths of length at most `k`
     joining `u` to `v`.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isolate.py` & `networkx-3.3rc0/networkx/algorithms/isolate.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Functions for identifying isolate (degree zero) nodes.
 """
 import networkx as nx
 
 __all__ = ["is_isolate", "isolates", "number_of_isolates"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_isolate(G, n):
     """Determines whether a node is an isolate.
 
     An *isolate* is a node with no neighbors (that is, with degree
     zero). For directed graphs, this means no in-neighbors and no
     out-neighbors.
 
@@ -35,15 +35,15 @@
     False
     >>> nx.is_isolate(G, 3)
     True
     """
     return G.degree(n) == 0
 
 
-@nx._dispatch
+@nx._dispatchable
 def isolates(G):
     """Iterator over isolates in the graph.
 
     An *isolate* is a node with no neighbors (that is, with degree
     zero). For directed graphs, this means no in-neighbors and no
     out-neighbors.
 
@@ -81,15 +81,15 @@
         >>> list(nx.isolates(G))
         [3]
 
     """
     return (n for n, d in G.degree() if d == 0)
 
 
-@nx._dispatch
+@nx._dispatchable
 def number_of_isolates(G):
     """Returns the number of isolates in the graph.
 
     An *isolate* is a node with no neighbors (that is, with degree
     zero). For directed graphs, this means no in-neighbors and no
     out-neighbors.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/ismags.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/ismags.py`

 * *Files 1% similar despite different names*

```diff
@@ -844,19 +844,19 @@
             # BASECASE
             if to_be_mapped == set(mapping.keys()):
                 yield {v: k for k, v in mapping.items()}
                 continue
             left_to_map = to_be_mapped - set(mapping.keys())
 
             new_candidates = candidates.copy()
-            sgn_neighbours = set(self.subgraph[sgn])
-            not_gn_neighbours = set(self.graph.nodes) - set(self.graph[gn])
+            sgn_nbrs = set(self.subgraph[sgn])
+            not_gn_nbrs = set(self.graph.nodes) - set(self.graph[gn])
             for sgn2 in left_to_map:
-                if sgn2 not in sgn_neighbours:
-                    gn2_options = not_gn_neighbours
+                if sgn2 not in sgn_nbrs:
+                    gn2_options = not_gn_nbrs
                 else:
                     # Get all edges to gn of the right color:
                     g_edges = self._edges_of_same_color(sgn, sgn2)
                     # FIXME directed graphs
                     # And all nodes involved in those which are connected to gn
                     gn2_options = {n for e in g_edges for n in e if gn in e}
                 # Node color compatibility should be taken care of by the
@@ -878,18 +878,15 @@
                     continue  # pragma: no cover
                 new_candidates[sgn2] = new_candidates[sgn2].union(
                     [frozenset(gn2_options)]
                 )
 
             # The next node is the one that is unmapped and has fewest
             # candidates
-            # Pylint disables because it's a one-shot function.
-            next_sgn = min(
-                left_to_map, key=lambda n: min(new_candidates[n], key=len)
-            )  # pylint: disable=cell-var-from-loop
+            next_sgn = min(left_to_map, key=lambda n: min(new_candidates[n], key=len))
             yield from self._map_nodes(
                 next_sgn,
                 new_candidates,
                 constraints,
                 mapping=mapping,
                 to_be_mapped=to_be_mapped,
             )
@@ -905,18 +902,15 @@
             to_be_mapped = {frozenset(self.subgraph.nodes)}
 
         # The LCS problem is basically a repeated subgraph isomorphism problem
         # with smaller and smaller subgraphs. We store the nodes that are
         # "part of" the subgraph in to_be_mapped, and we make it a little
         # smaller every iteration.
 
-        # pylint disable because it's guarded against by default value
-        current_size = len(
-            next(iter(to_be_mapped), [])
-        )  # pylint: disable=stop-iteration-return
+        current_size = len(next(iter(to_be_mapped), []))
 
         found_iso = False
         if current_size <= len(self.graph):
             # There's no point in trying to find isomorphisms of
             # graph >= subgraph if subgraph has more nodes than graph.
 
             # Try the isomorphism first with the nodes with lowest ID. So sort
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/isomorph.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/isomorph.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,15 @@
     "could_be_isomorphic",
     "fast_could_be_isomorphic",
     "faster_could_be_isomorphic",
     "is_isomorphic",
 ]
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1})
 def could_be_isomorphic(G1, G2):
     """Returns False if graphs are definitely not isomorphic.
     True does NOT guarantee isomorphism.
 
     Parameters
     ----------
     G1, G2 : graphs
@@ -56,15 +56,15 @@
     # OK...
     return True
 
 
 graph_could_be_isomorphic = could_be_isomorphic
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1})
 def fast_could_be_isomorphic(G1, G2):
     """Returns False if graphs are definitely not isomorphic.
 
     True does NOT guarantee isomorphism.
 
     Parameters
     ----------
@@ -97,15 +97,15 @@
     # OK...
     return True
 
 
 fast_graph_could_be_isomorphic = fast_could_be_isomorphic
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1})
 def faster_could_be_isomorphic(G1, G2):
     """Returns False if graphs are definitely not isomorphic.
 
     True does NOT guarantee isomorphism.
 
     Parameters
     ----------
@@ -130,15 +130,15 @@
     # OK...
     return True
 
 
 faster_graph_could_be_isomorphic = faster_could_be_isomorphic
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G1": 0, "G2": 1},
     preserve_edge_attrs="edge_match",
     preserve_node_attrs="node_match",
 )
 def is_isomorphic(G1, G2, node_match=None, edge_match=None):
     """Returns True if the graphs G1 and G2 are isomorphic and False otherwise.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/isomorphvf2.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/isomorphvf2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 """
 *************
 VF2 Algorithm
 *************
 
 An implementation of VF2 algorithm for graph isomorphism testing.
 
-The simplest interface to use this module is to call networkx.is_isomorphic().
+The simplest interface to use this module is to call the
+:func:`is_isomorphic <networkx.algorithms.isomorphism.is_isomorphic>`
+function.
 
 Introduction
 ------------
 
 The GraphMatcher and DiGraphMatcher are responsible for matching
 graphs or directed graphs in a predetermined manner.  This
 usually means a check for an isomorphism, though other checks
@@ -17,17 +19,18 @@
 can be checked for isomorphism to a second graph.
 
 Matching is done via syntactic feasibility. It is also possible
 to check for semantic feasibility. Feasibility, then, is defined
 as the logical AND of the two functions.
 
 To include a semantic check, the (Di)GraphMatcher class should be
-subclassed, and the semantic_feasibility() function should be
-redefined.  By default, the semantic feasibility function always
-returns True.  The effect of this is that semantics are not
+subclassed, and the
+:meth:`semantic_feasibility <networkx.algorithms.isomorphism.GraphMatcher.semantic_feasibility>`
+function should be redefined.  By default, the semantic feasibility function always
+returns ``True``.  The effect of this is that semantics are not
 considered in the matching of G1 and G2.
 
 Examples
 --------
 
 Suppose G1 and G2 are isomorphic graphs. Verification is as follows:
 
@@ -61,51 +64,52 @@
 
 
 Subgraph Isomorphism
 --------------------
 Graph theory literature can be ambiguous about the meaning of the
 above statement, and we seek to clarify it now.
 
-In the VF2 literature, a mapping M is said to be a graph-subgraph
-isomorphism iff M is an isomorphism between G2 and a subgraph of G1.
-Thus, to say that G1 and G2 are graph-subgraph isomorphic is to say
-that a subgraph of G1 is isomorphic to G2.
-
-Other literature uses the phrase 'subgraph isomorphic' as in 'G1 does
-not have a subgraph isomorphic to G2'.  Another use is as an in adverb
-for isomorphic.  Thus, to say that G1 and G2 are subgraph isomorphic
-is to say that a subgraph of G1 is isomorphic to G2.
+In the VF2 literature, a mapping `M` is said to be a graph-subgraph
+isomorphism iff `M` is an isomorphism between `G2` and a subgraph of `G1`.
+Thus, to say that `G1` and `G2` are graph-subgraph isomorphic is to say
+that a subgraph of `G1` is isomorphic to `G2`.
+
+Other literature uses the phrase 'subgraph isomorphic' as in '`G1` does
+not have a subgraph isomorphic to `G2`'.  Another use is as an in adverb
+for isomorphic.  Thus, to say that `G1` and `G2` are subgraph isomorphic
+is to say that a subgraph of `G1` is isomorphic to `G2`.
 
 Finally, the term 'subgraph' can have multiple meanings. In this
 context, 'subgraph' always means a 'node-induced subgraph'. Edge-induced
 subgraph isomorphisms are not directly supported, but one should be
-able to perform the check by making use of nx.line_graph(). For
+able to perform the check by making use of
+:func:`line_graph <networkx.generators.line.line_graph>`. For
 subgraphs which are not induced, the term 'monomorphism' is preferred
 over 'isomorphism'.
 
-Let G=(N,E) be a graph with a set of nodes N and set of edges E.
+Let ``G = (N, E)`` be a graph with a set of nodes `N` and set of edges `E`.
 
-If G'=(N',E') is a subgraph, then:
-    N' is a subset of N
-    E' is a subset of E
-
-If G'=(N',E') is a node-induced subgraph, then:
-    N' is a subset of N
-    E' is the subset of edges in E relating nodes in N'
-
-If G'=(N',E') is an edge-induced subgraph, then:
-    N' is the subset of nodes in N related by edges in E'
-    E' is a subset of E
-
-If G'=(N',E') is a monomorphism, then:
-    N' is a subset of N
-    E' is a subset of the set of edges in E relating nodes in N'
+If ``G' = (N', E')`` is a subgraph, then:
+    `N'` is a subset of `N` and
+    `E'` is a subset of `E`.
+
+If ``G' = (N', E')`` is a node-induced subgraph, then:
+    `N'` is a subset of `N` and
+    `E'` is the subset of edges in `E` relating nodes in `N'`.
+
+If `G' = (N', E')` is an edge-induced subgraph, then:
+    `N'` is the subset of nodes in `N` related by edges in `E'` and
+    `E'` is a subset of `E`.
+
+If `G' = (N', E')` is a monomorphism, then:
+    `N'` is a subset of `N` and
+    `E'` is a subset of the set of edges in `E` relating nodes in `N'`.
 
-Note that if G' is a node-induced subgraph of G, then it is always a
-subgraph monomorphism of G, but the opposite is not always true, as a
+Note that if `G'` is a node-induced subgraph of `G`, then it is always a
+subgraph monomorphism of `G`, but the opposite is not always true, as a
 monomorphism can have fewer edges.
 
 References
 ----------
 [1]   Luigi P. Cordella, Pasquale Foggia, Carlo Sansone, Mario Vento,
       "A (Sub)Graph Isomorphism Algorithm for Matching Large Graphs",
       IEEE Transactions on Pattern Analysis and Machine Intelligence,
@@ -116,15 +120,16 @@
       Algorithm for Matching Large Graphs", 3rd IAPR-TC15 Workshop
       on Graph-based Representations in Pattern Recognition, Cuen,
       pp. 149-159, 2001.
       https://www.researchgate.net/publication/200034365_An_Improved_Algorithm_for_Matching_Large_Graphs
 
 See Also
 --------
-syntactic_feasibility(), semantic_feasibility()
+:meth:`semantic_feasibility <networkx.algorithms.isomorphism.GraphMatcher.semantic_feasibility>`
+:meth:`syntactic_feasibility <networkx.algorithms.isomorphism.GraphMatcher.syntactic_feasibility>`
 
 Notes
 -----
 
 The implementation handles both directed and undirected graphs as well
 as multigraphs.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/matchhelpers.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/matchhelpers.py`

 * *Files 0% similar despite different names*

```diff
@@ -307,15 +307,14 @@
     --------
     >>> from operator import eq
     >>> from math import isclose
     >>> from networkx.algorithms.isomorphism import generic_node_match
     >>> nm = generic_node_match("weight", 1.0, isclose)
     >>> nm = generic_node_match("color", "red", eq)
     >>> nm = generic_node_match(["weight", "color"], [1.0, "red"], [isclose, eq])
-    ...
 
     """
 
     # This is slow, but generic.
     # We must test every possible isomorphism between the edges.
     if isinstance(attr, str):
         attr = [attr]
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/temporalisomorphvf2.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/temporalisomorphvf2.py`

 * *Files 2% similar despite different names*

```diff
@@ -85,17 +85,15 @@
 
         >>> from networkx.algorithms import isomorphism
         >>> from datetime import timedelta
         >>> G1 = nx.Graph(nx.path_graph(4, create_using=nx.Graph()))
 
         >>> G2 = nx.Graph(nx.path_graph(4, create_using=nx.Graph()))
 
-        >>> GM = isomorphism.TimeRespectingGraphMatcher(
-        ...     G1, G2, "date", timedelta(days=1)
-        ... )
+        >>> GM = isomorphism.TimeRespectingGraphMatcher(G1, G2, "date", timedelta(days=1))
         """
         self.temporal_attribute_name = temporal_attribute_name
         self.delta = delta
         super().__init__(G1, G2)
 
     def one_hop(self, Gx, Gx_node, neighbors):
         """
@@ -154,17 +152,15 @@
 
         >>> from networkx.algorithms import isomorphism
         >>> from datetime import timedelta
         >>> G1 = nx.DiGraph(nx.path_graph(4, create_using=nx.DiGraph()))
 
         >>> G2 = nx.DiGraph(nx.path_graph(4, create_using=nx.DiGraph()))
 
-        >>> GM = isomorphism.TimeRespectingDiGraphMatcher(
-        ...     G1, G2, "date", timedelta(days=1)
-        ... )
+        >>> GM = isomorphism.TimeRespectingDiGraphMatcher(G1, G2, "date", timedelta(days=1))
         """
         self.temporal_attribute_name = temporal_attribute_name
         self.delta = delta
         super().__init__(G1, G2)
 
     def get_pred_dates(self, Gx, Gx_node, core_x, pred):
         """
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.A99` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.A99`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.B99` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/iso_r01_s80.B99`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.B99` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/si2_b06_m200.B99`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_ismags.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_ismags.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_isomorphism.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_isomorphism.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+import pytest
+
 import networkx as nx
 from networkx.algorithms import isomorphism as iso
 
 
 class TestIsomorph:
     @classmethod
     def setup_class(cls):
@@ -34,7 +36,13 @@
         assert iso.faster_could_be_isomorphic(self.G3, self.G2)
         assert not iso.faster_could_be_isomorphic(self.G3, self.G5)
         assert not iso.faster_could_be_isomorphic(self.G1, self.G6)
 
     def test_is_isomorphic(self):
         assert iso.is_isomorphic(self.G1, self.G2)
         assert not iso.is_isomorphic(self.G1, self.G4)
+        assert iso.is_isomorphic(self.G1.to_directed(), self.G2.to_directed())
+        assert not iso.is_isomorphic(self.G1.to_directed(), self.G4.to_directed())
+        with pytest.raises(
+            nx.NetworkXError, match="Graphs G1 and G2 are not of the same type."
+        ):
+            iso.is_isomorphic(self.G1.to_directed(), self.G1)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_isomorphvf2.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_isomorphvf2.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_match_helpers.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_match_helpers.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_temporalisomorphvf2.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_temporalisomorphvf2.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_tree_isomorphism.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,18 +1,28 @@
 import random
 import time
 
+import pytest
+
 import networkx as nx
 from networkx.algorithms.isomorphism.tree_isomorphism import (
     rooted_tree_isomorphism,
     tree_isomorphism,
 )
 from networkx.classes.function import is_directed
 
 
+@pytest.mark.parametrize("graph_constructor", (nx.DiGraph, nx.MultiGraph))
+def test_tree_isomorphism_raises_on_directed_and_multigraphs(graph_constructor):
+    t1 = graph_constructor([(0, 1)])
+    t2 = graph_constructor([(1, 2)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.isomorphism.tree_isomorphism(t1, t2)
+
+
 # have this work for graph
 # given two trees (either the directed or undirected)
 # transform t2 according to the isomorphism
 # and confirm it is identical to t1
 # randomize the order of the edges when constructing
 def check_isomorphism(t1, t2, isomorphism):
     # get the name of t1, given the name in t2
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2pp.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2pp.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2pp_helpers.py`

 * *Files 1% similar despite different names*

```diff
@@ -53,16 +53,17 @@
 
         nx.set_node_attributes(G1, dict(zip(G1, it.cycle(labels_many))), "label")
         nx.set_node_attributes(
             G2,
             dict(zip(G2, it.cycle(labels_many))),
             "label",
         )
-        l1, l2 = nx.get_node_attributes(G1, "label"), nx.get_node_attributes(
-            G2, "label"
+        l1, l2 = (
+            nx.get_node_attributes(G1, "label"),
+            nx.get_node_attributes(G2, "label"),
         )
 
         gparams = _GraphParameters(
             G1,
             G2,
             l1,
             l2,
@@ -114,16 +115,17 @@
         G2 = G1.copy()
         nx.set_node_attributes(G1, dict(zip(G1, it.cycle(labels))), "label")
         nx.set_node_attributes(
             G2,
             dict(zip(G2, it.cycle(labels))),
             "label",
         )
-        l1, l2 = nx.get_node_attributes(G1, "label"), nx.get_node_attributes(
-            G2, "label"
+        l1, l2 = (
+            nx.get_node_attributes(G1, "label"),
+            nx.get_node_attributes(G2, "label"),
         )
         gparams = _GraphParameters(
             G1,
             G2,
             l1,
             l2,
             nx.utils.groups(l1),
@@ -151,16 +153,17 @@
         G2.nodes[0]["label"] = "black"
         G2.nodes[1]["label"] = "blue"
         G2.nodes[2]["label"] = "blue"
         G2.nodes[3]["label"] = "red"
         G2.nodes[4]["label"] = "red"
         G2.nodes[5]["label"] = "blue"
 
-        l1, l2 = nx.get_node_attributes(G1, "label"), nx.get_node_attributes(
-            G2, "label"
+        l1, l2 = (
+            nx.get_node_attributes(G1, "label"),
+            nx.get_node_attributes(G2, "label"),
         )
         gparams = _GraphParameters(
             G1,
             G2,
             l1,
             l2,
             nx.utils.groups(l1),
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tests/test_vf2userfunc.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tests/test_vf2userfunc.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/tree_isomorphism.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/tree_isomorphism.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
 import networkx as nx
 from networkx.utils.decorators import not_implemented_for
 
 __all__ = ["rooted_tree_isomorphism", "tree_isomorphism"]
 
 
-@nx._dispatch(graphs={"t1": 0, "t2": 2})
+@nx._dispatchable(graphs={"t1": 0, "t2": 2}, returns_graph=True)
 def root_trees(t1, root1, t2, root2):
     """Create a single digraph dT of free trees t1 and t2
     #   with roots root1 and root2 respectively
     # rename the nodes with consecutive integers
     # so that all nodes get a unique name between both trees
 
     # our new "fake" root node is 0
@@ -68,15 +68,15 @@
     for old, new in namemap2.items():
         namemap[new] = old
 
     return (dT, namemap, newroot1, newroot2)
 
 
 # figure out the level of each node, with 0 at root
-@nx._dispatch
+@nx._dispatchable
 def assign_levels(G, root):
     level = {}
     level[root] = 0
     for v1, v2 in nx.bfs_edges(G, root):
         level[v2] = level[v1] + 1
 
     return level
@@ -98,15 +98,15 @@
     # make sure tree1 comes first
     assert v < w
     M.append((v, w))
     for i, (x, y) in enumerate(zip(ordered_children[v], ordered_children[w])):
         generate_isomorphism(x, y, M, ordered_children)
 
 
-@nx._dispatch(graphs={"t1": 0, "t2": 2})
+@nx._dispatchable(graphs={"t1": 0, "t2": 2})
 def rooted_tree_isomorphism(t1, root1, t2, root2):
     """
     Given two rooted trees `t1` and `t2`,
     with roots `root1` and `root2` respectively
     this routine will determine if they are isomorphic.
 
     These trees may be either directed or undirected,
@@ -205,16 +205,17 @@
         # get the mapping back in terms of the old names
         # return in sorted order for neatness
         isomorphism = [(namemap[u], namemap[v]) for (u, v) in isomorphism]
 
     return isomorphism
 
 
-@not_implemented_for("directed", "multigraph")
-@nx._dispatch(graphs={"t1": 0, "t2": 1})
+@not_implemented_for("directed")
+@not_implemented_for("multigraph")
+@nx._dispatchable(graphs={"t1": 0, "t2": 1})
 def tree_isomorphism(t1, t2):
     """
     Given two undirected (or free) trees `t1` and `t2`,
     this routine will determine if they are isomorphic.
     It returns the isomorphism, a mapping of the nodes of `t1` onto the nodes
     of `t2`, such that two trees are then identical.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/vf2pp.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/vf2pp.py`

 * *Files 1% similar despite different names*

```diff
@@ -93,15 +93,15 @@
         "T2_in",
         "T2_tilde",
         "T2_tilde_in",
     ],
 )
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
 def vf2pp_isomorphism(G1, G2, node_label=None, default_label=None):
     """Return an isomorphic mapping between `G1` and `G2` if it exists.
 
     Parameters
     ----------
     G1, G2 : NetworkX Graph or MultiGraph instances.
         The two graphs to check for isomorphism.
@@ -124,15 +124,15 @@
     try:
         mapping = next(vf2pp_all_isomorphisms(G1, G2, node_label, default_label))
         return mapping
     except StopIteration:
         return None
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
 def vf2pp_is_isomorphic(G1, G2, node_label=None, default_label=None):
     """Examines whether G1 and G2 are isomorphic.
 
     Parameters
     ----------
     G1, G2 : NetworkX Graph or MultiGraph instances.
         The two graphs to check for isomorphism.
@@ -153,15 +153,15 @@
         True if the two graphs are isomorphic, False otherwise.
     """
     if vf2pp_isomorphism(G1, G2, node_label, default_label) is not None:
         return True
     return False
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1}, node_attrs={"node_label": "default_label"})
 def vf2pp_all_isomorphisms(G1, G2, node_label=None, default_label=None):
     """Yields all the possible mappings between G1 and G2.
 
     Parameters
     ----------
     G1, G2 : NetworkX Graph or MultiGraph instances.
         The two graphs to check for isomorphism.
@@ -472,34 +472,34 @@
     -------
     candidates: set
         The nodes from G2 which are candidates for u.
     """
     G1, G2, G1_labels, _, _, nodes_of_G2Labels, G2_nodes_of_degree = graph_params
     mapping, reverse_mapping, _, _, _, _, _, _, T2_tilde, _ = state_params
 
-    covered_neighbors = [nbr for nbr in G1[u] if nbr in mapping]
-    if not covered_neighbors:
+    covered_nbrs = [nbr for nbr in G1[u] if nbr in mapping]
+    if not covered_nbrs:
         candidates = set(nodes_of_G2Labels[G1_labels[u]])
         candidates.intersection_update(G2_nodes_of_degree[G1_degree[u]])
         candidates.intersection_update(T2_tilde)
         candidates.difference_update(reverse_mapping)
         if G1.is_multigraph():
             candidates.difference_update(
                 {
                     node
                     for node in candidates
                     if G1.number_of_edges(u, u) != G2.number_of_edges(node, node)
                 }
             )
         return candidates
 
-    nbr1 = covered_neighbors[0]
+    nbr1 = covered_nbrs[0]
     common_nodes = set(G2[mapping[nbr1]])
 
-    for nbr1 in covered_neighbors[1:]:
+    for nbr1 in covered_nbrs[1:]:
         common_nodes.intersection_update(G2[mapping[nbr1]])
 
     common_nodes.difference_update(reverse_mapping)
     common_nodes.intersection_update(G2_nodes_of_degree[G1_degree[u]])
     common_nodes.intersection_update(nodes_of_G2Labels[G1_labels[u]])
     if G1.is_multigraph():
         common_nodes.difference_update(
```

### Comparing `networkx-3.2rc0/networkx/algorithms/isomorphism/vf2userfunc.py` & `networkx-3.3rc0/networkx/algorithms/isomorphism/vf2userfunc.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/link_analysis/pagerank_alg.py` & `networkx-3.3rc0/networkx/algorithms/link_analysis/pagerank_alg.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from warnings import warn
 
 import networkx as nx
 
 __all__ = ["pagerank", "google_matrix"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def pagerank(
     G,
     alpha=0.85,
     personalization=None,
     max_iter=100,
     tol=1.0e-6,
     nstart=None,
@@ -168,15 +168,15 @@
         # check convergence, l1 norm
         err = sum(abs(x[n] - xlast[n]) for n in x)
         if err < N * tol:
             return x
     raise nx.PowerIterationFailedConvergence(max_iter)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def google_matrix(
     G, alpha=0.85, personalization=None, nodelist=None, weight="weight", dangling=None
 ):
     """Returns the Google matrix of the graph.
 
     Parameters
     ----------
```

### Comparing `networkx-3.2rc0/networkx/algorithms/link_analysis/tests/test_hits.py` & `networkx-3.3rc0/networkx/algorithms/link_analysis/tests/test_hits.py`

 * *Files 3% similar despite different names*

```diff
@@ -68,11 +68,11 @@
             _hits_scipy(G, max_iter=1)
         with pytest.raises(nx.PowerIterationFailedConvergence):
             _hits_python(G, max_iter=1)
         with pytest.raises(nx.PowerIterationFailedConvergence):
             _hits_scipy(G, max_iter=0)
         with pytest.raises(nx.PowerIterationFailedConvergence):
             _hits_python(G, max_iter=0)
-        with pytest.raises(ValueError):
+        with pytest.raises(nx.PowerIterationFailedConvergence):
             nx.hits(G, max_iter=0)
-        with pytest.raises(sp.sparse.linalg.ArpackNoConvergence):
+        with pytest.raises(nx.PowerIterationFailedConvergence):
             nx.hits(G, max_iter=1)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/link_analysis/tests/test_pagerank.py` & `networkx-3.3rc0/networkx/algorithms/link_analysis/tests/test_pagerank.py`

 * *Files 0% similar despite different names*

```diff
@@ -79,15 +79,15 @@
 
     def test_numpy_pagerank(self):
         G = self.G
         p = _pagerank_numpy(G, alpha=0.9)
         for n in G:
             assert p[n] == pytest.approx(G.pagerank[n], abs=1e-4)
 
-    # This additionally tests the @nx._dispatch mechanism, treating
+    # This additionally tests the @nx._dispatchable mechanism, treating
     # nx.google_matrix as if it were a re-implementation from another package
     @pytest.mark.parametrize("wrapper", [lambda x: x, dispatch_interface.convert])
     def test_google_matrix(self, wrapper):
         G = wrapper(self.G)
         M = nx.google_matrix(G, alpha=0.9, nodelist=sorted(G))
         _, ev = np.linalg.eig(M.T)
         p = ev[:, 0] / ev[:, 0].sum()
```

### Comparing `networkx-3.2rc0/networkx/algorithms/link_prediction.py` & `networkx-3.3rc0/networkx/algorithms/link_prediction.py`

 * *Files 5% similar despite different names*

```diff
@@ -33,20 +33,26 @@
 
     `ebunch` is an iterable of pairs of nodes. If not specified, all
     non-edges in the graph `G` will be used.
 
     """
     if ebunch is None:
         ebunch = nx.non_edges(G)
+    else:
+        for u, v in ebunch:
+            if u not in G:
+                raise nx.NodeNotFound(f"Node {u} not in G.")
+            if v not in G:
+                raise nx.NodeNotFound(f"Node {v} not in G.")
     return ((u, v, func(u, v)) for u, v in ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def resource_allocation_index(G, ebunch=None):
     r"""Compute the resource allocation index of all node pairs in ebunch.
 
     Resource allocation index of `u` and `v` is defined as
 
     .. math::
 
@@ -68,14 +74,22 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their resource allocation index.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.complete_graph(5)
     >>> preds = nx.resource_allocation_index(G, [(0, 1), (2, 3)])
     >>> for u, v, p in preds:
     ...     print(f"({u}, {v}) -> {p:.8f}")
     (0, 1) -> 0.75000000
@@ -93,15 +107,15 @@
         return sum(1 / G.degree(w) for w in nx.common_neighbors(G, u, v))
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def jaccard_coefficient(G, ebunch=None):
     r"""Compute the Jaccard coefficient of all node pairs in ebunch.
 
     Jaccard coefficient of nodes `u` and `v` is defined as
 
     .. math::
 
@@ -123,14 +137,22 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their Jaccard coefficient.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.complete_graph(5)
     >>> preds = nx.jaccard_coefficient(G, [(0, 1), (2, 3)])
     >>> for u, v, p in preds:
     ...     print(f"({u}, {v}) -> {p:.8f}")
     (0, 1) -> 0.60000000
@@ -143,22 +165,22 @@
            http://www.cs.cornell.edu/home/kleinber/link-pred.pdf
     """
 
     def predict(u, v):
         union_size = len(set(G[u]) | set(G[v]))
         if union_size == 0:
             return 0
-        return len(list(nx.common_neighbors(G, u, v))) / union_size
+        return len(nx.common_neighbors(G, u, v)) / union_size
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def adamic_adar_index(G, ebunch=None):
     r"""Compute the Adamic-Adar index of all node pairs in ebunch.
 
     Adamic-Adar index of `u` and `v` is defined as
 
     .. math::
 
@@ -182,14 +204,22 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their Adamic-Adar index.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.complete_graph(5)
     >>> preds = nx.adamic_adar_index(G, [(0, 1), (2, 3)])
     >>> for u, v, p in preds:
     ...     print(f"({u}, {v}) -> {p:.8f}")
     (0, 1) -> 2.16404256
@@ -206,15 +236,15 @@
         return sum(1 / log(G.degree(w)) for w in nx.common_neighbors(G, u, v))
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def common_neighbor_centrality(G, ebunch=None, alpha=0.8):
     r"""Return the CCPA score for each pair of nodes.
 
     Compute the Common Neighbor and Centrality based Parameterized Algorithm(CCPA)
     score of all node pairs in ebunch.
 
     CCPA score of `u` and `v` is defined as
@@ -260,14 +290,25 @@
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their Common Neighbor and Centrality based
         Parameterized Algorithm(CCPA) score.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NetworkXAlgorithmError
+        If self loops exsists in `ebunch` or in `G` (if `ebunch` is `None`).
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.complete_graph(5)
     >>> preds = nx.common_neighbor_centrality(G, [(0, 1), (2, 3)])
     >>> for u, v, p in preds:
     ...     print(f"({u}, {v}) -> {p}")
     (0, 1) -> 3.4000000000000004
@@ -282,37 +323,36 @@
     """
 
     # When alpha == 1, the CCPA score simplifies to the number of common neighbors.
     if alpha == 1:
 
         def predict(u, v):
             if u == v:
-                raise nx.NetworkXAlgorithmError("Self links are not supported")
+                raise nx.NetworkXAlgorithmError("Self loops are not supported")
 
-            return sum(1 for _ in nx.common_neighbors(G, u, v))
+            return len(nx.common_neighbors(G, u, v))
 
     else:
         spl = dict(nx.shortest_path_length(G))
         inf = float("inf")
 
         def predict(u, v):
             if u == v:
-                raise nx.NetworkXAlgorithmError("Self links are not supported")
+                raise nx.NetworkXAlgorithmError("Self loops are not supported")
             path_len = spl[u].get(v, inf)
 
-            return alpha * sum(1 for _ in nx.common_neighbors(G, u, v)) + (
-                1 - alpha
-            ) * (G.number_of_nodes() / path_len)
+            n_nbrs = len(nx.common_neighbors(G, u, v))
+            return alpha * n_nbrs + (1 - alpha) * len(G) / path_len
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def preferential_attachment(G, ebunch=None):
     r"""Compute the preferential attachment score of all node pairs in ebunch.
 
     Preferential attachment score of `u` and `v` is defined as
 
     .. math::
 
@@ -334,14 +374,22 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their preferential attachment score.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.complete_graph(5)
     >>> preds = nx.preferential_attachment(G, [(0, 1), (2, 3)])
     >>> for u, v, p in preds:
     ...     print(f"({u}, {v}) -> {p}")
     (0, 1) -> 16
@@ -358,15 +406,15 @@
         return G.degree(u) * G.degree(v)
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(node_attrs="community")
+@nx._dispatchable(node_attrs="community")
 def cn_soundarajan_hopcroft(G, ebunch=None, community="community"):
     r"""Count the number of common neighbors of all node pairs in ebunch
         using community information.
 
     For two nodes $u$ and $v$, this function computes the number of
     common neighbors and bonus one for each common neighbor belonging to
     the same community as $u$ and $v$. Mathematically,
@@ -398,14 +446,25 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their score.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NetworkXAlgorithmError
+        If no community information is available for a node in `ebunch` or in `G` (if `ebunch` is `None`).
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.path_graph(3)
     >>> G.nodes[0]["community"] = 0
     >>> G.nodes[1]["community"] = 0
     >>> G.nodes[2]["community"] = 0
     >>> preds = nx.cn_soundarajan_hopcroft(G, [(0, 2)])
@@ -422,26 +481,26 @@
        World Wide Web (WWW '12 Companion). ACM, New York, NY, USA, 607-608.
        http://doi.acm.org/10.1145/2187980.2188150
     """
 
     def predict(u, v):
         Cu = _community(G, u, community)
         Cv = _community(G, v, community)
-        cnbors = list(nx.common_neighbors(G, u, v))
+        cnbors = nx.common_neighbors(G, u, v)
         neighbors = (
             sum(_community(G, w, community) == Cu for w in cnbors) if Cu == Cv else 0
         )
         return len(cnbors) + neighbors
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(node_attrs="community")
+@nx._dispatchable(node_attrs="community")
 def ra_index_soundarajan_hopcroft(G, ebunch=None, community="community"):
     r"""Compute the resource allocation index of all node pairs in
     ebunch using community information.
 
     For two nodes $u$ and $v$, this function computes the resource
     allocation index considering only common neighbors belonging to the
     same community as $u$ and $v$. Mathematically,
@@ -473,14 +532,25 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their score.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NetworkXAlgorithmError
+        If no community information is available for a node in `ebunch` or in `G` (if `ebunch` is `None`).
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.Graph()
     >>> G.add_edges_from([(0, 1), (0, 2), (1, 3), (2, 3)])
     >>> G.nodes[0]["community"] = 0
     >>> G.nodes[1]["community"] = 0
     >>> G.nodes[2]["community"] = 1
@@ -509,15 +579,15 @@
         return sum(1 / G.degree(w) for w in cnbors if _community(G, w, community) == Cu)
 
     return _apply_prediction(G, predict, ebunch)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(node_attrs="community")
+@nx._dispatchable(node_attrs="community")
 def within_inter_cluster(G, ebunch=None, delta=0.001, community="community"):
     """Compute the ratio of within- and inter-cluster common neighbors
     of all node pairs in ebunch.
 
     For two nodes `u` and `v`, if a common neighbor `w` belongs to the
     same community as them, `w` is considered as within-cluster common
     neighbor of `u` and `v`. Otherwise, it is considered as
@@ -549,14 +619,26 @@
 
     Returns
     -------
     piter : iterator
         An iterator of 3-tuples in the form (u, v, p) where (u, v) is a
         pair of nodes and p is their WIC measure.
 
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is a `DiGraph`, a `Multigraph` or a `MultiDiGraph`.
+
+    NetworkXAlgorithmError
+        - If `delta` is less than or equal to zero.
+        - If no community information is available for a node in `ebunch` or in `G` (if `ebunch` is `None`).
+
+    NodeNotFound
+        If `ebunch` has a node that is not in `G`.
+
     Examples
     --------
     >>> G = nx.Graph()
     >>> G.add_edges_from([(0, 1), (0, 2), (0, 3), (1, 4), (2, 4), (3, 4)])
     >>> G.nodes[0]["community"] = 0
     >>> G.nodes[1]["community"] = 1
     >>> G.nodes[2]["community"] = 0
@@ -583,22 +665,24 @@
         raise nx.NetworkXAlgorithmError("Delta must be greater than zero")
 
     def predict(u, v):
         Cu = _community(G, u, community)
         Cv = _community(G, v, community)
         if Cu != Cv:
             return 0
-        cnbors = set(nx.common_neighbors(G, u, v))
+        cnbors = nx.common_neighbors(G, u, v)
         within = {w for w in cnbors if _community(G, w, community) == Cu}
         inter = cnbors - within
         return len(within) / (len(inter) + delta)
 
     return _apply_prediction(G, predict, ebunch)
 
 
 def _community(G, u, community):
     """Get the community of the given node."""
     node_u = G.nodes[u]
     try:
         return node_u[community]
     except KeyError as err:
-        raise nx.NetworkXAlgorithmError("No community information") from err
+        raise nx.NetworkXAlgorithmError(
+            f"No community information available for Node {u}"
+        ) from err
```

### Comparing `networkx-3.2rc0/networkx/algorithms/lowest_common_ancestors.py` & `networkx-3.3rc0/networkx/algorithms/lowest_common_ancestors.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     "all_pairs_lowest_common_ancestor",
     "tree_all_pairs_lowest_common_ancestor",
     "lowest_common_ancestor",
 ]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def all_pairs_lowest_common_ancestor(G, pairs=None):
     """Return the lowest common ancestor of all pairs or the provided pairs
 
     Parameters
     ----------
     G : NetworkX directed graph
 
@@ -108,15 +108,15 @@
                     common_ancestor = successor
                 yield ((v, w), common_ancestor)
 
     return generate_lca_from_pairs(G, pairs)
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def lowest_common_ancestor(G, node1, node2, default=None):
     """Compute the lowest common ancestor of the given pair of nodes.
 
     Parameters
     ----------
     G : NetworkX directed graph
 
@@ -146,15 +146,15 @@
     if ans:
         assert len(ans) == 1
         return ans[0][1]
     return default
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def tree_all_pairs_lowest_common_ancestor(G, root=None, pairs=None):
     r"""Yield the lowest common ancestor for sets of pairs in a tree.
 
     Parameters
     ----------
     G : NetworkX directed graph (must be a tree)
 
@@ -212,15 +212,15 @@
     if len(G) == 0:
         raise nx.NetworkXPointlessConcept("LCA meaningless on null graphs.")
 
     # Index pairs of interest for efficient lookup from either side.
     if pairs is not None:
         pair_dict = defaultdict(set)
         # See note on all_pairs_lowest_common_ancestor.
-        if not isinstance(pairs, (Mapping, Set)):
+        if not isinstance(pairs, Mapping | Set):
             pairs = set(pairs)
         for u, v in pairs:
             for n in (u, v):
                 if n not in G:
                     msg = f"The node {str(n)} is not in the digraph."
                     raise nx.NodeNotFound(msg)
             pair_dict[u].add(v)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/matching.py` & `networkx-3.3rc0/networkx/algorithms/matching.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     "min_weight_matching",
     "maximal_matching",
 ]
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def maximal_matching(G):
     r"""Find a maximal matching in the graph.
 
     A matching is a subset of edges in which no node occurs more than once.
     A maximal matching cannot add more edges and still be a matching.
 
     Parameters
@@ -78,15 +78,15 @@
             continue
         if u == v:
             raise nx.NetworkXError(f"Selfloops cannot appear in matchings {edge}")
         edges.add(edge)
     return edges
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_matching(G, matching):
     """Return True if ``matching`` is a valid matching of ``G``
 
     A *matching* in a graph is a set of edges in which no two distinct
     edges share a common endpoint. Each node is incident to at most one
     edge in the matching. The edges are said to be independent.
 
@@ -139,15 +139,15 @@
             return False
         if u in nodes or v in nodes:
             return False
         nodes.update(edge)
     return True
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_maximal_matching(G, matching):
     """Return True if ``matching`` is a maximal matching of ``G``
 
     A *maximal matching* in a graph is a matching in which adding any
     edge would cause the set to no longer be a valid matching.
 
     Parameters
@@ -201,15 +201,15 @@
         if (u, v) not in edges:
             # could add edge (u, v) to edges and have a bigger matching
             if u not in nodes and v not in nodes and u != v:
                 return False
     return True
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_perfect_matching(G, matching):
     """Return True if ``matching`` is a perfect matching for ``G``
 
     A *perfect matching* in a graph is a matching in which exactly one edge
     is incident upon each vertex.
 
     Parameters
@@ -255,15 +255,15 @@
             return False
         nodes.update(edge)
     return len(nodes) == len(G)
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def min_weight_matching(G, weight="weight"):
     """Computing a minimum-weight maximal matching of G.
 
     Use the maximum-weight algorithm with edge weights subtracted
     from the maximum weight of all edges.
 
     A matching is a subset of edges in which no node occurs more than once.
@@ -316,15 +316,15 @@
     edges = ((u, v, max_weight - w) for u, v, w in G_edges)
     InvG.add_weighted_edges_from(edges, weight=weight)
     return max_weight_matching(InvG, maxcardinality=True, weight=weight)
 
 
 @not_implemented_for("multigraph")
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def max_weight_matching(G, maxcardinality=False, weight="weight"):
     """Compute a maximum-weighted matching of G.
 
     A matching is a subset of edges in which no node occurs more than once.
     The weight of a matching is the sum of the weights of its edges.
     A maximal matching cannot add more edges and still be a matching.
     The cardinality of a matching is the number of matched edges.
@@ -406,15 +406,15 @@
         # the base and going round the blossom.
 
         # b.edges is the list of b's connecting edges, such that
         # b.edges[i] = (v, w) where v is a vertex in b.childs[i]
         # and w is a vertex in b.childs[wrap(i+1)].
 
         # If b is a top-level S-blossom,
-        # b.mybestedges is a list of least-slack edges to neighbouring
+        # b.mybestedges is a list of least-slack edges to neighboring
         # S-blossoms, or None if no such list has been computed yet.
         # This is used for efficient computation of delta3.
 
         # Generate the blossom's leaf vertices.
         def leaves(self):
             stack = [*self.childs]
             while stack:
@@ -667,15 +667,15 @@
             if mybestedge is None or kslack < mybestslack:
                 mybestedge = k
                 mybestslack = kslack
         bestedge[b] = mybestedge
 
     # Expand the given top-level blossom.
     def expandBlossom(b, endstage):
-        # This is an obnoxiously complicated recusive function for the sake of
+        # This is an obnoxiously complicated recursive function for the sake of
         # a stack-transformation.  So, we hack around the complexity by using
         # a trampoline pattern.  By yielding the arguments to each recursive
         # call, we keep the actual callstack flat.
 
         def _recurse(b, endstage):
             # Convert sub-blossoms into top-level blossoms.
             for s in b.childs:
@@ -734,20 +734,20 @@
                 label[w] = label[bw] = 2
                 labeledge[w] = labeledge[bw] = (v, w)
                 bestedge[bw] = None
                 # Continue along the blossom until we get back to entrychild.
                 j += jstep
                 while b.childs[j] != entrychild:
                     # Examine the vertices of the sub-blossom to see whether
-                    # it is reachable from a neighbouring S-vertex outside the
+                    # it is reachable from a neighboring S-vertex outside the
                     # expanding blossom.
                     bv = b.childs[j]
                     if label.get(bv) == 1:
                         # This sub-blossom just got label S through one of its
-                        # neighbours; leave it be.
+                        # neighbors; leave it be.
                         j += jstep
                         continue
                     if isinstance(bv, Blossom):
                         for v in bv.leaves():
                             if label.get(v):
                                 break
                     else:
@@ -783,15 +783,15 @@
             else:
                 stack.pop()
 
     # Swap matched/unmatched edges over an alternating path through blossom b
     # between vertex v and the base vertex. Keep blossom bookkeeping
     # consistent.
     def augmentBlossom(b, v):
-        # This is an obnoxiously complicated recusive function for the sake of
+        # This is an obnoxiously complicated recursive function for the sake of
         # a stack-transformation.  So, we hack around the complexity by using
         # a trampoline pattern.  By yielding the arguments to each recursive
         # call, we keep the actual callstack flat.
 
         def _recurse(b, v):
             # Bubble up through the blossom tree from vertex v to an immediate
             # sub-blossom of b.
@@ -968,19 +968,19 @@
             # Continue labeling until all vertices which are reachable
             # through an alternating path have got a label.
             while queue and not augmented:
                 # Take an S vertex from the queue.
                 v = queue.pop()
                 assert label[inblossom[v]] == 1
 
-                # Scan its neighbours:
+                # Scan its neighbors:
                 for w in G.neighbors(v):
                     if w == v:
                         continue  # ignore self-loops
-                    # w is a neighbour to v
+                    # w is a neighbor to v
                     bv = inblossom[v]
                     bw = inblossom[w]
                     if bv == bw:
                         # this edge is internal to a blossom; ignore it
                         continue
                     if (v, w) not in allowedge:
                         kslack = slack(v, w)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/minors/__init__.py` & `networkx-3.3rc0/networkx/algorithms/minors/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/minors/contraction.py` & `networkx-3.3rc0/networkx/algorithms/minors/contraction.py`

 * *Files 2% similar despite different names*

```diff
@@ -64,16 +64,17 @@
     The equivalence classes of this relation are `{0, 3, 6, 9}`, `{1, 4, 7}`,
     `{2, 5, 8}`: `0`, `3`, `6`, `9` are all divisible by `3` and leave zero
     remainder; `1`, `4`, `7` leave remainder `1`; while `2`, `5` and `8` leave
     remainder `2`. We can see this by calling `equivalence_classes` with
     `X` and a function implementation of `R`.
 
     >>> X = set(range(10))
-    >>> def mod3(x, y): return (x - y) % 3 == 0
-    >>> equivalence_classes(X, mod3)    # doctest: +SKIP
+    >>> def mod3(x, y):
+    ...     return (x - y) % 3 == 0
+    >>> equivalence_classes(X, mod3)  # doctest: +SKIP
     {frozenset({1, 4, 7}), frozenset({8, 2, 5}), frozenset({0, 9, 3, 6})}
     """
     # For simplicity of implementation, we initialize the return value as a
     # list of lists, then convert it to a set of sets at the end of the
     # function.
     blocks = []
     # Determine the equivalence class for each element of the iterable.
@@ -90,15 +91,15 @@
             # If the element y is not part of any known equivalence class, it
             # must be in its own, so we create a new singleton equivalence
             # class for it.
             blocks.append([y])
     return {frozenset(block) for block in blocks}
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight", returns_graph=True)
 def quotient_graph(
     G,
     partition,
     edge_relation=None,
     node_data=None,
     edge_data=None,
     weight="weight",
@@ -198,17 +199,15 @@
     Examples
     --------
     The quotient graph of the complete bipartite graph under the "same
     neighbors" equivalence relation is `K_2`. Under this relation, two nodes
     are equivalent if they are not adjacent but have the same neighbor set.
 
     >>> G = nx.complete_bipartite_graph(2, 3)
-    >>> same_neighbors = lambda u, v: (
-    ...     u not in G[v] and v not in G[u] and G[u] == G[v]
-    ... )
+    >>> same_neighbors = lambda u, v: (u not in G[v] and v not in G[u] and G[u] == G[v])
     >>> Q = nx.quotient_graph(G, same_neighbors)
     >>> K2 = nx.complete_graph(2)
     >>> nx.is_isomorphic(Q, K2)
     True
 
     The quotient graph of a directed graph under the "same strongly connected
     component" equivalence relation is the condensation of the graph (see
@@ -421,15 +420,17 @@
         # want the order of iteration to be the same for backward
         # compatibility with the nx.blockmodel() function.
         labels = {b: i for i, b in enumerate(partition)}
         H = nx.relabel_nodes(H, labels)
     return H
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(
+    preserve_all_attrs=True, mutates_input={"not copy": 4}, returns_graph=True
+)
 def contracted_nodes(G, u, v, self_loops=True, copy=True):
     """Returns the graph that results from contracting `u` and `v`.
 
     Node contraction identifies the two nodes as a single node incident to any
     edge that was incident to the original two nodes.
 
     Parameters
@@ -556,15 +557,17 @@
         H.nodes[u]["contraction"] = {v: v_data}
     return H
 
 
 identified_nodes = contracted_nodes
 
 
-@nx._dispatch(preserve_edge_attrs=True)
+@nx._dispatchable(
+    preserve_edge_attrs=True, mutates_input={"not copy": 3}, returns_graph=True
+)
 def contracted_edge(G, edge, self_loops=True, copy=True):
     """Returns the graph that results from contracting the specified edge.
 
     Edge contraction identifies the two endpoints of the edge as a single node
     incident to any edge that was incident to the original two nodes. A graph
     that results from edge contraction is called a *minor* of the original
     graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/minors/tests/test_contraction.py` & `networkx-3.3rc0/networkx/algorithms/minors/tests/test_contraction.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/mis.py` & `networkx-3.3rc0/networkx/algorithms/mis.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from networkx.utils import not_implemented_for, py_random_state
 
 __all__ = ["maximal_independent_set"]
 
 
 @not_implemented_for("directed")
 @py_random_state(2)
-@nx._dispatch
+@nx._dispatchable
 def maximal_independent_set(G, nodes=None, seed=None):
     """Returns a random maximal independent set guaranteed to contain
     a given set of nodes.
 
     An independent set is a set of nodes such that the subgraph
     of G induced by these nodes contains no edges. A maximal
     independent set is an independent set such that it is not possible
```

### Comparing `networkx-3.2rc0/networkx/algorithms/moral.py` & `networkx-3.3rc0/networkx/algorithms/moral.py`

 * *Files 9% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["moral_graph"]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def moral_graph(G):
     r"""Return the Moral Graph
 
     Returns the moralized graph of a given directed graph.
 
     Parameters
     ----------
```

### Comparing `networkx-3.2rc0/networkx/algorithms/node_classification.py` & `networkx-3.3rc0/networkx/algorithms/node_classification.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 """
 import networkx as nx
 
 __all__ = ["harmonic_function", "local_and_global_consistency"]
 
 
 @nx.utils.not_implemented_for("directed")
-@nx._dispatch(node_attrs="label_name")
+@nx._dispatchable(node_attrs="label_name")
 def harmonic_function(G, max_iter=30, label_name="label"):
     """Node classification by Harmonic function
 
     Function for computing Harmonic function algorithm by Zhu et al.
 
     Parameters
     ----------
@@ -101,15 +101,15 @@
     for _ in range(max_iter):
         F = (P @ F) + B
 
     return label_dict[np.argmax(F, axis=1)].tolist()
 
 
 @nx.utils.not_implemented_for("directed")
-@nx._dispatch(node_attrs="label_name")
+@nx._dispatchable(node_attrs="label_name")
 def local_and_global_consistency(G, alpha=0.99, max_iter=30, label_name="label"):
     """Node classification by Local and Global Consistency
 
     Function for computing Local and global consistency algorithm by Zhou et al.
 
     Parameters
     ----------
```

### Comparing `networkx-3.2rc0/networkx/algorithms/non_randomness.py` & `networkx-3.3rc0/networkx/algorithms/non_randomness.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["non_randomness"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def non_randomness(G, k=None, weight="weight"):
     """Compute the non-randomness of graph G.
 
     The first returned value nr is the sum of non-randomness values of all
     edges within the graph (where the non-randomness of an edge tends to be
     small when the two nodes linked by that edge are from two different
     communities).
@@ -53,15 +53,15 @@
     NetworkXError
         if the input graph contains self-loops.
 
     Examples
     --------
     >>> G = nx.karate_club_graph()
     >>> nr, nr_rd = nx.non_randomness(G, 2)
-    >>> nr, nr_rd = nx.non_randomness(G, 2, 'weight')
+    >>> nr, nr_rd = nx.non_randomness(G, 2, "weight")
 
     Notes
     -----
     This computes Eq. (4.4) and (4.5) in Ref. [1]_.
 
     If a weight field is passed, this algorithm will use the eigenvalues
     of the weighted adjacency matrix to compute Eq. (4.4) and (4.5).
@@ -80,15 +80,15 @@
         raise nx.NetworkXError("Graph must not contain self-loops")
 
     if k is None:
         k = len(tuple(nx.community.label_propagation_communities(G)))
 
     # eq. 4.4
     eigenvalues = np.linalg.eigvals(nx.to_numpy_array(G, weight=weight))
-    nr = np.real(np.sum(eigenvalues[:k]))
+    nr = float(np.real(np.sum(eigenvalues[:k])))
 
     n = G.number_of_nodes()
     m = G.number_of_edges()
     p = (2 * k * m) / (n * (n - k))
 
     # eq. 4.5
     nr_rd = (nr - ((n - 2 * k) * p + k)) / math.sqrt(2 * k * p * (1 - p))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/all.py` & `networkx-3.3rc0/networkx/algorithms/operators/all.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from itertools import chain, repeat
 
 import networkx as nx
 
 __all__ = ["union_all", "compose_all", "disjoint_union_all", "intersection_all"]
 
 
-@nx._dispatch(graphs="[graphs]", preserve_all_attrs=True)
+@nx._dispatchable(graphs="[graphs]", preserve_all_attrs=True, returns_graph=True)
 def union_all(graphs, rename=()):
     """Returns the union of all graphs.
 
     The graphs must be disjoint, otherwise an exception is raised.
 
     Parameters
     ----------
@@ -88,18 +88,17 @@
             R = G.__class__()
         elif G.is_directed() != R.is_directed():
             raise nx.NetworkXError("All graphs must be directed or undirected.")
         elif G.is_multigraph() != R.is_multigraph():
             raise nx.NetworkXError("All graphs must be graphs or multigraphs.")
         elif not seen_nodes.isdisjoint(G_nodes_set):
             raise nx.NetworkXError(
-                "The node sets of the graphs are not disjoint.",
-                "Use appropriate rename"
-                "=(G1prefix,G2prefix,...,GNprefix)"
-                "or use disjoint_union(G1,G2,...,GN).",
+                "The node sets of the graphs are not disjoint.\n"
+                "Use `rename` to specify prefixes for the graphs or use\n"
+                "disjoint_union(G1, G2, ..., GN)."
             )
 
         seen_nodes |= G_nodes_set
         R.graph.update(G.graph)
         R.add_nodes_from(G.nodes(data=True))
         R.add_edges_from(
             G.edges(keys=True, data=True) if G.is_multigraph() else G.edges(data=True)
@@ -107,15 +106,15 @@
 
     if R is None:
         raise ValueError("cannot apply union_all to an empty list")
 
     return R
 
 
-@nx._dispatch(graphs="[graphs]", preserve_all_attrs=True)
+@nx._dispatchable(graphs="[graphs]", preserve_all_attrs=True, returns_graph=True)
 def disjoint_union_all(graphs):
     """Returns the disjoint union of all graphs.
 
     This operation forces distinct integer node labels starting with 0
     for the first graph in the list and numbering consecutively.
 
     Parameters
@@ -161,15 +160,15 @@
             first_label += len(G)
 
     R = union_all(yield_relabeled(graphs))
 
     return R
 
 
-@nx._dispatch(graphs="[graphs]", preserve_all_attrs=True)
+@nx._dispatchable(graphs="[graphs]", preserve_all_attrs=True, returns_graph=True)
 def compose_all(graphs):
     """Returns the composition of all graphs.
 
     Composition is the simple union of the node sets and edge sets.
     The node sets of the supplied graphs need not be disjoint.
 
     Parameters
@@ -227,15 +226,15 @@
 
     if R is None:
         raise ValueError("cannot apply compose_all to an empty list")
 
     return R
 
 
-@nx._dispatch(graphs="[graphs]")
+@nx._dispatchable(graphs="[graphs]", returns_graph=True)
 def intersection_all(graphs):
     """Returns a new graph that contains only the nodes and the edges that exist in
     all graphs.
 
     Parameters
     ----------
     graphs : iterable
@@ -267,16 +266,19 @@
     >>> g.add_edge(0, 1)
 
     >>> h = g.copy()
     >>> h.nodes[0]["capacity"] = 2
 
     >>> gh = nx.intersection_all([g, h])
 
-    >>> new_node_attr = {n: min(*(anyG.nodes[n].get('capacity', float('inf')) for anyG in [g, h])) for n in gh}
-    >>> nx.set_node_attributes(gh, new_node_attr, 'new_capacity')
+    >>> new_node_attr = {
+    ...     n: min(*(anyG.nodes[n].get("capacity", float("inf")) for anyG in [g, h]))
+    ...     for n in gh
+    ... }
+    >>> nx.set_node_attributes(gh, new_node_attr, "new_capacity")
     >>> gh.nodes(data=True)
     NodeDataView({0: {'new_capacity': 2}, 1: {'new_capacity': 3}})
 
     Examples
     --------
     >>> G1 = nx.Graph([(1, 2), (2, 3)])
     >>> G2 = nx.Graph([(2, 3), (3, 4)])
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/binary.py` & `networkx-3.3rc0/networkx/algorithms/operators/binary.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,15 +11,15 @@
     "difference",
     "symmetric_difference",
     "full_join",
 ]
 _G_H = {"G": 0, "H": 1}
 
 
-@nx._dispatch(graphs=_G_H, preserve_all_attrs=True)
+@nx._dispatchable(graphs=_G_H, preserve_all_attrs=True, returns_graph=True)
 def union(G, H, rename=()):
     """Combine graphs G and H. The names of nodes must be unique.
 
     A name collision between the graphs will raise an exception.
 
     A renaming facility is provided to avoid name collisions.
 
@@ -67,15 +67,15 @@
     EdgeView([('G0', 'G1'), ('G0', 'G2'), ('G1', 'G2'), ('H0', 'H1'), ('H0', 'H3'), ('H1', 'H3'), ('H1', 'H2')])
 
 
     """
     return nx.union_all([G, H], rename)
 
 
-@nx._dispatch(graphs=_G_H, preserve_all_attrs=True)
+@nx._dispatchable(graphs=_G_H, preserve_all_attrs=True, returns_graph=True)
 def disjoint_union(G, H):
     """Combine graphs G and H. The nodes are assumed to be unique (disjoint).
 
     This algorithm automatically relabels nodes to avoid name collisions.
 
     Parameters
     ----------
@@ -121,15 +121,15 @@
     NodeDataView({0: {'key1': 5}, 1: {}, 2: {}, 3: {'key2': 10}, 4: {}, 5: {}, 6: {}})
     >>> U.edges
     EdgeView([(0, 1), (0, 2), (1, 2), (3, 4), (4, 6), (5, 6)])
     """
     return nx.disjoint_union_all([G, H])
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, returns_graph=True)
 def intersection(G, H):
     """Returns a new graph that contains only the nodes and the edges that exist in
     both G and H.
 
     Parameters
     ----------
     G,H : graph
@@ -166,15 +166,15 @@
     NodeView((0, 1, 2))
     >>> R.edges
     EdgeView([(1, 2)])
     """
     return nx.intersection_all([G, H])
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, returns_graph=True)
 def difference(G, H):
     """Returns a new graph that contains the edges that exist in G but not in H.
 
     The node sets of H and G must be the same.
 
     Parameters
     ----------
@@ -206,30 +206,30 @@
     NodeView((0, 1, 2, 3))
     >>> R.edges
     EdgeView([(0, 2), (1, 3)])
     """
     # create new graph
     if not G.is_multigraph() == H.is_multigraph():
         raise nx.NetworkXError("G and H must both be graphs or multigraphs.")
-    R = nx.create_empty_copy(G)
+    R = nx.create_empty_copy(G, with_data=False)
 
     if set(G) != set(H):
         raise nx.NetworkXError("Node sets of graphs not equal")
 
     if G.is_multigraph():
         edges = G.edges(keys=True)
     else:
         edges = G.edges()
     for e in edges:
         if not H.has_edge(*e):
             R.add_edge(*e)
     return R
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, returns_graph=True)
 def symmetric_difference(G, H):
     """Returns new graph with edges that exist in either G or H but not both.
 
     The node sets of H and G must be the same.
 
     Parameters
     ----------
@@ -254,15 +254,15 @@
     NodeView((0, 1, 2, 3))
     >>> R.edges
     EdgeView([(0, 2), (0, 3), (1, 3)])
     """
     # create new graph
     if not G.is_multigraph() == H.is_multigraph():
         raise nx.NetworkXError("G and H must both be graphs or multigraphs.")
-    R = nx.create_empty_copy(G)
+    R = nx.create_empty_copy(G, with_data=False)
 
     if set(G) != set(H):
         raise nx.NetworkXError("Node sets of graphs not equal")
 
     gnodes = set(G)  # set of nodes in G
     hnodes = set(H)  # set of nodes in H
     nodes = gnodes.symmetric_difference(hnodes)
@@ -284,15 +284,15 @@
         edges = H.edges()
     for e in edges:
         if not G.has_edge(*e):
             R.add_edge(*e)
     return R
 
 
-@nx._dispatch(graphs=_G_H, preserve_all_attrs=True)
+@nx._dispatchable(graphs=_G_H, preserve_all_attrs=True, returns_graph=True)
 def compose(G, H):
     """Compose graph G with H by combining nodes and edges into a single graph.
 
     The node sets and edges sets do not need to be disjoint.
 
     Composing preserves the attributes of nodes and edges.
     Attribute values from H take precedent over attribute values from G.
@@ -332,44 +332,48 @@
     NodeView((0, 1, 2))
     >>> R.edges
     EdgeView([(0, 1), (0, 2), (1, 2)])
 
     By default, the attributes from `H` take precedent over attributes from `G`.
     If you prefer another way of combining attributes, you can update them after the compose operation:
 
-    >>> G = nx.Graph([(0, 1, {'weight': 2.0}), (3, 0, {'weight': 100.0})])
-    >>> H = nx.Graph([(0, 1, {'weight': 10.0}), (1, 2, {'weight': -1.0})])
-    >>> nx.set_node_attributes(G, {0: 'dark', 1: 'light', 3: 'black'}, name='color')
-    >>> nx.set_node_attributes(H, {0: 'green', 1: 'orange', 2: 'yellow'}, name='color')
+    >>> G = nx.Graph([(0, 1, {"weight": 2.0}), (3, 0, {"weight": 100.0})])
+    >>> H = nx.Graph([(0, 1, {"weight": 10.0}), (1, 2, {"weight": -1.0})])
+    >>> nx.set_node_attributes(G, {0: "dark", 1: "light", 3: "black"}, name="color")
+    >>> nx.set_node_attributes(H, {0: "green", 1: "orange", 2: "yellow"}, name="color")
     >>> GcomposeH = nx.compose(G, H)
 
     Normally, color attribute values of nodes of GcomposeH come from H. We can workaround this as follows:
 
-    >>> node_data = {n: G.nodes[n]['color'] + " " + H.nodes[n]['color'] for n in G.nodes & H.nodes}
-    >>> nx.set_node_attributes(GcomposeH, node_data, 'color')
-    >>> print(GcomposeH.nodes[0]['color'])
+    >>> node_data = {
+    ...     n: G.nodes[n]["color"] + " " + H.nodes[n]["color"] for n in G.nodes & H.nodes
+    ... }
+    >>> nx.set_node_attributes(GcomposeH, node_data, "color")
+    >>> print(GcomposeH.nodes[0]["color"])
     dark green
 
-    >>> print(GcomposeH.nodes[3]['color'])
+    >>> print(GcomposeH.nodes[3]["color"])
     black
 
     Similarly, we can update edge attributes after the compose operation in a way we prefer:
 
-    >>> edge_data = {e: G.edges[e]['weight'] * H.edges[e]['weight'] for e in G.edges & H.edges}
-    >>> nx.set_edge_attributes(GcomposeH, edge_data, 'weight')
-    >>> print(GcomposeH.edges[(0, 1)]['weight'])
+    >>> edge_data = {
+    ...     e: G.edges[e]["weight"] * H.edges[e]["weight"] for e in G.edges & H.edges
+    ... }
+    >>> nx.set_edge_attributes(GcomposeH, edge_data, "weight")
+    >>> print(GcomposeH.edges[(0, 1)]["weight"])
     20.0
 
-    >>> print(GcomposeH.edges[(3, 0)]['weight'])
+    >>> print(GcomposeH.edges[(3, 0)]["weight"])
     100.0
     """
     return nx.compose_all([G, H])
 
 
-@nx._dispatch(graphs=_G_H, preserve_all_attrs=True)
+@nx._dispatchable(graphs=_G_H, preserve_all_attrs=True, returns_graph=True)
 def full_join(G, H, rename=(None, None)):
     """Returns the full join of graphs G and H.
 
     Full join is the union of G and H in which all edges between
     G and H are added.
     The node sets of G and H must be disjoint,
     otherwise an exception is raised.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/product.py` & `networkx-3.3rc0/networkx/algorithms/operators/product.py`

 * *Files 9% similar despite different names*

```diff
@@ -10,14 +10,15 @@
     "tensor_product",
     "cartesian_product",
     "lexicographic_product",
     "strong_product",
     "power",
     "rooted_product",
     "corona_product",
+    "modular_product",
 ]
 _G_H = {"G": 0, "H": 1}
 
 
 def _dict_product(d1, d2):
     return {k: (d1.get(k), d2.get(k)) for k in set(d1) | set(d2)}
 
@@ -119,20 +120,20 @@
     else:
         GH = nx.Graph()
     if G.is_directed():
         GH = GH.to_directed()
     return GH
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, preserve_node_attrs=True, returns_graph=True)
 def tensor_product(G, H):
     r"""Returns the tensor product of G and H.
 
     The tensor product $P$ of the graphs $G$ and $H$ has a node set that
-    is the tensor product of the node sets, $V(P)=V(G) \times V(H)$.
+    is the Cartesian product of the node sets, $V(P)=V(G) \times V(H)$.
     $P$ has an edge $((u,v), (x,y))$ if and only if $(u,x)$ is an edge in $G$
     and $(v,y)$ is an edge in $H$.
 
     Tensor product is sometimes also referred to as the categorical product,
     direct product, cardinal product or conjunction.
 
 
@@ -175,15 +176,15 @@
     GH.add_nodes_from(_node_product(G, H))
     GH.add_edges_from(_directed_edges_cross_edges(G, H))
     if not GH.is_directed():
         GH.add_edges_from(_undirected_edges_cross_edges(G, H))
     return GH
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, preserve_node_attrs=True, returns_graph=True)
 def cartesian_product(G, H):
     r"""Returns the Cartesian product of G and H.
 
     The Cartesian product $P$ of the graphs $G$ and $H$ has a node set that
     is the Cartesian product of the node sets, $V(P)=V(G) \times V(H)$.
     $P$ has an edge $((u,v),(x,y))$ if and only if either $u$ is equal to $x$
     and both $v$ and $y$ are adjacent in $H$ or if $v$ is equal to $y$ and
@@ -227,15 +228,15 @@
     GH = _init_product_graph(G, H)
     GH.add_nodes_from(_node_product(G, H))
     GH.add_edges_from(_edges_cross_nodes(G, H))
     GH.add_edges_from(_nodes_cross_edges(G, H))
     return GH
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, preserve_node_attrs=True, returns_graph=True)
 def lexicographic_product(G, H):
     r"""Returns the lexicographic product of G and H.
 
     The lexicographical product $P$ of the graphs $G$ and $H$ has a node set
     that is the Cartesian product of the node sets, $V(P)=V(G) \times V(H)$.
     $P$ has an edge $((u,v), (x,y))$ if and only if $(u,v)$ is an edge in $G$
     or $u==v$ and $(x,y)$ is an edge in $H$.
@@ -280,15 +281,15 @@
     # Edges in G regardless of H designation
     GH.add_edges_from(_edges_cross_nodes_and_nodes(G, H))
     # For each x in G, only if there is an edge in H
     GH.add_edges_from(_nodes_cross_edges(G, H))
     return GH
 
 
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, preserve_node_attrs=True, returns_graph=True)
 def strong_product(G, H):
     r"""Returns the strong product of G and H.
 
     The strong product $P$ of the graphs $G$ and $H$ has a node set that
     is the Cartesian product of the node sets, $V(P)=V(G) \times V(H)$.
     $P$ has an edge $((u,v), (x,y))$ if and only if
     $u==v$ and $(x,y)$ is an edge in $H$, or
@@ -338,15 +339,15 @@
     if not GH.is_directed():
         GH.add_edges_from(_undirected_edges_cross_edges(G, H))
     return GH
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def power(G, k):
     """Returns the specified power of a graph.
 
     The $k$th power of a simple graph $G$, denoted $G^k$, is a
     graph on the same set of nodes in which two distinct nodes $u$ and
     $v$ are adjacent in $G^k$ if and only if the shortest path
     distance between $u$ and $v$ in $G$ is at most $k$.
@@ -379,15 +380,15 @@
 
     >>> G = nx.path_graph(4)
     >>> list(nx.power(G, 2).edges)
     [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3)]
     >>> list(nx.power(G, 3).edges)
     [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]
 
-    The `k`\ th power of a cycle graph on *n* nodes is the complete graph
+    The `k` th power of a cycle graph on *n* nodes is the complete graph
     on *n* nodes, if `k` is at least ``n // 2``:
 
     >>> G = nx.cycle_graph(5)
     >>> H = nx.complete_graph(5)
     >>> nx.is_isomorphic(nx.power(G, 2), H)
     True
     >>> G = nx.cycle_graph(8)
@@ -427,15 +428,15 @@
                 break
             level += 1
         H.add_edges_from((n, nbr) for nbr in seen)
     return H
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, returns_graph=True)
 def rooted_product(G, H, root):
     """Return the rooted product of graphs G and H rooted at root in H.
 
     A new graph is constructed representing the rooted product of
     the inputted graphs, G and H, with a root in H.
     A rooted product duplicates H for each nodes in G with the root
     of H corresponding to the node in G. Nodes are renamed as the direct
@@ -467,15 +468,15 @@
     R.add_edges_from(((g, e[0]), (g, e[1])) for g in G for e in H.edges())
 
     return R
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(graphs=_G_H)
+@nx._dispatchable(graphs=_G_H, returns_graph=True)
 def corona_product(G, H):
     r"""Returns the Corona product of G and H.
 
     The corona product of $G$ and $H$ is the graph $C = G \circ H$ obtained by
     taking one copy of $G$, called the center graph, $|V(G)|$ copies of $H$,
     called the outer graph, and making the $i$-th vertex of $G$ adjacent to
     every vertex of the $i$-th copy of $H$, where $1 ≤ i ≤ |V(G)|$.
@@ -528,7 +529,102 @@
             ((G_node, e0), (G_node, e1), d) for e0, e1, d in H.edges.data()
         )
 
         # creating new edges between H_i and a G's node
         GH.add_edges_from((G_node, (G_node, H_node)) for H_node in H)
 
     return GH
+
+
+@nx._dispatchable(
+    graphs=_G_H, preserve_edge_attrs=True, preserve_node_attrs=True, returns_graph=True
+)
+def modular_product(G, H):
+    r"""Returns the Modular product of G and H.
+
+    The modular product of `G` and `H` is the graph $M = G \nabla H$,
+    consisting of the node set $V(M) = V(G) \times V(H)$ that is the Cartesian
+    product of the node sets of `G` and `H`. Further, M contains an edge ((u, v), (x, y)):
+
+    - if u is adjacent to x in `G` and v is adjacent to y in `H`, or
+    - if u is not adjacent to x in `G` and v is not adjacent to y in `H`.
+
+    More formally::
+
+        E(M) = {((u, v), (x, y)) | ((u, x) in E(G) and (v, y) in E(H)) or
+                                   ((u, x) not in E(G) and (v, y) not in E(H))}
+
+    Parameters
+    ----------
+    G, H: NetworkX graphs
+        The graphs to take the modular product of.
+
+    Returns
+    -------
+    M: NetworkX graph
+        The Modular product of `G` and `H`.
+
+    Raises
+    ------
+    NetworkXNotImplemented
+        If `G` is not a simple graph.
+
+    Examples
+    --------
+    >>> G = nx.cycle_graph(4)
+    >>> H = nx.path_graph(2)
+    >>> M = nx.modular_product(G, H)
+    >>> list(M)
+    [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1), (3, 0), (3, 1)]
+    >>> print(M)
+    Graph with 8 nodes and 8 edges
+
+    Notes
+    -----
+    The *modular product* is defined in [1]_ and was first
+    introduced as the *weak modular product*.
+
+    The modular product reduces the problem of counting isomorphic subgraphs
+    in `G` and `H` to the problem of counting cliques in M. The subgraphs of
+    `G` and `H` that are induced by the nodes of a clique in M are
+    isomorphic [2]_ [3]_.
+
+    References
+    ----------
+    .. [1] R. Hammack, W. Imrich, and S. Klavžar,
+        "Handbook of Product Graphs", CRC Press, 2011.
+
+    .. [2] H. G. Barrow and R. M. Burstall,
+        "Subgraph isomorphism, matching relational structures and maximal
+        cliques", Information Processing Letters, vol. 4, issue 4, pp. 83-84,
+        1976, https://doi.org/10.1016/0020-0190(76)90049-1.
+
+    .. [3] V. G. Vizing, "Reduction of the problem of isomorphism and isomorphic
+        entrance to the task of finding the nondensity of a graph." Proc. Third
+        All-Union Conference on Problems of Theoretical Cybernetics. 1974.
+    """
+    if G.is_directed() or H.is_directed():
+        raise nx.NetworkXNotImplemented(
+            "Modular product not implemented for directed graphs"
+        )
+    if G.is_multigraph() or H.is_multigraph():
+        raise nx.NetworkXNotImplemented(
+            "Modular product not implemented for multigraphs"
+        )
+
+    GH = _init_product_graph(G, H)
+    GH.add_nodes_from(_node_product(G, H))
+
+    for u, v, c in G.edges(data=True):
+        for x, y, d in H.edges(data=True):
+            GH.add_edge((u, x), (v, y), **_dict_product(c, d))
+            GH.add_edge((v, x), (u, y), **_dict_product(c, d))
+
+    G = nx.complement(G)
+    H = nx.complement(H)
+
+    for u, v, c in G.edges(data=True):
+        for x, y, d in H.edges(data=True):
+            GH.add_edge((u, x), (v, y), **_dict_product(c, d))
+            GH.add_edge((v, x), (u, y), **_dict_product(c, d))
+
+    return GH
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/tests/test_all.py` & `networkx-3.3rc0/networkx/algorithms/operators/tests/test_all.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/tests/test_binary.py` & `networkx-3.3rc0/networkx/algorithms/operators/tests/test_binary.py`

 * *Files 1% similar despite different names*

```diff
@@ -39,25 +39,25 @@
     H.add_edge(2, 3)
     H.add_edge(3, 4)
     I = nx.intersection(G, H)
     assert set(I.nodes()) == {1, 2, 3, 4}
     assert sorted(I.edges()) == [(2, 3)]
 
     ##################
-    # Tests for @nx._dispatch mechanism with multiple graph arguments
+    # Tests for @nx._dispatchable mechanism with multiple graph arguments
     # nx.intersection is called as if it were a re-implementation
     # from another package.
     ###################
     G2 = dispatch_interface.convert(G)
     H2 = dispatch_interface.convert(H)
     I2 = nx.intersection(G2, H2)
     assert set(I2.nodes()) == {1, 2, 3, 4}
     assert sorted(I2.edges()) == [(2, 3)]
     # Only test if not performing auto convert testing of backend implementations
-    if not nx.utils.backends._dispatch._automatic_backends:
+    if not nx.config["backend_priority"]:
         with pytest.raises(TypeError):
             nx.intersection(G2, H)
         with pytest.raises(TypeError):
             nx.intersection(G, H2)
 
 
 def test_intersection_node_sets_different():
@@ -195,14 +195,17 @@
     h.graph["attr"] = "attr"
     h.nodes[0]["x"] = 7
 
     gh = nx.difference(g, h)
     assert set(gh.nodes()) == set(g.nodes())
     assert set(gh.nodes()) == set(h.nodes())
     assert sorted(gh.edges()) == []
+    # node and graph data should not be copied over
+    assert gh.nodes.data() != g.nodes.data()
+    assert gh.graph != g.graph
 
 
 def test_difference_multigraph_attributes():
     g = nx.MultiGraph()
     g.add_edge(0, 1, key=0)
     g.add_edge(0, 1, key=1)
     g.add_edge(0, 1, key=2)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/tests/test_product.py` & `networkx-3.3rc0/networkx/algorithms/operators/tests/test_product.py`

 * *Files 14% similar despite different names*

```diff
@@ -429,7 +429,63 @@
 
 def test_corona_product():
     G = nx.cycle_graph(3)
     H = nx.path_graph(2)
     C = nx.corona_product(G, H)
     assert len(C) == (len(G) * len(H)) + len(G)
     assert C.size() == G.size() + len(G) * H.size() + len(G) * len(H)
+
+
+def test_modular_product():
+    G = nx.path_graph(3)
+    H = nx.path_graph(4)
+    M = nx.modular_product(G, H)
+    assert len(M) == len(G) * len(H)
+
+    assert edges_equal(
+        list(M.edges()),
+        [
+            ((0, 0), (1, 1)),
+            ((0, 0), (2, 2)),
+            ((0, 0), (2, 3)),
+            ((0, 1), (1, 0)),
+            ((0, 1), (1, 2)),
+            ((0, 1), (2, 3)),
+            ((0, 2), (1, 1)),
+            ((0, 2), (1, 3)),
+            ((0, 2), (2, 0)),
+            ((0, 3), (1, 2)),
+            ((0, 3), (2, 0)),
+            ((0, 3), (2, 1)),
+            ((1, 0), (2, 1)),
+            ((1, 1), (2, 0)),
+            ((1, 1), (2, 2)),
+            ((1, 2), (2, 1)),
+            ((1, 2), (2, 3)),
+            ((1, 3), (2, 2)),
+        ],
+    )
+
+
+def test_modular_product_raises():
+    G = nx.Graph([(0, 1), (1, 2), (2, 0)])
+    H = nx.Graph([(0, 1), (1, 2), (2, 0)])
+    DG = nx.DiGraph([(0, 1), (1, 2), (2, 0)])
+    DH = nx.DiGraph([(0, 1), (1, 2), (2, 0)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(G, DH)
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(DG, H)
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(DG, DH)
+
+    MG = nx.MultiGraph([(0, 1), (1, 2), (2, 0), (0, 1)])
+    MH = nx.MultiGraph([(0, 1), (1, 2), (2, 0), (0, 1)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(G, MH)
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(MG, H)
+    with pytest.raises(nx.NetworkXNotImplemented):
+        nx.modular_product(MG, MH)
+    with pytest.raises(nx.NetworkXNotImplemented):
+        # check multigraph with no multiedges
+        nx.modular_product(nx.MultiGraph(G), H)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/tests/test_unary.py` & `networkx-3.3rc0/networkx/algorithms/operators/tests/test_unary.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/operators/unary.py` & `networkx-3.3rc0/networkx/algorithms/operators/unary.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Unary operations on graphs"""
 import networkx as nx
 
 __all__ = ["complement", "reverse"]
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def complement(G):
     """Returns the graph complement of G.
 
     Parameters
     ----------
     G : graph
        A NetworkX graph
@@ -24,27 +24,27 @@
 
     Graph, node, and edge data are not propagated to the new graph.
 
     Examples
     --------
     >>> G = nx.Graph([(1, 2), (1, 3), (2, 3), (3, 4), (3, 5)])
     >>> G_complement = nx.complement(G)
-    >>> G_complement.edges() # This shows the edges of the complemented graph
+    >>> G_complement.edges()  # This shows the edges of the complemented graph
     EdgeView([(1, 4), (1, 5), (2, 4), (2, 5), (4, 5)])
 
     """
     R = G.__class__()
     R.add_nodes_from(G)
     R.add_edges_from(
         ((n, n2) for n, nbrs in G.adjacency() for n2 in G if n2 not in nbrs if n != n2)
     )
     return R
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def reverse(G, copy=True):
     """Returns the reverse directed graph of G.
 
     Parameters
     ----------
     G : directed graph
         A NetworkX directed graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/planar_drawing.py` & `networkx-3.3rc0/networkx/algorithms/planar_drawing.py`

 * *Files 2% similar despite different names*

```diff
@@ -74,26 +74,26 @@
 
     delta_x[v3] = 1
     y_coordinate[v3] = 1
     right_t_child[v3] = v2
     left_t_child[v3] = None
 
     for k in range(3, len(node_list)):
-        vk, contour_neighbors = node_list[k]
-        wp = contour_neighbors[0]
-        wp1 = contour_neighbors[1]
-        wq = contour_neighbors[-1]
-        wq1 = contour_neighbors[-2]
-        adds_mult_tri = len(contour_neighbors) > 2
+        vk, contour_nbrs = node_list[k]
+        wp = contour_nbrs[0]
+        wp1 = contour_nbrs[1]
+        wq = contour_nbrs[-1]
+        wq1 = contour_nbrs[-2]
+        adds_mult_tri = len(contour_nbrs) > 2
 
         # Stretch gaps:
         delta_x[wp1] += 1
         delta_x[wq] += 1
 
-        delta_x_wp_wq = sum(delta_x[x] for x in contour_neighbors[1:])
+        delta_x_wp_wq = sum(delta_x[x] for x in contour_nbrs[1:])
 
         # Adjust offsets
         delta_x[vk] = (-y_coordinate[wp] + delta_x_wp_wq + y_coordinate[wq]) // 2
         y_coordinate[vk] = (y_coordinate[wp] + delta_x_wp_wq + y_coordinate[wq]) // 2
         delta_x[wq] = delta_x_wp_wq - delta_x[vk]
         if adds_mult_tri:
             delta_x[wp1] -= delta_x[vk]
@@ -322,16 +322,16 @@
     while v1 != v4:
         # Add edge if not already present on other side
         if embedding.has_edge(v1, v3):
             # Cannot triangulate at this position
             v1, v2, v3 = v2, v3, v4
         else:
             # Add edge for triangulation
-            embedding.add_half_edge_cw(v1, v3, v2)
-            embedding.add_half_edge_ccw(v3, v1, v2)
+            embedding.add_half_edge(v1, v3, ccw=v2)
+            embedding.add_half_edge(v3, v1, cw=v2)
             v1, v2, v3 = v1, v3, v4
         # Get next node
         _, v4 = embedding.next_face_half_edge(v2, v3)
 
 
 def triangulate_embedding(embedding, fully_triangulate=True):
     """Triangulates the embedding.
@@ -441,16 +441,16 @@
     # Move the nodes v1, v2, v3 around the face:
     while v2 != starting_node or v3 != outgoing_node:
         if v1 == v2:
             raise nx.NetworkXException("Invalid half-edge")
         # cycle is not completed yet
         if v2 in face_set:
             # v2 encountered twice: Add edge to ensure 2-connectedness
-            embedding.add_half_edge_cw(v1, v3, v2)
-            embedding.add_half_edge_ccw(v3, v1, v2)
+            embedding.add_half_edge(v1, v3, ccw=v2)
+            embedding.add_half_edge(v3, v1, cw=v2)
             edges_counted.add((v2, v3))
             edges_counted.add((v3, v1))
             v2 = v1
         else:
             face_set.add(v2)
             face_list.append(v2)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/planarity.py` & `networkx-3.3rc0/networkx/algorithms/planarity.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from collections import defaultdict
 
 import networkx as nx
 
 __all__ = ["check_planarity", "is_planar", "PlanarEmbedding"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_planar(G):
     """Returns True if and only if `G` is planar.
 
     A graph is *planar* iff it can be drawn in a plane without
     any edge intersections.
 
     Parameters
@@ -34,15 +34,15 @@
     check_planarity :
         Check if graph is planar *and* return a `PlanarEmbedding` instance if True.
     """
 
     return check_planarity(G, counterexample=False)[0]
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def check_planarity(G, counterexample=False):
     """Check if a graph is planar and return a counterexample or an embedding.
 
     A graph is planar iff it can be drawn in a plane without
     any edge intersections.
 
     Parameters
@@ -110,15 +110,15 @@
         else:
             return False, None
     else:
         # graph is planar
         return True, embedding
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def check_planarity_recursive(G, counterexample=False):
     """Recursive version of :meth:`check_planarity`."""
     planarity_state = LRPlanarity(G)
     embedding = planarity_state.lr_planarity_recursive()
     if embedding is None:
         # graph is not planar
         if counterexample:
@@ -126,15 +126,15 @@
         else:
             return False, None
     else:
         # graph is planar
         return True, embedding
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def get_counterexample(G):
     """Obtains a Kuratowski subgraph.
 
     Raises nx.NetworkXException if G is planar.
 
     The function removes edges such that the graph is still not planar.
     At some point the removal of any edge would make the graph planar.
@@ -165,15 +165,15 @@
             if check_planarity(G)[0]:
                 G.add_edge(u, v)
                 subgraph.add_edge(u, v)
 
     return subgraph
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def get_counterexample_recursive(G):
     """Recursive version of :meth:`get_counterexample`."""
 
     # copy graph
     G = nx.Graph(G)
 
     if check_planarity_recursive(G)[0]:
@@ -372,15 +372,15 @@
             # sort the adjacency lists again
             self.ordered_adjs[v] = sorted(
                 self.DG[v], key=lambda x: self.nesting_depth[(v, x)]
             )
             # initialize the embedding
             previous_node = None
             for w in self.ordered_adjs[v]:
-                self.embedding.add_half_edge_cw(v, w, previous_node)
+                self.embedding.add_half_edge(v, w, ccw=previous_node)
                 previous_node = w
 
         # Free no longer used variables
         self.DG = None
         self.nesting_depth = None
         self.ref = None
 
@@ -432,15 +432,15 @@
             # sort the adjacency lists again
             self.ordered_adjs[v] = sorted(
                 self.DG[v], key=lambda x: self.nesting_depth[(v, x)]
             )
             # initialize the embedding
             previous_node = None
             for w in self.ordered_adjs[v]:
-                self.embedding.add_half_edge_cw(v, w, previous_node)
+                self.embedding.add_half_edge(v, w, ccw=previous_node)
                 previous_node = w
 
         # compute the complete embedding
         for v in self.roots:
             self.dfs_embedding_recursive(v)
 
         return self.embedding
@@ -710,35 +710,35 @@
                     self.right_ref[v] = w
 
                     dfs_stack.append(v)  # revisit v after finishing w
                     dfs_stack.append(w)  # visit w next
                     break  # handle next node in dfs_stack (i.e. w)
                 else:  # back edge
                     if self.side[ei] == 1:
-                        self.embedding.add_half_edge_cw(w, v, self.right_ref[w])
+                        self.embedding.add_half_edge(w, v, ccw=self.right_ref[w])
                     else:
-                        self.embedding.add_half_edge_ccw(w, v, self.left_ref[w])
+                        self.embedding.add_half_edge(w, v, cw=self.left_ref[w])
                         self.left_ref[w] = v
 
     def dfs_embedding_recursive(self, v):
         """Recursive version of :meth:`dfs_embedding`."""
         for w in self.ordered_adjs[v]:
             ei = (v, w)
             if ei == self.parent_edge[w]:  # tree edge
                 self.embedding.add_half_edge_first(w, v)
                 self.left_ref[v] = w
                 self.right_ref[v] = w
                 self.dfs_embedding_recursive(w)
             else:  # back edge
                 if self.side[ei] == 1:
                     # place v directly after right_ref[w] in embed. list of w
-                    self.embedding.add_half_edge_cw(w, v, self.right_ref[w])
+                    self.embedding.add_half_edge(w, v, ccw=self.right_ref[w])
                 else:
                     # place v directly before left_ref[w] in embed. list of w
-                    self.embedding.add_half_edge_ccw(w, v, self.left_ref[w])
+                    self.embedding.add_half_edge(w, v, cw=self.left_ref[w])
                     self.left_ref[w] = v
 
     def sign(self, e):
         """Resolve the relative side of an edge to the absolute side."""
         # the recursion stack
         dfs_stack = [e]
         # dict to remember reference edges
@@ -787,39 +787,36 @@
     conditions. It is possible to check if these conditions are fulfilled with
     the method :meth:`check_structure`.
     The conditions are:
 
     * Edges must go in both directions (because the edge attributes differ)
     * Every edge must have a 'cw' and 'ccw' attribute which corresponds to a
       correct planar embedding.
-    * A node with non zero degree must have a node attribute 'first_nbr'.
 
     As long as a PlanarEmbedding is invalid only the following methods should
     be called:
 
-    * :meth:`add_half_edge_ccw`
-    * :meth:`add_half_edge_cw`
+    * :meth:`add_half_edge`
     * :meth:`connect_components`
-    * :meth:`add_half_edge_first`
 
     Even though the graph is a subclass of nx.DiGraph, it can still be used
     for algorithms that require undirected graphs, because the method
     :meth:`is_directed` is overridden. This is possible, because a valid
     PlanarGraph must have edges in both directions.
 
     **Half edges:**
 
-    In methods like `add_half_edge_ccw` the term "half-edge" is used, which is
+    In methods like `add_half_edge` the term "half-edge" is used, which is
     a term that is used in `doubly connected edge lists
     <https://en.wikipedia.org/wiki/Doubly_connected_edge_list>`_. It is used
     to emphasize that the edge is only in one direction and there exists
     another half-edge in the opposite direction.
     While conventional edges always have two faces (including outer face) next
     to them, it is possible to assign each half-edge *exactly one* face.
-    For a half-edge (u, v) that is orientated such that u is below v then the
+    For a half-edge (u, v) that is oriented such that u is below v then the
     face that belongs to (u, v) is to the right of this half-edge.
 
     See Also
     --------
     is_planar :
         Preferred way to check if an existing graph is planar.
 
@@ -829,39 +826,55 @@
 
     Examples
     --------
 
     Create an embedding of a star graph (compare `nx.star_graph(3)`):
 
     >>> G = nx.PlanarEmbedding()
-    >>> G.add_half_edge_cw(0, 1, None)
-    >>> G.add_half_edge_cw(0, 2, 1)
-    >>> G.add_half_edge_cw(0, 3, 2)
-    >>> G.add_half_edge_cw(1, 0, None)
-    >>> G.add_half_edge_cw(2, 0, None)
-    >>> G.add_half_edge_cw(3, 0, None)
+    >>> G.add_half_edge(0, 1)
+    >>> G.add_half_edge(0, 2, ccw=1)
+    >>> G.add_half_edge(0, 3, ccw=2)
+    >>> G.add_half_edge(1, 0)
+    >>> G.add_half_edge(2, 0)
+    >>> G.add_half_edge(3, 0)
 
     Alternatively the same embedding can also be defined in counterclockwise
     orientation. The following results in exactly the same PlanarEmbedding:
 
     >>> G = nx.PlanarEmbedding()
-    >>> G.add_half_edge_ccw(0, 1, None)
-    >>> G.add_half_edge_ccw(0, 3, 1)
-    >>> G.add_half_edge_ccw(0, 2, 3)
-    >>> G.add_half_edge_ccw(1, 0, None)
-    >>> G.add_half_edge_ccw(2, 0, None)
-    >>> G.add_half_edge_ccw(3, 0, None)
+    >>> G.add_half_edge(0, 1)
+    >>> G.add_half_edge(0, 3, cw=1)
+    >>> G.add_half_edge(0, 2, cw=3)
+    >>> G.add_half_edge(1, 0)
+    >>> G.add_half_edge(2, 0)
+    >>> G.add_half_edge(3, 0)
 
     After creating a graph, it is possible to validate that the PlanarEmbedding
     object is correct:
 
     >>> G.check_structure()
 
     """
 
+    def __init__(self, incoming_graph_data=None, **attr):
+        super().__init__(incoming_graph_data=incoming_graph_data, **attr)
+        self.add_edge = self.__forbidden
+        self.add_edges_from = self.__forbidden
+        self.add_weighted_edges_from = self.__forbidden
+
+    def __forbidden(self, *args, **kwargs):
+        """Forbidden operation
+
+        Any edge additions to a PlanarEmbedding should be done using
+        method `add_half_edge`.
+        """
+        raise NotImplementedError(
+            "Use `add_half_edge` method to add edges to a PlanarEmbedding."
+        )
+
     def get_data(self):
         """Converts the adjacency structure into a better readable structure.
 
         Returns
         -------
         embedding : dict
             A dict mapping all nodes to a list of neighbors sorted in
@@ -890,48 +903,194 @@
 
         See Also
         --------
         get_data
 
         """
         for v in data:
+            ref = None
             for w in reversed(data[v]):
-                self.add_half_edge_first(v, w)
+                self.add_half_edge(v, w, cw=ref)
+                ref = w
+
+    def remove_node(self, n):
+        """Remove node n.
+
+        Removes the node n and all adjacent edges, updating the
+        PlanarEmbedding to account for any resulting edge removal.
+        Attempting to remove a non-existent node will raise an exception.
+
+        Parameters
+        ----------
+        n : node
+           A node in the graph
+
+        Raises
+        ------
+        NetworkXError
+           If n is not in the graph.
+
+        See Also
+        --------
+        remove_nodes_from
+
+        """
+        try:
+            for u in self._pred[n]:
+                succs_u = self._succ[u]
+                un_cw = succs_u[n]["cw"]
+                un_ccw = succs_u[n]["ccw"]
+                del succs_u[n]
+                del self._pred[u][n]
+                if n != un_cw:
+                    succs_u[un_cw]["ccw"] = un_ccw
+                    succs_u[un_ccw]["cw"] = un_cw
+            del self._node[n]
+            del self._succ[n]
+            del self._pred[n]
+        except KeyError as err:  # NetworkXError if n not in self
+            raise nx.NetworkXError(
+                f"The node {n} is not in the planar embedding."
+            ) from err
+
+    def remove_nodes_from(self, nodes):
+        """Remove multiple nodes.
+
+        Parameters
+        ----------
+        nodes : iterable container
+            A container of nodes (list, dict, set, etc.).  If a node
+            in the container is not in the graph it is silently ignored.
+
+        See Also
+        --------
+        remove_node
+
+        Notes
+        -----
+        When removing nodes from an iterator over the graph you are changing,
+        a `RuntimeError` will be raised with message:
+        `RuntimeError: dictionary changed size during iteration`. This
+        happens when the graph's underlying dictionary is modified during
+        iteration. To avoid this error, evaluate the iterator into a separate
+        object, e.g. by using `list(iterator_of_nodes)`, and pass this
+        object to `G.remove_nodes_from`.
+
+        """
+        for n in nodes:
+            if n in self._node:
+                self.remove_node(n)
+            # silently skip non-existing nodes
 
     def neighbors_cw_order(self, v):
         """Generator for the neighbors of v in clockwise order.
 
         Parameters
         ----------
         v : node
 
         Yields
         ------
         node
 
         """
-        if len(self[v]) == 0:
+        succs = self._succ[v]
+        if not succs:
             # v has no neighbors
             return
-        start_node = self.nodes[v]["first_nbr"]
+        start_node = next(reversed(succs))
         yield start_node
-        current_node = self[v][start_node]["cw"]
+        current_node = succs[start_node]["cw"]
         while start_node != current_node:
             yield current_node
-            current_node = self[v][current_node]["cw"]
+            current_node = succs[current_node]["cw"]
+
+    def add_half_edge(self, start_node, end_node, *, cw=None, ccw=None):
+        """Adds a half-edge from `start_node` to `end_node`.
+
+        If the half-edge is not the first one out of `start_node`, a reference
+        node must be provided either in the clockwise (parameter `cw`) or in
+        the counterclockwise (parameter `ccw`) direction. Only one of `cw`/`ccw`
+        can be specified (or neither in the case of the first edge).
+        Note that specifying a reference in the clockwise (`cw`) direction means
+        inserting the new edge in the first counterclockwise position with
+        respect to the reference (and vice-versa).
+
+        Parameters
+        ----------
+        start_node : node
+            Start node of inserted edge.
+        end_node : node
+            End node of inserted edge.
+        cw, ccw: node
+            End node of reference edge.
+            Omit or pass `None` if adding the first out-half-edge of `start_node`.
+
+
+        Raises
+        ------
+        NetworkXException
+            If the `cw` or `ccw` node is not a successor of `start_node`.
+            If `start_node` has successors, but neither `cw` or `ccw` is provided.
+            If both `cw` and `ccw` are specified.
+
+        See Also
+        --------
+        connect_components
+        """
+
+        succs = self._succ.get(start_node)
+        if succs:
+            # there is already some edge out of start_node
+            leftmost_nbr = next(reversed(self._succ[start_node]))
+            if cw is not None:
+                if cw not in succs:
+                    raise nx.NetworkXError("Invalid clockwise reference node.")
+                if ccw is not None:
+                    raise nx.NetworkXError("Only one of cw/ccw can be specified.")
+                ref_ccw = succs[cw]["ccw"]
+                super().add_edge(start_node, end_node, cw=cw, ccw=ref_ccw)
+                succs[ref_ccw]["cw"] = end_node
+                succs[cw]["ccw"] = end_node
+                # when (cw == leftmost_nbr), the newly added neighbor is
+                # already at the end of dict self._succ[start_node] and
+                # takes the place of the former leftmost_nbr
+                move_leftmost_nbr_to_end = cw != leftmost_nbr
+            elif ccw is not None:
+                if ccw not in succs:
+                    raise nx.NetworkXError("Invalid counterclockwise reference node.")
+                ref_cw = succs[ccw]["cw"]
+                super().add_edge(start_node, end_node, cw=ref_cw, ccw=ccw)
+                succs[ref_cw]["ccw"] = end_node
+                succs[ccw]["cw"] = end_node
+                move_leftmost_nbr_to_end = True
+            else:
+                raise nx.NetworkXError(
+                    "Node already has out-half-edge(s), either cw or ccw reference node required."
+                )
+            if move_leftmost_nbr_to_end:
+                # LRPlanarity (via self.add_half_edge_first()) requires that
+                # we keep track of the leftmost neighbor, which we accomplish
+                # by keeping it as the last key in dict self._succ[start_node]
+                succs[leftmost_nbr] = succs.pop(leftmost_nbr)
+
+        else:
+            if cw is not None or ccw is not None:
+                raise nx.NetworkXError("Invalid reference node.")
+            # adding the first edge out of start_node
+            super().add_edge(start_node, end_node, ccw=end_node, cw=end_node)
 
     def check_structure(self):
         """Runs without exceptions if this object is valid.
 
         Checks that the following properties are fulfilled:
 
         * Edges go in both directions (because the edge attributes differ).
         * Every edge has a 'cw' and 'ccw' attribute which corresponds to a
           correct planar embedding.
-        * A node with a degree larger than 0 has a node attribute 'first_nbr'.
 
         Running this method verifies that the underlying Graph must be planar.
 
         Raises
         ------
         NetworkXException
             This exception is raised with a short explanation if the
@@ -996,32 +1155,20 @@
         Raises
         ------
         NetworkXException
             If the reference_neighbor does not exist.
 
         See Also
         --------
+        add_half_edge
         add_half_edge_cw
         connect_components
-        add_half_edge_first
 
         """
-        if reference_neighbor is None:
-            # The start node has no neighbors
-            self.add_edge(start_node, end_node)  # Add edge to graph
-            self[start_node][end_node]["cw"] = end_node
-            self[start_node][end_node]["ccw"] = end_node
-            self.nodes[start_node]["first_nbr"] = end_node
-        else:
-            ccw_reference = self[start_node][reference_neighbor]["ccw"]
-            self.add_half_edge_cw(start_node, end_node, ccw_reference)
-
-            if reference_neighbor == self.nodes[start_node].get("first_nbr", None):
-                # Update first neighbor
-                self.nodes[start_node]["first_nbr"] = end_node
+        self.add_half_edge(start_node, end_node, cw=reference_neighbor)
 
     def add_half_edge_cw(self, start_node, end_node, reference_neighbor):
         """Adds a half-edge from start_node to end_node.
 
         The half-edge is added clockwise next to the existing half-edge
         (start_node, reference_neighbor).
 
@@ -1037,39 +1184,92 @@
         Raises
         ------
         NetworkXException
             If the reference_neighbor does not exist.
 
         See Also
         --------
+        add_half_edge
         add_half_edge_ccw
         connect_components
-        add_half_edge_first
         """
-        self.add_edge(start_node, end_node)  # Add edge to graph
+        self.add_half_edge(start_node, end_node, ccw=reference_neighbor)
 
-        if reference_neighbor is None:
-            # The start node has no neighbors
-            self[start_node][end_node]["cw"] = end_node
-            self[start_node][end_node]["ccw"] = end_node
-            self.nodes[start_node]["first_nbr"] = end_node
-            return
+    def remove_edge(self, u, v):
+        """Remove the edge between u and v.
 
-        if reference_neighbor not in self[start_node]:
-            raise nx.NetworkXException(
-                "Cannot add edge. Reference neighbor does not exist"
-            )
+        Parameters
+        ----------
+        u, v : nodes
+        Remove the half-edges (u, v) and (v, u) and update the
+        edge ordering around the removed edge.
+
+        Raises
+        ------
+        NetworkXError
+        If there is not an edge between u and v.
+
+        See Also
+        --------
+        remove_edges_from : remove a collection of edges
+        """
+        try:
+            succs_u = self._succ[u]
+            succs_v = self._succ[v]
+            uv_cw = succs_u[v]["cw"]
+            uv_ccw = succs_u[v]["ccw"]
+            vu_cw = succs_v[u]["cw"]
+            vu_ccw = succs_v[u]["ccw"]
+            del succs_u[v]
+            del self._pred[v][u]
+            del succs_v[u]
+            del self._pred[u][v]
+            if v != uv_cw:
+                succs_u[uv_cw]["ccw"] = uv_ccw
+                succs_u[uv_ccw]["cw"] = uv_cw
+            if u != vu_cw:
+                succs_v[vu_cw]["ccw"] = vu_ccw
+                succs_v[vu_ccw]["cw"] = vu_cw
+        except KeyError as err:
+            raise nx.NetworkXError(
+                f"The edge {u}-{v} is not in the planar embedding."
+            ) from err
 
-        # Get half-edge at the other side
-        cw_reference = self[start_node][reference_neighbor]["cw"]
-        # Alter half-edge data structures
-        self[start_node][reference_neighbor]["cw"] = end_node
-        self[start_node][end_node]["cw"] = cw_reference
-        self[start_node][cw_reference]["ccw"] = end_node
-        self[start_node][end_node]["ccw"] = reference_neighbor
+    def remove_edges_from(self, ebunch):
+        """Remove all edges specified in ebunch.
+
+        Parameters
+        ----------
+        ebunch: list or container of edge tuples
+            Each pair of half-edges between the nodes given in the tuples
+            will be removed from the graph. The nodes can be passed as:
+
+                - 2-tuples (u, v) half-edges (u, v) and (v, u).
+                - 3-tuples (u, v, k) where k is ignored.
+
+        See Also
+        --------
+        remove_edge : remove a single edge
+
+        Notes
+        -----
+        Will fail silently if an edge in ebunch is not in the graph.
+
+        Examples
+        --------
+        >>> G = nx.path_graph(4)  # or DiGraph, MultiGraph, MultiDiGraph, etc
+        >>> ebunch = [(1, 2), (2, 3)]
+        >>> G.remove_edges_from(ebunch)
+        """
+        for e in ebunch:
+            u, v = e[:2]  # ignore edge data
+            # assuming that the PlanarEmbedding is valid, if the half_edge
+            # (u, v) is in the graph, then so is half_edge (v, u)
+            if u in self._succ and v in self._succ[u]:
+                self.remove_edge(u, v)
 
     def connect_components(self, v, w):
         """Adds half-edges for (v, w) and (w, v) at some position.
 
         This method should only be called if v and w are in different
         components, or it might break the embedding.
         This especially means that if `connect_components(v, w)`
@@ -1080,40 +1280,48 @@
         Parameters
         ----------
         v : node
         w : node
 
         See Also
         --------
-        add_half_edge_ccw
-        add_half_edge_cw
-        add_half_edge_first
+        add_half_edge
         """
-        self.add_half_edge_first(v, w)
-        self.add_half_edge_first(w, v)
+        if v in self._succ and self._succ[v]:
+            ref = next(reversed(self._succ[v]))
+        else:
+            ref = None
+        self.add_half_edge(v, w, cw=ref)
+        if w in self._succ and self._succ[w]:
+            ref = next(reversed(self._succ[w]))
+        else:
+            ref = None
+        self.add_half_edge(w, v, cw=ref)
 
     def add_half_edge_first(self, start_node, end_node):
-        """The added half-edge is inserted at the first position in the order.
+        """Add a half-edge and set end_node as start_node's leftmost neighbor.
+
+        The new edge is inserted counterclockwise with respect to the current
+        leftmost neighbor, if there is one.
 
         Parameters
         ----------
         start_node : node
         end_node : node
 
         See Also
         --------
-        add_half_edge_ccw
-        add_half_edge_cw
+        add_half_edge
         connect_components
         """
-        if start_node in self and "first_nbr" in self.nodes[start_node]:
-            reference = self.nodes[start_node]["first_nbr"]
-        else:
-            reference = None
-        self.add_half_edge_ccw(start_node, end_node, reference)
+        succs = self._succ.get(start_node)
+        # the leftmost neighbor is the last entry in the
+        # self._succ[start_node] dict
+        leftmost_nbr = next(reversed(succs)) if succs else None
+        self.add_half_edge(start_node, end_node, cw=leftmost_nbr)
 
     def next_face_half_edge(self, v, w):
         """Returns the following half-edge left of a face.
 
         Parameters
         ----------
         v : node
@@ -1173,7 +1381,20 @@
         """A valid PlanarEmbedding is undirected.
 
         All reverse edges are contained, i.e. for every existing
         half-edge (v, w) the half-edge in the opposite direction (w, v) is also
         contained.
         """
         return False
+
+    def copy(self, as_view=False):
+        if as_view is True:
+            return nx.graphviews.generic_graph_view(self)
+        G = self.__class__()
+        G.graph.update(self.graph)
+        G.add_nodes_from((n, d.copy()) for n, d in self._node.items())
+        super(self.__class__, G).add_edges_from(
+            (u, v, datadict.copy())
+            for u, nbrs in self._adj.items()
+            for v, datadict in nbrs.items()
+        )
+        return G
```

### Comparing `networkx-3.2rc0/networkx/algorithms/polynomials.py` & `networkx-3.3rc0/networkx/algorithms/polynomials.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,15 +26,15 @@
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["tutte_polynomial", "chromatic_polynomial"]
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def tutte_polynomial(G):
     r"""Returns the Tutte polynomial of `G`
 
     This function computes the Tutte polynomial via an iterative version of
     the deletion-contraction algorithm.
 
     The Tutte polynomial `T_G(x, y)` is a fundamental graph polynomial invariant in
@@ -176,15 +176,15 @@
             G.remove_edge(*e)
             stack.append(G)
             stack.append(C)
     return sympy.simplify(polynomial)
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def chromatic_polynomial(G):
     r"""Returns the chromatic polynomial of `G`
 
     This function computes the chromatic polynomial via an iterative version of
     the deletion-contraction algorithm.
 
     The chromatic polynomial `X_G(x)` is a fundamental graph polynomial
```

### Comparing `networkx-3.2rc0/networkx/algorithms/reciprocity.py` & `networkx-3.3rc0/networkx/algorithms/reciprocity.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 
 from ..utils import not_implemented_for
 
 __all__ = ["reciprocity", "overall_reciprocity"]
 
 
 @not_implemented_for("undirected", "multigraph")
-@nx._dispatch
+@nx._dispatchable
 def reciprocity(G, nodes=None):
     r"""Compute the reciprocity in a directed graph.
 
     The reciprocity of a directed graph is defined as the ratio
     of the number of edges pointing in both directions to the total
     number of edges in the graph.
     Formally, $r = |{(u,v) \in G|(v,u) \in G}| / |{(u,v) \in G}|$.
@@ -72,15 +72,15 @@
             yield (node, None)
         else:
             reciprocity = 2 * len(overlap) / n_total
             yield (node, reciprocity)
 
 
 @not_implemented_for("undirected", "multigraph")
-@nx._dispatch
+@nx._dispatchable
 def overall_reciprocity(G):
     """Compute the reciprocity for the whole graph.
 
     See the doc of reciprocity for the definition.
 
     Parameters
     ----------
```

### Comparing `networkx-3.2rc0/networkx/algorithms/regular.py` & `networkx-3.3rc0/networkx/algorithms/regular.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Functions for computing and verifying regular graphs."""
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = ["is_regular", "is_k_regular", "k_factor"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_regular(G):
     """Determines whether the graph ``G`` is a regular graph.
 
     A regular graph is a graph where each vertex has the same degree. A
     regular digraph is a graph where the indegree and outdegree of each
     vertex are equal.
 
@@ -25,28 +25,30 @@
     Examples
     --------
     >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 4), (4, 1)])
     >>> nx.is_regular(G)
     True
 
     """
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept("Graph has no nodes.")
     n1 = nx.utils.arbitrary_element(G)
     if not G.is_directed():
         d1 = G.degree(n1)
         return all(d1 == d for _, d in G.degree)
     else:
         d_in = G.in_degree(n1)
         in_regular = all(d_in == d for _, d in G.in_degree)
         d_out = G.out_degree(n1)
         out_regular = all(d_out == d for _, d in G.out_degree)
         return in_regular and out_regular
 
 
 @not_implemented_for("directed")
-@nx._dispatch
+@nx._dispatchable
 def is_k_regular(G, k):
     """Determines whether the graph ``G`` is a k-regular graph.
 
     A k-regular graph is a graph where each vertex has degree k.
 
     Parameters
     ----------
@@ -65,15 +67,15 @@
 
     """
     return all(d == k for n, d in G.degree)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="matching_weight")
+@nx._dispatchable(preserve_edge_attrs=True, returns_graph=True)
 def k_factor(G, k, matching_weight="weight"):
     """Compute a k-factor of G
 
     A k-factor of a graph is a spanning k-regular subgraph.
     A spanning k-regular subgraph of G is a subgraph that contains
     each vertex of G and a subset of the edges of G such that each
     vertex has degree k.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/richclub.py` & `networkx-3.3rc0/networkx/algorithms/richclub.py`

 * *Files 16% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["rich_club_coefficient"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def rich_club_coefficient(G, normalized=True, Q=100, seed=None):
     r"""Returns the rich-club coefficient of the graph `G`.
 
     For each degree *k*, the *rich-club coefficient* is the ratio of the
     number of actual to the number of potential edges for nodes with
     degree greater than *k*:
 
@@ -40,27 +40,41 @@
         See :ref:`Randomness<randomness>`.
 
     Returns
     -------
     rc : dictionary
        A dictionary, keyed by degree, with rich-club coefficient values.
 
+    Raises
+    ------
+    NetworkXError
+        If `G` has fewer than four nodes and ``normalized=True``.
+        A randomly sampled graph for normalization cannot be generated in this case.
+
     Examples
     --------
     >>> G = nx.Graph([(0, 1), (0, 2), (1, 2), (1, 3), (1, 4), (4, 5)])
     >>> rc = nx.rich_club_coefficient(G, normalized=False, seed=42)
     >>> rc[0]
     0.4
 
     Notes
     -----
     The rich club definition and algorithm are found in [1]_.  This
     algorithm ignores any edge weights and is not defined for directed
     graphs or graphs with parallel edges or self loops.
 
+    Normalization is done by computing the rich club coefficient for a randomly
+    sampled graph with the same degree distribution as `G` by
+    repeatedly swapping the endpoints of existing edges. For graphs with fewer than 4
+    nodes, it is not possible to generate a random graph with a prescribed
+    degree distribution, as the degree distribution fully determines the graph
+    (hence making the coefficients trivially normalized to 1).
+    This function raises an exception in this case.
+
     Estimates for appropriate values of `Q` are found in [2]_.
 
     References
     ----------
     .. [1] Julian J. McAuley, Luciano da Fontoura Costa,
        and Tibério S. Caetano,
        "The rich-club phenomenon across complex network hierarchies",
@@ -68,15 +82,15 @@
        https://arxiv.org/abs/physics/0701290
     .. [2] R. Milo, N. Kashtan, S. Itzkovitz, M. E. J. Newman, U. Alon,
        "Uniform generation of random graphs with arbitrary degree
        sequences", 2006. https://arxiv.org/abs/cond-mat/0312028
     """
     if nx.number_of_selfloops(G) > 0:
         raise Exception(
-            "rich_club_coefficient is not implemented for " "graphs with self loops."
+            "rich_club_coefficient is not implemented for graphs with self loops."
         )
     rc = _compute_rc(G)
     if normalized:
         # make R a copy of G, randomize with Q*|E| double edge swaps
         # and use rich_club coefficient of R to normalize
         R = G.copy()
         E = R.number_of_edges()
@@ -104,14 +118,17 @@
     # Create a sorted list of pairs of edge endpoint degrees.
     #
     # The list is sorted in reverse order so that we can pop from the
     # right side of the list later, instead of popping from the left
     # side of the list, which would have a linear time cost.
     edge_degrees = sorted((sorted(map(G.degree, e)) for e in G.edges()), reverse=True)
     ek = G.number_of_edges()
+    if ek == 0:
+        return {}
+
     k1, k2 = edge_degrees.pop()
     rc = {}
     for d, nk in enumerate(nks):
         while k1 <= d:
             if len(edge_degrees) == 0:
                 ek = 0
                 break
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/astar.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/astar.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 
 import networkx as nx
 from networkx.algorithms.shortest_paths.weighted import _weight_function
 
 __all__ = ["astar_path", "astar_path_length"]
 
 
-@nx._dispatch(edge_attrs="weight", preserve_node_attrs="heuristic")
-def astar_path(G, source, target, heuristic=None, weight="weight"):
+@nx._dispatchable(edge_attrs="weight", preserve_node_attrs="heuristic")
+def astar_path(G, source, target, heuristic=None, weight="weight", *, cutoff=None):
     """Returns a list of nodes in a shortest path between source and target
     using the A* ("A-star") algorithm.
 
     There may be more than one shortest path.  This returns only one.
 
     Parameters
     ----------
@@ -45,14 +45,23 @@
        be one.
        If this is a function, the weight of an edge is the value
        returned by the function. The function must accept exactly three
        positional arguments: the two endpoints of an edge and the
        dictionary of edge attributes for that edge. The function must
        return a number or None to indicate a hidden edge.
 
+    cutoff : float, optional
+       If this is provided, the search will be bounded to this value. I.e. if
+       the evaluation function surpasses this value for a node n, the node will not
+       be expanded further and will be ignored. More formally, let h'(n) be the
+       heuristic function, and g(n) be the cost of reaching n from the source node. Then,
+       if g(n) + h'(n) > cutoff, the node will not be explored further.
+       Note that if the heuristic is inadmissible, it is possible that paths
+       are ignored even though they satisfy the cutoff.
+
     Raises
     ------
     NetworkXNoPath
         If no path exists between source and target.
 
     Examples
     --------
@@ -148,22 +157,28 @@
                 # neighbor to the source was already determined.
                 # Therefore, we won't attempt to push this neighbor
                 # to the queue
                 if qcost <= ncost:
                     continue
             else:
                 h = heuristic(neighbor, target)
+
+            if cutoff and ncost + h > cutoff:
+                continue
+
             enqueued[neighbor] = ncost, h
             push(queue, (ncost + h, next(c), neighbor, ncost, curnode))
 
     raise nx.NetworkXNoPath(f"Node {target} not reachable from {source}")
 
 
-@nx._dispatch(edge_attrs="weight", preserve_node_attrs="heuristic")
-def astar_path_length(G, source, target, heuristic=None, weight="weight"):
+@nx._dispatchable(edge_attrs="weight", preserve_node_attrs="heuristic")
+def astar_path_length(
+    G, source, target, heuristic=None, weight="weight", *, cutoff=None
+):
     """Returns the length of the shortest path between source and target using
     the A* ("A-star") algorithm.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -191,14 +206,24 @@
        such edge attribute exists, the weight of the edge is assumed to
        be one.
        If this is a function, the weight of an edge is the value
        returned by the function. The function must accept exactly three
        positional arguments: the two endpoints of an edge and the
        dictionary of edge attributes for that edge. The function must
        return a number or None to indicate a hidden edge.
+
+    cutoff : float, optional
+       If this is provided, the search will be bounded to this value. I.e. if
+       the evaluation function surpasses this value for a node n, the node will not
+       be expanded further and will be ignored. More formally, let h'(n) be the
+       heuristic function, and g(n) be the cost of reaching n from the source node. Then,
+       if g(n) + h'(n) > cutoff, the node will not be explored further.
+       Note that if the heuristic is inadmissible, it is possible that paths
+       are ignored even though they satisfy the cutoff.
+
     Raises
     ------
     NetworkXNoPath
         If no path exists between source and target.
 
     See Also
     --------
@@ -206,9 +231,9 @@
 
     """
     if source not in G or target not in G:
         msg = f"Either source {source} or target {target} is not in G"
         raise nx.NodeNotFound(msg)
 
     weight = _weight_function(G, weight)
-    path = astar_path(G, source, target, heuristic, weight)
+    path = astar_path(G, source, target, heuristic, weight, cutoff=cutoff)
     return sum(weight(u, v, G[u][v]) for u, v in zip(path[:-1], path[1:]))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/dense.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/dense.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,15 +6,15 @@
     "floyd_warshall",
     "floyd_warshall_predecessor_and_distance",
     "reconstruct_path",
     "floyd_warshall_numpy",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def floyd_warshall_numpy(G, nodelist=None, weight="weight"):
     """Find all-pairs shortest path lengths using Floyd's algorithm.
 
     This algorithm for finding shortest paths takes advantage of
     matrix representations of a graph and works well for dense
     graphs where all-pairs shortest path lengths are desired.
     The results are returned as a NumPy array, distance[i, j],
@@ -80,15 +80,15 @@
     np.fill_diagonal(A, 0)  # diagonal elements should be zero
     for i in range(n):
         # The second term has the same shape as A due to broadcasting
         A = np.minimum(A, A[i, :][np.newaxis, :] + A[:, i][:, np.newaxis])
     return A
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def floyd_warshall_predecessor_and_distance(G, weight="weight"):
     """Find all-pairs shortest path lengths using Floyd's algorithm.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -163,15 +163,15 @@
                 d = dist_u[w] + dist_w[v]
                 if dist_u[v] > d:
                     dist_u[v] = d
                     pred[u][v] = pred[w][v]
     return dict(pred), dict(dist)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def reconstruct_path(source, target, predecessors):
     """Reconstruct a path from source to target using the predecessors
     dict as returned by floyd_warshall_predecessor_and_distance
 
     Parameters
     ----------
     source : node
@@ -207,15 +207,15 @@
     path = [target, curr]
     while curr != source:
         curr = prev[curr]
         path.append(curr)
     return list(reversed(path))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def floyd_warshall(G, weight="weight"):
     """Find all-pairs shortest path lengths using Floyd's algorithm.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -229,15 +229,15 @@
        A dictionary,  keyed by source and target, of shortest paths distances
        between nodes.
 
     Examples
     --------
     >>> G = nx.DiGraph()
     >>> G.add_weighted_edges_from([(0, 1, 5), (1, 2, 2), (2, 3, -3), (1, 3, 10), (3, 2, 8)])
-    >>> fw = nx.floyd_warshall(G, weight='weight')
+    >>> fw = nx.floyd_warshall(G, weight="weight")
     >>> results = {a: dict(b) for a, b in fw.items()}
     >>> print(results)
     {0: {0: 0, 1: 5, 2: 7, 3: 4}, 1: {1: 0, 2: 2, 3: -1, 0: inf}, 2: {2: 0, 3: -3, 0: inf, 1: inf}, 3: {3: 0, 2: 8, 0: inf, 1: inf}}
 
     Notes
     -----
     Floyd's algorithm is appropriate for finding shortest paths
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/generic.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/generic.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
     "all_pairs_all_shortest_paths",
     "shortest_path_length",
     "average_shortest_path_length",
     "has_path",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def has_path(G, source, target):
     """Returns *True* if *G* has a path from *source* to *target*.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -36,15 +36,15 @@
     try:
         nx.shortest_path(G, source, target)
     except nx.NetworkXNoPath:
         return False
     return True
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def shortest_path(G, source=None, target=None, weight=None, method="dijkstra"):
     """Compute shortest paths in the graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -102,21 +102,21 @@
 
     Examples
     --------
     >>> G = nx.path_graph(5)
     >>> print(nx.shortest_path(G, source=0, target=4))
     [0, 1, 2, 3, 4]
     >>> p = nx.shortest_path(G, source=0)  # target not specified
-    >>> p[3] # shortest path from source=0 to target=3
+    >>> p[3]  # shortest path from source=0 to target=3
     [0, 1, 2, 3]
     >>> p = nx.shortest_path(G, target=4)  # source not specified
-    >>> p[1] # shortest path from source=1 to target=4
+    >>> p[1]  # shortest path from source=1 to target=4
     [1, 2, 3, 4]
-    >>> p = nx.shortest_path(G)  # source, target not specified
-    >>> p[2][4] # shortest path from source=2 to target=4
+    >>> p = dict(nx.shortest_path(G))  # source, target not specified
+    >>> p[2][4]  # shortest path from source=2 to target=4
     [2, 3, 4]
 
     Notes
     -----
     There may be more than one shortest path between a source and target.
     This returns only one of them.
 
@@ -131,16 +131,25 @@
     """
     if method not in ("dijkstra", "bellman-ford"):
         # so we don't need to check in each branch later
         raise ValueError(f"method not supported: {method}")
     method = "unweighted" if weight is None else method
     if source is None:
         if target is None:
-            msg = "shortest_path for all_pairs will return an iterator in v3.3"
-            warnings.warn(msg, DeprecationWarning)
+            warnings.warn(
+                (
+                    "\n\nshortest_path will return an iterator that yields\n"
+                    "(node, path) pairs instead of a dictionary when source\n"
+                    "and target are unspecified beginning in version 3.5\n\n"
+                    "To keep the current behavior, use:\n\n"
+                    "\tdict(nx.shortest_path(G))"
+                ),
+                FutureWarning,
+                stacklevel=3,
+            )
 
             # Find paths between all pairs.
             if method == "unweighted":
                 paths = dict(nx.all_pairs_shortest_path(G))
             elif method == "dijkstra":
                 paths = dict(nx.all_pairs_dijkstra_path(G, weight=weight))
             else:  # method == 'bellman-ford':
@@ -174,15 +183,15 @@
             elif method == "dijkstra":
                 _, paths = nx.bidirectional_dijkstra(G, source, target, weight)
             else:  # method == 'bellman-ford':
                 paths = nx.bellman_ford_path(G, source, target, weight)
     return paths
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def shortest_path_length(G, source=None, target=None, weight=None, method="dijkstra"):
     """Compute shortest path lengths in the graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -318,15 +327,15 @@
             elif method == "dijkstra":
                 paths = nx.dijkstra_path_length(G, source, target, weight)
             else:  # method == 'bellman-ford':
                 paths = nx.bellman_ford_path_length(G, source, target, weight)
     return paths
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def average_shortest_path_length(G, weight=None, method=None):
     r"""Returns the average shortest path length.
 
     The average shortest path length is
 
     .. math::
 
@@ -431,19 +440,19 @@
         # Sum the distances for each (ordered) pair of source and target node.
         s = sum(l for u in G for l in path_length(u).values())
     else:
         if method == "floyd-warshall":
             all_pairs = nx.floyd_warshall(G, weight=weight)
             s = sum(sum(t.values()) for t in all_pairs.values())
         elif method == "floyd-warshall-numpy":
-            s = nx.floyd_warshall_numpy(G, weight=weight).sum()
+            s = float(nx.floyd_warshall_numpy(G, weight=weight).sum())
     return s / (n * (n - 1))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_shortest_paths(G, source, target, weight=None, method="dijkstra"):
     """Compute all shortest simple paths in the graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -513,15 +522,15 @@
         pred, dist = nx.bellman_ford_predecessor_and_distance(G, source, weight=weight)
     else:
         raise ValueError(f"method not supported: {method}")
 
     return _build_paths_from_predecessors({source}, target, pred)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_all_shortest_paths(G, source, weight=None, method="dijkstra"):
     """Compute all shortest simple paths from the given source in the graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -589,15 +598,15 @@
     for n in G:
         try:
             yield n, list(_build_paths_from_predecessors({source}, n, pred))
         except nx.NetworkXNoPath:
             pass
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_all_shortest_paths(G, weight=None, method="dijkstra"):
     """Compute all shortest paths between all nodes.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -643,16 +652,17 @@
 
     See Also
     --------
     all_pairs_shortest_path
     single_source_all_shortest_paths
     """
     for n in G:
-        yield n, dict(
-            single_source_all_shortest_paths(G, n, weight=weight, method=method)
+        yield (
+            n,
+            dict(single_source_all_shortest_paths(G, n, weight=weight, method=method)),
         )
 
 
 def _build_paths_from_predecessors(sources, target, pred):
     """Compute all simple paths to target, given the predecessors found in
     pred, terminating when any source in sources is found.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_astar.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_astar.py`

 * *Files 14% similar despite different names*

```diff
@@ -172,14 +172,52 @@
         assert nx.astar_path(G, "s", "v") == ["s", "u", "v"]
         assert nx.astar_path_length(G, "s", "v") == 2
 
     def test_astar_nopath(self):
         with pytest.raises(nx.NodeNotFound):
             nx.astar_path(self.XG, "s", "moon")
 
+    def test_astar_cutoff(self):
+        with pytest.raises(nx.NetworkXNoPath):
+            # optimal path_length in XG is 9
+            nx.astar_path(self.XG, "s", "v", cutoff=8.0)
+        with pytest.raises(nx.NetworkXNoPath):
+            nx.astar_path_length(self.XG, "s", "v", cutoff=8.0)
+
+    def test_astar_admissible_heuristic_with_cutoff(self):
+        heuristic_values = {"s": 36, "y": 4, "x": 0, "u": 0, "v": 0}
+
+        def h(u, v):
+            return heuristic_values[u]
+
+        assert nx.astar_path_length(self.XG, "s", "v") == 9
+        assert nx.astar_path_length(self.XG, "s", "v", heuristic=h) == 9
+        assert nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=12) == 9
+        assert nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=9) == 9
+        with pytest.raises(nx.NetworkXNoPath):
+            nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=8)
+
+    def test_astar_inadmissible_heuristic_with_cutoff(self):
+        heuristic_values = {"s": 36, "y": 14, "x": 10, "u": 10, "v": 0}
+
+        def h(u, v):
+            return heuristic_values[u]
+
+        # optimal path_length in XG is 9. This heuristic gives over-estimate.
+        assert nx.astar_path_length(self.XG, "s", "v", heuristic=h) == 10
+        assert nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=15) == 10
+        with pytest.raises(nx.NetworkXNoPath):
+            nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=9)
+        with pytest.raises(nx.NetworkXNoPath):
+            nx.astar_path_length(self.XG, "s", "v", heuristic=h, cutoff=12)
+
+    def test_astar_cutoff2(self):
+        assert nx.astar_path(self.XG, "s", "v", cutoff=10.0) == ["s", "x", "u", "v"]
+        assert nx.astar_path_length(self.XG, "s", "v") == 9
+
     def test_cycle(self):
         C = nx.cycle_graph(7)
         assert nx.astar_path(C, 0, 3) == [0, 1, 2, 3]
         assert nx.dijkstra_path(C, 0, 4) == [0, 6, 5, 4]
 
     def test_unorderable_nodes(self):
         """Tests that A* accommodates nodes that are not orderable.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_dense.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_dense.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_dense_numpy.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_dense_numpy.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_generic.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_generic.py`

 * *Files 2% similar despite different names*

```diff
@@ -208,30 +208,32 @@
         G.add_node(4)
         ans = dict(nx.single_source_all_shortest_paths(G, 0))
         assert sorted(ans[2]) == [[0, 1, 2], [0, 3, 2]]
         ans = dict(nx.single_source_all_shortest_paths(G, 4))
         assert sorted(ans[4]) == [[4]]
 
     def test_all_pairs_shortest_path(self):
+        # shortest_path w/o source and target will return a generator instead of
+        # a dict beginning in version 3.5. Only the first call needs changed here.
         p = nx.shortest_path(self.cycle)
         assert p[0][3] == [0, 1, 2, 3]
         assert p == dict(nx.all_pairs_shortest_path(self.cycle))
-        p = nx.shortest_path(self.grid)
+        p = dict(nx.shortest_path(self.grid))
         validate_grid_path(4, 4, 1, 12, p[1][12])
         # now with weights
-        p = nx.shortest_path(self.cycle, weight="weight")
+        p = dict(nx.shortest_path(self.cycle, weight="weight"))
         assert p[0][3] == [0, 1, 2, 3]
         assert p == dict(nx.all_pairs_dijkstra_path(self.cycle))
-        p = nx.shortest_path(self.grid, weight="weight")
+        p = dict(nx.shortest_path(self.grid, weight="weight"))
         validate_grid_path(4, 4, 1, 12, p[1][12])
         # weights and method specified
-        p = nx.shortest_path(self.cycle, weight="weight", method="dijkstra")
+        p = dict(nx.shortest_path(self.cycle, weight="weight", method="dijkstra"))
         assert p[0][3] == [0, 1, 2, 3]
         assert p == dict(nx.all_pairs_dijkstra_path(self.cycle))
-        p = nx.shortest_path(self.cycle, weight="weight", method="bellman-ford")
+        p = dict(nx.shortest_path(self.cycle, weight="weight", method="bellman-ford"))
         assert p[0][3] == [0, 1, 2, 3]
         assert p == dict(nx.all_pairs_bellman_ford_path(self.cycle))
 
     def test_all_pairs_shortest_path_length(self):
         ans = dict(nx.shortest_path_length(self.cycle))
         assert ans[0] == {0: 0, 1: 1, 2: 2, 3: 3, 4: 3, 5: 2, 6: 1}
         assert ans == dict(nx.all_pairs_shortest_path_length(self.cycle))
@@ -274,14 +276,18 @@
     def test_has_path(self):
         G = nx.Graph()
         nx.add_path(G, range(3))
         nx.add_path(G, range(3, 5))
         assert nx.has_path(G, 0, 2)
         assert not nx.has_path(G, 0, 4)
 
+    def test_has_path_singleton(self):
+        G = nx.empty_graph(1)
+        assert nx.has_path(G, 0, 0)
+
     def test_all_shortest_paths(self):
         G = nx.Graph()
         nx.add_path(G, [0, 1, 2, 3])
         nx.add_path(G, [0, 10, 20, 3])
         assert [[0, 1, 2, 3], [0, 10, 20, 3]] == sorted(nx.all_shortest_paths(G, 0, 3))
         # with weights
         G = nx.Graph()
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_unweighted.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_unweighted.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/tests/test_weighted.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/tests/test_weighted.py`

 * *Files 0% similar despite different names*

```diff
@@ -608,15 +608,15 @@
             nx.NetworkXUnbounded, nx.bellman_ford_predecessor_and_distance, G, 1
         )
         pytest.raises(nx.NetworkXUnbounded, nx.goldberg_radzik, G, 1)
 
     def test_zero_cycle(self):
         G = nx.cycle_graph(5, create_using=nx.DiGraph())
         G.add_edge(2, 3, weight=-4)
-        # check that zero cycle doesnt raise
+        # check that zero cycle doesn't raise
         nx.goldberg_radzik(G, 1)
         nx.bellman_ford_predecessor_and_distance(G, 1)
 
         G.add_edge(2, 3, weight=-4.0001)
         # check that negative cycle does raise
         pytest.raises(
             nx.NetworkXUnbounded, nx.bellman_ford_predecessor_and_distance, G, 1
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/unweighted.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/unweighted.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     "single_target_shortest_path_length",
     "all_pairs_shortest_path",
     "all_pairs_shortest_path_length",
     "predecessor",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def single_source_shortest_path_length(G, source, cutoff=None):
     """Compute the shortest path lengths from source to all reachable nodes.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -91,15 +91,15 @@
                     seen.add(w)
                     nextlevel.append(w)
                     yield (w, level)
             if len(seen) == n:
                 return
 
 
-@nx._dispatch
+@nx._dispatchable
 def single_target_shortest_path_length(G, target, cutoff=None):
     """Compute the shortest path lengths to target from all reachable nodes.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -131,28 +131,34 @@
     See Also
     --------
     single_source_shortest_path_length, shortest_path_length
     """
     if target not in G:
         raise nx.NodeNotFound(f"Target {target} is not in G")
 
-    msg = "single_target_shortest_path_length will return a dict starting in v3.3"
-    warnings.warn(msg, DeprecationWarning)
+    warnings.warn(
+        (
+            "\n\nsingle_target_shortest_path_length will return a dict instead of"
+            "\nan iterator in version 3.5"
+        ),
+        FutureWarning,
+        stacklevel=3,
+    )
 
     if cutoff is None:
         cutoff = float("inf")
     # handle either directed or undirected
     adj = G._pred if G.is_directed() else G._adj
     nextlevel = [target]
     # for version 3.3 we will return a dict like this:
     # return dict(_single_shortest_path_length(adj, nextlevel, cutoff))
     return _single_shortest_path_length(adj, nextlevel, cutoff)
 
 
-@nx._dispatch
+@nx._dispatchable
 def all_pairs_shortest_path_length(G, cutoff=None):
     """Computes the shortest path lengths between all nodes in `G`.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -189,15 +195,15 @@
     """
     length = single_source_shortest_path_length
     # TODO This can be trivially parallelized.
     for n in G:
         yield (n, length(G, n, cutoff=cutoff))
 
 
-@nx._dispatch
+@nx._dispatchable
 def bidirectional_shortest_path(G, source, target):
     """Returns a list of nodes in a shortest path between source and target.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -305,15 +311,15 @@
                         reverse_fringe.append(w)
                     if w in pred:  # found path
                         return pred, succ, w
 
     raise nx.NetworkXNoPath(f"No path between {source} and {target}.")
 
 
-@nx._dispatch
+@nx._dispatchable
 def single_source_shortest_path(G, source, cutoff=None):
     """Compute shortest path between source
     and all other nodes reachable from source.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -389,15 +395,15 @@
                 if w not in paths:
                     paths[w] = join(paths[v], [w])
                     nextlevel[w] = 1
         level += 1
     return paths
 
 
-@nx._dispatch
+@nx._dispatchable
 def single_target_shortest_path(G, target, cutoff=None):
     """Compute shortest path to target from all nodes that reach target.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -441,15 +447,15 @@
     if cutoff is None:
         cutoff = float("inf")
     nextlevel = {target: 1}  # list of nodes to check at next level
     paths = {target: [target]}  # paths dictionary  (paths to key from source)
     return dict(_single_shortest_path(adj, nextlevel, paths, cutoff, join))
 
 
-@nx._dispatch
+@nx._dispatchable
 def all_pairs_shortest_path(G, cutoff=None):
     """Compute shortest paths between all nodes.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -481,15 +487,15 @@
 
     """
     # TODO This can be trivially parallelized.
     for n in G:
         yield (n, single_source_shortest_path(G, n, cutoff=cutoff))
 
 
-@nx._dispatch
+@nx._dispatchable
 def predecessor(G, source, target=None, cutoff=None, return_seen=None):
     """Returns dict of predecessors for the path from source to all nodes in G.
 
     Parameters
     ----------
     G : NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/shortest_paths/weighted.py` & `networkx-3.3rc0/networkx/algorithms/shortest_paths/weighted.py`

 * *Files 1% similar despite different names*

```diff
@@ -74,15 +74,15 @@
     # string representing the edge attribute containing the weight of
     # the edge.
     if G.is_multigraph():
         return lambda u, v, d: min(attr.get(weight, 1) for attr in d.values())
     return lambda u, v, data: data.get(weight, 1)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def dijkstra_path(G, source, target, weight="weight"):
     """Returns the shortest weighted path from source to target in G.
 
     Uses Dijkstra's Method to compute the shortest weighted path
     between two nodes in a graph.
 
     Parameters
@@ -129,15 +129,18 @@
 
     Find edges of shortest path in Multigraph
 
     >>> G = nx.MultiDiGraph()
     >>> G.add_weighted_edges_from([(1, 2, 0.75), (1, 2, 0.5), (2, 3, 0.5), (1, 3, 1.5)])
     >>> nodes = nx.dijkstra_path(G, 1, 3)
     >>> edges = nx.utils.pairwise(nodes)
-    >>> list((u, v, min(G[u][v], key=lambda k: G[u][v][k].get('weight', 1))) for u, v in edges)
+    >>> list(
+    ...     (u, v, min(G[u][v], key=lambda k: G[u][v][k].get("weight", 1)))
+    ...     for u, v in edges
+    ... )
     [(1, 2, 1), (2, 3, 0)]
 
     Notes
     -----
     Edge weight attributes must be numerical.
     Distances are calculated as sums of weighted edges traversed.
 
@@ -165,15 +168,15 @@
     bellman_ford_path
     single_source_dijkstra
     """
     (length, path) = single_source_dijkstra(G, source, target=target, weight=weight)
     return path
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def dijkstra_path_length(G, source, target, weight="weight"):
     """Returns the shortest weighted path length in G from source to target.
 
     Uses Dijkstra's Method to compute the shortest weighted path length
     between two nodes in a graph.
 
     Parameters
@@ -245,15 +248,15 @@
     length = _dijkstra(G, source, weight, target=target)
     try:
         return length[target]
     except KeyError as err:
         raise nx.NetworkXNoPath(f"Node {target} not reachable from {source}") from err
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_dijkstra_path(G, source, cutoff=None, weight="weight"):
     """Find shortest weighted paths in G from a source node.
 
     Compute shortest path between source and all other reachable
     nodes for a weighted graph.
 
     Parameters
@@ -310,15 +313,15 @@
     --------
     single_source_dijkstra, single_source_bellman_ford
 
     """
     return multi_source_dijkstra_path(G, {source}, cutoff=cutoff, weight=weight)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_dijkstra_path_length(G, source, cutoff=None, weight="weight"):
     """Find shortest weighted path lengths in G from a source node.
 
     Compute the shortest path length between source and all other
     reachable nodes for a weighted graph.
 
     Parameters
@@ -382,15 +385,15 @@
     --------
     single_source_dijkstra, single_source_bellman_ford_path_length
 
     """
     return multi_source_dijkstra_path_length(G, {source}, cutoff=cutoff, weight=weight)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_dijkstra(G, source, target=None, cutoff=None, weight="weight"):
     """Find shortest weighted paths and lengths from a source node.
 
     Compute the shortest path length between source and all other
     reachable nodes for a weighted graph.
 
     Uses Dijkstra's algorithm to compute shortest paths and lengths
@@ -484,15 +487,15 @@
     single_source_bellman_ford
     """
     return multi_source_dijkstra(
         G, {source}, cutoff=cutoff, target=target, weight=weight
     )
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def multi_source_dijkstra_path(G, sources, cutoff=None, weight="weight"):
     """Find shortest weighted paths in G from a given set of source
     nodes.
 
     Compute shortest path between any of the source nodes and all other
     reachable nodes for a weighted graph.
 
@@ -558,15 +561,15 @@
     multi_source_dijkstra, multi_source_bellman_ford
 
     """
     length, path = multi_source_dijkstra(G, sources, cutoff=cutoff, weight=weight)
     return path
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def multi_source_dijkstra_path_length(G, sources, cutoff=None, weight="weight"):
     """Find shortest weighted path lengths in G from a given set of
     source nodes.
 
     Compute the shortest path length between any of the source nodes and
     all other reachable nodes for a weighted graph.
 
@@ -640,15 +643,15 @@
     for s in sources:
         if s not in G:
             raise nx.NodeNotFound(f"Node {s} not found in graph")
     weight = _weight_function(G, weight)
     return _dijkstra_multisource(G, sources, weight, cutoff=cutoff)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def multi_source_dijkstra(G, sources, target=None, cutoff=None, weight="weight"):
     """Find shortest weighted paths and lengths from a given set of
     source nodes.
 
     Uses Dijkstra's algorithm to compute the shortest paths and lengths
     between one of the source nodes and the given `target`, or all other
     reachable nodes if not specified, for a weighted graph.
@@ -877,15 +880,15 @@
                     pred[u].append(v)
 
     # The optional predecessor and path dictionaries can be accessed
     # by the caller via the pred and paths objects passed as arguments.
     return dist
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def dijkstra_predecessor_and_distance(G, source, cutoff=None, weight="weight"):
     """Compute weighted shortest path length and predecessors.
 
     Uses Dijkstra's Method to obtain the shortest weighted paths
     and return dictionaries of predecessors for each node and
     distance for each node from the `source`.
 
@@ -950,15 +953,15 @@
     if source not in G:
         raise nx.NodeNotFound(f"Node {source} is not found in the graph")
     weight = _weight_function(G, weight)
     pred = {source: []}  # dictionary of predecessors
     return (pred, _dijkstra(G, source, weight, pred=pred, cutoff=cutoff))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_dijkstra(G, cutoff=None, weight="weight"):
     """Find shortest weighted paths and lengths between all nodes.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1019,15 +1022,15 @@
     The yielded dicts only have keys for reachable nodes.
     """
     for n in G:
         dist, path = single_source_dijkstra(G, n, cutoff=cutoff, weight=weight)
         yield (n, (dist, path))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_dijkstra_path_length(G, cutoff=None, weight="weight"):
     """Compute shortest path lengths between all nodes in a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1078,15 +1081,15 @@
     The dictionary returned only has keys for reachable node pairs.
     """
     length = single_source_dijkstra_path_length
     for n in G:
         yield (n, length(G, n, cutoff=cutoff, weight=weight))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_dijkstra_path(G, cutoff=None, weight="weight"):
     """Compute shortest paths between all nodes in a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1132,15 +1135,15 @@
     """
     path = single_source_dijkstra_path
     # TODO This can be trivially parallelized.
     for n in G:
         yield (n, path(G, n, cutoff=cutoff, weight=weight))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def bellman_ford_predecessor_and_distance(
     G, source, target=None, weight="weight", heuristic=False
 ):
     """Compute shortest path lengths and predecessors on shortest paths
     in weighted graphs.
 
     The algorithm has a running time of $O(mn)$ where $n$ is the number of
@@ -1480,15 +1483,15 @@
                 elif dist.get(v) is not None and dist_v == dist.get(v):
                     pred[v].append(u)
 
     # successfully found shortest_path. No negative cycles found.
     return None
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def bellman_ford_path(G, source, target, weight="weight"):
     """Returns the shortest path from source to target in a weighted graph G.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1539,15 +1542,15 @@
     --------
     dijkstra_path, bellman_ford_path_length
     """
     length, path = single_source_bellman_ford(G, source, target=target, weight=weight)
     return path
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def bellman_ford_path_length(G, source, target, weight="weight"):
     """Returns the shortest path length from source to target
     in a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -1610,15 +1613,15 @@
 
     try:
         return length[target]
     except KeyError as err:
         raise nx.NetworkXNoPath(f"node {target} not reachable from {source}") from err
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_bellman_ford_path(G, source, weight="weight"):
     """Compute shortest path between source and all other reachable
     nodes for a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -1666,15 +1669,15 @@
     single_source_dijkstra, single_source_bellman_ford
 
     """
     (length, path) = single_source_bellman_ford(G, source, weight=weight)
     return path
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_bellman_ford_path_length(G, source, weight="weight"):
     """Compute the shortest path length between source and all other
     reachable nodes for a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -1729,15 +1732,15 @@
     single_source_dijkstra, single_source_bellman_ford
 
     """
     weight = _weight_function(G, weight)
     return _bellman_ford(G, [source], weight)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def single_source_bellman_ford(G, source, target=None, weight="weight"):
     """Compute shortest paths and lengths in a weighted graph G.
 
     Uses Bellman-Ford algorithm for shortest paths.
 
     Parameters
     ----------
@@ -1823,15 +1826,15 @@
     try:
         return (dist[target], paths[target])
     except KeyError as err:
         msg = f"Node {target} not reachable from {source}"
         raise nx.NetworkXNoPath(msg) from err
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_bellman_ford_path_length(G, weight="weight"):
     """Compute shortest path lengths between all nodes in a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1878,15 +1881,15 @@
     The dictionary returned only has keys for reachable node pairs.
     """
     length = single_source_bellman_ford_path_length
     for n in G:
         yield (n, dict(length(G, n, weight=weight)))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def all_pairs_bellman_ford_path(G, weight="weight"):
     """Compute shortest paths between all nodes in a weighted graph.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -1928,15 +1931,15 @@
     """
     path = single_source_bellman_ford_path
     # TODO This can be trivially parallelized.
     for n in G:
         yield (n, path(G, n, weight=weight))
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def goldberg_radzik(G, source, weight="weight"):
     """Compute shortest path lengths and predecessors on shortest paths
     in weighted graphs.
 
     The algorithm has a running time of $O(mn)$ where $n$ is the number of
     nodes and $m$ is the number of edges.  It is slower than Dijkstra but
     can handle negative edge weights.
@@ -2115,15 +2118,15 @@
         to_scan = topo_sort(relabeled)
         relabeled = relax(to_scan)
 
     d = {u: d[u] for u in pred}
     return pred, d
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def negative_edge_cycle(G, weight="weight", heuristic=True):
     """Returns True if there exists a negative edge cycle anywhere in G.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -2186,15 +2189,15 @@
     except nx.NetworkXUnbounded:
         return True
     finally:
         G.remove_node(newnode)
     return False
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def find_negative_cycle(G, source, weight="weight"):
     """Returns a cycle with negative total weight if it exists.
 
     Bellman-Ford is used to find shortest_paths. That algorithm
     stops if there exists a negative cycle. This algorithm
     picks up from there and returns the found negative cycle.
 
@@ -2279,15 +2282,15 @@
                 # should not reach here
                 raise nx.NetworkXError("Negative cycle is detected but not found")
     # should not get here...
     msg = "negative cycle detected but not identified"
     raise nx.NetworkXUnbounded(msg)
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def bidirectional_dijkstra(G, source, target, weight="weight"):
     r"""Dijkstra's algorithm for shortest paths using bidirectional search.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -2427,15 +2430,15 @@
                         finaldist = totaldist
                         revpath = paths[1][w][:]
                         revpath.reverse()
                         finalpath = paths[0][w] + revpath[1:]
     raise nx.NetworkXNoPath(f"No path between {source} and {target}.")
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def johnson(G, weight="weight"):
     r"""Uses Johnson's Algorithm to compute shortest paths.
 
     Johnson's Algorithm finds a shortest path between each pair of
     nodes in a weighted graph even if negative weights are present.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/similarity.py` & `networkx-3.3rc0/networkx/algorithms/similarity.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,14 +16,15 @@
 import math
 import time
 import warnings
 from dataclasses import dataclass
 from itertools import product
 
 import networkx as nx
+from networkx.utils import np_random_state
 
 __all__ = [
     "graph_edit_distance",
     "optimal_edit_paths",
     "optimize_graph_edit_distance",
     "optimize_edit_paths",
     "simrank_similarity",
@@ -32,15 +33,15 @@
 ]
 
 
 def debug_print(*args, **kwargs):
     print(*args, **kwargs)
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G1": 0, "G2": 1}, preserve_edge_attrs=True, preserve_node_attrs=True
 )
 def graph_edit_distance(
     G1,
     G2,
     node_match=None,
     edge_match=None,
@@ -206,15 +207,15 @@
         timeout,
     ):
         # assert bestcost is None or cost < bestcost
         bestcost = cost
     return bestcost
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1})
 def optimal_edit_paths(
     G1,
     G2,
     node_match=None,
     edge_match=None,
     node_subst_cost=None,
     node_del_cost=None,
@@ -318,26 +319,35 @@
     Returns
     -------
     edit_paths : list of tuples (node_edit_path, edge_edit_path)
         node_edit_path : list of tuples (u, v)
         edge_edit_path : list of tuples ((u1, v1), (u2, v2))
 
     cost : numeric
-        Optimal edit path cost (graph edit distance).
+        Optimal edit path cost (graph edit distance). When the cost
+        is zero, it indicates that `G1` and `G2` are isomorphic.
 
     Examples
     --------
     >>> G1 = nx.cycle_graph(4)
     >>> G2 = nx.wheel_graph(5)
     >>> paths, cost = nx.optimal_edit_paths(G1, G2)
     >>> len(paths)
     40
     >>> cost
     5.0
 
+    Notes
+    -----
+    To transform `G1` into a graph isomorphic to `G2`, apply the node
+    and edge edits in the returned ``edit_paths``.
+    In the case of isomorphic graphs, the cost is zero, and the paths
+    represent different isomorphic mappings (isomorphisms). That is, the
+    edits involve renaming nodes and edges to match the structure of `G2`.
+
     See Also
     --------
     graph_edit_distance, optimize_edit_paths
 
     References
     ----------
     .. [1] Zeina Abu-Aisheh, Romain Raveaux, Jean-Yves Ramel, Patrick
@@ -369,15 +379,15 @@
         if bestcost is not None and cost < bestcost:
             paths = []
         paths.append((vertex_path, edge_path))
         bestcost = cost
     return paths, bestcost
 
 
-@nx._dispatch(graphs={"G1": 0, "G2": 1})
+@nx._dispatchable(graphs={"G1": 0, "G2": 1})
 def optimize_graph_edit_distance(
     G1,
     G2,
     node_match=None,
     edge_match=None,
     node_subst_cost=None,
     node_del_cost=None,
@@ -520,15 +530,15 @@
         edge_ins_cost,
         upper_bound,
         True,
     ):
         yield cost
 
 
-@nx._dispatch(
+@nx._dispatchable(
     graphs={"G1": 0, "G2": 1}, preserve_edge_attrs=True, preserve_node_attrs=True
 )
 def optimize_edit_paths(
     G1,
     G2,
     node_match=None,
     edge_match=None,
@@ -1196,18 +1206,18 @@
     ):
         # assert sorted(G1.nodes) == sorted(u for u, v in vertex_path if u is not None)
         # assert sorted(G2.nodes) == sorted(v for u, v in vertex_path if v is not None)
         # assert sorted(G1.edges) == sorted(g for g, h in edge_path if g is not None)
         # assert sorted(G2.edges) == sorted(h for g, h in edge_path if h is not None)
         # print(vertex_path, edge_path, cost, file = sys.stderr)
         # assert cost == maxcost_value
-        yield list(vertex_path), list(edge_path), cost
+        yield list(vertex_path), list(edge_path), float(cost)
 
 
-@nx._dispatch
+@nx._dispatchable
 def simrank_similarity(
     G,
     source=None,
     target=None,
     importance_factor=0.9,
     max_iterations=1000,
     tolerance=1e-4,
@@ -1219,17 +1229,17 @@
 
     The pseudo-code definition from the paper is::
 
         def simrank(G, u, v):
             in_neighbors_u = G.predecessors(u)
             in_neighbors_v = G.predecessors(v)
             scale = C / (len(in_neighbors_u) * len(in_neighbors_v))
-            return scale * sum(simrank(G, w, x)
-                               for w, x in product(in_neighbors_u,
-                                                   in_neighbors_v))
+            return scale * sum(
+                simrank(G, w, x) for w, x in product(in_neighbors_u, in_neighbors_v)
+            )
 
     where ``G`` is the graph, ``u`` is the source, ``v`` is the target,
     and ``C`` is a float decay or importance factor between 0 and 1.
 
     The SimRank algorithm for determining node similarity is defined in
     [2]_.
 
@@ -1271,14 +1281,22 @@
         If ``source`` is not ``None`` but ``target`` is, this returns a
         dictionary mapping node to the similarity of ``source`` and that
         node.
 
         If neither ``source`` nor ``target`` is ``None``, this returns
         the similarity value for the given pair of nodes.
 
+    Raises
+    ------
+    ExceededMaxIterations
+        If the algorithm does not converge within ``max_iterations``.
+
+    NodeNotFound
+        If either ``source`` or ``target`` is not in `G`.
+
     Examples
     --------
     >>> G = nx.cycle_graph(2)
     >>> nx.simrank_similarity(G)
     {0: {0: 1.0, 1: 0.0}, 1: {0: 0.0, 1: 1.0}}
     >>> nx.simrank_similarity(G, source=0)
     {0: 1.0, 1: 0.0}
@@ -1307,27 +1325,40 @@
            In KDD'02: Proceedings of the Eighth ACM SIGKDD
            International Conference on Knowledge Discovery and Data Mining,
            pp. 538--543. ACM Press, 2002.
     """
     import numpy as np
 
     nodelist = list(G)
-    s_indx = None if source is None else nodelist.index(source)
-    t_indx = None if target is None else nodelist.index(target)
+    if source is not None:
+        if source not in nodelist:
+            raise nx.NodeNotFound(f"Source node {source} not in G")
+        else:
+            s_indx = nodelist.index(source)
+    else:
+        s_indx = None
+
+    if target is not None:
+        if target not in nodelist:
+            raise nx.NodeNotFound(f"Target node {target} not in G")
+        else:
+            t_indx = nodelist.index(target)
+    else:
+        t_indx = None
 
     x = _simrank_similarity_numpy(
         G, s_indx, t_indx, importance_factor, max_iterations, tolerance
     )
 
     if isinstance(x, np.ndarray):
         if x.ndim == 1:
-            return dict(zip(G, x))
+            return dict(zip(G, x.tolist()))
         # else x.ndim == 2
-        return {u: dict(zip(G, row)) for u, row in zip(G, x)}
-    return x
+        return {u: dict(zip(G, row)) for u, row in zip(G, x.tolist())}
+    return float(x)
 
 
 def _simrank_similarity_python(
     G,
     source=None,
     target=None,
     importance_factor=0.9,
@@ -1359,15 +1390,15 @@
     Gadj = G.pred if G.is_directed() else G.adj
 
     def sim(u, v):
         return importance_factor * avg_sim(list(product(Gadj[u], Gadj[v])))
 
     for its in range(max_iterations):
         oldsim = newsim
-        newsim = {u: {v: sim(u, v) if u is not v else 1 for v in G} for u in G}
+        newsim = {u: {v: sim(u, v) if u != v else 1 for v in G} for u in G}
         is_close = all(
             all(
                 abs(newsim[u][v] - old) <= tolerance * (1 + abs(old))
                 for v, old in nbrs.items()
             )
             for u, nbrs in oldsim.items()
         )
@@ -1491,15 +1522,15 @@
     if source is not None and target is not None:
         return newsim[source, target]
     if source is not None:
         return newsim[source]
     return newsim
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def panther_similarity(
     G, source, k=5, path_length=5, c=0.5, delta=0.1, eps=None, weight="weight"
 ):
     r"""Returns the Panther similarity of nodes in the graph `G` to node ``v``.
 
     Panther is a similarity metric that says "two objects are considered
     to be similar if they frequently appear on the same paths." [1]_.
@@ -1507,15 +1538,15 @@
     Parameters
     ----------
     G : NetworkX graph
         A NetworkX graph
     source : node
         Source node for which to find the top `k` similar other nodes
     k : int (default = 5)
-        The number of most similar nodes to return
+        The number of most similar nodes to return.
     path_length : int (default = 5)
         How long the randomly generated paths should be (``T`` in [1]_)
     c : float (default = 0.5)
         A universal positive constant used to scale the number
         of sample random paths to generate.
     delta : float (default = 0.1)
         The probability that the similarity $S$ is not an epsilon-approximation to (R, phi),
@@ -1529,15 +1560,28 @@
         used as a weight. If None then each edge has weight 1.
 
     Returns
     -------
     similarity : dictionary
         Dictionary of nodes to similarity scores (as floats). Note:
         the self-similarity (i.e., ``v``) will not be included in
-        the returned dictionary.
+        the returned dictionary. So, for ``k = 5``, a dictionary of
+        top 4 nodes and their similarity scores will be returned.
+
+    Raises
+    ------
+    NetworkXUnfeasible
+        If `source` is an isolated node.
+
+    NodeNotFound
+        If `source` is not in `G`.
+
+    Notes
+    -----
+        The isolated nodes in `G` are ignored.
 
     Examples
     --------
     >>> G = nx.star_graph(10)
     >>> sim = nx.panther_similarity(G, 0)
 
     References
@@ -1546,14 +1590,26 @@
            Panther: Fast top-k similarity search on large networks.
            In Proceedings of the ACM SIGKDD International Conference
            on Knowledge Discovery and Data Mining (Vol. 2015-August, pp. 1445–1454).
            Association for Computing Machinery. https://doi.org/10.1145/2783258.2783267.
     """
     import numpy as np
 
+    if source not in G:
+        raise nx.NodeNotFound(f"Source node {source} not in G")
+
+    isolates = set(nx.isolates(G))
+
+    if source in isolates:
+        raise nx.NetworkXUnfeasible(
+            f"Panther similarity is not defined for the isolated source node {source}."
+        )
+
+    G = G.subgraph([node for node in G.nodes if node not in isolates]).copy()
+
     num_nodes = G.number_of_nodes()
     if num_nodes < k:
         warnings.warn(
             f"Number of nodes is {num_nodes}, but requested k is {k}. "
             "Setting k to number of nodes."
         )
         k = num_nodes
@@ -1594,25 +1650,27 @@
     # Retrieve top ``k`` similar
     # Note: the below performed anywhere from 4-10x faster
     # (depending on input sizes) vs the equivalent ``np.argsort(S)[::-1]``
     top_k_unsorted = np.argpartition(S, -k)[-k:]
     top_k_sorted = top_k_unsorted[np.argsort(S[top_k_unsorted])][::-1]
 
     # Add back the similarity scores
-    top_k_sorted_names = (node_map[n] for n in top_k_sorted)
-    top_k_with_val = dict(zip(top_k_sorted_names, S[top_k_sorted]))
+    top_k_with_val = dict(
+        zip(node_map[top_k_sorted].tolist(), S[top_k_sorted].tolist())
+    )
 
     # Remove the self-similarity
     top_k_with_val.pop(source, None)
     return top_k_with_val
 
 
-@nx._dispatch(edge_attrs="weight")
+@np_random_state(5)
+@nx._dispatchable(edge_attrs="weight")
 def generate_random_paths(
-    G, sample_size, path_length=5, index_map=None, weight="weight"
+    G, sample_size, path_length=5, index_map=None, weight="weight", seed=None
 ):
     """Randomly generate `sample_size` paths of length `path_length`.
 
     Parameters
     ----------
     G : NetworkX graph
         A NetworkX graph
@@ -1625,14 +1683,17 @@
     index_map : dictionary, optional
         If provided, this will be populated with the inverted
         index of nodes mapped to the set of generated random path
         indices within ``paths``.
     weight : string or None, optional (default="weight")
         The name of an edge attribute that holds the numerical value
         used as a weight. If None then each edge has weight 1.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
     Returns
     -------
     paths : generator of lists
         Generator of `sample_size` paths each with length `path_length`.
 
     Examples
@@ -1644,38 +1705,44 @@
 
     By passing a dictionary into `index_map`, it will build an
     inverted index mapping of nodes to the paths in which that node is present:
 
     >>> G = nx.star_graph(3)
     >>> index_map = {}
     >>> random_path = nx.generate_random_paths(G, 3, index_map=index_map)
-    >>> paths_containing_node_0 = [random_path[path_idx] for path_idx in index_map.get(0, [])]
+    >>> paths_containing_node_0 = [
+    ...     random_path[path_idx] for path_idx in index_map.get(0, [])
+    ... ]
 
     References
     ----------
     .. [1] Zhang, J., Tang, J., Ma, C., Tong, H., Jing, Y., & Li, J.
            Panther: Fast top-k similarity search on large networks.
            In Proceedings of the ACM SIGKDD International Conference
            on Knowledge Discovery and Data Mining (Vol. 2015-August, pp. 1445–1454).
            Association for Computing Machinery. https://doi.org/10.1145/2783258.2783267.
     """
     import numpy as np
 
+    randint_fn = (
+        seed.integers if isinstance(seed, np.random.Generator) else seed.randint
+    )
+
     # Calculate transition probabilities between
     # every pair of vertices according to Eq. (3)
     adj_mat = nx.to_numpy_array(G, weight=weight)
     inv_row_sums = np.reciprocal(adj_mat.sum(axis=1)).reshape(-1, 1)
     transition_probabilities = adj_mat * inv_row_sums
 
-    node_map = np.array(G)
+    node_map = list(G)
     num_nodes = G.number_of_nodes()
 
     for path_index in range(sample_size):
         # Sample current vertex v = v_i uniformly at random
-        node_index = np.random.randint(0, high=num_nodes)
+        node_index = randint_fn(num_nodes)
         node = node_map[node_index]
 
         # Add v into p_r and add p_r into the path set
         # of v, i.e., P_v
         path = [node]
 
         # Build the inverted index (P_v) of vertices to paths
@@ -1685,26 +1752,26 @@
             else:
                 index_map[node] = {path_index}
 
         starting_index = node_index
         for _ in range(path_length):
             # Randomly sample a neighbor (v_j) according
             # to transition probabilities from ``node`` (v) to its neighbors
-            neighbor_index = np.random.choice(
+            nbr_index = seed.choice(
                 num_nodes, p=transition_probabilities[starting_index]
             )
 
             # Set current vertex (v = v_j)
-            starting_index = neighbor_index
+            starting_index = nbr_index
 
             # Add v into p_r
-            neighbor_node = node_map[neighbor_index]
-            path.append(neighbor_node)
+            nbr_node = node_map[nbr_index]
+            path.append(nbr_node)
 
             # Add p_r into P_v
             if index_map is not None:
-                if neighbor_node in index_map:
-                    index_map[neighbor_node].add(path_index)
+                if nbr_node in index_map:
+                    index_map[nbr_node].add(path_index)
                 else:
-                    index_map[neighbor_node] = {path_index}
+                    index_map[nbr_node] = {path_index}
 
         yield path
```

### Comparing `networkx-3.2rc0/networkx/algorithms/simple_paths.py` & `networkx-3.3rc0/networkx/algorithms/simple_paths.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     "all_simple_paths",
     "is_simple_path",
     "shortest_simple_paths",
     "all_simple_edge_paths",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_simple_path(G, nodes):
     """Returns True if and only if `nodes` form a simple path in `G`.
 
     A *simple path* in a graph is a nonempty sequence of nodes in which
     no node appears more than once in the sequence, and each adjacent
     pair of nodes in the sequence is adjacent in the graph.
 
@@ -87,15 +87,15 @@
     if len(set(nodes)) != len(nodes):
         return False
 
     # Test that each adjacent pair of nodes is adjacent.
     return all(v in G[u] for u, v in pairwise(nodes))
 
 
-@nx._dispatch
+@nx._dispatchable
 def all_simple_paths(G, source, target, cutoff=None):
     """Generate all simple paths in the graph G from source to target.
 
     A simple path is a path with no repeated nodes.
 
     Parameters
     ----------
@@ -165,14 +165,25 @@
         [0, 2]
         [0, 2, 1, 3]
         [0, 2, 3]
         [0, 3]
         [0, 3, 1, 2]
         [0, 3, 2]
 
+    The singleton path from ``source`` to itself is considered a simple path and is
+    included in the results:
+
+        >>> G = nx.empty_graph(5)
+        >>> list(nx.all_simple_paths(G, source=0, target=0))
+        [[0]]
+
+        >>> G = nx.path_graph(3)
+        >>> list(nx.all_simple_paths(G, source=0, target={0, 1, 2}))
+        [[0], [0, 1], [0, 1, 2]]
+
     Iterate over each path from the root nodes to the leaf nodes in a
     directed acyclic graph using a functional programming approach::
 
         >>> from itertools import chain
         >>> from itertools import product
         >>> from itertools import starmap
         >>> from functools import partial
@@ -238,94 +249,19 @@
        Addison Wesley Professional, 3rd ed., 2001.
 
     See Also
     --------
     all_shortest_paths, shortest_path, has_path
 
     """
-    if source not in G:
-        raise nx.NodeNotFound(f"source node {source} not in graph")
-    if target in G:
-        targets = {target}
-    else:
-        try:
-            targets = set(target)
-        except TypeError as err:
-            raise nx.NodeNotFound(f"target node {target} not in graph") from err
-    if source in targets:
-        return _empty_generator()
-    if cutoff is None:
-        cutoff = len(G) - 1
-    if cutoff < 1:
-        return _empty_generator()
-    if G.is_multigraph():
-        return _all_simple_paths_multigraph(G, source, targets, cutoff)
-    else:
-        return _all_simple_paths_graph(G, source, targets, cutoff)
-
-
-def _empty_generator():
-    yield from ()
-
-
-def _all_simple_paths_graph(G, source, targets, cutoff):
-    visited = {source: True}
-    stack = [iter(G[source])]
-    while stack:
-        children = stack[-1]
-        child = next(children, None)
-        if child is None:
-            stack.pop()
-            visited.popitem()
-        elif len(visited) < cutoff:
-            if child in visited:
-                continue
-            if child in targets:
-                yield list(visited) + [child]
-            visited[child] = True
-            if targets - set(visited.keys()):  # expand stack until find all targets
-                stack.append(iter(G[child]))
-            else:
-                visited.popitem()  # maybe other ways to child
-        else:  # len(visited) == cutoff:
-            for target in (targets & (set(children) | {child})) - set(visited.keys()):
-                yield list(visited) + [target]
-            stack.pop()
-            visited.popitem()
+    for edge_path in all_simple_edge_paths(G, source, target, cutoff):
+        yield [source] + [edge[1] for edge in edge_path]
 
 
-def _all_simple_paths_multigraph(G, source, targets, cutoff):
-    visited = {source: True}
-    stack = [(v for u, v in G.edges(source))]
-    while stack:
-        children = stack[-1]
-        child = next(children, None)
-        if child is None:
-            stack.pop()
-            visited.popitem()
-        elif len(visited) < cutoff:
-            if child in visited:
-                continue
-            if child in targets:
-                yield list(visited) + [child]
-            visited[child] = True
-            if targets - set(visited.keys()):
-                stack.append((v for u, v in G.edges(child)))
-            else:
-                visited.popitem()
-        else:  # len(visited) == cutoff:
-            for target in targets - set(visited.keys()):
-                count = ([child] + list(children)).count(target)
-                for i in range(count):
-                    yield list(visited) + [target]
-            stack.pop()
-            visited.popitem()
-
-
-@nx._dispatch
+@nx._dispatchable
 def all_simple_edge_paths(G, source, target, cutoff=None):
     """Generate lists of edges for all simple paths in G from source to target.
 
     A simple path is a path with no repeated nodes.
 
     Parameters
     ----------
@@ -371,14 +307,27 @@
         >>> mg.add_edge(2, 3, key="k0")
         'k0'
         >>> for path in sorted(nx.all_simple_edge_paths(mg, 1, 3)):
         ...     print(path)
         [(1, 2, 'k0'), (2, 3, 'k0')]
         [(1, 2, 'k1'), (2, 3, 'k0')]
 
+    When ``source`` is one of the targets, the empty path starting and ending at
+    ``source`` without traversing any edge is considered a valid simple edge path
+    and is included in the results:
+
+        >>> G = nx.Graph()
+        >>> G.add_node(0)
+        >>> paths = list(nx.all_simple_edge_paths(G, 0, 0))
+        >>> for path in paths:
+        ...     print(path)
+        []
+        >>> len(paths)
+        1
+
 
     Notes
     -----
     This algorithm uses a modified depth-first search to generate the
     paths [1]_.  A single path can be found in $O(V+E)$ time but the
     number of simple paths in a graph can be very large, e.g. $O(n!)$ in
     the complete graph of order $n$.
@@ -390,64 +339,74 @@
 
     See Also
     --------
     all_shortest_paths, shortest_path, all_simple_paths
 
     """
     if source not in G:
-        raise nx.NodeNotFound("source node %s not in graph" % source)
+        raise nx.NodeNotFound(f"source node {source} not in graph")
+
     if target in G:
         targets = {target}
     else:
         try:
             targets = set(target)
-        except TypeError:
-            raise nx.NodeNotFound("target node %s not in graph" % target)
-    if source in targets:
-        return []
-    if cutoff is None:
-        cutoff = len(G) - 1
-    if cutoff < 1:
-        return []
-    if G.is_multigraph():
-        for simp_path in _all_simple_edge_paths_multigraph(G, source, targets, cutoff):
-            yield simp_path
-    else:
-        for simp_path in _all_simple_paths_graph(G, source, targets, cutoff):
-            yield list(zip(simp_path[:-1], simp_path[1:]))
+        except TypeError as err:
+            raise nx.NodeNotFound(f"target node {target} not in graph") from err
+
+    cutoff = cutoff if cutoff is not None else len(G) - 1
 
+    if cutoff >= 0 and targets:
+        yield from _all_simple_edge_paths(G, source, targets, cutoff)
 
-def _all_simple_edge_paths_multigraph(G, source, targets, cutoff):
-    if not cutoff or cutoff < 1:
-        return []
-    visited = [source]
-    stack = [iter(G.edges(source, keys=True))]
+
+def _all_simple_edge_paths(G, source, targets, cutoff):
+    # We simulate recursion with a stack, keeping the current path being explored
+    # and the outgoing edge iterators at each point in the stack.
+    # To avoid unnecessary checks, the loop is structured in a way such that a path
+    # is considered for yielding only after a new node/edge is added.
+    # We bootstrap the search by adding a dummy iterator to the stack that only yields
+    # a dummy edge to source (so that the trivial path has a chance of being included).
+
+    get_edges = (
+        (lambda node: G.edges(node, keys=True))
+        if G.is_multigraph()
+        else (lambda node: G.edges(node))
+    )
+
+    # The current_path is a dictionary that maps nodes in the path to the edge that was
+    # used to enter that node (instead of a list of edges) because we want both a fast
+    # membership test for nodes in the path and the preservation of insertion order.
+    current_path = {None: None}
+    stack = [iter([(None, source)])]
 
     while stack:
-        children = stack[-1]
-        child = next(children, None)
-        if child is None:
-            stack.pop()
-            visited.pop()
-        elif len(visited) < cutoff:
-            if child[1] in targets:
-                yield visited[1:] + [child]
-            elif child[1] not in [v[0] for v in visited[1:]]:
-                visited.append(child)
-                stack.append(iter(G.edges(child[1], keys=True)))
-        else:  # len(visited) == cutoff:
-            for u, v, k in [child] + list(children):
-                if v in targets:
-                    yield visited[1:] + [(u, v, k)]
+        # 1. Try to extend the current path.
+        next_edge = next((e for e in stack[-1] if e[1] not in current_path), None)
+        if next_edge is None:
+            # All edges of the last node in the current path have been explored.
             stack.pop()
-            visited.pop()
+            current_path.popitem()
+            continue
+        previous_node, next_node, *_ = next_edge
+
+        # 2. Check if we've reached a target.
+        if next_node in targets:
+            yield (list(current_path.values()) + [next_edge])[2:]  # remove dummy edge
+
+        # 3. Only expand the search through the next node if it makes sense.
+        if len(current_path) - 1 < cutoff and (
+            targets - current_path.keys() - {next_node}
+        ):
+            current_path[next_node] = next_edge
+            stack.append(iter(get_edges(next_node)))
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def shortest_simple_paths(G, source, target, weight=None):
     """Generate all simple paths in the graph G from source to target,
        starting from shortest ones.
 
     A simple path is a path with no repeated nodes.
 
     If a weighted shortest path search is to be used, no negative weights
```

### Comparing `networkx-3.2rc0/networkx/algorithms/smallworld.py` & `networkx-3.3rc0/networkx/algorithms/smallworld.py`

 * *Files 1% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 
 __all__ = ["random_reference", "lattice_reference", "sigma", "omega"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def random_reference(G, niter=1, connectivity=True, seed=None):
     """Compute a random graph by swapping edges of a given graph.
 
     Parameters
     ----------
     G : graph
         An undirected graph with 4 or more nodes.
@@ -117,15 +117,15 @@
             n += 1
     return G
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
 @py_random_state(4)
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def lattice_reference(G, niter=5, D=None, connectivity=True, seed=None):
     """Latticize the given graph by swapping edges.
 
     Parameters
     ----------
     G : graph
         An undirected graph.
@@ -241,15 +241,15 @@
 
     return G
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable
 def sigma(G, niter=100, nrand=10, seed=None):
     """Returns the small-world coefficient (sigma) of the given graph.
 
     The small-world coefficient is defined as:
     sigma = C/Cr / L/Lr
     where C and L are respectively the average clustering coefficient and
     average shortest path length of G. Cr and Lr are respectively the average
@@ -304,21 +304,21 @@
     C = nx.transitivity(G)
     L = nx.average_shortest_path_length(G)
     Cr = np.mean(randMetrics["C"])
     Lr = np.mean(randMetrics["L"])
 
     sigma = (C / Cr) / (L / Lr)
 
-    return sigma
+    return float(sigma)
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable
 def omega(G, niter=5, nrand=10, seed=None):
     """Returns the small-world coefficient (omega) of a graph
 
     The small-world coefficient of a graph G is:
 
     omega = Lr/L - C/Cl
 
@@ -396,8 +396,8 @@
 
     C = nx.average_clustering(G)
     L = nx.average_shortest_path_length(G)
     Lr = np.mean(randMetrics["L"])
 
     omega = (Lr / L) - (C / Cl)
 
-    return omega
+    return float(omega)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/smetric.py` & `networkx-3.3rc0/networkx/algorithms/smetric.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import networkx as nx
 
 __all__ = ["s_metric"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def s_metric(G, **kwargs):
     """Returns the s-metric [1]_ of graph.
 
     The s-metric is defined as the sum of the products ``deg(u) * deg(v)``
     for every edge ``(u, v)`` in `G`.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/sparsifiers.py` & `networkx-3.3rc0/networkx/algorithms/sparsifiers.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 
 __all__ = ["spanner"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
 @py_random_state(3)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight", returns_graph=True)
 def spanner(G, stretch, weight=None, seed=None):
     """Returns a spanner of the given graph with the given stretch.
 
     A spanner of a graph G = (V, E) with stretch t is a subgraph
     H = (V, E_S) such that E_S is a subset of E and the distance between
     any pair of nodes in H is at most t times the distance between the
     nodes in G.
@@ -132,19 +132,19 @@
                     if edge_weight < closest_center_weight:
                         neighbor = lightest_edge_neighbor[center]
                         edges_to_add.add((v, neighbor))
 
                 # remove edges to centers with edge weight less than
                 # closest_center_weight
                 for neighbor in residual_graph.adj[v]:
-                    neighbor_cluster = clustering[neighbor]
-                    neighbor_weight = lightest_edge_weight[neighbor_cluster]
+                    nbr_cluster = clustering[neighbor]
+                    nbr_weight = lightest_edge_weight[nbr_cluster]
                     if (
-                        neighbor_cluster == closest_center
-                        or neighbor_weight < closest_center_weight
+                        nbr_cluster == closest_center
+                        or nbr_weight < closest_center_weight
                     ):
                         edges_to_remove.add((v, neighbor))
 
         # check whether iteration added too many edges to spanner,
         # if so repeat
         if len(edges_to_add) > size_limit:
             # an iteration is repeated O(1) times on expectation
@@ -253,22 +253,22 @@
     If a cluster has no node that is adjacent to the given node in the
     residual graph then the center of the cluster is not a key in the
     returned dictionaries.
     """
     lightest_edge_neighbor = {}
     lightest_edge_weight = {}
     for neighbor in residual_graph.adj[node]:
-        neighbor_center = clustering[neighbor]
+        nbr_center = clustering[neighbor]
         weight = residual_graph[node][neighbor]["weight"]
         if (
-            neighbor_center not in lightest_edge_weight
-            or weight < lightest_edge_weight[neighbor_center]
+            nbr_center not in lightest_edge_weight
+            or weight < lightest_edge_weight[nbr_center]
         ):
-            lightest_edge_neighbor[neighbor_center] = neighbor
-            lightest_edge_weight[neighbor_center] = weight
+            lightest_edge_neighbor[nbr_center] = neighbor
+            lightest_edge_weight[nbr_center] = weight
     return lightest_edge_neighbor, lightest_edge_weight
 
 
 def _add_edge_to_spanner(H, residual_graph, u, v, weight):
     """Add the edge {u, v} to the spanner H and take weight from
     the residual graph.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/structuralholes.py` & `networkx-3.3rc0/networkx/algorithms/structuralholes.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Functions for computing measures of structural holes."""
 
 import networkx as nx
 
 __all__ = ["constraint", "local_constraint", "effective_size"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def mutual_weight(G, u, v, weight=None):
     """Returns the sum of the weights of the edge from `u` to `v` and
     the edge from `v` to `u` in `G`.
 
     `weight` is the edge data key that represents the edge weight. If
     the specified key is `None` or is not in the edge data for an edge,
     that edge is assumed to have weight 1.
@@ -24,15 +24,15 @@
     try:
         a_vu = G[v][u].get(weight, 1)
     except KeyError:
         a_vu = 0
     return a_uv + a_vu
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def normalized_mutual_weight(G, u, v, norm=sum, weight=None):
     """Returns normalized mutual weight of the edges from `u` to `v`
     with respect to the mutual weights of the neighbors of `u` in `G`.
 
     `norm` specifies how the normalization factor is computed. It must
     be a function that takes a single argument and returns a number.
     The argument will be an iterable of mutual weights
@@ -45,15 +45,15 @@
     attribute used as weight.
 
     """
     scale = norm(mutual_weight(G, u, w, weight) for w in set(nx.all_neighbors(G, u)))
     return 0 if scale == 0 else mutual_weight(G, u, v, weight) / scale
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def effective_size(G, nodes=None, weight=None):
     r"""Returns the effective size of all nodes in the graph ``G``.
 
     The *effective size* of a node's ego network is based on the concept
     of redundancy. A person's ego network has redundancy to the extent
     that her contacts are connected to each other as well. The
     nonredundant part of a person's relationships is the effective
@@ -158,15 +158,15 @@
                 continue
             effective_size[v] = sum(
                 redundancy(G, v, u, weight) for u in set(nx.all_neighbors(G, v))
             )
     return effective_size
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def constraint(G, nodes=None, weight=None):
     r"""Returns the constraint on all nodes in the graph ``G``.
 
     The *constraint* is a measure of the extent to which a node *v* is
     invested in those nodes that are themselves invested in the
     neighbors of *v*. Formally, the *constraint on v*, denoted `c(v)`,
     is defined by
@@ -219,21 +219,21 @@
             continue
         constraint[v] = sum(
             local_constraint(G, v, n, weight) for n in set(nx.all_neighbors(G, v))
         )
     return constraint
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def local_constraint(G, u, v, weight=None):
     r"""Returns the local constraint on the node ``u`` with respect to
     the node ``v`` in the graph ``G``.
 
     Formally, the *local constraint on u with respect to v*, denoted
-    $\ell(v)$, is defined by
+    $\ell(u, v)$, is defined by
 
     .. math::
 
        \ell(u, v) = \left(p_{uv} + \sum_{w \in N(v)} p_{uw} p_{wv}\right)^2,
 
     where $N(v)$ is the set of neighbors of $v$ and $p_{uv}$ is the
     normalized mutual weight of the (directed or undirected) edges
```

### Comparing `networkx-3.2rc0/networkx/algorithms/summarization.py` & `networkx-3.3rc0/networkx/generators/joint_degree_seq.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,561 +1,664 @@
-"""
-Graph summarization finds smaller representations of graphs resulting in faster
-runtime of algorithms, reduced storage needs, and noise reduction.
-Summarization has applications in areas such as visualization, pattern mining,
-clustering and community detection, and more.  Core graph summarization
-techniques are grouping/aggregation, bit-compression,
-simplification/sparsification, and influence based. Graph summarization
-algorithms often produce either summary graphs in the form of supergraphs or
-sparsified graphs, or a list of independent structures. Supergraphs are the
-most common product, which consist of supernodes and original nodes and are
-connected by edges and superedges, which represent aggregate edges between
-nodes and supernodes.
-
-Grouping/aggregation based techniques compress graphs by representing
-close/connected nodes and edges in a graph by a single node/edge in a
-supergraph. Nodes can be grouped together into supernodes based on their
-structural similarities or proximity within a graph to reduce the total number
-of nodes in a graph. Edge-grouping techniques group edges into lossy/lossless
-nodes called compressor or virtual nodes to reduce the total number of edges in
-a graph. Edge-grouping techniques can be lossless, meaning that they can be
-used to re-create the original graph, or techniques can be lossy, requiring
-less space to store the summary graph, but at the expense of lower
-reconstruction accuracy of the original graph.
-
-Bit-compression techniques minimize the amount of information needed to
-describe the original graph, while revealing structural patterns in the
-original graph.  The two-part minimum description length (MDL) is often used to
-represent the model and the original graph in terms of the model.  A key
-difference between graph compression and graph summarization is that graph
-summarization focuses on finding structural patterns within the original graph,
-whereas graph compression focuses on compressions the original graph to be as
-small as possible.  **NOTE**: Some bit-compression methods exist solely to
-compress a graph without creating a summary graph or finding comprehensible
-structural patterns.
-
-Simplification/Sparsification techniques attempt to create a sparse
-representation of a graph by removing unimportant nodes and edges from the
-graph.  Sparsified graphs differ from supergraphs created by
-grouping/aggregation by only containing a subset of the original nodes and
-edges of the original graph.
-
-Influence based techniques aim to find a high-level description of influence
-propagation in a large graph.  These methods are scarce and have been mostly
-applied to social graphs.
-
-*dedensification* is a grouping/aggregation based technique to compress the
-neighborhoods around high-degree nodes in unweighted graphs by adding
-compressor nodes that summarize multiple edges of the same type to
-high-degree nodes (nodes with a degree greater than a given threshold).
-Dedensification was developed for the purpose of increasing performance of
-query processing around high-degree nodes in graph databases and enables direct
-operations on the compressed graph.  The structural patterns surrounding
-high-degree nodes in the original is preserved while using fewer edges and
-adding a small number of compressor nodes.  The degree of nodes present in the
-original graph is also preserved. The current implementation of dedensification
-supports graphs with one edge type.
-
-For more information on graph summarization, see `Graph Summarization Methods
-and Applications: A Survey <https://dl.acm.org/doi/abs/10.1145/3186727>`_
-"""
-from collections import Counter, defaultdict
+"""Generate graphs with a given joint degree and directed joint degree"""
 
 import networkx as nx
+from networkx.utils import py_random_state
 
-__all__ = ["dedensify", "snap_aggregation"]
+__all__ = [
+    "is_valid_joint_degree",
+    "is_valid_directed_joint_degree",
+    "joint_degree_graph",
+    "directed_joint_degree_graph",
+]
+
+
+@nx._dispatchable(graphs=None)
+def is_valid_joint_degree(joint_degrees):
+    """Checks whether the given joint degree dictionary is realizable.
+
+    A *joint degree dictionary* is a dictionary of dictionaries, in
+    which entry ``joint_degrees[k][l]`` is an integer representing the
+    number of edges joining nodes of degree *k* with nodes of degree
+    *l*. Such a dictionary is realizable as a simple graph if and only
+    if the following conditions are satisfied.
+
+    - each entry must be an integer,
+    - the total number of nodes of degree *k*, computed by
+      ``sum(joint_degrees[k].values()) / k``, must be an integer,
+    - the total number of edges joining nodes of degree *k* with
+      nodes of degree *l* cannot exceed the total number of possible edges,
+    - each diagonal entry ``joint_degrees[k][k]`` must be even (this is
+      a convention assumed by the :func:`joint_degree_graph` function).
 
 
-@nx._dispatch
-def dedensify(G, threshold, prefix=None, copy=True):
-    """Compresses neighborhoods around high-degree nodes
-
-    Reduces the number of edges to high-degree nodes by adding compressor nodes
-    that summarize multiple edges of the same type to high-degree nodes (nodes
-    with a degree greater than a given threshold).  Dedensification also has
-    the added benefit of reducing the number of edges around high-degree nodes.
-    The implementation currently supports graphs with a single edge type.
-
     Parameters
     ----------
-    G: graph
-       A networkx graph
-    threshold: int
-       Minimum degree threshold of a node to be considered a high degree node.
-       The threshold must be greater than or equal to 2.
-    prefix: str or None, optional (default: None)
-       An optional prefix for denoting compressor nodes
-    copy: bool, optional (default: True)
-       Indicates if dedensification should be done inplace
+    joint_degrees :  dictionary of dictionary of integers
+        A joint degree dictionary in which entry ``joint_degrees[k][l]``
+        is the number of edges joining nodes of degree *k* with nodes of
+        degree *l*.
 
     Returns
     -------
-    dedensified networkx graph : (graph, set)
-        2-tuple of the dedensified graph and set of compressor nodes
+    bool
+        Whether the given joint degree dictionary is realizable as a
+        simple graph.
 
-    Notes
-    -----
-    According to the algorithm in [1]_, removes edges in a graph by
-    compressing/decompressing the neighborhoods around high degree nodes by
-    adding compressor nodes that summarize multiple edges of the same type
-    to high-degree nodes.  Dedensification will only add a compressor node when
-    doing so will reduce the total number of edges in the given graph. This
-    implementation currently supports graphs with a single edge type.
+    References
+    ----------
+    .. [1] M. Gjoka, M. Kurant, A. Markopoulou, "2.5K Graphs: from Sampling
+       to Generation", IEEE Infocom, 2013.
+    .. [2] I. Stanton, A. Pinar, "Constructing and sampling graphs with a
+       prescribed joint degree distribution", Journal of Experimental
+       Algorithmics, 2012.
+    """
 
-    Examples
-    --------
-    Dedensification will only add compressor nodes when doing so would result
-    in fewer edges::
+    degree_count = {}
+    for k in joint_degrees:
+        if k > 0:
+            k_size = sum(joint_degrees[k].values()) / k
+            if not k_size.is_integer():
+                return False
+            degree_count[k] = k_size
+
+    for k in joint_degrees:
+        for l in joint_degrees[k]:
+            if not float(joint_degrees[k][l]).is_integer():
+                return False
+
+            if (k != l) and (joint_degrees[k][l] > degree_count[k] * degree_count[l]):
+                return False
+            elif k == l:
+                if joint_degrees[k][k] > degree_count[k] * (degree_count[k] - 1):
+                    return False
+                if joint_degrees[k][k] % 2 != 0:
+                    return False
+
+    # if all above conditions have been satisfied then the input
+    # joint degree is realizable as a simple graph.
+    return True
 
-        >>> original_graph = nx.DiGraph()
-        >>> original_graph.add_nodes_from(
-        ...     ["1", "2", "3", "4", "5", "6", "A", "B", "C"]
-        ... )
-        >>> original_graph.add_edges_from(
-        ...     [
-        ...         ("1", "C"), ("1", "B"),
-        ...         ("2", "C"), ("2", "B"), ("2", "A"),
-        ...         ("3", "B"), ("3", "A"), ("3", "6"),
-        ...         ("4", "C"), ("4", "B"), ("4", "A"),
-        ...         ("5", "B"), ("5", "A"),
-        ...         ("6", "5"),
-        ...         ("A", "6")
-        ...     ]
-        ... )
-        >>> c_graph, c_nodes = nx.dedensify(original_graph, threshold=2)
-        >>> original_graph.number_of_edges()
-        15
-        >>> c_graph.number_of_edges()
-        14
-
-    A dedensified, directed graph can be "densified" to reconstruct the
-    original graph::
-
-        >>> original_graph = nx.DiGraph()
-        >>> original_graph.add_nodes_from(
-        ...     ["1", "2", "3", "4", "5", "6", "A", "B", "C"]
-        ... )
-        >>> original_graph.add_edges_from(
-        ...     [
-        ...         ("1", "C"), ("1", "B"),
-        ...         ("2", "C"), ("2", "B"), ("2", "A"),
-        ...         ("3", "B"), ("3", "A"), ("3", "6"),
-        ...         ("4", "C"), ("4", "B"), ("4", "A"),
-        ...         ("5", "B"), ("5", "A"),
-        ...         ("6", "5"),
-        ...         ("A", "6")
-        ...     ]
-        ... )
-        >>> c_graph, c_nodes = nx.dedensify(original_graph, threshold=2)
-        >>> # re-densifies the compressed graph into the original graph
-        >>> for c_node in c_nodes:
-        ...     all_neighbors = set(nx.all_neighbors(c_graph, c_node))
-        ...     out_neighbors = set(c_graph.neighbors(c_node))
-        ...     for out_neighbor in out_neighbors:
-        ...         c_graph.remove_edge(c_node, out_neighbor)
-        ...     in_neighbors = all_neighbors - out_neighbors
-        ...     for in_neighbor in in_neighbors:
-        ...         c_graph.remove_edge(in_neighbor, c_node)
-        ...         for out_neighbor in out_neighbors:
-        ...             c_graph.add_edge(in_neighbor, out_neighbor)
-        ...     c_graph.remove_node(c_node)
-        ...
-        >>> nx.is_isomorphic(original_graph, c_graph)
-        True
 
-    References
+def _neighbor_switch(G, w, unsat, h_node_residual, avoid_node_id=None):
+    """Releases one free stub for ``w``, while preserving joint degree in G.
+
+    Parameters
     ----------
-    .. [1] Maccioni, A., & Abadi, D. J. (2016, August).
-       Scalable pattern matching over compressed graphs via dedensification.
-       In Proceedings of the 22nd ACM SIGKDD International Conference on
-       Knowledge Discovery and Data Mining (pp. 1755-1764).
-       http://www.cs.umd.edu/~abadi/papers/graph-dedense.pdf
-    """
-    if threshold < 2:
-        raise nx.NetworkXError("The degree threshold must be >= 2")
+    G : NetworkX graph
+        Graph in which the neighbor switch will take place.
+    w : integer
+        Node id for which we will execute this neighbor switch.
+    unsat : set of integers
+        Set of unsaturated node ids that have the same degree as w.
+    h_node_residual: dictionary of integers
+        Keeps track of the remaining stubs  for a given node.
+    avoid_node_id: integer
+        Node id to avoid when selecting w_prime.
 
-    degrees = G.in_degree if G.is_directed() else G.degree
-    # Group nodes based on degree threshold
-    high_degree_nodes = {n for n, d in degrees if d > threshold}
-    low_degree_nodes = G.nodes() - high_degree_nodes
-
-    auxiliary = {}
-    for node in G:
-        high_degree_neighbors = frozenset(high_degree_nodes & set(G[node]))
-        if high_degree_neighbors:
-            if high_degree_neighbors in auxiliary:
-                auxiliary[high_degree_neighbors].add(node)
-            else:
-                auxiliary[high_degree_neighbors] = {node}
-
-    if copy:
-        G = G.copy()
-
-    compressor_nodes = set()
-    for index, (high_degree_nodes, low_degree_nodes) in enumerate(auxiliary.items()):
-        low_degree_node_count = len(low_degree_nodes)
-        high_degree_node_count = len(high_degree_nodes)
-        old_edges = high_degree_node_count * low_degree_node_count
-        new_edges = high_degree_node_count + low_degree_node_count
-        if old_edges <= new_edges:
-            continue
-        compression_node = "".join(str(node) for node in high_degree_nodes)
-        if prefix:
-            compression_node = str(prefix) + compression_node
-        for node in low_degree_nodes:
-            for high_node in high_degree_nodes:
-                if G.has_edge(node, high_node):
-                    G.remove_edge(node, high_node)
-
-            G.add_edge(node, compression_node)
-        for node in high_degree_nodes:
-            G.add_edge(compression_node, node)
-        compressor_nodes.add(compression_node)
-    return G, compressor_nodes
-
-
-def _snap_build_graph(
-    G,
-    groups,
-    node_attributes,
-    edge_attributes,
-    neighbor_info,
-    edge_types,
-    prefix,
-    supernode_attribute,
-    superedge_attribute,
-):
+    Notes
+    -----
+    First, it selects *w_prime*, an  unsaturated node that has the same degree
+    as ``w``. Second, it selects *switch_node*, a neighbor node of ``w`` that
+    is not  connected to *w_prime*. Then it executes an edge swap i.e. removes
+    (``w``,*switch_node*) and adds (*w_prime*,*switch_node*). Gjoka et. al. [1]
+    prove that such an edge swap is always possible.
+
+    References
+    ----------
+    .. [1] M. Gjoka, B. Tillman, A. Markopoulou, "Construction of Simple
+       Graphs with a Target Joint Degree Matrix and Beyond", IEEE Infocom, '15
     """
-    Build the summary graph from the data structures produced in the SNAP aggregation algorithm
 
-    Used in the SNAP aggregation algorithm to build the output summary graph and supernode
-    lookup dictionary.  This process uses the original graph and the data structures to
-    create the supernodes with the correct node attributes, and the superedges with the correct
-    edge attributes
+    if (avoid_node_id is None) or (h_node_residual[avoid_node_id] > 1):
+        # select unsaturated node w_prime that has the same degree as w
+        w_prime = next(iter(unsat))
+    else:
+        # assume that the node pair (v,w) has been selected for connection. if
+        # - neighbor_switch is called for node w,
+        # - nodes v and w have the same degree,
+        # - node v=avoid_node_id has only one stub left,
+        # then prevent v=avoid_node_id from being selected as w_prime.
+
+        iter_var = iter(unsat)
+        while True:
+            w_prime = next(iter_var)
+            if w_prime != avoid_node_id:
+                break
+
+    # select switch_node, a neighbor of w, that is not connected to w_prime
+    w_prime_neighbs = G[w_prime]  # slightly faster declaring this variable
+    for v in G[w]:
+        if (v not in w_prime_neighbs) and (v != w_prime):
+            switch_node = v
+            break
+
+    # remove edge (w,switch_node), add edge (w_prime,switch_node) and update
+    # data structures
+    G.remove_edge(w, switch_node)
+    G.add_edge(w_prime, switch_node)
+    h_node_residual[w] += 1
+    h_node_residual[w_prime] -= 1
+    if h_node_residual[w_prime] == 0:
+        unsat.remove(w_prime)
+
+
+@py_random_state(1)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def joint_degree_graph(joint_degrees, seed=None):
+    """Generates a random simple graph with the given joint degree dictionary.
 
     Parameters
     ----------
-    G: networkx.Graph
-        the original graph to be summarized
-    groups: dict
-        A dictionary of unique group IDs and their corresponding node groups
-    node_attributes: iterable
-        An iterable of the node attributes considered in the summarization process
-    edge_attributes: iterable
-        An iterable of the edge attributes considered in the summarization process
-    neighbor_info: dict
-        A data structure indicating the number of edges a node has with the
-        groups in the current summarization of each edge type
-    edge_types: dict
-        dictionary of edges in the graph and their corresponding attributes recognized
-        in the summarization
-    prefix: string
-        The prefix to be added to all supernodes
-    supernode_attribute: str
-        The node attribute for recording the supernode groupings of nodes
-    superedge_attribute: str
-        The edge attribute for recording the edge types represented by superedges
+    joint_degrees :  dictionary of dictionary of integers
+        A joint degree dictionary in which entry ``joint_degrees[k][l]`` is the
+        number of edges joining nodes of degree *k* with nodes of degree *l*.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
     Returns
     -------
-    summary graph: Networkx graph
-    """
-    output = G.__class__()
-    node_label_lookup = {}
-    for index, group_id in enumerate(groups):
-        group_set = groups[group_id]
-        supernode = f"{prefix}{index}"
-        node_label_lookup[group_id] = supernode
-        supernode_attributes = {
-            attr: G.nodes[next(iter(group_set))][attr] for attr in node_attributes
-        }
-        supernode_attributes[supernode_attribute] = group_set
-        output.add_node(supernode, **supernode_attributes)
-
-    for group_id in groups:
-        group_set = groups[group_id]
-        source_supernode = node_label_lookup[group_id]
-        for other_group, group_edge_types in neighbor_info[
-            next(iter(group_set))
-        ].items():
-            if group_edge_types:
-                target_supernode = node_label_lookup[other_group]
-                summary_graph_edge = (source_supernode, target_supernode)
-
-                edge_types = [
-                    dict(zip(edge_attributes, edge_type))
-                    for edge_type in group_edge_types
-                ]
-
-                has_edge = output.has_edge(*summary_graph_edge)
-                if output.is_multigraph():
-                    if not has_edge:
-                        for edge_type in edge_types:
-                            output.add_edge(*summary_graph_edge, **edge_type)
-                    elif not output.is_directed():
-                        existing_edge_data = output.get_edge_data(*summary_graph_edge)
-                        for edge_type in edge_types:
-                            if edge_type not in existing_edge_data.values():
-                                output.add_edge(*summary_graph_edge, **edge_type)
-                else:
-                    superedge_attributes = {superedge_attribute: edge_types}
-                    output.add_edge(*summary_graph_edge, **superedge_attributes)
+    G : Graph
+        A graph with the specified joint degree dictionary.
 
-    return output
+    Raises
+    ------
+    NetworkXError
+        If *joint_degrees* dictionary is not realizable.
 
+    Notes
+    -----
+    In each iteration of the "while loop" the algorithm picks two disconnected
+    nodes *v* and *w*, of degree *k* and *l* correspondingly,  for which
+    ``joint_degrees[k][l]`` has not reached its target yet. It then adds
+    edge (*v*, *w*) and increases the number of edges in graph G by one.
+
+    The intelligence of the algorithm lies in the fact that  it is always
+    possible to add an edge between such disconnected nodes *v* and *w*,
+    even if one or both nodes do not have free stubs. That is made possible by
+    executing a "neighbor switch", an edge rewiring move that releases
+    a free stub while keeping the joint degree of G the same.
+
+    The algorithm continues for E (number of edges) iterations of
+    the "while loop", at the which point all entries of the given
+    ``joint_degrees[k][l]`` have reached their target values and the
+    construction is complete.
+
+    References
+    ----------
+    ..  [1] M. Gjoka, B. Tillman, A. Markopoulou, "Construction of Simple
+        Graphs with a Target Joint Degree Matrix and Beyond", IEEE Infocom, '15
 
-def _snap_eligible_group(G, groups, group_lookup, edge_types):
+    Examples
+    --------
+    >>> joint_degrees = {
+    ...     1: {4: 1},
+    ...     2: {2: 2, 3: 2, 4: 2},
+    ...     3: {2: 2, 4: 1},
+    ...     4: {1: 1, 2: 2, 3: 1},
+    ... }
+    >>> G = nx.joint_degree_graph(joint_degrees)
+    >>>
     """
-    Determines if a group is eligible to be split.
 
-    A group is eligible to be split if all nodes in the group have edges of the same type(s)
-    with the same other groups.
+    if not is_valid_joint_degree(joint_degrees):
+        msg = "Input joint degree dict not realizable as a simple graph"
+        raise nx.NetworkXError(msg)
+
+    # compute degree count from joint_degrees
+    degree_count = {k: sum(l.values()) // k for k, l in joint_degrees.items() if k > 0}
+
+    # start with empty N-node graph
+    N = sum(degree_count.values())
+    G = nx.empty_graph(N)
+
+    # for a given degree group, keep the list of all node ids
+    h_degree_nodelist = {}
+
+    # for a given node, keep track of the remaining stubs
+    h_node_residual = {}
+
+    # populate h_degree_nodelist and h_node_residual
+    nodeid = 0
+    for degree, num_nodes in degree_count.items():
+        h_degree_nodelist[degree] = range(nodeid, nodeid + num_nodes)
+        for v in h_degree_nodelist[degree]:
+            h_node_residual[v] = degree
+        nodeid += int(num_nodes)
+
+    # iterate over every degree pair (k,l) and add the number of edges given
+    # for each pair
+    for k in joint_degrees:
+        for l in joint_degrees[k]:
+            # n_edges_add is the number of edges to add for the
+            # degree pair (k,l)
+            n_edges_add = joint_degrees[k][l]
+
+            if (n_edges_add > 0) and (k >= l):
+                # number of nodes with degree k and l
+                k_size = degree_count[k]
+                l_size = degree_count[l]
+
+                # k_nodes and l_nodes consist of all nodes of degree k and l
+                k_nodes = h_degree_nodelist[k]
+                l_nodes = h_degree_nodelist[l]
+
+                # k_unsat and l_unsat consist of nodes of degree k and l that
+                # are unsaturated (nodes that have at least 1 available stub)
+                k_unsat = {v for v in k_nodes if h_node_residual[v] > 0}
+
+                if k != l:
+                    l_unsat = {w for w in l_nodes if h_node_residual[w] > 0}
+                else:
+                    l_unsat = k_unsat
+                    n_edges_add = joint_degrees[k][l] // 2
+
+                while n_edges_add > 0:
+                    # randomly pick nodes v and w that have degrees k and l
+                    v = k_nodes[seed.randrange(k_size)]
+                    w = l_nodes[seed.randrange(l_size)]
+
+                    # if nodes v and w are disconnected then attempt to connect
+                    if not G.has_edge(v, w) and (v != w):
+                        # if node v has no free stubs then do neighbor switch
+                        if h_node_residual[v] == 0:
+                            _neighbor_switch(G, v, k_unsat, h_node_residual)
+
+                        # if node w has no free stubs then do neighbor switch
+                        if h_node_residual[w] == 0:
+                            if k != l:
+                                _neighbor_switch(G, w, l_unsat, h_node_residual)
+                            else:
+                                _neighbor_switch(
+                                    G, w, l_unsat, h_node_residual, avoid_node_id=v
+                                )
+
+                        # add edge (v, w) and update data structures
+                        G.add_edge(v, w)
+                        h_node_residual[v] -= 1
+                        h_node_residual[w] -= 1
+                        n_edges_add -= 1
+
+                        if h_node_residual[v] == 0:
+                            k_unsat.discard(v)
+                        if h_node_residual[w] == 0:
+                            l_unsat.discard(w)
+    return G
+
+
+@nx._dispatchable(graphs=None)
+def is_valid_directed_joint_degree(in_degrees, out_degrees, nkk):
+    """Checks whether the given directed joint degree input is realizable
 
     Parameters
     ----------
-    G: graph
-        graph to be summarized
-    groups: dict
-        A dictionary of unique group IDs and their corresponding node groups
-    group_lookup: dict
-        dictionary of nodes and their current corresponding group ID
-    edge_types: dict
-        dictionary of edges in the graph and their corresponding attributes recognized
-        in the summarization
+    in_degrees :  list of integers
+        in degree sequence contains the in degrees of nodes.
+    out_degrees : list of integers
+        out degree sequence contains the out degrees of nodes.
+    nkk  :  dictionary of dictionary of integers
+        directed joint degree dictionary. for nodes of out degree k (first
+        level of dict) and nodes of in degree l (second level of dict)
+        describes the number of edges.
 
     Returns
     -------
-    tuple: group ID to split, and neighbor-groups participation_counts data structure
-    """
-    neighbor_info = {node: {gid: Counter() for gid in groups} for node in group_lookup}
-    for group_id in groups:
-        current_group = groups[group_id]
-
-        # build neighbor_info for nodes in group
-        for node in current_group:
-            neighbor_info[node] = {group_id: Counter() for group_id in groups}
-            edges = G.edges(node, keys=True) if G.is_multigraph() else G.edges(node)
-            for edge in edges:
-                neighbor = edge[1]
-                edge_type = edge_types[edge]
-                neighbor_group_id = group_lookup[neighbor]
-                neighbor_info[node][neighbor_group_id][edge_type] += 1
-
-        # check if group_id is eligible to be split
-        group_size = len(current_group)
-        for other_group_id in groups:
-            edge_counts = Counter()
-            for node in current_group:
-                edge_counts.update(neighbor_info[node][other_group_id].keys())
-
-            if not all(count == group_size for count in edge_counts.values()):
-                # only the neighbor_info of the returned group_id is required for handling group splits
-                return group_id, neighbor_info
+    boolean
+        returns true if given input is realizable, else returns false.
 
-    # if no eligible groups, complete neighbor_info is calculated
-    return None, neighbor_info
+    Notes
+    -----
+    Here is the list of conditions that the inputs (in/out degree sequences,
+    nkk) need to satisfy for simple directed graph realizability:
 
+    - Condition 0: in_degrees and out_degrees have the same length
+    - Condition 1: nkk[k][l]  is integer for all k,l
+    - Condition 2: sum(nkk[k])/k = number of nodes with partition id k, is an
+                   integer and matching degree sequence
+    - Condition 3: number of edges and non-chords between k and l cannot exceed
+                   maximum possible number of edges
 
-def _snap_split(groups, neighbor_info, group_lookup, group_id):
+
+    References
+    ----------
+    [1] B. Tillman, A. Markopoulou, C. T. Butts & M. Gjoka,
+        "Construction of Directed 2K Graphs". In Proc. of KDD 2017.
     """
-    Splits a group based on edge types and updates the groups accordingly
+    V = {}  # number of nodes with in/out degree.
+    forbidden = {}
+    if len(in_degrees) != len(out_degrees):
+        return False
+
+    for idx in range(len(in_degrees)):
+        i = in_degrees[idx]
+        o = out_degrees[idx]
+        V[(i, 0)] = V.get((i, 0), 0) + 1
+        V[(o, 1)] = V.get((o, 1), 0) + 1
+
+        forbidden[(o, i)] = forbidden.get((o, i), 0) + 1
+
+    S = {}  # number of edges going from in/out degree nodes.
+    for k in nkk:
+        for l in nkk[k]:
+            val = nkk[k][l]
+            if not float(val).is_integer():  # condition 1
+                return False
+
+            if val > 0:
+                S[(k, 1)] = S.get((k, 1), 0) + val
+                S[(l, 0)] = S.get((l, 0), 0) + val
+                # condition 3
+                if val + forbidden.get((k, l), 0) > V[(k, 1)] * V[(l, 0)]:
+                    return False
+
+    return all(S[s] / s[0] == V[s] for s in S)
 
-    Splits the group with the given group_id based on the edge types
-    of the nodes so that each new grouping will all have the same
-    edges with other nodes.
+
+def _directed_neighbor_switch(
+    G, w, unsat, h_node_residual_out, chords, h_partition_in, partition
+):
+    """Releases one free stub for node w, while preserving joint degree in G.
 
     Parameters
     ----------
-    groups: dict
-        A dictionary of unique group IDs and their corresponding node groups
-    neighbor_info: dict
-        A data structure indicating the number of edges a node has with the
-        groups in the current summarization of each edge type
-    edge_types: dict
-        dictionary of edges in the graph and their corresponding attributes recognized
-        in the summarization
-    group_lookup: dict
-        dictionary of nodes and their current corresponding group ID
-    group_id: object
-        ID of group to be split
+    G : networkx directed graph
+        graph within which the edge swap will take place.
+    w : integer
+        node id for which we need to perform a neighbor switch.
+    unsat: set of integers
+        set of node ids that have the same degree as w and are unsaturated.
+    h_node_residual_out: dict of integers
+        for a given node, keeps track of the remaining stubs to be added.
+    chords: set of tuples
+        keeps track of available positions to add edges.
+    h_partition_in: dict of integers
+        for a given node, keeps track of its partition id (in degree).
+    partition: integer
+        partition id to check if chords have to be updated.
 
-    Returns
-    -------
-    dict
-        The updated groups based on the split
+    Notes
+    -----
+    First, it selects node w_prime that (1) has the same degree as w and
+    (2) is unsaturated. Then, it selects node v, a neighbor of w, that is
+    not connected to w_prime and does an edge swap i.e. removes (w,v) and
+    adds (w_prime,v). If neighbor switch is not possible for w using
+    w_prime and v, then return w_prime; in [1] it's proven that
+    such unsaturated nodes can be used.
+
+    References
+    ----------
+    [1] B. Tillman, A. Markopoulou, C. T. Butts & M. Gjoka,
+        "Construction of Directed 2K Graphs". In Proc. of KDD 2017.
     """
-    new_group_mappings = defaultdict(set)
-    for node in groups[group_id]:
-        signature = tuple(
-            frozenset(edge_types) for edge_types in neighbor_info[node].values()
-        )
-        new_group_mappings[signature].add(node)
-
-    # leave the biggest new_group as the original group
-    new_groups = sorted(new_group_mappings.values(), key=len)
-    for new_group in new_groups[:-1]:
-        # Assign unused integer as the new_group_id
-        # ids are tuples, so will not interact with the original group_ids
-        new_group_id = len(groups)
-        groups[new_group_id] = new_group
-        groups[group_id] -= new_group
-        for node in new_group:
-            group_lookup[node] = new_group_id
-
-    return groups
-
-
-@nx._dispatch(node_attrs="[node_attributes]", edge_attrs="[edge_attributes]")
-def snap_aggregation(
-    G,
-    node_attributes,
-    edge_attributes=(),
-    prefix="Supernode-",
-    supernode_attribute="group",
-    superedge_attribute="types",
+    w_prime = unsat.pop()
+    unsat.add(w_prime)
+    # select node t, a neighbor of w, that is not connected to w_prime
+    w_neighbs = list(G.successors(w))
+    # slightly faster declaring this variable
+    w_prime_neighbs = list(G.successors(w_prime))
+
+    for v in w_neighbs:
+        if (v not in w_prime_neighbs) and w_prime != v:
+            # removes (w,v), add (w_prime,v)  and update data structures
+            G.remove_edge(w, v)
+            G.add_edge(w_prime, v)
+
+            if h_partition_in[v] == partition:
+                chords.add((w, v))
+                chords.discard((w_prime, v))
+
+            h_node_residual_out[w] += 1
+            h_node_residual_out[w_prime] -= 1
+            if h_node_residual_out[w_prime] == 0:
+                unsat.remove(w_prime)
+            return None
+
+    # If neighbor switch didn't work, use unsaturated node
+    return w_prime
+
+
+def _directed_neighbor_switch_rev(
+    G, w, unsat, h_node_residual_in, chords, h_partition_out, partition
 ):
-    """Creates a summary graph based on attributes and connectivity.
+    """The reverse of directed_neighbor_switch.
+
+    Parameters
+    ----------
+    G : networkx directed graph
+        graph within which the edge swap will take place.
+    w : integer
+        node id for which we need to perform a neighbor switch.
+    unsat: set of integers
+        set of node ids that have the same degree as w and are unsaturated.
+    h_node_residual_in: dict of integers
+        for a given node, keeps track of the remaining stubs to be added.
+    chords: set of tuples
+        keeps track of available positions to add edges.
+    h_partition_out: dict of integers
+        for a given node, keeps track of its partition id (out degree).
+    partition: integer
+        partition id to check if chords have to be updated.
 
-    This function uses the Summarization by Grouping Nodes on Attributes
-    and Pairwise edges (SNAP) algorithm for summarizing a given
-    graph by grouping nodes by node attributes and their edge attributes
-    into supernodes in a summary graph.  This name SNAP should not be
-    confused with the Stanford Network Analysis Project (SNAP).
-
-    Here is a high-level view of how this algorithm works:
-
-    1) Group nodes by node attribute values.
-
-    2) Iteratively split groups until all nodes in each group have edges
-    to nodes in the same groups. That is, until all the groups are homogeneous
-    in their member nodes' edges to other groups.  For example,
-    if all the nodes in group A only have edge to nodes in group B, then the
-    group is homogeneous and does not need to be split. If all nodes in group B
-    have edges with nodes in groups {A, C}, but some also have edges with other
-    nodes in B, then group B is not homogeneous and needs to be split into
-    groups have edges with {A, C} and a group of nodes having
-    edges with {A, B, C}.  This way, viewers of the summary graph can
-    assume that all nodes in the group have the exact same node attributes and
-    the exact same edges.
-
-    3) Build the output summary graph, where the groups are represented by
-    super-nodes. Edges represent the edges shared between all the nodes in each
-    respective groups.
-
-    A SNAP summary graph can be used to visualize graphs that are too large to display
-    or visually analyze, or to efficiently identify sets of similar nodes with similar connectivity
-    patterns to other sets of similar nodes based on specified node and/or edge attributes in a graph.
+    Notes
+    -----
+    Same operation as directed_neighbor_switch except it handles this operation
+    for incoming edges instead of outgoing.
+    """
+    w_prime = unsat.pop()
+    unsat.add(w_prime)
+    # slightly faster declaring these as variables.
+    w_neighbs = list(G.predecessors(w))
+    w_prime_neighbs = list(G.predecessors(w_prime))
+    # select node v, a neighbor of w, that is not connected to w_prime.
+    for v in w_neighbs:
+        if (v not in w_prime_neighbs) and w_prime != v:
+            # removes (v,w), add (v,w_prime) and update data structures.
+            G.remove_edge(v, w)
+            G.add_edge(v, w_prime)
+            if h_partition_out[v] == partition:
+                chords.add((v, w))
+                chords.discard((v, w_prime))
+
+            h_node_residual_in[w] += 1
+            h_node_residual_in[w_prime] -= 1
+            if h_node_residual_in[w_prime] == 0:
+                unsat.remove(w_prime)
+            return None
+
+    # If neighbor switch didn't work, use the unsaturated node.
+    return w_prime
+
+
+@py_random_state(3)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def directed_joint_degree_graph(in_degrees, out_degrees, nkk, seed=None):
+    """Generates a random simple directed graph with the joint degree.
 
     Parameters
     ----------
-    G: graph
-        Networkx Graph to be summarized
-    node_attributes: iterable, required
-        An iterable of the node attributes used to group nodes in the summarization process. Nodes
-        with the same values for these attributes will be grouped together in the summary graph.
-    edge_attributes: iterable, optional
-        An iterable of the edge attributes considered in the summarization process.  If provided, unique
-        combinations of the attribute values found in the graph are used to
-        determine the edge types in the graph.  If not provided, all edges
-        are considered to be of the same type.
-    prefix: str
-        The prefix used to denote supernodes in the summary graph. Defaults to 'Supernode-'.
-    supernode_attribute: str
-        The node attribute for recording the supernode groupings of nodes. Defaults to 'group'.
-    superedge_attribute: str
-        The edge attribute for recording the edge types of multiple edges. Defaults to 'types'.
+    degree_seq :  list of tuples (of size 3)
+        degree sequence contains tuples of nodes with node id, in degree and
+        out degree.
+    nkk  :  dictionary of dictionary of integers
+        directed joint degree dictionary, for nodes of out degree k (first
+        level of dict) and nodes of in degree l (second level of dict)
+        describes the number of edges.
+    seed : hashable object, optional
+        Seed for random number generator.
 
     Returns
     -------
-    networkx.Graph: summary graph
+    G : Graph
+        A directed graph with the specified inputs.
+
+    Raises
+    ------
+    NetworkXError
+        If degree_seq and nkk are not realizable as a simple directed graph.
 
-    Examples
-    --------
-    SNAP aggregation takes a graph and summarizes it in the context of user-provided
-    node and edge attributes such that a viewer can more easily extract and
-    analyze the information represented by the graph
-
-    >>> nodes = {
-    ...     "A": dict(color="Red"),
-    ...     "B": dict(color="Red"),
-    ...     "C": dict(color="Red"),
-    ...     "D": dict(color="Red"),
-    ...     "E": dict(color="Blue"),
-    ...     "F": dict(color="Blue"),
-    ... }
-    >>> edges = [
-    ...     ("A", "E", "Strong"),
-    ...     ("B", "F", "Strong"),
-    ...     ("C", "E", "Weak"),
-    ...     ("D", "F", "Weak"),
-    ... ]
-    >>> G = nx.Graph()
-    >>> for node in nodes:
-    ...     attributes = nodes[node]
-    ...     G.add_node(node, **attributes)
-    ...
-    >>> for source, target, type in edges:
-    ...     G.add_edge(source, target, type=type)
-    ...
-    >>> node_attributes = ('color', )
-    >>> edge_attributes = ('type', )
-    >>> summary_graph = nx.snap_aggregation(G, node_attributes=node_attributes, edge_attributes=edge_attributes)
 
     Notes
     -----
-    The summary graph produced is called a maximum Attribute-edge
-    compatible (AR-compatible) grouping.  According to [1]_, an
-    AR-compatible grouping means that all nodes in each group have the same
-    exact node attribute values and the same exact edges and
-    edge types to one or more nodes in the same groups.  The maximal
-    AR-compatible grouping is the grouping with the minimal cardinality.
-
-    The AR-compatible grouping is the most detailed grouping provided by
-    any of the SNAP algorithms.
+    Similarly to the undirected version:
+    In each iteration of the "while loop" the algorithm picks two disconnected
+    nodes v and w, of degree k and l correspondingly,  for which nkk[k][l] has
+    not reached its target yet i.e. (for given k,l): n_edges_add < nkk[k][l].
+    It then adds edge (v,w) and always increases the number of edges in graph G
+    by one.
+
+    The intelligence of the algorithm lies in the fact that  it is always
+    possible to add an edge between disconnected nodes v and w, for which
+    nkk[degree(v)][degree(w)] has not reached its target, even if one or both
+    nodes do not have free stubs. If either node v or w does not have a free
+    stub, we perform a "neighbor switch", an edge rewiring move that releases a
+    free stub while keeping nkk the same.
+
+    The difference for the directed version lies in the fact that neighbor
+    switches might not be able to rewire, but in these cases unsaturated nodes
+    can be reassigned to use instead, see [1] for detailed description and
+    proofs.
+
+    The algorithm continues for E (number of edges in the graph) iterations of
+    the "while loop", at which point all entries of the given nkk[k][l] have
+    reached their target values and the construction is complete.
 
     References
     ----------
-    .. [1] Y. Tian, R. A. Hankins, and J. M. Patel. Efficient aggregation
-       for graph summarization. In Proc. 2008 ACM-SIGMOD Int. Conf.
-       Management of Data (SIGMOD’08), pages 567–580, Vancouver, Canada,
-       June 2008.
+    [1] B. Tillman, A. Markopoulou, C. T. Butts & M. Gjoka,
+        "Construction of Directed 2K Graphs". In Proc. of KDD 2017.
+
+    Examples
+    --------
+    >>> in_degrees = [0, 1, 1, 2]
+    >>> out_degrees = [1, 1, 1, 1]
+    >>> nkk = {1: {1: 2, 2: 2}}
+    >>> G = nx.directed_joint_degree_graph(in_degrees, out_degrees, nkk)
+    >>>
     """
-    edge_types = {
-        edge: tuple(attrs.get(attr) for attr in edge_attributes)
-        for edge, attrs in G.edges.items()
-    }
-    if not G.is_directed():
-        if G.is_multigraph():
-            # list is needed to avoid mutating while iterating
-            edges = [((v, u, k), etype) for (u, v, k), etype in edge_types.items()]
-        else:
-            # list is needed to avoid mutating while iterating
-            edges = [((v, u), etype) for (u, v), etype in edge_types.items()]
-        edge_types.update(edges)
-
-    group_lookup = {
-        node: tuple(attrs[attr] for attr in node_attributes)
-        for node, attrs in G.nodes.items()
-    }
-    groups = defaultdict(set)
-    for node, node_type in group_lookup.items():
-        groups[node_type].add(node)
-
-    eligible_group_id, neighbor_info = _snap_eligible_group(
-        G, groups, group_lookup, edge_types
-    )
-    while eligible_group_id:
-        groups = _snap_split(groups, neighbor_info, group_lookup, eligible_group_id)
-        eligible_group_id, neighbor_info = _snap_eligible_group(
-            G, groups, group_lookup, edge_types
-        )
-    return _snap_build_graph(
-        G,
-        groups,
-        node_attributes,
-        edge_attributes,
-        neighbor_info,
-        edge_types,
-        prefix,
-        supernode_attribute,
-        superedge_attribute,
-    )
+    if not is_valid_directed_joint_degree(in_degrees, out_degrees, nkk):
+        msg = "Input is not realizable as a simple graph"
+        raise nx.NetworkXError(msg)
+
+    # start with an empty directed graph.
+    G = nx.DiGraph()
+
+    # for a given group, keep the list of all node ids.
+    h_degree_nodelist_in = {}
+    h_degree_nodelist_out = {}
+    # for a given group, keep the list of all unsaturated node ids.
+    h_degree_nodelist_in_unsat = {}
+    h_degree_nodelist_out_unsat = {}
+    # for a given node, keep track of the remaining stubs to be added.
+    h_node_residual_out = {}
+    h_node_residual_in = {}
+    # for a given node, keep track of the partition id.
+    h_partition_out = {}
+    h_partition_in = {}
+    # keep track of non-chords between pairs of partition ids.
+    non_chords = {}
+
+    # populate data structures
+    for idx, i in enumerate(in_degrees):
+        idx = int(idx)
+        if i > 0:
+            h_degree_nodelist_in.setdefault(i, [])
+            h_degree_nodelist_in_unsat.setdefault(i, set())
+            h_degree_nodelist_in[i].append(idx)
+            h_degree_nodelist_in_unsat[i].add(idx)
+            h_node_residual_in[idx] = i
+            h_partition_in[idx] = i
+
+    for idx, o in enumerate(out_degrees):
+        o = out_degrees[idx]
+        non_chords[(o, in_degrees[idx])] = non_chords.get((o, in_degrees[idx]), 0) + 1
+        idx = int(idx)
+        if o > 0:
+            h_degree_nodelist_out.setdefault(o, [])
+            h_degree_nodelist_out_unsat.setdefault(o, set())
+            h_degree_nodelist_out[o].append(idx)
+            h_degree_nodelist_out_unsat[o].add(idx)
+            h_node_residual_out[idx] = o
+            h_partition_out[idx] = o
+
+        G.add_node(idx)
+
+    nk_in = {}
+    nk_out = {}
+    for p in h_degree_nodelist_in:
+        nk_in[p] = len(h_degree_nodelist_in[p])
+    for p in h_degree_nodelist_out:
+        nk_out[p] = len(h_degree_nodelist_out[p])
+
+    # iterate over every degree pair (k,l) and add the number of edges given
+    # for each pair.
+    for k in nkk:
+        for l in nkk[k]:
+            n_edges_add = nkk[k][l]
+
+            if n_edges_add > 0:
+                # chords contains a random set of potential edges.
+                chords = set()
+
+                k_len = nk_out[k]
+                l_len = nk_in[l]
+                chords_sample = seed.sample(
+                    range(k_len * l_len), n_edges_add + non_chords.get((k, l), 0)
+                )
+
+                num = 0
+                while len(chords) < n_edges_add:
+                    i = h_degree_nodelist_out[k][chords_sample[num] % k_len]
+                    j = h_degree_nodelist_in[l][chords_sample[num] // k_len]
+                    num += 1
+                    if i != j:
+                        chords.add((i, j))
+
+                # k_unsat and l_unsat consist of nodes of in/out degree k and l
+                # that are unsaturated i.e. those nodes that have at least one
+                # available stub
+                k_unsat = h_degree_nodelist_out_unsat[k]
+                l_unsat = h_degree_nodelist_in_unsat[l]
+
+                while n_edges_add > 0:
+                    v, w = chords.pop()
+                    chords.add((v, w))
+
+                    # if node v has no free stubs then do neighbor switch.
+                    if h_node_residual_out[v] == 0:
+                        _v = _directed_neighbor_switch(
+                            G,
+                            v,
+                            k_unsat,
+                            h_node_residual_out,
+                            chords,
+                            h_partition_in,
+                            l,
+                        )
+                        if _v is not None:
+                            v = _v
+
+                    # if node w has no free stubs then do neighbor switch.
+                    if h_node_residual_in[w] == 0:
+                        _w = _directed_neighbor_switch_rev(
+                            G,
+                            w,
+                            l_unsat,
+                            h_node_residual_in,
+                            chords,
+                            h_partition_out,
+                            k,
+                        )
+                        if _w is not None:
+                            w = _w
+
+                    # add edge (v,w) and update data structures.
+                    G.add_edge(v, w)
+                    h_node_residual_out[v] -= 1
+                    h_node_residual_in[w] -= 1
+                    n_edges_add -= 1
+                    chords.discard((v, w))
+
+                    if h_node_residual_out[v] == 0:
+                        k_unsat.discard(v)
+                    if h_node_residual_in[w] == 0:
+                        l_unsat.discard(w)
+    return G
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `networkx-3.2rc0/networkx/algorithms/swap.py` & `networkx-3.3rc0/networkx/algorithms/swap.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from networkx.utils import py_random_state
 
 __all__ = ["double_edge_swap", "connected_double_edge_swap", "directed_edge_swap"]
 
 
 @nx.utils.not_implemented_for("undirected")
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable(mutates_input=True, returns_graph=True)
 def directed_edge_swap(G, *, nswap=1, max_tries=100, seed=None):
     """Swap three edges in a directed graph while keeping the node degrees fixed.
 
     A directed edge swap swaps three edges such that a -> b -> c -> d becomes
     a -> c -> b -> d. This pattern of swapping allows all possible states with the
     same in- and out-degree distribution in a directed graph to be reached.
 
@@ -53,14 +53,16 @@
 
     Notes
     -----
     Does not enforce any connectivity constraints.
 
     The graph G is modified in place.
 
+    A later swap is allowed to undo a previous swap.
+
     References
     ----------
     .. [1] Erdős, Péter L., et al. “A Simple Havel-Hakimi Type Algorithm to Realize
            Graphical Degree Sequences of Directed Graphs.” ArXiv:0905.4913 [Math],
            Jan. 2010. https://doi.org/10.48550/arXiv.0905.4913.
            Published  2010 in Elec. J. Combinatorics (17(1)). R66.
            http://www.combinatorics.org/Volume_17/PDF/v17i1r66.pdf
@@ -127,15 +129,15 @@
             G.remove_edge(third, fourth)
             swapcount += 1
 
     return G
 
 
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable(mutates_input=True, returns_graph=True)
 def double_edge_swap(G, nswap=1, max_tries=100, seed=None):
     """Swap two edges in the graph while keeping the node degrees fixed.
 
     A double-edge swap removes two randomly chosen edges u-v and x-y
     and creates the new edges u-x and v-y::
 
      u--v            u  v
@@ -225,15 +227,15 @@
             )
             raise nx.NetworkXAlgorithmError(e)
         n += 1
     return G
 
 
 @py_random_state(3)
-@nx._dispatch
+@nx._dispatchable(mutates_input=True)
 def connected_double_edge_swap(G, nswap=1, _window_threshold=3, seed=None):
     """Attempts the specified number of double-edge swaps in the graph `G`.
 
     A double-edge swap removes two randomly chosen edges `(u, v)` and `(x,
     y)` and creates the new edges `(u, x)` and `(v, y)`::
 
      u--v            u  v
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_boundary.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_boundary.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_bridges.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_bridges.py`

 * *Files 0% similar despite different names*

```diff
@@ -123,15 +123,15 @@
         assert set(nx.local_bridges(self.square, with_span=False)) == self.square.edges
         assert list(nx.local_bridges(self.tri, with_span=False)) == []
 
     def test_no_weight(self):
         inf = float("inf")
         expected = {(3, 4, inf), (4, 3, inf)}
         assert next(nx.local_bridges(self.BB)) in expected
-        expected = {(u, v, 3) for u, v, in self.square.edges}
+        expected = {(u, v, 3) for u, v in self.square.edges}
         assert set(nx.local_bridges(self.square)) == expected
         assert list(nx.local_bridges(self.tri)) == []
 
     def test_weight(self):
         inf = float("inf")
         G = self.square.copy()
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_chains.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_chains.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_chordal.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_chordal.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_cluster.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_cluster.py`

 * *Files 1% similar despite different names*

```diff
@@ -453,14 +453,20 @@
         assert nx.square_clustering(G2, [1])[1] == 1 / 5
 
     def test_peng_square_clustering(self):
         """Test eq2 for figure 1 Peng et al (2008)"""
         G = nx.Graph([(1, 2), (1, 3), (2, 4), (3, 4), (3, 5), (3, 6)])
         assert nx.square_clustering(G, [1])[1] == 1 / 3
 
+    def test_self_loops_square_clustering(self):
+        G = nx.path_graph(5)
+        assert nx.square_clustering(G) == {0: 0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0}
+        G.add_edges_from([(0, 0), (1, 1), (2, 2)])
+        assert nx.square_clustering(G) == {0: 1, 1: 0.5, 2: 0.2, 3: 0.0, 4: 0}
+
 
 class TestAverageClustering:
     @classmethod
     def setup_class(cls):
         pytest.importorskip("numpy")
 
     def test_empty(self):
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_communicability.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_communicability.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_covering.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_covering.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_cuts.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_cuts.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_cycles.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_cycles.py`

 * *Files 0% similar despite different names*

```diff
@@ -93,14 +93,18 @@
         G = nx.DiGraph(edges)
         cc = sorted(nx.simple_cycles(G))
         ca = [[0], [0, 1, 2], [0, 2], [1, 2], [2]]
         assert len(cc) == len(ca)
         for c in cc:
             assert any(self.is_cyclic_permutation(c, rc) for rc in ca)
 
+    def test_simple_cycles_singleton(self):
+        G = nx.Graph([(0, 0)])  # self-loop
+        assert list(nx.simple_cycles(G)) == [[0]]
+
     def test_unsortable(self):
         # this test ensures that graphs whose nodes without an intrinsic
         # ordering do not cause issues
         G = nx.DiGraph()
         nx.add_cycle(G, ["a", 1])
         c = list(nx.simple_cycles(G))
         assert len(c) == 1
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_dag.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_dag.py`

 * *Files 1% similar despite different names*

```diff
@@ -614,19 +614,25 @@
 def test_is_aperiodic_selfloop():
     G = nx.DiGraph()
     nx.add_cycle(G, [1, 2, 3, 4])
     G.add_edge(1, 1)
     assert nx.is_aperiodic(G)
 
 
-def test_is_aperiodic_raise():
+def test_is_aperiodic_undirected_raises():
     G = nx.Graph()
     pytest.raises(nx.NetworkXError, nx.is_aperiodic, G)
 
 
+def test_is_aperiodic_empty_graph():
+    G = nx.empty_graph(create_using=nx.DiGraph)
+    with pytest.raises(nx.NetworkXPointlessConcept, match="Graph has no nodes."):
+        nx.is_aperiodic(G)
+
+
 def test_is_aperiodic_bipartite():
     # Bipartite graph
     G = nx.DiGraph(nx.davis_southern_women_graph())
     assert not nx.is_aperiodic(G)
 
 
 def test_is_aperiodic_rary_tree():
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_distance_measures.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_distance_measures.py`

 * *Files 7% similar despite different names*

```diff
@@ -419,14 +419,99 @@
 
     def test_resistance_distance_all(self):
         rd = nx.resistance_distance(self.G)
         assert type(rd) == dict
         assert round(rd[1][3], 5) == 1
 
 
+class TestEffectiveGraphResistance:
+    @classmethod
+    def setup_class(cls):
+        global np
+        np = pytest.importorskip("numpy")
+
+    def setup_method(self):
+        G = nx.Graph()
+        G.add_edge(1, 2, weight=2)
+        G.add_edge(1, 3, weight=1)
+        G.add_edge(2, 3, weight=4)
+        self.G = G
+
+    def test_effective_graph_resistance_directed_graph(self):
+        G = nx.DiGraph()
+        with pytest.raises(nx.NetworkXNotImplemented):
+            nx.effective_graph_resistance(G)
+
+    def test_effective_graph_resistance_empty(self):
+        G = nx.Graph()
+        with pytest.raises(nx.NetworkXError):
+            nx.effective_graph_resistance(G)
+
+    def test_effective_graph_resistance_not_connected(self):
+        G = nx.Graph([(1, 2), (3, 4)])
+        RG = nx.effective_graph_resistance(G)
+        assert np.isinf(RG)
+
+    def test_effective_graph_resistance(self):
+        RG = nx.effective_graph_resistance(self.G, "weight", True)
+        rd12 = 1 / (1 / (1 + 4) + 1 / 2)
+        rd13 = 1 / (1 / (1 + 2) + 1 / 4)
+        rd23 = 1 / (1 / (2 + 4) + 1 / 1)
+        assert np.isclose(RG, rd12 + rd13 + rd23)
+
+    def test_effective_graph_resistance_noinv(self):
+        RG = nx.effective_graph_resistance(self.G, "weight", False)
+        rd12 = 1 / (1 / (1 / 1 + 1 / 4) + 1 / (1 / 2))
+        rd13 = 1 / (1 / (1 / 1 + 1 / 2) + 1 / (1 / 4))
+        rd23 = 1 / (1 / (1 / 2 + 1 / 4) + 1 / (1 / 1))
+        assert np.isclose(RG, rd12 + rd13 + rd23)
+
+    def test_effective_graph_resistance_no_weight(self):
+        RG = nx.effective_graph_resistance(self.G)
+        assert np.isclose(RG, 2)
+
+    def test_effective_graph_resistance_neg_weight(self):
+        self.G[2][3]["weight"] = -4
+        RG = nx.effective_graph_resistance(self.G, "weight", True)
+        rd12 = 1 / (1 / (1 + -4) + 1 / 2)
+        rd13 = 1 / (1 / (1 + 2) + 1 / (-4))
+        rd23 = 1 / (1 / (2 + -4) + 1 / 1)
+        assert np.isclose(RG, rd12 + rd13 + rd23)
+
+    def test_effective_graph_resistance_multigraph(self):
+        G = nx.MultiGraph()
+        G.add_edge(1, 2, weight=2)
+        G.add_edge(1, 3, weight=1)
+        G.add_edge(2, 3, weight=1)
+        G.add_edge(2, 3, weight=3)
+        RG = nx.effective_graph_resistance(G, "weight", True)
+        edge23 = 1 / (1 / 1 + 1 / 3)
+        rd12 = 1 / (1 / (1 + edge23) + 1 / 2)
+        rd13 = 1 / (1 / (1 + 2) + 1 / edge23)
+        rd23 = 1 / (1 / (2 + edge23) + 1 / 1)
+        assert np.isclose(RG, rd12 + rd13 + rd23)
+
+    def test_effective_graph_resistance_div0(self):
+        with pytest.raises(ZeroDivisionError):
+            self.G[1][2]["weight"] = 0
+            nx.effective_graph_resistance(self.G, "weight")
+
+    def test_effective_graph_resistance_complete_graph(self):
+        N = 10
+        G = nx.complete_graph(N)
+        RG = nx.effective_graph_resistance(G)
+        assert np.isclose(RG, N - 1)
+
+    def test_effective_graph_resistance_path_graph(self):
+        N = 10
+        G = nx.path_graph(N)
+        RG = nx.effective_graph_resistance(G)
+        assert np.isclose(RG, (N - 1) * N * (N + 1) // 6)
+
+
 class TestBarycenter:
     """Test :func:`networkx.algorithms.distance_measures.barycenter`."""
 
     def barycenter_as_subgraph(self, g, **kwargs):
         """Return the subgraph induced on the barycenter of g"""
         b = nx.barycenter(g, **kwargs)
         assert isinstance(b, list)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_distance_regular.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_distance_regular.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,11 +1,23 @@
+import pytest
+
 import networkx as nx
 from networkx import is_strongly_regular
 
 
+@pytest.mark.parametrize(
+    "f", (nx.is_distance_regular, nx.intersection_array, nx.is_strongly_regular)
+)
+@pytest.mark.parametrize("graph_constructor", (nx.DiGraph, nx.MultiGraph))
+def test_raises_on_directed_and_multigraphs(f, graph_constructor):
+    G = graph_constructor([(0, 1), (1, 2)])
+    with pytest.raises(nx.NetworkXNotImplemented):
+        f(G)
+
+
 class TestDistanceRegular:
     def test_is_distance_regular(self):
         assert nx.is_distance_regular(nx.icosahedral_graph())
         assert nx.is_distance_regular(nx.petersen_graph())
         assert nx.is_distance_regular(nx.cubical_graph())
         assert nx.is_distance_regular(nx.complete_bipartite_graph(3, 3))
         assert nx.is_distance_regular(nx.tetrahedral_graph())
@@ -37,14 +49,21 @@
         assert b == [3, 2, 1, 1, 1]
         assert c == [1, 1, 1, 2, 3]
         b, c = nx.intersection_array(nx.icosahedral_graph())
         assert b == [5, 2, 1]
         assert c == [1, 2, 5]
 
 
+@pytest.mark.parametrize("f", (nx.is_distance_regular, nx.is_strongly_regular))
+def test_empty_graph_raises(f):
+    G = nx.Graph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="Graph has no nodes"):
+        f(G)
+
+
 class TestStronglyRegular:
     """Unit tests for the :func:`~networkx.is_strongly_regular`
     function.
 
     """
 
     def test_cycle_graph(self):
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_dominance.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_dominance.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_dominating.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_dominating.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_efficiency.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_efficiency.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_euler.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_euler.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,21 @@
 import collections
 
 import pytest
 
 import networkx as nx
 
 
+@pytest.mark.parametrize("f", (nx.is_eulerian, nx.is_semieulerian))
+def test_empty_graph_raises(f):
+    G = nx.Graph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="Connectivity is undefined"):
+        f(G)
+
+
 class TestIsEulerian:
     def test_is_eulerian(self):
         assert nx.is_eulerian(nx.complete_graph(5))
         assert nx.is_eulerian(nx.complete_graph(7))
         assert nx.is_eulerian(nx.hypercube_graph(4))
         assert nx.is_eulerian(nx.hypercube_graph(6))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_graph_hashing.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_graph_hashing.py`

 * *Files 3% similar despite different names*

```diff
@@ -651,7 +651,36 @@
         digest_size16_hashes = nx.weisfeiler_lehman_subgraph_hashes(G)
         digest_size32_hashes = nx.weisfeiler_lehman_subgraph_hashes(G, digest_size=32)
 
         assert digest_size16_hashes != digest_size32_hashes
 
         assert hexdigest_sizes_correct(digest_size16_hashes, 16)
         assert hexdigest_sizes_correct(digest_size32_hashes, 32)
+
+
+def test_initial_node_labels_subgraph_hash():
+    """
+    Including the hashed initial label prepends an extra hash to the lists
+    """
+    G = nx.path_graph(5)
+    nx.set_node_attributes(G, {i: int(0 < i < 4) for i in G}, "label")
+    # initial node labels:
+    # 0--1--1--1--0
+
+    without_initial_label = nx.weisfeiler_lehman_subgraph_hashes(G, node_attr="label")
+    assert all(len(v) == 3 for v in without_initial_label.values())
+    # 3 different 1 hop nhds
+    assert len({v[0] for v in without_initial_label.values()}) == 3
+
+    with_initial_label = nx.weisfeiler_lehman_subgraph_hashes(
+        G, node_attr="label", include_initial_labels=True
+    )
+    assert all(len(v) == 4 for v in with_initial_label.values())
+    # 2 different initial labels
+    assert len({v[0] for v in with_initial_label.values()}) == 2
+
+    # check hashes match otherwise
+    for u in G:
+        for a, b in zip(
+            with_initial_label[u][1:], without_initial_label[u], strict=True
+        ):
+            assert a == b
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_graphical.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_graphical.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_hierarchy.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_hierarchy.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_hybrid.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_hybrid.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_isolate.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_isolate.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_link_prediction.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_link_prediction.py`

 * *Files 6% similar despite different names*

```diff
@@ -30,31 +30,25 @@
         G = nx.path_graph(3)
         self.test(G, [(0, 2)], [(0, 2, 0.5)])
 
     def test_S4(self):
         G = nx.star_graph(4)
         self.test(G, [(1, 2)], [(1, 2, 0.25)])
 
-    def test_notimplemented(self):
-        assert pytest.raises(
-            nx.NetworkXNotImplemented, self.func, nx.DiGraph([(0, 1), (1, 2)]), [(0, 2)]
-        )
-        assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
-        )
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
         assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiDiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
+            nx.NetworkXNotImplemented, self.func, graph_type([(0, 1), (1, 2)]), [(0, 2)]
         )
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
     def test_equal_nodes(self):
         G = nx.complete_graph(4)
@@ -76,31 +70,25 @@
         G = nx.complete_graph(5)
         self.test(G, [(0, 1)], [(0, 1, 0.6)])
 
     def test_P4(self):
         G = nx.path_graph(4)
         self.test(G, [(0, 2)], [(0, 2, 0.5)])
 
-    def test_notimplemented(self):
-        assert pytest.raises(
-            nx.NetworkXNotImplemented, self.func, nx.DiGraph([(0, 1), (1, 2)]), [(0, 2)]
-        )
-        assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
-        )
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
         assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiDiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
+            nx.NetworkXNotImplemented, self.func, graph_type([(0, 1), (1, 2)]), [(0, 2)]
         )
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_edges_from([(0, 1), (2, 3)])
         self.test(G, [(0, 2)], [(0, 2, 0)])
 
     def test_isolated_nodes(self):
         G = nx.Graph()
@@ -127,31 +115,25 @@
         G = nx.path_graph(3)
         self.test(G, [(0, 2)], [(0, 2, 1 / math.log(2))])
 
     def test_S4(self):
         G = nx.star_graph(4)
         self.test(G, [(1, 2)], [(1, 2, 1 / math.log(4))])
 
-    def test_notimplemented(self):
-        assert pytest.raises(
-            nx.NetworkXNotImplemented, self.func, nx.DiGraph([(0, 1), (1, 2)]), [(0, 2)]
-        )
-        assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
-        )
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
         assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiDiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
+            nx.NetworkXNotImplemented, self.func, graph_type([(0, 1), (1, 2)]), [(0, 2)]
         )
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
     def test_equal_nodes(self):
         G = nx.complete_graph(4)
@@ -186,23 +168,39 @@
 
     @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
     def test_notimplemented(self, graph_type):
         assert pytest.raises(
             nx.NetworkXNotImplemented, self.func, graph_type([(0, 1), (1, 2)]), [(0, 2)]
         )
 
+    def test_node_u_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(1, 3), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 1)])
+
+    def test_node_v_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
     def test_equal_nodes(self):
         G = nx.complete_graph(4)
         assert pytest.raises(nx.NetworkXAlgorithmError, self.test, G, [(0, 0)], [])
 
+    def test_equal_nodes_with_alpha_one_raises_error(self):
+        G = nx.complete_graph(4)
+        assert pytest.raises(
+            nx.NetworkXAlgorithmError, self.test, G, [(0, 0)], [], alpha=1.0
+        )
+
     def test_all_nonexistent_edges(self):
         G = nx.Graph()
         G.add_edges_from([(0, 1), (0, 2), (2, 3)])
         self.test(G, None, [(0, 3, 1.5), (1, 2, 1.5), (1, 3, 2 / 3)], alpha=0.5)
 
 
 class TestPreferentialAttachment:
@@ -219,31 +217,25 @@
         G = nx.path_graph(3)
         self.test(G, [(0, 1)], [(0, 1, 2)])
 
     def test_S4(self):
         G = nx.star_graph(4)
         self.test(G, [(0, 2)], [(0, 2, 4)])
 
-    def test_notimplemented(self):
-        assert pytest.raises(
-            nx.NetworkXNotImplemented, self.func, nx.DiGraph([(0, 1), (1, 2)]), [(0, 2)]
-        )
-        assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
-        )
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
         assert pytest.raises(
-            nx.NetworkXNotImplemented,
-            self.func,
-            nx.MultiDiGraph([(0, 1), (1, 2)]),
-            [(0, 2)],
+            nx.NetworkXNotImplemented, self.func, graph_type([(0, 1), (1, 2)]), [(0, 2)]
         )
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_zero_degrees(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
     def test_all_nonexistent_edges(self):
         G = nx.Graph()
@@ -278,25 +270,29 @@
         G.nodes[0]["community"] = 1
         G.nodes[1]["community"] = 1
         G.nodes[2]["community"] = 1
         G.nodes[3]["community"] = 0
         G.nodes[4]["community"] = 0
         self.test(G, [(1, 2)], [(1, 2, 2)])
 
-    def test_notimplemented(self):
-        G = nx.DiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiDiGraph([(0, 1), (1, 2)])
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
+        G = graph_type([(0, 1), (1, 2)])
         G.add_nodes_from([0, 1, 2], community=0)
         assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        G.nodes[0]["community"] = 0
+        G.nodes[1]["community"] = 1
+        G.nodes[2]["community"] = 0
+        G.nodes[3]["community"] = 0
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         G.nodes[0]["community"] = 0
         G.nodes[1]["community"] = 0
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
@@ -383,25 +379,29 @@
         G.nodes[0]["community"] = 1
         G.nodes[1]["community"] = 1
         G.nodes[2]["community"] = 1
         G.nodes[3]["community"] = 0
         G.nodes[4]["community"] = 0
         self.test(G, [(1, 2)], [(1, 2, 0.25)])
 
-    def test_notimplemented(self):
-        G = nx.DiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiDiGraph([(0, 1), (1, 2)])
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
+        G = graph_type([(0, 1), (1, 2)])
         G.add_nodes_from([0, 1, 2], community=0)
         assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        G.nodes[0]["community"] = 0
+        G.nodes[1]["community"] = 1
+        G.nodes[2]["community"] = 0
+        G.nodes[3]["community"] = 0
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         G.nodes[0]["community"] = 0
         G.nodes[1]["community"] = 0
         self.test(G, [(0, 1)], [(0, 1, 0)])
 
@@ -491,25 +491,29 @@
         G.nodes[0]["community"] = 1
         G.nodes[1]["community"] = 1
         G.nodes[2]["community"] = 1
         G.nodes[3]["community"] = 0
         G.nodes[4]["community"] = 0
         self.test(G, [(1, 2)], [(1, 2, 1 / self.delta)])
 
-    def test_notimplemented(self):
-        G = nx.DiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiGraph([(0, 1), (1, 2)])
-        G.add_nodes_from([0, 1, 2], community=0)
-        assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
-        G = nx.MultiDiGraph([(0, 1), (1, 2)])
+    @pytest.mark.parametrize("graph_type", (nx.DiGraph, nx.MultiGraph, nx.MultiDiGraph))
+    def test_notimplemented(self, graph_type):
+        G = graph_type([(0, 1), (1, 2)])
         G.add_nodes_from([0, 1, 2], community=0)
         assert pytest.raises(nx.NetworkXNotImplemented, self.func, G, [(0, 2)])
 
+    def test_node_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (2, 3)])
+        G.nodes[0]["community"] = 0
+        G.nodes[1]["community"] = 1
+        G.nodes[2]["community"] = 0
+        G.nodes[3]["community"] = 0
+        assert pytest.raises(nx.NodeNotFound, self.func, G, [(0, 4)])
+
     def test_no_common_neighbor(self):
         G = nx.Graph()
         G.add_nodes_from([0, 1])
         G.nodes[0]["community"] = 0
         G.nodes[1]["community"] = 0
         self.test(G, [(0, 1)], [(0, 1, 0)])
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_lowest_common_ancestors.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_lowest_common_ancestors.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_matching.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_matching.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_max_weight_clique.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_max_weight_clique.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_mis.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_mis.py`

 * *Files 15% similar despite different names*

```diff
@@ -54,9 +54,9 @@
 def test_random_graphs():
     """Generate 5 random graphs of different types and sizes and
     make sure that all sets are independent and maximal."""
     for i in range(0, 50, 10):
         G = nx.erdos_renyi_graph(i * 10 + 1, random.random())
         IS = nx.maximal_independent_set(G)
         assert G.subgraph(IS).number_of_edges() == 0
-        neighbors_of_MIS = set.union(*(set(G.neighbors(v)) for v in IS))
-        assert all(v in neighbors_of_MIS for v in set(G.nodes()).difference(IS))
+        nbrs_of_MIS = set.union(*(set(G.neighbors(v)) for v in IS))
+        assert all(v in nbrs_of_MIS for v in set(G.nodes()).difference(IS))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_node_classification.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_node_classification.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_non_randomness.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_non_randomness.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_planar_drawing.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_planar_drawing.py`

 * *Files 0% similar despite different names*

```diff
@@ -117,19 +117,19 @@
 
 
 def check_embedding_data(embedding_data):
     """Checks that the planar embedding of the input is correct"""
     embedding = nx.PlanarEmbedding()
     embedding.set_data(embedding_data)
     pos_fully = nx.combinatorial_embedding_to_pos(embedding, False)
-    msg = "Planar drawing does not conform to the embedding (fully " "triangulation)"
+    msg = "Planar drawing does not conform to the embedding (fully triangulation)"
     assert planar_drawing_conforms_to_embedding(embedding, pos_fully), msg
     check_edge_intersections(embedding, pos_fully)
     pos_internally = nx.combinatorial_embedding_to_pos(embedding, True)
-    msg = "Planar drawing does not conform to the embedding (internal " "triangulation)"
+    msg = "Planar drawing does not conform to the embedding (internal triangulation)"
     assert planar_drawing_conforms_to_embedding(embedding, pos_internally), msg
     check_edge_intersections(embedding, pos_internally)
 
 
 def is_close(a, b, rel_tol=1e-09, abs_tol=0.0):
     # Check if float numbers are basically equal, for python >=3.5 there is
     # function for that in the standard library
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_planarity.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_planarity.py`

 * *Files 17% similar despite different names*

```diff
@@ -273,14 +273,28 @@
     def test_counterexample_planar_recursive(self):
         with pytest.raises(nx.NetworkXException):
             # Try to get a counterexample of a planar graph
             G = nx.Graph()
             G.add_node(1)
             get_counterexample_recursive(G)
 
+    def test_edge_removal_from_planar_embedding(self):
+        # PlanarEmbedding.check_structure() must succeed after edge removal
+        edges = ((0, 1), (1, 2), (2, 3), (3, 4), (4, 0), (0, 2), (0, 3))
+        G = nx.Graph(edges)
+        cert, P = nx.check_planarity(G)
+        assert cert is True
+        P.remove_edge(0, 2)
+        self.check_graph(P, is_planar=True)
+        P.add_half_edge_ccw(1, 3, 2)
+        P.add_half_edge_cw(3, 1, 2)
+        self.check_graph(P, is_planar=True)
+        P.remove_edges_from(((0, 3), (1, 3)))
+        self.check_graph(P, is_planar=True)
+
 
 def check_embedding(G, embedding):
     """Raises an exception if the combinatorial embedding is not correct
 
     Parameters
     ----------
     G : NetworkX graph
@@ -368,75 +382,154 @@
         if not nx.is_isomorphic(nx.complete_bipartite_graph(3, 3), sub_graph):
             raise nx.NetworkXException("Bad counter example.")
     else:
         raise nx.NetworkXException("Bad counter example.")
 
 
 class TestPlanarEmbeddingClass:
+    def test_add_half_edge(self):
+        embedding = nx.PlanarEmbedding()
+        embedding.add_half_edge(0, 1)
+        with pytest.raises(
+            nx.NetworkXException, match="Invalid clockwise reference node."
+        ):
+            embedding.add_half_edge(0, 2, cw=3)
+        with pytest.raises(
+            nx.NetworkXException, match="Invalid counterclockwise reference node."
+        ):
+            embedding.add_half_edge(0, 2, ccw=3)
+        with pytest.raises(
+            nx.NetworkXException, match="Only one of cw/ccw can be specified."
+        ):
+            embedding.add_half_edge(0, 2, cw=1, ccw=1)
+        with pytest.raises(
+            nx.NetworkXException,
+            match=(
+                r"Node already has out-half-edge\(s\), either"
+                " cw or ccw reference node required."
+            ),
+        ):
+            embedding.add_half_edge(0, 2)
+        # these should work
+        embedding.add_half_edge(0, 2, cw=1)
+        embedding.add_half_edge(0, 3, ccw=1)
+        assert sorted(embedding.edges(data=True)) == [
+            (0, 1, {"ccw": 2, "cw": 3}),
+            (0, 2, {"cw": 1, "ccw": 3}),
+            (0, 3, {"cw": 2, "ccw": 1}),
+        ]
+
     def test_get_data(self):
-        embedding = self.get_star_embedding(3)
+        embedding = self.get_star_embedding(4)
         data = embedding.get_data()
-        data_cmp = {0: [2, 1], 1: [0], 2: [0]}
+        data_cmp = {0: [3, 2, 1], 1: [0], 2: [0], 3: [0]}
         assert data == data_cmp
 
+    def test_edge_removal(self):
+        embedding = nx.PlanarEmbedding()
+        embedding.set_data(
+            {
+                1: [2, 5, 7],
+                2: [1, 3, 4, 5],
+                3: [2, 4],
+                4: [3, 6, 5, 2],
+                5: [7, 1, 2, 4],
+                6: [4, 7],
+                7: [6, 1, 5],
+            }
+        )
+        # remove_edges_from() calls remove_edge(), so both are tested here
+        embedding.remove_edges_from(((5, 4), (1, 5)))
+        embedding.check_structure()
+        embedding_expected = nx.PlanarEmbedding()
+        embedding_expected.set_data(
+            {
+                1: [2, 7],
+                2: [1, 3, 4, 5],
+                3: [2, 4],
+                4: [3, 6, 2],
+                5: [7, 2],
+                6: [4, 7],
+                7: [6, 1, 5],
+            }
+        )
+        assert nx.utils.graphs_equal(embedding, embedding_expected)
+
     def test_missing_edge_orientation(self):
+        embedding = nx.PlanarEmbedding({1: {2: {}}, 2: {1: {}}})
         with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            embedding.add_edge(1, 2)
-            embedding.add_edge(2, 1)
             # Invalid structure because the orientation of the edge was not set
             embedding.check_structure()
 
     def test_invalid_edge_orientation(self):
+        embedding = nx.PlanarEmbedding(
+            {
+                1: {2: {"cw": 2, "ccw": 2}},
+                2: {1: {"cw": 1, "ccw": 1}},
+                1: {3: {}},
+                3: {1: {}},
+            }
+        )
         with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            embedding.add_half_edge_first(1, 2)
-            embedding.add_half_edge_first(2, 1)
-            embedding.add_edge(1, 3)
             embedding.check_structure()
 
     def test_missing_half_edge(self):
+        embedding = nx.PlanarEmbedding()
+        embedding.add_half_edge(1, 2)
         with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            embedding.add_half_edge_first(1, 2)
             # Invalid structure because other half edge is missing
             embedding.check_structure()
 
     def test_not_fulfilling_euler_formula(self):
+        embedding = nx.PlanarEmbedding()
+        for i in range(5):
+            ref = None
+            for j in range(5):
+                if i != j:
+                    embedding.add_half_edge(i, j, cw=ref)
+                    ref = j
         with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            for i in range(5):
-                for j in range(5):
-                    if i != j:
-                        embedding.add_half_edge_first(i, j)
             embedding.check_structure()
 
     def test_missing_reference(self):
-        with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            embedding.add_half_edge_cw(1, 2, 3)
+        embedding = nx.PlanarEmbedding()
+        with pytest.raises(nx.NetworkXException, match="Invalid reference node."):
+            embedding.add_half_edge(1, 2, ccw=3)
 
     def test_connect_components(self):
         embedding = nx.PlanarEmbedding()
         embedding.connect_components(1, 2)
 
     def test_successful_face_traversal(self):
         embedding = nx.PlanarEmbedding()
-        embedding.add_half_edge_first(1, 2)
-        embedding.add_half_edge_first(2, 1)
+        embedding.add_half_edge(1, 2)
+        embedding.add_half_edge(2, 1)
         face = embedding.traverse_face(1, 2)
         assert face == [1, 2]
 
     def test_unsuccessful_face_traversal(self):
+        embedding = nx.PlanarEmbedding(
+            {1: {2: {"cw": 3, "ccw": 2}}, 2: {1: {"cw": 3, "ccw": 1}}}
+        )
         with pytest.raises(nx.NetworkXException):
-            embedding = nx.PlanarEmbedding()
-            embedding.add_edge(1, 2, ccw=2, cw=3)
-            embedding.add_edge(2, 1, ccw=1, cw=3)
             embedding.traverse_face(1, 2)
 
+    def test_forbidden_methods(self):
+        embedding = nx.PlanarEmbedding()
+        embedding.add_node(42)  # no exception
+        embedding.add_nodes_from([(23, 24)])  # no exception
+        with pytest.raises(NotImplementedError):
+            embedding.add_edge(1, 3)
+        with pytest.raises(NotImplementedError):
+            embedding.add_edges_from([(0, 2), (1, 4)])
+        with pytest.raises(NotImplementedError):
+            embedding.add_weighted_edges_from([(0, 2, 350), (1, 4, 125)])
+
     @staticmethod
     def get_star_embedding(n):
         embedding = nx.PlanarEmbedding()
+        ref = None
         for i in range(1, n):
-            embedding.add_half_edge_first(0, i)
-            embedding.add_half_edge_first(i, 0)
+            embedding.add_half_edge(0, i, cw=ref)
+            ref = i
+            embedding.add_half_edge(i, 0)
         return embedding
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_polynomials.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_polynomials.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_reciprocity.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_reciprocity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_regular.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_regular.py`

 * *Files 10% similar despite different names*

```diff
@@ -64,14 +64,20 @@
 
     def test_is_regular4(self):
         g = nx.DiGraph()
         g.add_edges_from([(0, 1), (1, 2), (2, 0)])
         assert reg.is_regular(g)
 
 
+def test_is_regular_empty_graph_raises():
+    G = nx.Graph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="Graph has no nodes"):
+        nx.is_regular(G)
+
+
 class TestIsKRegular:
     def test_is_k_regular1(self):
         g = gen.cycle_graph(4)
         assert reg.is_k_regular(g, 2)
         assert not reg.is_k_regular(g, 3)
 
     def test_is_k_regular2(self):
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_similarity.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_similarity.py`

 * *Files 2% similar despite different names*

```diff
@@ -695,14 +695,24 @@
         assert expected == pytest.approx(actual, abs=1e-5)
 
     @pytest.mark.parametrize("alg", simrank_algs)
     def test_simrank_max_iterations(self, alg):
         G = nx.cycle_graph(5)
         pytest.raises(nx.ExceededMaxIterations, alg, G, max_iterations=10)
 
+    def test_simrank_source_not_found(self):
+        G = nx.cycle_graph(5)
+        with pytest.raises(nx.NodeNotFound, match="Source node 10 not in G"):
+            nx.simrank_similarity(G, source=10)
+
+    def test_simrank_target_not_found(self):
+        G = nx.cycle_graph(5)
+        with pytest.raises(nx.NodeNotFound, match="Target node 10 not in G"):
+            nx.simrank_similarity(G, target=10)
+
     def test_simrank_between_versions(self):
         G = nx.cycle_graph(5)
         # _python tolerance 1e-4
         expected_python_tol4 = {
             0: 1,
             1: 0.394512499239852,
             2: 0.5703550452791322,
@@ -815,28 +825,41 @@
         G.add_edge("v1", "v4", w=2)
         G.add_edge("v2", "v3", w=0.1)
         G.add_edge("v3", "v5", w=1)
         expected = {"v3": 0.75, "v4": 0.5, "v2": 0.5, "v5": 0.25}
         sim = nx.panther_similarity(G, "v1", path_length=2, weight="w")
         assert sim == expected
 
-    def test_generate_random_paths_unweighted(self):
-        np.random.seed(42)
+    def test_panther_similarity_source_not_found(self):
+        G = nx.Graph()
+        G.add_edges_from([(0, 1), (0, 2), (0, 3), (1, 2), (2, 4)])
+        with pytest.raises(nx.NodeNotFound, match="Source node 10 not in G"):
+            nx.panther_similarity(G, source=10)
 
+    def test_panther_similarity_isolated(self):
+        G = nx.Graph()
+        G.add_nodes_from(range(5))
+        with pytest.raises(
+            nx.NetworkXUnfeasible,
+            match="Panther similarity is not defined for the isolated source node 1.",
+        ):
+            nx.panther_similarity(G, source=1)
+
+    def test_generate_random_paths_unweighted(self):
         index_map = {}
         num_paths = 10
         path_length = 2
         G = nx.Graph()
         G.add_edge(0, 1)
         G.add_edge(0, 2)
         G.add_edge(0, 3)
         G.add_edge(1, 2)
         G.add_edge(2, 4)
         paths = nx.generate_random_paths(
-            G, num_paths, path_length=path_length, index_map=index_map
+            G, num_paths, path_length=path_length, index_map=index_map, seed=42
         )
         expected_paths = [
             [3, 0, 3],
             [4, 2, 1],
             [2, 1, 0],
             [2, 0, 3],
             [3, 0, 1],
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_simple_paths.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_simple_paths.py`

 * *Files 3% similar despite different names*

```diff
@@ -136,16 +136,15 @@
     G.add_edge(1, 3)
     paths = nx.all_simple_paths(G, 0, [2, 3])
     assert {tuple(p) for p in paths} == {(0, 1, 2), (0, 1, 3)}
 
 
 def test_all_simple_paths_source_target():
     G = nx.path_graph(4)
-    paths = nx.all_simple_paths(G, 1, 1)
-    assert list(paths) == []
+    assert list(nx.all_simple_paths(G, 1, 1)) == [[1]]
 
 
 def test_all_simple_paths_cutoff():
     G = nx.complete_graph(4)
     paths = nx.all_simple_paths(G, 0, 1, cutoff=1)
     assert {tuple(p) for p in paths} == {(0, 1)}
     paths = nx.all_simple_paths(G, 0, 1, cutoff=2)
@@ -177,28 +176,31 @@
     }
     paths = nx.all_simple_paths(G, 1, [2, 3], cutoff=2)
     assert {tuple(p) for p in paths} == {(1, 2), (1, 3), (1, 2, 3)}
 
 
 def test_all_simple_paths_multigraph():
     G = nx.MultiGraph([(1, 2), (1, 2)])
-    paths = nx.all_simple_paths(G, 1, 1)
-    assert list(paths) == []
+    assert list(nx.all_simple_paths(G, 1, 1)) == [[1]]
     nx.add_path(G, [3, 1, 10, 2])
     paths = list(nx.all_simple_paths(G, 1, 2))
     assert len(paths) == 3
     assert {tuple(p) for p in paths} == {(1, 2), (1, 2), (1, 10, 2)}
 
 
 def test_all_simple_paths_multigraph_with_cutoff():
     G = nx.MultiGraph([(1, 2), (1, 2), (1, 10), (10, 2)])
     paths = list(nx.all_simple_paths(G, 1, 2, cutoff=1))
     assert len(paths) == 2
     assert {tuple(p) for p in paths} == {(1, 2), (1, 2)}
 
+    # See GitHub issue #6732.
+    G = nx.MultiGraph([(0, 1), (0, 2)])
+    assert list(nx.all_simple_paths(G, 0, {1, 2}, cutoff=1)) == [[0, 1], [0, 2]]
+
 
 def test_all_simple_paths_directed():
     G = nx.DiGraph()
     nx.add_path(G, [1, 2, 3])
     nx.add_path(G, [3, 2, 1])
     paths = nx.all_simple_paths(G, 1, 3)
     assert {tuple(p) for p in paths} == {(1, 2, 3)}
@@ -207,19 +209,25 @@
 def test_all_simple_paths_empty():
     G = nx.path_graph(4)
     paths = nx.all_simple_paths(G, 0, 3, cutoff=2)
     assert list(paths) == []
 
 
 def test_all_simple_paths_corner_cases():
-    assert list(nx.all_simple_paths(nx.empty_graph(2), 0, 0)) == []
+    assert list(nx.all_simple_paths(nx.empty_graph(2), 0, 0)) == [[0]]
     assert list(nx.all_simple_paths(nx.empty_graph(2), 0, 1)) == []
     assert list(nx.all_simple_paths(nx.path_graph(9), 0, 8, 0)) == []
 
 
+def test_all_simple_paths_source_in_targets():
+    # See GitHub issue #6690.
+    G = nx.path_graph(3)
+    assert list(nx.all_simple_paths(G, 0, {0, 1, 2})) == [[0], [0, 1], [0, 1, 2]]
+
+
 def hamiltonian_path(G, source):
     source = arbitrary_element(G)
     neighbors = set(G[source]) - {source}
     n = len(G)
     for target in neighbors:
         for path in nx.all_simple_paths(G, source, target):
             if len(path) == n:
@@ -260,14 +268,19 @@
 # Tests for all_simple_edge_paths
 def test_all_simple_edge_paths():
     G = nx.path_graph(4)
     paths = nx.all_simple_edge_paths(G, 0, 3)
     assert {tuple(p) for p in paths} == {((0, 1), (1, 2), (2, 3))}
 
 
+def test_all_simple_edge_paths_empty_path():
+    G = nx.empty_graph(1)
+    assert list(nx.all_simple_edge_paths(G, 0, 0)) == [[]]
+
+
 def test_all_simple_edge_paths_with_two_targets_emits_two_paths():
     G = nx.path_graph(4)
     G.add_edge(2, 4)
     paths = nx.all_simple_edge_paths(G, 0, [3, 4])
     assert {tuple(p) for p in paths} == {
         ((0, 1), (1, 2), (2, 3)),
         ((0, 1), (1, 2), (2, 4)),
@@ -323,15 +336,15 @@
     paths = nx.all_simple_edge_paths(G, 0, [2, 3])
     assert {tuple(p) for p in paths} == {((0, 1), (1, 2)), ((0, 1), (1, 3))}
 
 
 def test_all_simple_edge_paths_source_target():
     G = nx.path_graph(4)
     paths = nx.all_simple_edge_paths(G, 1, 1)
-    assert list(paths) == []
+    assert list(paths) == [[]]
 
 
 def test_all_simple_edge_paths_cutoff():
     G = nx.complete_graph(4)
     paths = nx.all_simple_edge_paths(G, 0, 1, cutoff=1)
     assert {tuple(p) for p in paths} == {((0, 1),)}
     paths = nx.all_simple_edge_paths(G, 0, 1, cutoff=2)
@@ -364,15 +377,15 @@
     paths = nx.all_simple_edge_paths(G, 1, [2, 3], cutoff=2)
     assert {tuple(p) for p in paths} == {((1, 2),), ((1, 3),), ((1, 2), (2, 3))}
 
 
 def test_all_simple_edge_paths_multigraph():
     G = nx.MultiGraph([(1, 2), (1, 2)])
     paths = nx.all_simple_edge_paths(G, 1, 1)
-    assert list(paths) == []
+    assert list(paths) == [[]]
     nx.add_path(G, [3, 1, 10, 2])
     paths = list(nx.all_simple_edge_paths(G, 1, 2))
     assert len(paths) == 3
     assert {tuple(p) for p in paths} == {
         ((1, 2, 0),),
         ((1, 2, 1),),
         ((1, 10, 0), (10, 2, 0)),
@@ -397,19 +410,24 @@
 def test_all_simple_edge_paths_empty():
     G = nx.path_graph(4)
     paths = nx.all_simple_edge_paths(G, 0, 3, cutoff=2)
     assert list(paths) == []
 
 
 def test_all_simple_edge_paths_corner_cases():
-    assert list(nx.all_simple_edge_paths(nx.empty_graph(2), 0, 0)) == []
+    assert list(nx.all_simple_edge_paths(nx.empty_graph(2), 0, 0)) == [[]]
     assert list(nx.all_simple_edge_paths(nx.empty_graph(2), 0, 1)) == []
     assert list(nx.all_simple_edge_paths(nx.path_graph(9), 0, 8, 0)) == []
 
 
+def test_all_simple_edge_paths_ignores_self_loop():
+    G = nx.Graph([(0, 0), (0, 1), (1, 1), (1, 2)])
+    assert list(nx.all_simple_edge_paths(G, 0, 2)) == [[(0, 1), (1, 2)]]
+
+
 def hamiltonian_edge_path(G, source):
     source = arbitrary_element(G)
     neighbors = set(G[source]) - {source}
     n = len(G)
     for target in neighbors:
         for path in nx.all_simple_edge_paths(G, source, target):
             if len(path) == n - 1:
@@ -454,14 +472,19 @@
     assert next(paths) == [1, 2, 3, 4, 8, 12]
     assert next(paths) == [1, 5, 6, 7, 8, 12]
     assert [len(path) for path in nx.shortest_simple_paths(G, 1, 12)] == sorted(
         len(path) for path in nx.all_simple_paths(G, 1, 12)
     )
 
 
+def test_shortest_simple_paths_singleton_path():
+    G = nx.empty_graph(3)
+    assert list(nx.shortest_simple_paths(G, 0, 0)) == [[0]]
+
+
 def test_shortest_simple_paths_directed():
     G = nx.cycle_graph(7, create_using=nx.DiGraph())
     paths = nx.shortest_simple_paths(G, 0, 3)
     assert list(paths) == [[0, 1, 2, 3]]
 
 
 def test_shortest_simple_paths_directed_with_weight_function():
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_smallworld.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_smallworld.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_smetric.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_smetric.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_sparsifiers.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_sparsifiers.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_structuralholes.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_structuralholes.py`

 * *Files 0% similar despite different names*

```diff
@@ -48,15 +48,15 @@
             ("F", "G"): 3,
             ("B", "G"): 4,
             ("B", "D"): 1,
             ("D", "G"): 3,
             ("G", "C"): 10,
         }
 
-    # This additionally tests the @nx._dispatch mechanism, treating
+    # This additionally tests the @nx._dispatchable mechanism, treating
     # nx.mutual_weight as if it were a re-implementation from another package
     @pytest.mark.parametrize("wrapper", [lambda x: x, dispatch_interface.convert])
     def test_constraint_directed(self, wrapper):
         constraint = nx.constraint(wrapper(self.D))
         assert constraint[0] == pytest.approx(1.003, abs=1e-3)
         assert constraint[1] == pytest.approx(1.003, abs=1e-3)
         assert constraint[2] == pytest.approx(1.389, abs=1e-3)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_summarization.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_summarization.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_swap.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_swap.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,41 @@
 import pytest
 
 import networkx as nx
 
+cycle = nx.cycle_graph(5, create_using=nx.DiGraph)
+tree = nx.random_tree(10, create_using=nx.DiGraph, seed=42)
+path = nx.path_graph(5, create_using=nx.DiGraph)
+binomial = nx.binomial_tree(3, create_using=nx.DiGraph)
+HH = nx.directed_havel_hakimi_graph([1, 2, 1, 2, 2, 2], [3, 1, 0, 1, 2, 3])
+balanced_tree = nx.balanced_tree(2, 3, create_using=nx.DiGraph)
 
-def test_directed_edge_swap():
-    graph = nx.path_graph(200, create_using=nx.DiGraph)
-    in_degrees = sorted((n, d) for n, d in graph.in_degree())
-    out_degrees = sorted((n, d) for n, d in graph.out_degree())
-    G = nx.directed_edge_swap(graph, nswap=40, max_tries=500, seed=1)
-    assert in_degrees == sorted((n, d) for n, d in G.in_degree())
-    assert out_degrees == sorted((n, d) for n, d in G.out_degree())
+
+@pytest.mark.parametrize("G", [path, binomial, HH, cycle, tree, balanced_tree])
+def test_directed_edge_swap(G):
+    in_degree = set(G.in_degree)
+    out_degree = set(G.out_degree)
+    edges = set(G.edges)
+    nx.directed_edge_swap(G, nswap=1, max_tries=100, seed=1)
+    assert in_degree == set(G.in_degree)
+    assert out_degree == set(G.out_degree)
+    assert edges != set(G.edges)
+    assert 3 == sum(e not in edges for e in G.edges)
+
+
+def test_directed_edge_swap_undo_previous_swap():
+    G = nx.DiGraph(nx.path_graph(4).edges)  # only 1 swap possible
+    edges = set(G.edges)
+    nx.directed_edge_swap(G, nswap=2, max_tries=100)
+    assert edges == set(G.edges)
+
+    nx.directed_edge_swap(G, nswap=1, max_tries=100, seed=1)
+    assert {(0, 2), (1, 3), (2, 1)} == set(G.edges)
+    nx.directed_edge_swap(G, nswap=1, max_tries=100, seed=1)
+    assert edges == set(G.edges)
 
 
 def test_edge_cases_directed_edge_swap():
     # Tests cases when swaps are impossible, either too few edges exist, or self loops/cycles are unavoidable
     # TODO: Rewrite function to explicitly check for impossible swaps and raise error
     e = (
         "Maximum number of swap attempts \\(11\\) exceeded "
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_threshold.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_threshold.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_time_dependent.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_time_dependent.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_tournament.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_tournament.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_triads.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_triads.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,14 +5,26 @@
 from random import sample
 
 import pytest
 
 import networkx as nx
 
 
+def test_all_triplets_deprecated():
+    G = nx.DiGraph([(1, 2), (2, 3), (3, 4)])
+    with pytest.deprecated_call():
+        nx.all_triplets(G)
+
+
+def test_random_triad_deprecated():
+    G = nx.path_graph(3, create_using=nx.DiGraph)
+    with pytest.deprecated_call():
+        nx.random_triad(G)
+
+
 def test_triadic_census():
     """Tests the triadic_census function."""
     G = nx.DiGraph()
     G.add_edges_from(["01", "02", "03", "04", "05", "12", "16", "51", "56", "65"])
     expected = {
         "030T": 2,
         "120C": 1,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_vitality.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_vitality.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_voronoi.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_voronoi.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tests/test_walks.py` & `networkx-3.3rc0/networkx/algorithms/tests/test_walks.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/threshold.py` & `networkx-3.3rc0/networkx/algorithms/threshold.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 
 import networkx as nx
 from networkx.utils import py_random_state
 
 __all__ = ["is_threshold_graph", "find_threshold_graph"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_threshold_graph(G):
     """
     Returns `True` if `G` is a threshold graph.
 
     Parameters
     ----------
     G : NetworkX graph instance
@@ -297,15 +297,15 @@
         return cs
     if compact:
         return make_compact(cs)
     return [v[1] for v in cs]  # not labeled
 
 
 # Manipulating NetworkX.Graphs in context of threshold graphs
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def threshold_graph(creation_sequence, create_using=None):
     """
     Create a threshold graph from the creation sequence or compact
     creation_sequence.
 
     The input sequence can be a
 
@@ -349,15 +349,15 @@
             # `RuntimeError: dictionary changed size during iteration`
             for u in list(G):
                 G.add_edge(v, u)
         G.add_node(v)
     return G
 
 
-@nx._dispatch
+@nx._dispatchable
 def find_alternating_4_cycle(G):
     """
     Returns False if there aren't any alternating 4 cycles.
     Otherwise returns the cycle as [a,b,c,d] where (a,b)
     and (c,d) are edges and (a,c) and (b,d) are not.
     """
     for u, v in G.edges():
@@ -365,15 +365,15 @@
             if not G.has_edge(u, w) and u != w:
                 for x in G.neighbors(w):
                     if not G.has_edge(v, x) and v != x:
                         return [u, v, w, x]
     return False
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def find_threshold_graph(G, create_using=None):
     """
     Returns a threshold subgraph that is close to largest in `G`.
 
     The threshold graph will contain the largest degree node in G.
 
     Parameters
@@ -390,25 +390,25 @@
         A graph instance representing the threshold graph
 
     Examples
     --------
     >>> from networkx.algorithms.threshold import find_threshold_graph
     >>> G = nx.barbell_graph(3, 3)
     >>> T = find_threshold_graph(G)
-    >>> T.nodes # may vary
+    >>> T.nodes  # may vary
     NodeView((7, 8, 5, 6))
 
     References
     ----------
     .. [1] Threshold graphs: https://en.wikipedia.org/wiki/Threshold_graph
     """
     return threshold_graph(find_creation_sequence(G), create_using)
 
 
-@nx._dispatch
+@nx._dispatchable
 def find_creation_sequence(G):
     """
     Find a threshold subgraph that is close to largest in G.
     Returns the labeled creation sequence of that threshold graph.
     """
     cs = []
     # get a local pointer to the working part of the graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/time_dependent.py` & `networkx-3.3rc0/networkx/algorithms/time_dependent.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["cd_index"]
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch(node_attrs={"time": None, "weight": 1})
+@nx._dispatchable(node_attrs={"time": None, "weight": 1})
 def cd_index(G, node, time_delta, *, time="time", weight=None):
     r"""Compute the CD index for `node` within the graph `G`.
 
     Calculates the CD index for the given node of the graph,
     considering only its predecessors who have the `time` attribute
     smaller than or equal to the `time` attribute of the `node`
     plus `time_delta`.
@@ -51,18 +51,18 @@
 
     Examples
     --------
     >>> from datetime import datetime, timedelta
     >>> G = nx.DiGraph()
     >>> nodes = {
     ...     1: {"time": datetime(2015, 1, 1)},
-    ...     2: {"time": datetime(2012, 1, 1), 'weight': 4},
+    ...     2: {"time": datetime(2012, 1, 1), "weight": 4},
     ...     3: {"time": datetime(2010, 1, 1)},
     ...     4: {"time": datetime(2008, 1, 1)},
-    ...     5: {"time": datetime(2014, 1, 1)}
+    ...     5: {"time": datetime(2014, 1, 1)},
     ... }
     >>> G.add_nodes_from([(n, nodes[n]) for n in nodes])
     >>> edges = [(1, 3), (1, 4), (2, 3), (3, 4), (3, 5)]
     >>> G.add_edges_from(edges)
     >>> delta = timedelta(days=5 * 365)
     >>> nx.cd_index(G, 3, time_delta=delta, time="time")
     0.5
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tournament.py` & `networkx-3.3rc0/networkx/algorithms/tournament.py`

 * *Files 2% similar despite different names*

```diff
@@ -61,15 +61,15 @@
         return i + 1
     except NameError as err:
         raise ValueError("iterable must be non-empty") from err
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_tournament(G):
     """Returns True if and only if `G` is a tournament.
 
     A tournament is a directed graph, with neither self-loops nor
     multi-edges, in which there is exactly one directed edge joining
     each pair of distinct nodes.
 
@@ -100,15 +100,15 @@
         all((v in G[u]) ^ (u in G[v]) for u, v in combinations(G, 2))
         and nx.number_of_selfloops(G) == 0
     )
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def hamiltonian_path(G):
     """Returns a Hamiltonian path in the given tournament graph.
 
     Each tournament has a Hamiltonian path. If furthermore, the
     tournament is strongly connected, then the returned Hamiltonian path
     is a Hamiltonian cycle (by joining the endpoints of the path).
 
@@ -147,15 +147,15 @@
     # an edge to `v`, then insert `v` before that node.
     index = index_satisfying(hampath, lambda u: v not in G[u])
     hampath.insert(index, v)
     return hampath
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_tournament(n, seed=None):
     r"""Returns a random tournament graph on `n` nodes.
 
     Parameters
     ----------
     n : int
         The number of nodes in the returned graph.
@@ -182,15 +182,15 @@
     pairs = combinations(range(n), 2)
     edges = ((u, v) if r < 0.5 else (v, u) for (u, v), r in zip(pairs, coins))
     return nx.DiGraph(edges)
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def score_sequence(G):
     """Returns the score sequence for the given tournament graph.
 
     The score sequence is the sorted list of the out-degrees of the
     nodes of the graph.
 
     Parameters
@@ -213,15 +213,15 @@
 
     """
     return sorted(d for v, d in G.out_degree())
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(preserve_edge_attrs={"G": {"weight": 1}})
 def tournament_matrix(G):
     r"""Returns the tournament matrix for the given tournament graph.
 
     This function requires SciPy.
 
     The *tournament matrix* of a tournament graph with edge set *E* is
     the matrix *T* defined by
@@ -256,15 +256,15 @@
     """
     A = nx.adjacency_matrix(G)
     return A - A.T
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def is_reachable(G, s, t):
     """Decides whether there is a path from `s` to `t` in the
     tournament.
 
     This function is more theoretically efficient than the reachability
     checks than the shortest path algorithms in
     :mod:`networkx.algorithms.shortest_paths`.
@@ -345,15 +345,15 @@
     # TODO This is trivially parallelizable.
     neighborhoods = [two_neighborhood(G, v) for v in G]
     return all(not (is_closed(G, S) and s in S and t not in S) for S in neighborhoods)
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch(name="tournament_is_strongly_connected")
+@nx._dispatchable(name="tournament_is_strongly_connected")
 def is_strongly_connected(G):
     """Decides whether the given tournament is strongly connected.
 
     This function is more theoretically efficient than the
     :func:`~networkx.algorithms.components.is_strongly_connected`
     function.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/beamsearch.py` & `networkx-3.3rc0/networkx/algorithms/traversal/beamsearch.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,32 @@
 """Basic algorithms for breadth-first searching the nodes of a graph."""
 import networkx as nx
 
-from .breadth_first_search import generic_bfs_edges
-
 __all__ = ["bfs_beam_edges"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_beam_edges(G, source, value, width=None):
     """Iterates over edges in a beam search.
 
     The beam search is a generalized breadth-first search in which only
     the "best" *w* neighbors of the current node are enqueued, where *w*
     is the beam width and "best" is an application-specific
     heuristic. In general, a beam search with a small beam width might
     not visit each node in the graph.
 
+    .. note::
+
+       With the default value of ``width=None`` or `width` greater than the
+       maximum degree of the graph, this function equates to a slower
+       version of `~networkx.algorithms.traversal.breadth_first_search.bfs_edges`.
+       All nodes will be visited, though the order of the reported edges may
+       vary. In such cases, `value` has no effect - consider using `bfs_edges`
+       directly instead.
+
     Parameters
     ----------
     G : NetworkX graph
 
     source : node
         Starting node for the breadth-first search; this function
         iterates over only those edges in the component reachable from
@@ -46,61 +53,37 @@
     --------
     To give nodes with, for example, a higher centrality precedence
     during the search, set the `value` function to return the centrality
     value of the node:
 
     >>> G = nx.karate_club_graph()
     >>> centrality = nx.eigenvector_centrality(G)
-    >>> source = 0
-    >>> width = 5
-    >>> for u, v in nx.bfs_beam_edges(G, source, centrality.get, width):
-    ...     print((u, v))
-    ...
-    (0, 2)
-    (0, 1)
-    (0, 8)
-    (0, 13)
-    (0, 3)
-    (2, 32)
-    (1, 30)
-    (8, 33)
-    (3, 7)
-    (32, 31)
-    (31, 28)
-    (31, 25)
-    (25, 23)
-    (25, 24)
-    (23, 29)
-    (23, 27)
-    (29, 26)
+    >>> list(nx.bfs_beam_edges(G, source=0, value=centrality.get, width=3))
+    [(0, 2), (0, 1), (0, 8), (2, 32), (1, 13), (8, 33)]
     """
 
     if width is None:
         width = len(G)
 
     def successors(v):
         """Returns a list of the best neighbors of a node.
 
         `v` is a node in the graph `G`.
 
         The "best" neighbors are chosen according to the `value`
         function (higher is better). Only the `width` best neighbors of
         `v` are returned.
-
-        The list returned by this function is in decreasing value as
-        measured by the `value` function.
-
         """
         # TODO The Python documentation states that for small values, it
         # is better to use `heapq.nlargest`. We should determine the
         # threshold at which its better to use `heapq.nlargest()`
         # instead of `sorted()[:]` and apply that optimization here.
         #
         # If `width` is greater than the number of neighbors of `v`, all
         # neighbors are returned by the semantics of slicing in
         # Python. This occurs in the special case that the user did not
         # specify a `width`: in this case all neighbors are always
         # returned, so this is just a (slower) implementation of
         # `bfs_edges(G, source)` but with a sorted enqueue step.
         return iter(sorted(G.neighbors(v), key=value, reverse=True)[:width])
 
-    yield from generic_bfs_edges(G, source, successors)
+    yield from nx.generic_bfs_edges(G, source, successors)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/breadth_first_search.py` & `networkx-3.3rc0/networkx/algorithms/traversal/breadth_first_search.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """Basic algorithms for breadth-first searching the nodes of a graph."""
-import math
 from collections import deque
 
 import networkx as nx
 
 __all__ = [
     "bfs_edges",
     "bfs_tree",
@@ -12,15 +11,15 @@
     "descendants_at_distance",
     "bfs_layers",
     "bfs_labeled_edges",
     "generic_bfs_edges",
 ]
 
 
-@nx._dispatch
+@nx._dispatchable
 def generic_bfs_edges(G, source, neighbors=None, depth_limit=None, sort_neighbors=None):
     """Iterate over edges in a breadth-first search.
 
     The breadth-first search begins at `source` and enqueues the
     neighbors of newly visited nodes specified by the `neighbors`
     function.
 
@@ -33,45 +32,60 @@
         iterates over only those edges in the component reachable from
         this node.
 
     neighbors : function
         A function that takes a newly visited node of the graph as input
         and returns an *iterator* (not just a list) of nodes that are
         neighbors of that node with custom ordering. If not specified, this is
-        just the``G.neighbors`` method, but in general it can be any function
+        just the ``G.neighbors`` method, but in general it can be any function
         that returns an iterator over some or all of the neighbors of a
         given node, in any order.
 
     depth_limit : int, optional(default=len(G))
         Specify the maximum search depth.
 
-    sort_neighbors : Callable
+    sort_neighbors : Callable (default=None)
 
         .. deprecated:: 3.2
 
            The sort_neighbors parameter is deprecated and will be removed in
            version 3.4. A custom (e.g. sorted) ordering of neighbors can be
            specified with the `neighbors` parameter.
 
-        A function that takes the list of neighbors of a given node as input,
-        and returns an iterator over these neighbors but with a custom
-        ordering.
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
 
     Yields
     ------
     edge
         Edges in the breadth-first search starting from `source`.
 
     Examples
     --------
-    >>> G = nx.path_graph(3)
-    >>> list(nx.bfs_edges(G, 0))
-    [(0, 1), (1, 2)]
-    >>> list(nx.bfs_edges(G, source=0, depth_limit=1))
-    [(0, 1)]
+    >>> G = nx.path_graph(7)
+    >>> list(nx.generic_bfs_edges(G, source=0))
+    [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]
+    >>> list(nx.generic_bfs_edges(G, source=2))
+    [(2, 1), (2, 3), (1, 0), (3, 4), (4, 5), (5, 6)]
+    >>> list(nx.generic_bfs_edges(G, source=2, depth_limit=2))
+    [(2, 1), (2, 3), (1, 0), (3, 4)]
+
+    The `neighbors` param can be used to specify the visitation order of each
+    node's neighbors generically. In the following example, we modify the default
+    neighbor to return *odd* nodes first:
+
+    >>> def odd_first(n):
+    ...     return sorted(G.neighbors(n), key=lambda x: x % 2, reverse=True)
+
+    >>> G = nx.star_graph(5)
+    >>> list(nx.generic_bfs_edges(G, source=0))  # Default neighbor ordering
+    [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]
+    >>> list(nx.generic_bfs_edges(G, source=0, neighbors=odd_first))
+    [(0, 1), (0, 3), (0, 5), (0, 2), (0, 4)]
 
     Notes
     -----
     This implementation is from `PADS`_, which was in the public domain
     when it was first accessed in July, 2004.  The modifications
     to allow depth limits are based on the Wikipedia article
     "`Depth-limited-search`_".
@@ -111,15 +125,15 @@
                     next_parents_children.append((child, neighbors(child)))
                     yield parent, child
             if len(seen) == n:
                 return
         depth += 1
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_edges(G, source, reverse=False, depth_limit=None, sort_neighbors=None):
     """Iterate over edges in a breadth-first-search starting at source.
 
     Parameters
     ----------
     G : NetworkX graph
 
@@ -130,17 +144,18 @@
 
     reverse : bool, optional
        If True traverse a directed graph in the reverse direction
 
     depth_limit : int, optional(default=len(G))
         Specify the maximum search depth
 
-    sort_neighbors : function
-        A function that takes the list of neighbors of given node as input, and
-        returns an *iterator* over these neighbors but with custom ordering.
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
 
     Yields
     ------
     edge: 2-tuple of nodes
        Yields edges resulting from the breadth-first search.
 
     Examples
@@ -191,23 +206,23 @@
 
     """
     if reverse and G.is_directed():
         successors = G.predecessors
     else:
         successors = G.neighbors
 
-    if callable(sort_neighbors):
+    if sort_neighbors is not None:
         yield from generic_bfs_edges(
             G, source, lambda node: iter(sort_neighbors(successors(node))), depth_limit
         )
     else:
         yield from generic_bfs_edges(G, source, successors, depth_limit)
 
 
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def bfs_tree(G, source, reverse=False, depth_limit=None, sort_neighbors=None):
     """Returns an oriented tree constructed from of a breadth-first-search
     starting at source.
 
     Parameters
     ----------
     G : NetworkX graph
@@ -217,17 +232,18 @@
 
     reverse : bool, optional
        If True traverse a directed graph in the reverse direction
 
     depth_limit : int, optional(default=len(G))
         Specify the maximum search depth
 
-    sort_neighbors : function
-        A function that takes the list of neighbors of given node as input, and
-        returns an *iterator* over these neighbors but with custom ordering.
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
 
     Returns
     -------
     T: NetworkX DiGraph
        An oriented tree
 
     Examples
@@ -266,31 +282,32 @@
         depth_limit=depth_limit,
         sort_neighbors=sort_neighbors,
     )
     T.add_edges_from(edges_gen)
     return T
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_predecessors(G, source, depth_limit=None, sort_neighbors=None):
     """Returns an iterator of predecessors in breadth-first-search from source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node
        Specify starting node for breadth-first search
 
     depth_limit : int, optional(default=len(G))
         Specify the maximum search depth
 
-    sort_neighbors : function
-        A function that takes the list of neighbors of given node as input, and
-        returns an *iterator* over these neighbors but with custom ordering.
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
 
     Returns
     -------
     pred: iterator
         (node, predecessor) iterator where `predecessor` is the predecessor of
         `node` in a breadth first search starting from `source`.
 
@@ -331,31 +348,32 @@
     """
     for s, t in bfs_edges(
         G, source, depth_limit=depth_limit, sort_neighbors=sort_neighbors
     ):
         yield (t, s)
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_successors(G, source, depth_limit=None, sort_neighbors=None):
     """Returns an iterator of successors in breadth-first-search from source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node
        Specify starting node for breadth-first search
 
     depth_limit : int, optional(default=len(G))
         Specify the maximum search depth
 
-    sort_neighbors : function
-        A function that takes the list of neighbors of given node as input, and
-        returns an *iterator* over these neighbors but with custom ordering.
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
 
     Returns
     -------
     succ: iterator
        (node, successors) iterator where `successors` is the non-empty list of
        successors of `node` in a breadth first search from `source`.
        To appear in the iterator, `node` must have successors.
@@ -404,15 +422,15 @@
             continue
         yield (parent, children)
         children = [c]
         parent = p
     yield (parent, children)
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_layers(G, sources):
     """Returns an iterator of all the layers in breadth-first search traversal.
 
     Parameters
     ----------
     G : NetworkX graph
         A graph over which to find the layers using breadth-first search.
@@ -462,15 +480,15 @@
 
 REVERSE_EDGE = "reverse"
 TREE_EDGE = "tree"
 FORWARD_EDGE = "forward"
 LEVEL_EDGE = "level"
 
 
-@nx._dispatch
+@nx._dispatchable
 def bfs_labeled_edges(G, sources):
     """Iterate over edges in a breadth-first search (BFS) labeled by type.
 
     We generate triple of the form (*u*, *v*, *d*), where (*u*, *v*) is the
     edge being explored in the breadth-first search and *d* is one of the
     strings 'tree', 'forward', 'level', or 'reverse'.  A 'tree' edge is one in
     which *v* is first discovered and placed into the layer below *u*.  A
@@ -494,15 +512,15 @@
     ------
     edges: generator
        A generator of triples (*u*, *v*, *d*) where (*u*, *v*) is the edge being
        explored and *d* is described above.
 
     Examples
     --------
-    >>> G = nx.cycle_graph(4, create_using = nx.DiGraph)
+    >>> G = nx.cycle_graph(4, create_using=nx.DiGraph)
     >>> list(nx.bfs_labeled_edges(G, 0))
     [(0, 1, 'tree'), (1, 2, 'tree'), (2, 3, 'tree'), (3, 0, 'reverse')]
     >>> G = nx.complete_graph(3)
     >>> list(nx.bfs_labeled_edges(G, 0))
     [(0, 1, 'tree'), (0, 2, 'tree'), (1, 2, 'level')]
     >>> list(nx.bfs_labeled_edges(G, [0, 1]))
     [(0, 1, 'level'), (0, 2, 'tree'), (1, 2, 'forward')]
@@ -537,15 +555,15 @@
                 elif du < dv:
                     yield u, v, FORWARD_EDGE
                 elif directed:
                     yield u, v, REVERSE_EDGE
         visit(u)
 
 
-@nx._dispatch
+@nx._dispatchable
 def descendants_at_distance(G, source, distance):
     """Returns all nodes at a fixed `distance` from `source` in `G`.
 
     Parameters
     ----------
     G : NetworkX graph
         A graph
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/depth_first_search.py` & `networkx-3.3rc0/networkx/algorithms/traversal/depth_first_search.py`

 * *Files 20% similar despite different names*

```diff
@@ -10,16 +10,16 @@
     "dfs_successors",
     "dfs_preorder_nodes",
     "dfs_postorder_nodes",
     "dfs_labeled_edges",
 ]
 
 
-@nx._dispatch
-def dfs_edges(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_edges(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Iterate over edges in a depth-first-search (DFS).
 
     Perform a depth-first-search over the nodes of `G` and yield
     the edges in order. This may not generate all edges in `G`
     (see `~networkx.algorithms.traversal.edgedfs.edge_dfs`).
 
     Parameters
@@ -29,14 +29,19 @@
     source : node, optional
        Specify starting node for depth-first search and yield edges in
        the component reachable from source.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Yields
     ------
     edge: 2-tuple of nodes
        Yields edges resulting from the depth-first-search.
 
     Examples
     --------
@@ -74,50 +79,61 @@
         nodes = G
     else:
         # edges for components with source
         nodes = [source]
     if depth_limit is None:
         depth_limit = len(G)
 
+    get_children = (
+        G.neighbors
+        if sort_neighbors is None
+        else lambda n: iter(sort_neighbors(G.neighbors(n)))
+    )
+
     visited = set()
     for start in nodes:
         if start in visited:
             continue
         visited.add(start)
-        stack = [(start, iter(G[start]))]
+        stack = [(start, get_children(start))]
         depth_now = 1
         while stack:
             parent, children = stack[-1]
             for child in children:
                 if child not in visited:
                     yield parent, child
                     visited.add(child)
                     if depth_now < depth_limit:
-                        stack.append((child, iter(G[child])))
+                        stack.append((child, get_children(child)))
                         depth_now += 1
                         break
             else:
                 stack.pop()
                 depth_now -= 1
 
 
-@nx._dispatch
-def dfs_tree(G, source=None, depth_limit=None):
+@nx._dispatchable(returns_graph=True)
+def dfs_tree(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Returns oriented tree constructed from a depth-first-search from source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
        Specify starting node for depth-first search.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     T : NetworkX DiGraph
        An oriented tree
 
     Examples
     --------
@@ -130,28 +146,28 @@
     [(0, 1), (1, 2), (2, 3), (3, 4)]
 
     See Also
     --------
     dfs_preorder_nodes
     dfs_postorder_nodes
     dfs_labeled_edges
-    edge_dfs
-    bfs_tree
+    :func:`~networkx.algorithms.traversal.edgedfs.edge_dfs`
+    :func:`~networkx.algorithms.traversal.breadth_first_search.bfs_tree`
     """
     T = nx.DiGraph()
     if source is None:
         T.add_nodes_from(G)
     else:
         T.add_node(source)
-    T.add_edges_from(dfs_edges(G, source, depth_limit))
+    T.add_edges_from(dfs_edges(G, source, depth_limit, sort_neighbors=sort_neighbors))
     return T
 
 
-@nx._dispatch
-def dfs_predecessors(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_predecessors(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Returns dictionary of predecessors in depth-first-search from source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
@@ -159,14 +175,19 @@
        Note that you will get predecessors for all nodes in the
        component containing `source`. This input only specifies
        where the DFS starts.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     pred: dict
        A dictionary with nodes as keys and predecessor nodes as values.
 
     Examples
     --------
@@ -190,22 +211,25 @@
     .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
 
     See Also
     --------
     dfs_preorder_nodes
     dfs_postorder_nodes
     dfs_labeled_edges
-    edge_dfs
-    bfs_tree
+    :func:`~networkx.algorithms.traversal.edgedfs.edge_dfs`
+    :func:`~networkx.algorithms.traversal.breadth_first_search.bfs_tree`
     """
-    return {t: s for s, t in dfs_edges(G, source, depth_limit)}
+    return {
+        t: s
+        for s, t in dfs_edges(G, source, depth_limit, sort_neighbors=sort_neighbors)
+    }
 
 
-@nx._dispatch
-def dfs_successors(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_successors(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Returns dictionary of successors in depth-first-search from source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
@@ -213,14 +237,19 @@
        Note that you will get successors for all nodes in the
        component containing `source`. This input only specifies
        where the DFS starts.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     succ: dict
        A dictionary with nodes as keys and list of successor nodes as values.
 
     Examples
     --------
@@ -244,37 +273,47 @@
     .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
 
     See Also
     --------
     dfs_preorder_nodes
     dfs_postorder_nodes
     dfs_labeled_edges
-    edge_dfs
-    bfs_tree
+    :func:`~networkx.algorithms.traversal.edgedfs.edge_dfs`
+    :func:`~networkx.algorithms.traversal.breadth_first_search.bfs_tree`
     """
     d = defaultdict(list)
-    for s, t in dfs_edges(G, source=source, depth_limit=depth_limit):
+    for s, t in dfs_edges(
+        G,
+        source=source,
+        depth_limit=depth_limit,
+        sort_neighbors=sort_neighbors,
+    ):
         d[s].append(t)
     return dict(d)
 
 
-@nx._dispatch
-def dfs_postorder_nodes(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_postorder_nodes(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Generate nodes in a depth-first-search post-ordering starting at source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
        Specify starting node for depth-first search.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     nodes: generator
        A generator of nodes in a depth-first-search post-ordering.
 
     Examples
     --------
@@ -298,36 +337,43 @@
     .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
 
     See Also
     --------
     dfs_edges
     dfs_preorder_nodes
     dfs_labeled_edges
-    edge_dfs
-    bfs_tree
+    :func:`~networkx.algorithms.traversal.edgedfs.edge_dfs`
+    :func:`~networkx.algorithms.traversal.breadth_first_search.bfs_tree`
     """
-    edges = nx.dfs_labeled_edges(G, source=source, depth_limit=depth_limit)
+    edges = nx.dfs_labeled_edges(
+        G, source=source, depth_limit=depth_limit, sort_neighbors=sort_neighbors
+    )
     return (v for u, v, d in edges if d == "reverse")
 
 
-@nx._dispatch
-def dfs_preorder_nodes(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_preorder_nodes(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Generate nodes in a depth-first-search pre-ordering starting at source.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
        Specify starting node for depth-first search and return nodes in
        the component reachable from source.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     nodes: generator
        A generator of nodes in a depth-first-search pre-ordering.
 
     Examples
     --------
@@ -351,35 +397,42 @@
     .. _Depth-limited search: https://en.wikipedia.org/wiki/Depth-limited_search
 
     See Also
     --------
     dfs_edges
     dfs_postorder_nodes
     dfs_labeled_edges
-    bfs_edges
+    :func:`~networkx.algorithms.traversal.breadth_first_search.bfs_edges`
     """
-    edges = nx.dfs_labeled_edges(G, source=source, depth_limit=depth_limit)
+    edges = nx.dfs_labeled_edges(
+        G, source=source, depth_limit=depth_limit, sort_neighbors=sort_neighbors
+    )
     return (v for u, v, d in edges if d == "forward")
 
 
-@nx._dispatch
-def dfs_labeled_edges(G, source=None, depth_limit=None):
+@nx._dispatchable
+def dfs_labeled_edges(G, source=None, depth_limit=None, *, sort_neighbors=None):
     """Iterate over edges in a depth-first-search (DFS) labeled by type.
 
     Parameters
     ----------
     G : NetworkX graph
 
     source : node, optional
        Specify starting node for depth-first search and return edges in
        the component reachable from source.
 
     depth_limit : int, optional (default=len(G))
        Specify the maximum search depth.
 
+    sort_neighbors : function (default=None)
+        A function that takes an iterator over nodes as the input, and
+        returns an iterable of the same nodes with a custom ordering.
+        For example, `sorted` will sort the nodes in increasing order.
+
     Returns
     -------
     edges: generator
        A generator of triples of the form (*u*, *v*, *d*), where (*u*,
        *v*) is the edge being explored in the depth-first search and *d*
        is one of the strings 'forward', 'nontree', 'reverse', or 'reverse-depth_limit'.
        A 'forward' edge is one in which *u* has been visited but *v* has
@@ -435,32 +488,38 @@
         nodes = G
     else:
         # edges for components with source
         nodes = [source]
     if depth_limit is None:
         depth_limit = len(G)
 
+    get_children = (
+        G.neighbors
+        if sort_neighbors is None
+        else lambda n: iter(sort_neighbors(G.neighbors(n)))
+    )
+
     visited = set()
     for start in nodes:
         if start in visited:
             continue
         yield start, start, "forward"
         visited.add(start)
-        stack = [(start, iter(G[start]))]
+        stack = [(start, get_children(start))]
         depth_now = 1
         while stack:
             parent, children = stack[-1]
             for child in children:
                 if child in visited:
                     yield parent, child, "nontree"
                 else:
                     yield parent, child, "forward"
                     visited.add(child)
                     if depth_now < depth_limit:
-                        stack.append((child, iter(G[child])))
+                        stack.append((child, iter(get_children(child))))
                         depth_now += 1
                         break
                     else:
                         yield parent, child, "reverse-depth_limit"
             else:
                 stack.pop()
                 depth_now -= 1
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/edgebfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/edgebfs.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 FORWARD = "forward"
 REVERSE = "reverse"
 
 __all__ = ["edge_bfs"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def edge_bfs(G, source=None, orientation=None):
     """A directed, breadth-first-search of edges in `G`, beginning at `source`.
 
     Yield the edges of G in a breadth-first-search order continuing until
     all edges are generated.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/edgedfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/edgedfs.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 
 FORWARD = "forward"
 REVERSE = "reverse"
 
 __all__ = ["edge_dfs"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def edge_dfs(G, source=None, orientation=None):
     """A directed, depth-first-search of edges in `G`, beginning at `source`.
 
     Yield the edges of G in a depth-first-search order continuing until
     all edges are generated.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/tests/test_beamsearch.py` & `networkx-3.3rc0/networkx/algorithms/traversal/tests/test_beamsearch.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,32 +1,24 @@
 """Unit tests for the beam search functions."""
+import pytest
 
 import networkx as nx
 
 
-def identity(x):
-    return x
-
-
-class TestBeamSearch:
-    """Unit tests for the beam search function."""
-
-    def test_narrow(self):
-        """Tests that a narrow beam width may cause an incomplete search."""
-        # In this search, we enqueue only the neighbor 3 at the first
-        # step, then only the neighbor 2 at the second step. Once at
-        # node 2, the search chooses node 3, since it has a higher value
-        # that node 1, but node 3 has already been visited, so the
-        # search terminates.
-        G = nx.cycle_graph(4)
-        edges = nx.bfs_beam_edges(G, 0, identity, width=1)
-        assert list(edges) == [(0, 3), (3, 2)]
-
-    def test_wide(self):
-        G = nx.cycle_graph(4)
-        edges = nx.bfs_beam_edges(G, 0, identity, width=2)
-        assert list(edges) == [(0, 3), (0, 1), (3, 2)]
-
-    def test_width_none(self):
-        G = nx.cycle_graph(4)
-        edges = nx.bfs_beam_edges(G, 0, identity, width=None)
-        assert list(edges) == [(0, 3), (0, 1), (3, 2)]
+def test_narrow():
+    """Tests that a narrow beam width may cause an incomplete search."""
+    # In this search, we enqueue only the neighbor 3 at the first
+    # step, then only the neighbor 2 at the second step. Once at
+    # node 2, the search chooses node 3, since it has a higher value
+    # than node 1, but node 3 has already been visited, so the
+    # search terminates.
+    G = nx.cycle_graph(4)
+    edges = nx.bfs_beam_edges(G, source=0, value=lambda n: n, width=1)
+    assert list(edges) == [(0, 3), (3, 2)]
+
+
+@pytest.mark.parametrize("width", (2, None))
+def test_wide(width):
+    """All nodes are searched when `width` is None or >= max degree"""
+    G = nx.cycle_graph(4)
+    edges = nx.bfs_beam_edges(G, source=0, value=lambda n: n, width=width)
+    assert list(edges) == [(0, 3), (0, 1), (3, 2)]
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/tests/test_bfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/tests/test_bfs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/tests/test_dfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/tests/test_dfs.py`

 * *Files 13% similar despite different names*

```diff
@@ -51,14 +51,22 @@
 
     def test_dfs_edges(self):
         edges = nx.dfs_edges(self.G, source=0)
         assert list(edges) == [(0, 1), (1, 2), (2, 4), (1, 3)]
         edges = nx.dfs_edges(self.D)
         assert list(edges) == [(0, 1), (2, 3)]
 
+    def test_dfs_edges_sorting(self):
+        G = nx.Graph([(0, 1), (1, 2), (1, 3), (2, 4), (3, 0), (0, 4)])
+        edges_asc = nx.dfs_edges(G, source=0, sort_neighbors=sorted)
+        sorted_desc = lambda x: sorted(x, reverse=True)
+        edges_desc = nx.dfs_edges(G, source=0, sort_neighbors=sorted_desc)
+        assert list(edges_asc) == [(0, 1), (1, 2), (2, 4), (1, 3)]
+        assert list(edges_desc) == [(0, 4), (4, 2), (2, 1), (1, 3)]
+
     def test_dfs_labeled_edges(self):
         edges = list(nx.dfs_labeled_edges(self.G, source=0))
         forward = [(u, v) for (u, v, d) in edges if d == "forward"]
         assert forward == [(0, 0), (0, 1), (1, 2), (2, 4), (1, 3)]
         assert edges == [
             (0, 0, "forward"),
             (0, 1, "forward"),
@@ -76,14 +84,60 @@
             (1, 3, "reverse"),
             (0, 1, "reverse"),
             (0, 3, "nontree"),
             (0, 4, "nontree"),
             (0, 0, "reverse"),
         ]
 
+    def test_dfs_labeled_edges_sorting(self):
+        G = nx.Graph([(0, 1), (1, 2), (1, 3), (2, 4), (3, 0), (0, 4)])
+        edges_asc = nx.dfs_labeled_edges(G, source=0, sort_neighbors=sorted)
+        sorted_desc = lambda x: sorted(x, reverse=True)
+        edges_desc = nx.dfs_labeled_edges(G, source=0, sort_neighbors=sorted_desc)
+        assert list(edges_asc) == [
+            (0, 0, "forward"),
+            (0, 1, "forward"),
+            (1, 0, "nontree"),
+            (1, 2, "forward"),
+            (2, 1, "nontree"),
+            (2, 4, "forward"),
+            (4, 0, "nontree"),
+            (4, 2, "nontree"),
+            (2, 4, "reverse"),
+            (1, 2, "reverse"),
+            (1, 3, "forward"),
+            (3, 0, "nontree"),
+            (3, 1, "nontree"),
+            (1, 3, "reverse"),
+            (0, 1, "reverse"),
+            (0, 3, "nontree"),
+            (0, 4, "nontree"),
+            (0, 0, "reverse"),
+        ]
+        assert list(edges_desc) == [
+            (0, 0, "forward"),
+            (0, 4, "forward"),
+            (4, 2, "forward"),
+            (2, 4, "nontree"),
+            (2, 1, "forward"),
+            (1, 3, "forward"),
+            (3, 1, "nontree"),
+            (3, 0, "nontree"),
+            (1, 3, "reverse"),
+            (1, 2, "nontree"),
+            (1, 0, "nontree"),
+            (2, 1, "reverse"),
+            (4, 2, "reverse"),
+            (4, 0, "nontree"),
+            (0, 4, "reverse"),
+            (0, 3, "nontree"),
+            (0, 1, "nontree"),
+            (0, 0, "reverse"),
+        ]
+
     def test_dfs_labeled_disconnected_edges(self):
         edges = list(nx.dfs_labeled_edges(self.D))
         forward = [(u, v) for (u, v, d) in edges if d == "forward"]
         assert forward == [(0, 0), (0, 1), (2, 2), (2, 3)]
         assert edges == [
             (0, 0, "forward"),
             (0, 1, "forward"),
```

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/tests/test_edgebfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/tests/test_edgebfs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/traversal/tests/test_edgedfs.py` & `networkx-3.3rc0/networkx/algorithms/traversal/tests/test_edgedfs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/branchings.py` & `networkx-3.3rc0/networkx/algorithms/tree/branchings.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,15 +24,14 @@
 #    author={Gabow, Harold N. and Galil, Zvi and Spencer, Thomas and Tarjan,
 #        Robert E.},
 #    pages={109-122},
 #    language={English}
 # }
 import string
 from dataclasses import dataclass, field
-from enum import Enum
 from operator import itemgetter
 from queue import PriorityQueue
 
 import networkx as nx
 from networkx.utils import py_random_state
 
 from .recognition import is_arborescence, is_branching
@@ -69,15 +68,15 @@
     return -weight
 
 
 def _max_weight(weight):
     return weight
 
 
-@nx._dispatch(edge_attrs={"attr": "default"})
+@nx._dispatchable(edge_attrs={"attr": "default"})
 def branching_weight(G, attr="weight", default=1):
     """
     Returns the total weight of a branching.
 
     You must access this function through the networkx.algorithms.tree module.
 
     Parameters
@@ -104,15 +103,15 @@
     11
 
     """
     return sum(edge[2].get(attr, default) for edge in G.edges(data=True))
 
 
 @py_random_state(4)
-@nx._dispatch(edge_attrs={"attr": "default"})
+@nx._dispatchable(edge_attrs={"attr": "default"}, returns_graph=True)
 def greedy_branching(G, attr="weight", default=1, kind="max", seed=None):
     """
     Returns a branching obtained through a greedy algorithm.
 
     This algorithm is wrong, and cannot give a proper optimal branching.
     However, we include it for pedagogical reasons, as it can be helpful to
     see what its outputs are.
@@ -320,15 +319,15 @@
 
         # Since we will be creating graphs with new nodes, we need to make
         # sure that our node names do not conflict with the real node names.
         self.template = random_string(seed=seed) + "_{0}"
 
         import warnings
 
-        msg = "Edmonds has been deprecated and will be removed in NetworkX 3.4. Please use the approiate minimum or maximum branching or arborescence function directly."
+        msg = "Edmonds has been deprecated and will be removed in NetworkX 3.4. Please use the appropriate minimum or maximum branching or arborescence function directly."
         warnings.warn(msg, DeprecationWarning)
 
     def _init(self, attr, default, kind, style, preserve_attrs, seed, partition):
         """
         So we need the code in _init and find_optimum to successfully run edmonds algorithm.
         Responsibilities of the _init function:
         - Check that the kind argument is in {min, max} or raise a NetworkXException.
@@ -466,15 +465,14 @@
 
         # This enormous while loop could use some refactoring...
 
         G, B = self.G, self.B
         D = set()
         nodes = iter(list(G.nodes()))
         attr = self._attr
-        G_pred = G.pred
 
         def desired_edge(v):
             """
             Find the edge directed toward v with maximal weight.
 
             If an edge partition exists in this graph, return the included edge
             if it exists and no not return any excluded edges. There can only
@@ -741,17 +739,18 @@
 
             # TODO: make this preserve the key.
             H.add_edge(u, v, **dd)
 
         return H
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"attr": "default", "partition": 0},
     preserve_edge_attrs="preserve_attrs",
+    returns_graph=True,
 )
 def maximum_branching(
     G,
     attr="weight",
     default=1,
     preserve_attrs=False,
     partition=None,
@@ -843,15 +842,15 @@
 
         edmonds_add_edge(G, G_edge_index, u, v, key, **d)
 
     level = 0  # Stores the number of contracted nodes
 
     # These are the buckets from the paper.
     #
-    # In the paper, G^i are modifed versions of the original graph.
+    # In the paper, G^i are modified versions of the original graph.
     # D^i and E^i are the nodes and edges of the maximal edges that are
     # consistent with G^i. In this implementation, D^i and E^i are stored
     # together as the graph B^i. We will have strictly more B^i then the
     # paper will have.
     #
     # Note that the data in graphs and branchings are tuples with the graph as
     # the first element and the edge index as the second.
@@ -926,15 +925,15 @@
                 max_weight = new_weight
                 edge = (u, v, key, new_weight, data)
 
         return edge, max_weight
 
     def edmonds_step_I2(v, desired_edge, level):
         """
-        Perfrom step I2 from Edmonds' paper
+        Perform step I2 from Edmonds' paper
 
         First, check if the last step I1 created a cycle. If it did not, do nothing.
         If it did, store the cycle for later reference and contract it.
 
         Parameters
         ----------
         v : node
@@ -1113,16 +1112,16 @@
     # Start with the branching edges in the last level.
     edges = set(branchings[level][1])
     while level > 0:
         level -= 1
 
         # The current level is i, and we start counting from 0.
         #
-        # We need the node at level i+1 that resuilts from merging a circuit
-        # at level i. basename_0 is the first merged node and this happends
+        # We need the node at level i+1 that results from merging a circuit
+        # at level i. basename_0 is the first merged node and this happens
         # at level 1. That is basename_0 is a node at level 1 that results
         # from merging a circuit at level 0.
 
         merged_node = new_node_base_name + str(level)
         circuit = circuits[level]
         isroot, edgekey = is_root(graphs[level + 1][0], merged_node, edges)
         edges.update(circuit)
@@ -1169,38 +1168,40 @@
     ###################
     ### END STEP I3 ###
     ###################
 
     return H
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"attr": "default", "partition": None},
     preserve_edge_attrs="preserve_attrs",
+    returns_graph=True,
 )
 def minimum_branching(
     G, attr="weight", default=1, preserve_attrs=False, partition=None
 ):
     for _, _, d in G.edges(data=True):
-        d[attr] = -d[attr]
+        d[attr] = -d.get(attr, default)
 
     B = maximum_branching(G, attr, default, preserve_attrs, partition)
 
     for _, _, d in G.edges(data=True):
-        d[attr] = -d[attr]
+        d[attr] = -d.get(attr, default)
 
     for _, _, d in B.edges(data=True):
-        d[attr] = -d[attr]
+        d[attr] = -d.get(attr, default)
 
     return B
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"attr": "default", "partition": None},
     preserve_edge_attrs="preserve_attrs",
+    returns_graph=True,
 )
 def minimal_branching(
     G, /, *, attr="weight", default=1, preserve_attrs=False, partition=None
 ):
     """
     Returns a minimal branching from `G`.
 
@@ -1229,42 +1230,43 @@
     Returns
     -------
     B : (multi)digraph-like
         A minimal branching.
     """
     max_weight = -INF
     min_weight = INF
-    for _, _, w in G.edges(data=attr):
+    for _, _, w in G.edges(data=attr, default=default):
         if w > max_weight:
             max_weight = w
         if w < min_weight:
             min_weight = w
 
     for _, _, d in G.edges(data=True):
         # Transform the weights so that the minimum weight is larger than
         # the difference between the max and min weights. This is important
         # in order to prevent the edge weights from becoming negative during
         # computation
-        d[attr] = max_weight + 1 + (max_weight - min_weight) - d[attr]
+        d[attr] = max_weight + 1 + (max_weight - min_weight) - d.get(attr, default)
 
     B = maximum_branching(G, attr, default, preserve_attrs, partition)
 
     # Reverse the weight transformations
     for _, _, d in G.edges(data=True):
-        d[attr] = max_weight + 1 + (max_weight - min_weight) - d[attr]
+        d[attr] = max_weight + 1 + (max_weight - min_weight) - d.get(attr, default)
 
     for _, _, d in B.edges(data=True):
-        d[attr] = max_weight + 1 + (max_weight - min_weight) - d[attr]
+        d[attr] = max_weight + 1 + (max_weight - min_weight) - d.get(attr, default)
 
     return B
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"attr": "default", "partition": None},
     preserve_edge_attrs="preserve_attrs",
+    returns_graph=True,
 )
 def maximum_spanning_arborescence(
     G, attr="weight", default=1, preserve_attrs=False, partition=None
 ):
     # In order to use the same algorithm is the maximum branching, we need to adjust
     # the weights of the graph. The branching algorithm can choose to not include an
     # edge if it doesn't help find a branching, mainly triggered by edges with negative
@@ -1273,40 +1275,41 @@
     # To prevent this from happening while trying to find a spanning arborescence, we
     # just have to tweak the edge weights so that they are all positive and cannot
     # become negative during the branching algorithm, find the maximum branching and
     # then return them to their original values.
 
     min_weight = INF
     max_weight = -INF
-    for _, _, w in G.edges(data=attr):
+    for _, _, w in G.edges(data=attr, default=default):
         if w < min_weight:
             min_weight = w
         if w > max_weight:
             max_weight = w
 
     for _, _, d in G.edges(data=True):
-        d[attr] = d[attr] - min_weight + 1 - (min_weight - max_weight)
+        d[attr] = d.get(attr, default) - min_weight + 1 - (min_weight - max_weight)
 
     B = maximum_branching(G, attr, default, preserve_attrs, partition)
 
     for _, _, d in G.edges(data=True):
-        d[attr] = d[attr] + min_weight - 1 + (min_weight - max_weight)
+        d[attr] = d.get(attr, default) + min_weight - 1 + (min_weight - max_weight)
 
     for _, _, d in B.edges(data=True):
-        d[attr] = d[attr] + min_weight - 1 + (min_weight - max_weight)
+        d[attr] = d.get(attr, default) + min_weight - 1 + (min_weight - max_weight)
 
     if not is_arborescence(B):
         raise nx.exception.NetworkXException("No maximum spanning arborescence in G.")
 
     return B
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"attr": "default", "partition": None},
     preserve_edge_attrs="preserve_attrs",
+    returns_graph=True,
 )
 def minimum_spanning_arborescence(
     G, attr="weight", default=1, preserve_attrs=False, partition=None
 ):
     B = minimal_branching(
         G,
         attr=attr,
@@ -1361,16 +1364,16 @@
 maximum_branching.__doc__ = docstring_branching.format(
     kind="maximum", style="branching"
 )
 
 minimum_branching.__doc__ = (
     docstring_branching.format(kind="minimum", style="branching")
     + """
-See Also 
--------- 
+See Also
+--------
     minimal_branching
 """
 )
 
 maximum_spanning_arborescence.__doc__ = docstring_arborescence.format(
     kind="maximum", style="spanning arborescence"
 )
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/coding.py` & `networkx-3.3rc0/networkx/algorithms/tree/coding.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,15 @@
     undirected graph with no cycles) but gets a non-tree graph as input
     instead.
 
     """
 
 
 @not_implemented_for("directed")
-@nx._dispatch(graphs="T")
+@nx._dispatchable(graphs="T")
 def to_nested_tuple(T, root, canonical_form=False):
     """Returns a nested tuple representation of the given tree.
 
     The nested tuple representation of a tree is defined
     recursively. The tree with one node and no edges is represented by
     the empty tuple, ``()``. A tree with ``k`` subtrees is represented
     by a tuple of length ``k`` in which each element is the nested tuple
@@ -124,15 +124,15 @@
         raise nx.NotATree("provided graph is not a tree")
     if root not in T:
         raise nx.NodeNotFound(f"Graph {T} contains no node {root}")
 
     return _make_tuple(T, root, None)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_nested_tuple(sequence, sensible_relabeling=False):
     """Returns the rooted tree corresponding to the given nested tuple.
 
     The nested tuple representation of a tree is defined
     recursively. The tree with one node and no edges is represented by
     the empty tuple, ``()``. A tree with ``k`` subtrees is represented
     by a tuple of length ``k`` in which each element is the nested tuple
@@ -209,15 +209,15 @@
         # We would like to use `copy=False`, but `relabel_nodes` doesn't
         # allow a relabel mapping that can't be topologically sorted.
         T = nx.relabel_nodes(T, labels)
     return T
 
 
 @not_implemented_for("directed")
-@nx._dispatch(graphs="T")
+@nx._dispatchable(graphs="T")
 def to_prufer_sequence(T):
     r"""Returns the Prüfer sequence of the given tree.
 
     A *Prüfer sequence* is a list of *n* - 2 numbers between 0 and
     *n* - 1, inclusive. The tree corresponding to a given Prüfer
     sequence can be recovered by repeatedly joining a node in the
     sequence with a node with the smallest potential degree according to
@@ -310,15 +310,15 @@
         if v < index and degree[v] == 1:
             u = v
         else:
             index = u = next(k for k in range(index + 1, n) if degree[k] == 1)
     return result
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_prufer_sequence(sequence):
     r"""Returns the tree corresponding to the given Prüfer sequence.
 
     A *Prüfer sequence* is a list of *n* - 2 numbers between 0 and
     *n* - 1, inclusive. The tree corresponding to a given Prüfer
     sequence can be recovered by repeatedly joining a node in the
     sequence with a node with the smallest potential degree according to
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/decomposition.py` & `networkx-3.3rc0/networkx/algorithms/tree/decomposition.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from networkx.algorithms import chordal_graph_cliques, complete_to_chordal_graph, moral
 from networkx.utils import not_implemented_for
 
 __all__ = ["junction_tree"]
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def junction_tree(G):
     r"""Returns a junction tree of a given graph.
 
     A junction tree (or clique tree) is constructed from a (un)directed graph G.
     The tree is constructed based on a moralized and triangulated version of G.
     The tree's nodes consist of maximal cliques and sepsets of the revised graph.
     The sepset of two cliques is the intersection of the nodes of these cliques,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/mst.py` & `networkx-3.3rc0/networkx/algorithms/tree/mst.py`

 * *Files 9% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 from networkx.utils import UnionFind, not_implemented_for, py_random_state
 
 __all__ = [
     "minimum_spanning_edges",
     "maximum_spanning_edges",
     "minimum_spanning_tree",
     "maximum_spanning_tree",
+    "number_of_spanning_trees",
     "random_spanning_tree",
     "partition_spanning_tree",
     "EdgePartition",
     "SpanningTreeIterator",
 ]
 
 
@@ -37,15 +38,15 @@
 
     OPEN = 0
     INCLUDED = 1
     EXCLUDED = 2
 
 
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight", preserve_edge_attrs="data")
+@nx._dispatchable(edge_attrs="weight", preserve_edge_attrs="data")
 def boruvka_mst_edges(
     G, minimum=True, weight="weight", keys=False, data=True, ignore_nan=False
 ):
     """Iterate over edges of a Borůvka's algorithm min/max spanning tree.
 
     Parameters
     ----------
@@ -134,15 +135,15 @@
                 if data:
                     yield u, v, d
                 else:
                     yield u, v
                 forest.union(u, v)
 
 
-@nx._dispatch(
+@nx._dispatchable(
     edge_attrs={"weight": None, "partition": None}, preserve_edge_attrs="data"
 )
 def kruskal_mst_edges(
     G, minimum, weight="weight", keys=True, data=True, ignore_nan=False, partition=None
 ):
     """
     Iterate over edge of a Kruskal's algorithm min/max spanning tree.
@@ -247,15 +248,15 @@
                 if data:
                     yield u, v, d
                 else:
                     yield u, v
                 subtrees.union(u, v)
 
 
-@nx._dispatch(edge_attrs="weight", preserve_edge_attrs="data")
+@nx._dispatchable(edge_attrs="weight", preserve_edge_attrs="data")
 def prim_mst_edges(G, minimum, weight="weight", keys=True, data=True, ignore_nan=False):
     """Iterate over edges of Prim's algorithm min/max spanning tree.
 
     Parameters
     ----------
     G : NetworkX Graph
         The graph holding the tree of interest.
@@ -363,15 +364,15 @@
     "borůvka": boruvka_mst_edges,
     "kruskal": kruskal_mst_edges,
     "prim": prim_mst_edges,
 }
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight", preserve_edge_attrs="data")
+@nx._dispatchable(edge_attrs="weight", preserve_edge_attrs="data")
 def minimum_spanning_edges(
     G, algorithm="kruskal", weight="weight", keys=True, data=True, ignore_nan=False
 ):
     """Generate edges in a minimum spanning forest of an undirected
     weighted graph.
 
     A minimum spanning tree is a subgraph of the graph (a tree)
@@ -458,15 +459,15 @@
 
     return algo(
         G, minimum=True, weight=weight, keys=keys, data=data, ignore_nan=ignore_nan
     )
 
 
 @not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight", preserve_edge_attrs="data")
+@nx._dispatchable(edge_attrs="weight", preserve_edge_attrs="data")
 def maximum_spanning_edges(
     G, algorithm="kruskal", weight="weight", keys=True, data=True, ignore_nan=False
 ):
     """Generate edges in a maximum spanning forest of an undirected
     weighted graph.
 
     A maximum spanning tree is a subgraph of the graph (a tree)
@@ -551,15 +552,15 @@
         raise ValueError(msg) from err
 
     return algo(
         G, minimum=False, weight=weight, keys=keys, data=data, ignore_nan=ignore_nan
     )
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def minimum_spanning_tree(G, weight="weight", algorithm="kruskal", ignore_nan=False):
     """Returns a minimum spanning tree or forest on an undirected graph `G`.
 
     Parameters
     ----------
     G : undirected graph
         An undirected graph. If `G` is connected, then the algorithm finds a
@@ -611,15 +612,15 @@
     T = G.__class__()  # Same graph class as G
     T.graph.update(G.graph)
     T.add_nodes_from(G.nodes.items())
     T.add_edges_from(edges)
     return T
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def partition_spanning_tree(
     G, minimum=True, weight="weight", partition="partition", ignore_nan=False
 ):
     """
     Find a spanning tree while respecting a partition of edges.
 
     Edges can be flagged as either `INCLUDED` which are required to be in the
@@ -675,15 +676,15 @@
     T = G.__class__()  # Same graph class as G
     T.graph.update(G.graph)
     T.add_nodes_from(G.nodes.items())
     T.add_edges_from(edges)
     return T
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def maximum_spanning_tree(G, weight="weight", algorithm="kruskal", ignore_nan=False):
     """Returns a maximum spanning tree or forest on an undirected graph `G`.
 
     Parameters
     ----------
     G : undirected graph
         An undirected graph. If `G` is connected, then the algorithm finds a
@@ -739,15 +740,15 @@
     T.graph.update(G.graph)
     T.add_nodes_from(G.nodes.items())
     T.add_edges_from(edges)
     return T
 
 
 @py_random_state(3)
-@nx._dispatch(preserve_edge_attrs=True)
+@nx._dispatchable(preserve_edge_attrs=True, returns_graph=True)
 def random_spanning_tree(G, weight=None, *, multiplicative=True, seed=None):
     """
     Sample a random spanning tree using the edges weights of `G`.
 
     This function supports two different methods for determining the
     probability of the graph. If ``multiplicative=True``, the probability
     is based on the product of edge weights, and if ``multiplicative=False``
@@ -893,30 +894,35 @@
         else:
             # There are two cases for the total spanning tree additive weight.
             # 1. There is one edge in the graph. Then the only spanning tree is
             #    that edge itself, which will have a total weight of that edge
             #    itself.
             if G.number_of_edges() == 1:
                 return G.edges(data=weight).__iter__().__next__()[2]
-            # 2. There are more than two edges in the graph. Then, we can find the
+            # 2. There are no edges or two or more edges in the graph. Then, we find the
             #    total weight of the spanning trees using the formula in the
-            #    reference paper: take the weight of that edge and multiple it by
-            #    the number of spanning trees which have to include that edge. This
+            #    reference paper: take the weight of each edge and multiply it by
+            #    the number of spanning trees which include that edge. This
             #    can be accomplished by contracting the edge and finding the
             #    multiplicative total spanning tree weight if the weight of each edge
             #    is assumed to be 1, which is conveniently built into networkx already,
-            #    by calling total_spanning_tree_weight with weight=None
+            #    by calling total_spanning_tree_weight with weight=None.
+            #    Note that with no edges the returned value is just zero.
             else:
                 total = 0
                 for u, v, w in G.edges(data=weight):
                     total += w * nx.total_spanning_tree_weight(
                         nx.contracted_edge(G, edge=(u, v), self_loops=False), None
                     )
                 return total
 
+    if G.number_of_nodes() < 2:
+        # no edges in the spanning tree
+        return nx.empty_graph(G.nodes)
+
     U = set()
     st_cached_value = 0
     V = set(G.edges())
     shuffled_edges = list(G.edges())
     seed.shuffle(shuffled_edges)
 
     for u, v in shuffled_edges:
@@ -1127,7 +1133,141 @@
     def _clear_partition(self, G):
         """
         Removes partition data from the graph
         """
         for u, v, d in G.edges(data=True):
             if self.partition_key in d:
                 del d[self.partition_key]
+
+
+@nx._dispatchable(edge_attrs="weight")
+def number_of_spanning_trees(G, *, root=None, weight=None):
+    """Returns the number of spanning trees in `G`.
+
+    A spanning tree for an undirected graph is a tree that connects
+    all nodes in the graph. For a directed graph, the analog of a
+    spanning tree is called a (spanning) arborescence. The arborescence
+    includes a unique directed path from the `root` node to each other node.
+    The graph must be weakly connected, and the root must be a node
+    that includes all nodes as successors [3]_. Note that to avoid
+    discussing sink-roots and reverse-arborescences, we have reversed
+    the edge orientation from [3]_ and use the in-degree laplacian.
+
+    This function (when `weight` is `None`) returns the number of
+    spanning trees for an undirected graph and the number of
+    arborescences from a single root node for a directed graph.
+    When `weight` is the name of an edge attribute which holds the
+    weight value of each edge, the function returns the sum over
+    all trees of the multiplicative weight of each tree. That is,
+    the weight of the tree is the product of its edge weights.
+
+    Kirchoff's Tree Matrix Theorem states that any cofactor of the
+    Laplacian matrix of a graph is the number of spanning trees in the
+    graph. (Here we use cofactors for a diagonal entry so that the
+    cofactor becomes the determinant of the matrix with one row
+    and its matching column removed.) For a weighted Laplacian matrix,
+    the cofactor is the sum across all spanning trees of the
+    multiplicative weight of each tree. That is, the weight of each
+    tree is the product of its edge weights. The theorem is also
+    known as Kirchhoff's theorem [1]_ and the Matrix-Tree theorem [2]_.
+
+    For directed graphs, a similar theorem (Tutte's Theorem) holds with
+    the cofactor chosen to be the one with row and column removed that
+    correspond to the root. The cofactor is the number of arborescences
+    with the specified node as root. And the weighted version gives the
+    sum of the arborescence weights with root `root`. The arborescence
+    weight is the product of its edge weights.
+
+    Parameters
+    ----------
+    G : NetworkX graph
+
+    root : node
+       A node in the directed graph `G` that has all nodes as descendants.
+       (This is ignored for undirected graphs.)
+
+    weight : string or None, optional (default=None)
+        The name of the edge attribute holding the edge weight.
+        If `None`, then each edge is assumed to have a weight of 1.
+
+    Returns
+    -------
+    Number
+        Undirected graphs:
+            The number of spanning trees of the graph `G`.
+            Or the sum of all spanning tree weights of the graph `G`
+            where the weight of a tree is the product of its edge weights.
+        Directed graphs:
+            The number of arborescences of `G` rooted at node `root`.
+            Or the sum of all arborescence weights of the graph `G` with
+            specified root where the weight of an arborescence is the product
+            of its edge weights.
+
+    Raises
+    ------
+    NetworkXPointlessConcept
+        If `G` does not contain any nodes.
+
+    NetworkXError
+        If the graph `G` is directed and the root node
+        is not specified or is not in G.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> round(nx.number_of_spanning_trees(G))
+    125
+
+    >>> G = nx.Graph()
+    >>> G.add_edge(1, 2, weight=2)
+    >>> G.add_edge(1, 3, weight=1)
+    >>> G.add_edge(2, 3, weight=1)
+    >>> round(nx.number_of_spanning_trees(G, weight="weight"))
+    5
+
+    Notes
+    -----
+    Self-loops are excluded. Multi-edges are contracted in one edge
+    equal to the sum of the weights.
+
+    References
+    ----------
+    .. [1] Wikipedia
+       "Kirchhoff's theorem."
+       https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem
+    .. [2] Kirchhoff, G. R.
+        Über die Auflösung der Gleichungen, auf welche man
+        bei der Untersuchung der linearen Vertheilung
+        Galvanischer Ströme geführt wird
+        Annalen der Physik und Chemie, vol. 72, pp. 497-508, 1847.
+    .. [3] Margoliash, J.
+        "Matrix-Tree Theorem for Directed Graphs"
+        https://www.math.uchicago.edu/~may/VIGRE/VIGRE2010/REUPapers/Margoliash.pdf
+    """
+    import numpy as np
+
+    if len(G) == 0:
+        raise nx.NetworkXPointlessConcept("Graph G must contain at least one node.")
+
+    # undirected G
+    if not nx.is_directed(G):
+        if not nx.is_connected(G):
+            return 0
+        G_laplacian = nx.laplacian_matrix(G, weight=weight).toarray()
+        return float(np.linalg.det(G_laplacian[1:, 1:]))
+
+    # directed G
+    if root is None:
+        raise nx.NetworkXError("Input `root` must be provided when G is directed")
+    if root not in G:
+        raise nx.NetworkXError("The node root is not in the graph G.")
+    if not nx.is_weakly_connected(G):
+        return 0
+
+    # Compute directed Laplacian matrix
+    nodelist = [root] + [n for n in G if n != root]
+    A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight)
+    D = np.diag(A.sum(axis=0))
+    G_laplacian = D - A
+
+    # Compute number of spanning trees
+    return float(np.linalg.det(G_laplacian[1:, 1:]))
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/operations.py` & `networkx-3.3rc0/networkx/algorithms/tree/operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,15 @@
         stacklevel=2,
     )
 
     return join_trees(rooted_trees, label_attribute=label_attribute)
 
 
 # Argument types don't match dispatching, but allow manual selection of backend
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def join_trees(rooted_trees, *, label_attribute=None, first_label=0):
     """Returns a new rooted tree made by joining `rooted_trees`
 
     Constructs a new tree by joining each tree in `rooted_trees`.
     A new root node is added and connected to each of the roots
     of the input trees. While copying the nodes from the trees,
     relabeling to integers occurs. If the `label_attribute` is provided,
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/recognition.py` & `networkx-3.3rc0/networkx/algorithms/tree/recognition.py`

 * *Files 0% similar despite different names*

```diff
@@ -75,15 +75,15 @@
 
 import networkx as nx
 
 __all__ = ["is_arborescence", "is_branching", "is_forest", "is_tree"]
 
 
 @nx.utils.not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_arborescence(G):
     """
     Returns True if `G` is an arborescence.
 
     An arborescence is a directed tree with maximum in-degree equal to 1.
 
     Parameters
@@ -115,15 +115,15 @@
     is_tree
 
     """
     return is_tree(G) and max(d for n, d in G.in_degree()) <= 1
 
 
 @nx.utils.not_implemented_for("undirected")
-@nx._dispatch
+@nx._dispatchable
 def is_branching(G):
     """
     Returns True if `G` is a branching.
 
     A branching is a directed forest with maximum in-degree equal to 1.
 
     Parameters
@@ -154,15 +154,15 @@
     --------
     is_forest
 
     """
     return is_forest(G) and max(d for n, d in G.in_degree()) <= 1
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_forest(G):
     """
     Returns True if `G` is a forest.
 
     A forest is a graph with no undirected cycles.
 
     For directed graphs, `G` is a forest if the underlying graph is a forest.
@@ -211,15 +211,15 @@
         components = (G.subgraph(c) for c in nx.weakly_connected_components(G))
     else:
         components = (G.subgraph(c) for c in nx.connected_components(G))
 
     return all(len(c) - 1 == c.number_of_edges() for c in components)
 
 
-@nx._dispatch
+@nx._dispatchable
 def is_tree(G):
     """
     Returns True if `G` is a tree.
 
     A tree is a connected graph with no undirected cycles.
 
     For directed graphs, `G` is a tree if the underlying graph is a tree. The
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_branchings.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_branchings.py`

 * *Files 2% similar despite different names*

```diff
@@ -626,7 +626,33 @@
         assert new_arborescence_weight >= arborescence_weight
         arborescence_weight = new_arborescence_weight
         for e in included_edges:
             assert e in B.edges
         for e in excluded_edges:
             assert e not in B.edges
     assert arborescence_count == 16
+
+
+def test_branchings_with_default_weights():
+    """
+    Tests that various brancing algorithms work on graphs without weights.
+    For more information, see issue #7279.
+    """
+    graph = nx.erdos_renyi_graph(10, p=0.2, directed=True, seed=123)
+
+    assert all(
+        "weight" not in d for (u, v, d) in graph.edges(data=True)
+    ), "test is for graphs without a weight attribute"
+
+    # Calling these functions will modify graph inplace to add weights
+    # copy the graph to avoid this.
+    nx.minimum_spanning_arborescence(graph.copy())
+    nx.maximum_spanning_arborescence(graph.copy())
+    nx.minimum_branching(graph.copy())
+    nx.maximum_branching(graph.copy())
+    nx.algorithms.tree.minimal_branching(graph.copy())
+    nx.algorithms.tree.branching_weight(graph.copy())
+    nx.algorithms.tree.greedy_branching(graph.copy())
+
+    assert all(
+        "weight" not in d for (u, v, d) in graph.edges(data=True)
+    ), "The above calls should not modify the initial graph in-place"
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_coding.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_coding.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_decomposition.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_decomposition.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_mst.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_mst.py`

 * *Files 15% similar despite different names*

```diff
@@ -702,7 +702,154 @@
     # H_a: The distribution of trees in tree_actual follows some other
     # distribution of spanning trees.
     _, p = stats.chisquare(list(tree_actual.values()), list(tree_expected.values()))
 
     # Assert that p is greater than the significance level so that we do not
     # reject the null hypothesis
     assert not p < 0.05
+
+
+def test_random_spanning_tree_empty_graph():
+    G = nx.Graph()
+    rst = nx.tree.random_spanning_tree(G)
+    assert len(rst.nodes) == 0
+    assert len(rst.edges) == 0
+
+
+def test_random_spanning_tree_single_node_graph():
+    G = nx.Graph()
+    G.add_node(0)
+    rst = nx.tree.random_spanning_tree(G)
+    assert len(rst.nodes) == 1
+    assert len(rst.edges) == 0
+
+
+def test_random_spanning_tree_single_node_loop():
+    G = nx.Graph()
+    G.add_node(0)
+    G.add_edge(0, 0)
+    rst = nx.tree.random_spanning_tree(G)
+    assert len(rst.nodes) == 1
+    assert len(rst.edges) == 0
+
+
+class TestNumberSpanningTrees:
+    @classmethod
+    def setup_class(cls):
+        global np
+        np = pytest.importorskip("numpy")
+
+    def test_nst_disconnected(self):
+        G = nx.empty_graph(2)
+        assert np.isclose(nx.number_of_spanning_trees(G), 0)
+
+    def test_nst_no_nodes(self):
+        G = nx.Graph()
+        with pytest.raises(nx.NetworkXPointlessConcept):
+            nx.number_of_spanning_trees(G)
+
+    def test_nst_weight(self):
+        G = nx.Graph()
+        G.add_edge(1, 2, weight=1)
+        G.add_edge(1, 3, weight=1)
+        G.add_edge(2, 3, weight=2)
+        # weights are ignored
+        assert np.isclose(nx.number_of_spanning_trees(G), 3)
+        # including weight
+        assert np.isclose(nx.number_of_spanning_trees(G, weight="weight"), 5)
+
+    def test_nst_negative_weight(self):
+        G = nx.Graph()
+        G.add_edge(1, 2, weight=1)
+        G.add_edge(1, 3, weight=-1)
+        G.add_edge(2, 3, weight=-2)
+        # weights are ignored
+        assert np.isclose(nx.number_of_spanning_trees(G), 3)
+        # including weight
+        assert np.isclose(nx.number_of_spanning_trees(G, weight="weight"), -1)
+
+    def test_nst_selfloop(self):
+        # self-loops are ignored
+        G = nx.complete_graph(3)
+        G.add_edge(1, 1)
+        assert np.isclose(nx.number_of_spanning_trees(G), 3)
+
+    def test_nst_multigraph(self):
+        G = nx.MultiGraph()
+        G.add_edge(1, 2)
+        G.add_edge(1, 2)
+        G.add_edge(1, 3)
+        G.add_edge(2, 3)
+        assert np.isclose(nx.number_of_spanning_trees(G), 5)
+
+    def test_nst_complete_graph(self):
+        # this is known as Cayley's formula
+        N = 5
+        G = nx.complete_graph(N)
+        assert np.isclose(nx.number_of_spanning_trees(G), N ** (N - 2))
+
+    def test_nst_path_graph(self):
+        G = nx.path_graph(5)
+        assert np.isclose(nx.number_of_spanning_trees(G), 1)
+
+    def test_nst_cycle_graph(self):
+        G = nx.cycle_graph(5)
+        assert np.isclose(nx.number_of_spanning_trees(G), 5)
+
+    def test_nst_directed_noroot(self):
+        G = nx.empty_graph(3, create_using=nx.MultiDiGraph)
+        with pytest.raises(nx.NetworkXError):
+            nx.number_of_spanning_trees(G)
+
+    def test_nst_directed_root_not_exist(self):
+        G = nx.empty_graph(3, create_using=nx.MultiDiGraph)
+        with pytest.raises(nx.NetworkXError):
+            nx.number_of_spanning_trees(G, root=42)
+
+    def test_nst_directed_not_weak_connected(self):
+        G = nx.DiGraph()
+        G.add_edge(1, 2)
+        G.add_edge(3, 4)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=1), 0)
+
+    def test_nst_directed_cycle_graph(self):
+        G = nx.DiGraph()
+        G = nx.cycle_graph(7, G)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=0), 1)
+
+    def test_nst_directed_complete_graph(self):
+        G = nx.DiGraph()
+        G = nx.complete_graph(7, G)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=0), 7**5)
+
+    def test_nst_directed_multi(self):
+        G = nx.MultiDiGraph()
+        G = nx.cycle_graph(3, G)
+        G.add_edge(1, 2)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=0), 2)
+
+    def test_nst_directed_selfloop(self):
+        G = nx.MultiDiGraph()
+        G = nx.cycle_graph(3, G)
+        G.add_edge(1, 1)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=0), 1)
+
+    def test_nst_directed_weak_connected(self):
+        G = nx.MultiDiGraph()
+        G = nx.cycle_graph(3, G)
+        G.remove_edge(1, 2)
+        assert np.isclose(nx.number_of_spanning_trees(G, root=0), 0)
+
+    def test_nst_directed_weighted(self):
+        # from root=1:
+        # arborescence 1: 1->2, 1->3, weight=2*1
+        # arborescence 2: 1->2, 2->3, weight=2*3
+        G = nx.DiGraph()
+        G.add_edge(1, 2, weight=2)
+        G.add_edge(1, 3, weight=1)
+        G.add_edge(2, 3, weight=3)
+        Nst = nx.number_of_spanning_trees(G, root=1, weight="weight")
+        assert np.isclose(Nst, 8)
+        Nst = nx.number_of_spanning_trees(G, root=2, weight="weight")
+        assert np.isclose(Nst, 0)
+        Nst = nx.number_of_spanning_trees(G, root=3, weight="weight")
+        assert np.isclose(Nst, 0)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_operations.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_operations.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/algorithms/tree/tests/test_recognition.py` & `networkx-3.3rc0/networkx/algorithms/tree/tests/test_recognition.py`

 * *Files 4% similar despite different names*

```diff
@@ -115,14 +115,20 @@
 def test_emptybranch():
     G = nx.DiGraph()
     G.add_nodes_from(range(10))
     assert nx.is_branching(G)
     assert not nx.is_arborescence(G)
 
 
+def test_is_branching_empty_graph_raises():
+    G = nx.DiGraph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="G has no nodes."):
+        nx.is_branching(G)
+
+
 def test_path():
     G = nx.DiGraph()
     nx.add_path(G, range(5))
     assert nx.is_branching(G)
     assert nx.is_arborescence(G)
 
 
@@ -156,7 +162,13 @@
 def test_notarborescence2():
     # Not an arborescence due to in-degree violation.
     G = nx.MultiDiGraph()
     nx.add_path(G, range(5))
     G.add_edge(6, 4)
     assert not nx.is_branching(G)
     assert not nx.is_arborescence(G)
+
+
+def test_is_arborescense_empty_graph_raises():
+    G = nx.DiGraph()
+    with pytest.raises(nx.NetworkXPointlessConcept, match="G has no nodes."):
+        nx.is_arborescence(G)
```

### Comparing `networkx-3.2rc0/networkx/algorithms/triads.py` & `networkx-3.3rc0/networkx/convert.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,565 +1,494 @@
-# See https://github.com/networkx/networkx/pull/1474
-# Copyright 2011 Reya Group <http://www.reyagroup.com>
-# Copyright 2011 Alex Levenson <alex@isnotinvain.com>
-# Copyright 2011 Diederik van Liere <diederik.vanliere@rotman.utoronto.ca>
-"""Functions for analyzing triads of a graph."""
+"""Functions to convert NetworkX graphs to and from other formats.
 
-from collections import defaultdict
-from itertools import combinations, permutations
+The preferred way of converting data to a NetworkX graph is through the
+graph constructor.  The constructor calls the to_networkx_graph() function
+which attempts to guess the input type and convert it automatically.
+
+Examples
+--------
+Create a graph with a single edge from a dictionary of dictionaries
+
+>>> d = {0: {1: 1}}  # dict-of-dicts single edge (0,1)
+>>> G = nx.Graph(d)
+
+See Also
+--------
+nx_agraph, nx_pydot
+"""
+import warnings
+from collections.abc import Collection, Generator, Iterator
 
 import networkx as nx
-from networkx.utils import not_implemented_for, py_random_state
 
 __all__ = [
-    "triadic_census",
-    "is_triad",
-    "all_triplets",
-    "all_triads",
-    "triads_by_type",
-    "triad_type",
-    "random_triad",
+    "to_networkx_graph",
+    "from_dict_of_dicts",
+    "to_dict_of_dicts",
+    "from_dict_of_lists",
+    "to_dict_of_lists",
+    "from_edgelist",
+    "to_edgelist",
 ]
 
-#: The integer codes representing each type of triad.
-#:
-#: Triads that are the same up to symmetry have the same code.
-TRICODES = (
-    1,
-    2,
-    2,
-    3,
-    2,
-    4,
-    6,
-    8,
-    2,
-    6,
-    5,
-    7,
-    3,
-    8,
-    7,
-    11,
-    2,
-    6,
-    4,
-    8,
-    5,
-    9,
-    9,
-    13,
-    6,
-    10,
-    9,
-    14,
-    7,
-    14,
-    12,
-    15,
-    2,
-    5,
-    6,
-    7,
-    6,
-    9,
-    10,
-    14,
-    4,
-    9,
-    9,
-    12,
-    8,
-    13,
-    14,
-    15,
-    3,
-    7,
-    8,
-    11,
-    7,
-    12,
-    14,
-    15,
-    8,
-    14,
-    13,
-    15,
-    11,
-    15,
-    15,
-    16,
-)
-
-#: The names of each type of triad. The order of the elements is
-#: important: it corresponds to the tricodes given in :data:`TRICODES`.
-TRIAD_NAMES = (
-    "003",
-    "012",
-    "102",
-    "021D",
-    "021U",
-    "021C",
-    "111D",
-    "111U",
-    "030T",
-    "030C",
-    "201",
-    "120D",
-    "120U",
-    "120C",
-    "210",
-    "300",
-)
-
-
-#: A dictionary mapping triad code to triad name.
-TRICODE_TO_NAME = {i: TRIAD_NAMES[code - 1] for i, code in enumerate(TRICODES)}
-
-
-def _tricode(G, v, u, w):
-    """Returns the integer code of the given triad.
-
-    This is some fancy magic that comes from Batagelj and Mrvar's paper. It
-    treats each edge joining a pair of `v`, `u`, and `w` as a bit in
-    the binary representation of an integer.
 
-    """
-    combos = ((v, u, 1), (u, v, 2), (v, w, 4), (w, v, 8), (u, w, 16), (w, u, 32))
-    return sum(x for u, v, x in combos if v in G[u])
-
-
-@not_implemented_for("undirected")
-@nx._dispatch
-def triadic_census(G, nodelist=None):
-    """Determines the triadic census of a directed graph.
-
-    The triadic census is a count of how many of the 16 possible types of
-    triads are present in a directed graph. If a list of nodes is passed, then
-    only those triads are taken into account which have elements of nodelist in them.
-
-    Parameters
-    ----------
-    G : digraph
-       A NetworkX DiGraph
-    nodelist : list
-        List of nodes for which you want to calculate triadic census
-
-    Returns
-    -------
-    census : dict
-       Dictionary with triad type as keys and number of occurrences as values.
+def to_networkx_graph(data, create_using=None, multigraph_input=False):
+    """Make a NetworkX graph from a known data structure.
 
-    Examples
-    --------
-    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1), (3, 4), (4, 1), (4, 2)])
-    >>> triadic_census = nx.triadic_census(G)
-    >>> for key, value in triadic_census.items():
-    ...     print(f"{key}: {value}")
-    ...
-    003: 0
-    012: 0
-    102: 0
-    021D: 0
-    021U: 0
-    021C: 0
-    111D: 0
-    111U: 0
-    030T: 2
-    030C: 2
-    201: 0
-    120D: 0
-    120U: 0
-    120C: 0
-    210: 0
-    300: 0
+    The preferred way to call this is automatically
+    from the class constructor
 
-    Notes
-    -----
-    This algorithm has complexity $O(m)$ where $m$ is the number of edges in
-    the graph.
+    >>> d = {0: {1: {"weight": 1}}}  # dict-of-dicts single edge (0,1)
+    >>> G = nx.Graph(d)
 
-    Raises
-    ------
-    ValueError
-        If `nodelist` contains duplicate nodes or nodes not in `G`.
-        If you want to ignore this you can preprocess with `set(nodelist) & G.nodes`
+    instead of the equivalent
 
-    See also
-    --------
-    triad_graph
+    >>> G = nx.from_dict_of_dicts(d)
 
-    References
+    Parameters
     ----------
-    .. [1] Vladimir Batagelj and Andrej Mrvar, A subquadratic triad census
-        algorithm for large sparse networks with small maximum degree,
-        University of Ljubljana,
-        http://vlado.fmf.uni-lj.si/pub/networks/doc/triads/triads.pdf
+    data : object to be converted
+
+        Current known types are:
+         any NetworkX graph
+         dict-of-dicts
+         dict-of-lists
+         container (e.g. set, list, tuple) of edges
+         iterator (e.g. itertools.chain) that produces edges
+         generator of edges
+         Pandas DataFrame (row per edge)
+         2D numpy array
+         scipy sparse array
+         pygraphviz agraph
+
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+        Graph type to create. If graph instance, then cleared before populated.
+
+    multigraph_input : bool (default False)
+        If True and  data is a dict_of_dicts,
+        try to create a multigraph assuming dict_of_dict_of_lists.
+        If data and create_using are both multigraphs then create
+        a multigraph from a multigraph.
 
     """
-    nodeset = set(G.nbunch_iter(nodelist))
-    if nodelist is not None and len(nodelist) != len(nodeset):
-        raise ValueError("nodelist includes duplicate nodes or nodes not in G")
-
-    N = len(G)
-    Nnot = N - len(nodeset)  # can signal special counting for subset of nodes
-
-    # create an ordering of nodes with nodeset nodes first
-    m = {n: i for i, n in enumerate(nodeset)}
-    if Nnot:
-        # add non-nodeset nodes later in the ordering
-        not_nodeset = G.nodes - nodeset
-        m.update((n, i + N) for i, n in enumerate(not_nodeset))
-
-    # build all_neighbor dicts for easy counting
-    # After Python 3.8 can leave off these keys(). Speedup also using G._pred
-    # nbrs = {n: G._pred[n].keys() | G._succ[n].keys() for n in G}
-    nbrs = {n: G.pred[n].keys() | G.succ[n].keys() for n in G}
-    dbl_nbrs = {n: G.pred[n].keys() & G.succ[n].keys() for n in G}
-
-    if Nnot:
-        sgl_nbrs = {n: G.pred[n].keys() ^ G.succ[n].keys() for n in not_nodeset}
-        # find number of edges not incident to nodes in nodeset
-        sgl = sum(1 for n in not_nodeset for nbr in sgl_nbrs[n] if nbr not in nodeset)
-        sgl_edges_outside = sgl // 2
-        dbl = sum(1 for n in not_nodeset for nbr in dbl_nbrs[n] if nbr not in nodeset)
-        dbl_edges_outside = dbl // 2
-
-    # Initialize the count for each triad to be zero.
-    census = {name: 0 for name in TRIAD_NAMES}
-    # Main loop over nodes
-    for v in nodeset:
-        vnbrs = nbrs[v]
-        dbl_vnbrs = dbl_nbrs[v]
-        if Nnot:
-            # set up counts of edges attached to v.
-            sgl_unbrs_bdy = sgl_unbrs_out = dbl_unbrs_bdy = dbl_unbrs_out = 0
-        for u in vnbrs:
-            if m[u] <= m[v]:
-                continue
-            unbrs = nbrs[u]
-            neighbors = (vnbrs | unbrs) - {u, v}
-            # Count connected triads.
-            for w in neighbors:
-                if m[u] < m[w] or (m[v] < m[w] < m[u] and v not in nbrs[w]):
-                    code = _tricode(G, v, u, w)
-                    census[TRICODE_TO_NAME[code]] += 1
-
-            # Use a formula for dyadic triads with edge incident to v
-            if u in dbl_vnbrs:
-                census["102"] += N - len(neighbors) - 2
+    # NX graph
+    if hasattr(data, "adj"):
+        try:
+            result = from_dict_of_dicts(
+                data.adj,
+                create_using=create_using,
+                multigraph_input=data.is_multigraph(),
+            )
+            # data.graph should be dict-like
+            result.graph.update(data.graph)
+            # data.nodes should be dict-like
+            # result.add_node_from(data.nodes.items()) possible but
+            # for custom node_attr_dict_factory which may be hashable
+            # will be unexpected behavior
+            for n, dd in data.nodes.items():
+                result._node[n].update(dd)
+            return result
+        except Exception as err:
+            raise nx.NetworkXError("Input is not a correct NetworkX graph.") from err
+
+    # pygraphviz  agraph
+    if hasattr(data, "is_strict"):
+        try:
+            return nx.nx_agraph.from_agraph(data, create_using=create_using)
+        except Exception as err:
+            raise nx.NetworkXError("Input is not a correct pygraphviz graph.") from err
+
+    # dict of dicts/lists
+    if isinstance(data, dict):
+        try:
+            return from_dict_of_dicts(
+                data, create_using=create_using, multigraph_input=multigraph_input
+            )
+        except Exception as err1:
+            if multigraph_input is True:
+                raise nx.NetworkXError(
+                    f"converting multigraph_input raised:\n{type(err1)}: {err1}"
+                )
+            try:
+                return from_dict_of_lists(data, create_using=create_using)
+            except Exception as err2:
+                raise TypeError("Input is not known type.") from err2
+
+    # Pandas DataFrame
+    try:
+        import pandas as pd
+
+        if isinstance(data, pd.DataFrame):
+            if data.shape[0] == data.shape[1]:
+                try:
+                    return nx.from_pandas_adjacency(data, create_using=create_using)
+                except Exception as err:
+                    msg = "Input is not a correct Pandas DataFrame adjacency matrix."
+                    raise nx.NetworkXError(msg) from err
             else:
-                census["012"] += N - len(neighbors) - 2
-
-            # Count edges attached to v. Subtract later to get triads with v isolated
-            # _out are (u,unbr) for unbrs outside boundary of nodeset
-            # _bdy are (u,unbr) for unbrs on boundary of nodeset (get double counted)
-            if Nnot and u not in nodeset:
-                sgl_unbrs = sgl_nbrs[u]
-                sgl_unbrs_bdy += len(sgl_unbrs & vnbrs - nodeset)
-                sgl_unbrs_out += len(sgl_unbrs - vnbrs - nodeset)
-                dbl_unbrs = dbl_nbrs[u]
-                dbl_unbrs_bdy += len(dbl_unbrs & vnbrs - nodeset)
-                dbl_unbrs_out += len(dbl_unbrs - vnbrs - nodeset)
-        # if nodeset == G.nodes, skip this b/c we will find the edge later.
-        if Nnot:
-            # Count edges outside nodeset not connected with v (v isolated triads)
-            census["012"] += sgl_edges_outside - (sgl_unbrs_out + sgl_unbrs_bdy // 2)
-            census["102"] += dbl_edges_outside - (dbl_unbrs_out + dbl_unbrs_bdy // 2)
-
-    # calculate null triads: "003"
-    # null triads = total number of possible triads - all found triads
-    total_triangles = (N * (N - 1) * (N - 2)) // 6
-    triangles_without_nodeset = (Nnot * (Nnot - 1) * (Nnot - 2)) // 6
-    total_census = total_triangles - triangles_without_nodeset
-    census["003"] = total_census - sum(census.values())
-
-    return census
-
-
-@nx._dispatch
-def is_triad(G):
-    """Returns True if the graph G is a triad, else False.
+                try:
+                    return nx.from_pandas_edgelist(
+                        data, edge_attr=True, create_using=create_using
+                    )
+                except Exception as err:
+                    msg = "Input is not a correct Pandas DataFrame edge-list."
+                    raise nx.NetworkXError(msg) from err
+    except ImportError:
+        warnings.warn("pandas not found, skipping conversion test.", ImportWarning)
+
+    # numpy array
+    try:
+        import numpy as np
+
+        if isinstance(data, np.ndarray):
+            try:
+                return nx.from_numpy_array(data, create_using=create_using)
+            except Exception as err:
+                raise nx.NetworkXError(
+                    f"Failed to interpret array as an adjacency matrix."
+                ) from err
+    except ImportError:
+        warnings.warn("numpy not found, skipping conversion test.", ImportWarning)
+
+    # scipy sparse array - any format
+    try:
+        import scipy
+
+        if hasattr(data, "format"):
+            try:
+                return nx.from_scipy_sparse_array(data, create_using=create_using)
+            except Exception as err:
+                raise nx.NetworkXError(
+                    "Input is not a correct scipy sparse array type."
+                ) from err
+    except ImportError:
+        warnings.warn("scipy not found, skipping conversion test.", ImportWarning)
+
+    # Note: most general check - should remain last in order of execution
+    # Includes containers (e.g. list, set, dict, etc.), generators, and
+    # iterators (e.g. itertools.chain) of edges
+
+    if isinstance(data, Collection | Generator | Iterator):
+        try:
+            return from_edgelist(data, create_using=create_using)
+        except Exception as err:
+            raise nx.NetworkXError("Input is not a valid edge list") from err
+
+    raise nx.NetworkXError("Input is not a known data type for conversion.")
+
+
+@nx._dispatchable
+def to_dict_of_lists(G, nodelist=None):
+    """Returns adjacency representation of graph as a dictionary of lists.
 
     Parameters
     ----------
     G : graph
-       A NetworkX Graph
+       A NetworkX graph
 
-    Returns
-    -------
-    istriad : boolean
-       Whether G is a valid triad
+    nodelist : list
+       Use only nodes specified in nodelist
+
+    Notes
+    -----
+    Completely ignores edge data for MultiGraph and MultiDiGraph.
 
-    Examples
-    --------
-    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1)])
-    >>> nx.is_triad(G)
-    True
-    >>> G.add_edge(0, 1)
-    >>> nx.is_triad(G)
-    False
     """
-    if isinstance(G, nx.Graph):
-        if G.order() == 3 and nx.is_directed(G):
-            if not any((n, n) in G.edges() for n in G.nodes()):
-                return True
-    return False
+    if nodelist is None:
+        nodelist = G
+
+    d = {}
+    for n in nodelist:
+        d[n] = [nbr for nbr in G.neighbors(n) if nbr in nodelist]
+    return d
 
 
-@not_implemented_for("undirected")
-@nx._dispatch
-def all_triplets(G):
-    """Returns a generator of all possible sets of 3 nodes in a DiGraph.
+@nx._dispatchable(graphs=None, returns_graph=True)
+def from_dict_of_lists(d, create_using=None):
+    """Returns a graph from a dictionary of lists.
 
     Parameters
     ----------
-    G : digraph
-       A NetworkX DiGraph
+    d : dictionary of lists
+      A dictionary of lists adjacency representation.
 
-    Returns
-    -------
-    triplets : generator of 3-tuples
-       Generator of tuples of 3 nodes
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+        Graph type to create. If graph instance, then cleared before populated.
 
     Examples
     --------
-    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 4)])
-    >>> list(nx.all_triplets(G))
-    [(1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4)]
+    >>> dol = {0: [1]}  # single edge (0,1)
+    >>> G = nx.from_dict_of_lists(dol)
+
+    or
+
+    >>> G = nx.Graph(dol)  # use Graph constructor
 
     """
-    triplets = combinations(G.nodes(), 3)
-    return triplets
+    G = nx.empty_graph(0, create_using)
+    G.add_nodes_from(d)
+    if G.is_multigraph() and not G.is_directed():
+        # a dict_of_lists can't show multiedges.  BUT for undirected graphs,
+        # each edge shows up twice in the dict_of_lists.
+        # So we need to treat this case separately.
+        seen = {}
+        for node, nbrlist in d.items():
+            for nbr in nbrlist:
+                if nbr not in seen:
+                    G.add_edge(node, nbr)
+            seen[node] = 1  # don't allow reverse edge to show up
+    else:
+        G.add_edges_from(
+            ((node, nbr) for node, nbrlist in d.items() for nbr in nbrlist)
+        )
+    return G
 
 
-@not_implemented_for("undirected")
-@nx._dispatch
-def all_triads(G):
-    """A generator of all possible triads in G.
+def to_dict_of_dicts(G, nodelist=None, edge_data=None):
+    """Returns adjacency representation of graph as a dictionary of dictionaries.
 
     Parameters
     ----------
-    G : digraph
-       A NetworkX DiGraph
+    G : graph
+       A NetworkX graph
+
+    nodelist : list
+       Use only nodes specified in nodelist
+
+    edge_data : scalar, optional
+       If provided, the value of the dictionary will be set to `edge_data` for
+       all edges. Usual values could be `1` or `True`. If `edge_data` is
+       `None` (the default), the edgedata in `G` is used, resulting in a
+       dict-of-dict-of-dicts. If `G` is a MultiGraph, the result will be a
+       dict-of-dict-of-dict-of-dicts. See Notes for an approach to customize
+       handling edge data. `edge_data` should *not* be a container.
 
     Returns
     -------
-    all_triads : generator of DiGraphs
-       Generator of triads (order-3 DiGraphs)
+    dod : dict
+       A nested dictionary representation of `G`. Note that the level of
+       nesting depends on the type of `G` and the value of `edge_data`
+       (see Examples).
 
-    Examples
+    See Also
     --------
-    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1), (3, 4), (4, 1), (4, 2)])
-    >>> for triad in nx.all_triads(G):
-    ...     print(triad.edges)
-    [(1, 2), (2, 3), (3, 1)]
-    [(1, 2), (4, 1), (4, 2)]
-    [(3, 1), (3, 4), (4, 1)]
-    [(2, 3), (3, 4), (4, 2)]
+    from_dict_of_dicts, to_dict_of_lists
 
-    """
-    triplets = combinations(G.nodes(), 3)
-    for triplet in triplets:
-        yield G.subgraph(triplet).copy()
-
-
-@not_implemented_for("undirected")
-@nx._dispatch
-def triads_by_type(G):
-    """Returns a list of all triads for each triad type in a directed graph.
-    There are exactly 16 different types of triads possible. Suppose 1, 2, 3 are three
-    nodes, they will be classified as a particular triad type if their connections
-    are as follows:
-
-    - 003: 1, 2, 3
-    - 012: 1 -> 2, 3
-    - 102: 1 <-> 2, 3
-    - 021D: 1 <- 2 -> 3
-    - 021U: 1 -> 2 <- 3
-    - 021C: 1 -> 2 -> 3
-    - 111D: 1 <-> 2 <- 3
-    - 111U: 1 <-> 2 -> 3
-    - 030T: 1 -> 2 -> 3, 1 -> 3
-    - 030C: 1 <- 2 <- 3, 1 -> 3
-    - 201: 1 <-> 2 <-> 3
-    - 120D: 1 <- 2 -> 3, 1 <-> 3
-    - 120U: 1 -> 2 <- 3, 1 <-> 3
-    - 120C: 1 -> 2 -> 3, 1 <-> 3
-    - 210: 1 -> 2 <-> 3, 1 <-> 3
-    - 300: 1 <-> 2 <-> 3, 1 <-> 3
+    Notes
+    -----
+    For a more custom approach to handling edge data, try::
 
-    Refer to the :doc:`example gallery </auto_examples/graph/plot_triad_types>`
-    for visual examples of the triad types.
+        dod = {
+            n: {nbr: custom(n, nbr, dd) for nbr, dd in nbrdict.items()}
+            for n, nbrdict in G.adj.items()
+        }
+
+    where `custom` returns the desired edge data for each edge between `n` and
+    `nbr`, given existing edge data `dd`.
+
+    Examples
+    --------
+    >>> G = nx.path_graph(3)
+    >>> nx.to_dict_of_dicts(G)
+    {0: {1: {}}, 1: {0: {}, 2: {}}, 2: {1: {}}}
+
+    Edge data is preserved by default (``edge_data=None``), resulting
+    in dict-of-dict-of-dicts where the innermost dictionary contains the
+    edge data:
+
+    >>> G = nx.Graph()
+    >>> G.add_edges_from(
+    ...     [
+    ...         (0, 1, {"weight": 1.0}),
+    ...         (1, 2, {"weight": 2.0}),
+    ...         (2, 0, {"weight": 1.0}),
+    ...     ]
+    ... )
+    >>> d = nx.to_dict_of_dicts(G)
+    >>> d  # doctest: +SKIP
+    {0: {1: {'weight': 1.0}, 2: {'weight': 1.0}},
+     1: {0: {'weight': 1.0}, 2: {'weight': 2.0}},
+     2: {1: {'weight': 2.0}, 0: {'weight': 1.0}}}
+    >>> d[1][2]["weight"]
+    2.0
+
+    If `edge_data` is not `None`, edge data in the original graph (if any) is
+    replaced:
+
+    >>> d = nx.to_dict_of_dicts(G, edge_data=1)
+    >>> d
+    {0: {1: 1, 2: 1}, 1: {0: 1, 2: 1}, 2: {1: 1, 0: 1}}
+    >>> d[1][2]
+    1
+
+    This also applies to MultiGraphs: edge data is preserved by default:
+
+    >>> G = nx.MultiGraph()
+    >>> G.add_edge(0, 1, key="a", weight=1.0)
+    'a'
+    >>> G.add_edge(0, 1, key="b", weight=5.0)
+    'b'
+    >>> d = nx.to_dict_of_dicts(G)
+    >>> d  # doctest: +SKIP
+    {0: {1: {'a': {'weight': 1.0}, 'b': {'weight': 5.0}}},
+     1: {0: {'a': {'weight': 1.0}, 'b': {'weight': 5.0}}}}
+    >>> d[0][1]["b"]["weight"]
+    5.0
+
+    But multi edge data is lost if `edge_data` is not `None`:
+
+    >>> d = nx.to_dict_of_dicts(G, edge_data=10)
+    >>> d
+    {0: {1: 10}, 1: {0: 10}}
+    """
+    dod = {}
+    if nodelist is None:
+        if edge_data is None:
+            for u, nbrdict in G.adjacency():
+                dod[u] = nbrdict.copy()
+        else:  # edge_data is not None
+            for u, nbrdict in G.adjacency():
+                dod[u] = dod.fromkeys(nbrdict, edge_data)
+    else:  # nodelist is not None
+        if edge_data is None:
+            for u in nodelist:
+                dod[u] = {}
+                for v, data in ((v, data) for v, data in G[u].items() if v in nodelist):
+                    dod[u][v] = data
+        else:  # nodelist and edge_data are not None
+            for u in nodelist:
+                dod[u] = {}
+                for v in (v for v in G[u] if v in nodelist):
+                    dod[u][v] = edge_data
+    return dod
+
+
+@nx._dispatchable(graphs=None, returns_graph=True)
+def from_dict_of_dicts(d, create_using=None, multigraph_input=False):
+    """Returns a graph from a dictionary of dictionaries.
 
     Parameters
     ----------
-    G : digraph
-       A NetworkX DiGraph
+    d : dictionary of dictionaries
+      A dictionary of dictionaries adjacency representation.
 
-    Returns
-    -------
-    tri_by_type : dict
-       Dictionary with triad types as keys and lists of triads as values.
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+        Graph type to create. If graph instance, then cleared before populated.
+
+    multigraph_input : bool (default False)
+       When True, the dict `d` is assumed
+       to be a dict-of-dict-of-dict-of-dict structure keyed by
+       node to neighbor to edge keys to edge data for multi-edges.
+       Otherwise this routine assumes dict-of-dict-of-dict keyed by
+       node to neighbor to edge data.
 
     Examples
     --------
-    >>> G = nx.DiGraph([(1, 2), (1, 3), (2, 3), (3, 1), (5, 6), (5, 4), (6, 7)])
-    >>> dict = nx.triads_by_type(G)
-    >>> dict['120C'][0].edges()
-    OutEdgeView([(1, 2), (1, 3), (2, 3), (3, 1)])
-    >>> dict['012'][0].edges()
-    OutEdgeView([(1, 2)])
+    >>> dod = {0: {1: {"weight": 1}}}  # single edge (0,1)
+    >>> G = nx.from_dict_of_dicts(dod)
 
-    References
-    ----------
-    .. [1] Snijders, T. (2012). "Transitivity and triads." University of
-        Oxford.
-        https://web.archive.org/web/20170830032057/http://www.stats.ox.ac.uk/~snijders/Trans_Triads_ha.pdf
-    """
-    # num_triads = o * (o - 1) * (o - 2) // 6
-    # if num_triads > TRIAD_LIMIT: print(WARNING)
-    all_tri = all_triads(G)
-    tri_by_type = defaultdict(list)
-    for triad in all_tri:
-        name = triad_type(triad)
-        tri_by_type[name].append(triad)
-    return tri_by_type
+    or
 
+    >>> G = nx.Graph(dod)  # use Graph constructor
 
-@not_implemented_for("undirected")
-@nx._dispatch
-def triad_type(G):
-    """Returns the sociological triad type for a triad.
+    """
+    G = nx.empty_graph(0, create_using)
+    G.add_nodes_from(d)
+    # does dict d represent a MultiGraph or MultiDiGraph?
+    if multigraph_input:
+        if G.is_directed():
+            if G.is_multigraph():
+                G.add_edges_from(
+                    (u, v, key, data)
+                    for u, nbrs in d.items()
+                    for v, datadict in nbrs.items()
+                    for key, data in datadict.items()
+                )
+            else:
+                G.add_edges_from(
+                    (u, v, data)
+                    for u, nbrs in d.items()
+                    for v, datadict in nbrs.items()
+                    for key, data in datadict.items()
+                )
+        else:  # Undirected
+            if G.is_multigraph():
+                seen = set()  # don't add both directions of undirected graph
+                for u, nbrs in d.items():
+                    for v, datadict in nbrs.items():
+                        if (u, v) not in seen:
+                            G.add_edges_from(
+                                (u, v, key, data) for key, data in datadict.items()
+                            )
+                            seen.add((v, u))
+            else:
+                seen = set()  # don't add both directions of undirected graph
+                for u, nbrs in d.items():
+                    for v, datadict in nbrs.items():
+                        if (u, v) not in seen:
+                            G.add_edges_from(
+                                (u, v, data) for key, data in datadict.items()
+                            )
+                            seen.add((v, u))
+
+    else:  # not a multigraph to multigraph transfer
+        if G.is_multigraph() and not G.is_directed():
+            # d can have both representations u-v, v-u in dict.  Only add one.
+            # We don't need this check for digraphs since we add both directions,
+            # or for Graph() since it is done implicitly (parallel edges not allowed)
+            seen = set()
+            for u, nbrs in d.items():
+                for v, data in nbrs.items():
+                    if (u, v) not in seen:
+                        G.add_edge(u, v, key=0)
+                        G[u][v][0].update(data)
+                    seen.add((v, u))
+        else:
+            G.add_edges_from(
+                ((u, v, data) for u, nbrs in d.items() for v, data in nbrs.items())
+            )
+    return G
+
+
+@nx._dispatchable(preserve_edge_attrs=True)
+def to_edgelist(G, nodelist=None):
+    """Returns a list of edges in the graph.
 
     Parameters
     ----------
-    G : digraph
-       A NetworkX DiGraph with 3 nodes
+    G : graph
+       A NetworkX graph
 
-    Returns
-    -------
-    triad_type : str
-       A string identifying the triad type
+    nodelist : list
+       Use only nodes specified in nodelist
 
-    Examples
-    --------
-    >>> G = nx.DiGraph([(1, 2), (2, 3), (3, 1)])
-    >>> nx.triad_type(G)
-    '030C'
-    >>> G.add_edge(1, 3)
-    >>> nx.triad_type(G)
-    '120C'
+    """
+    if nodelist is None:
+        return G.edges(data=True)
+    return G.edges(nodelist, data=True)
 
-    Notes
-    -----
-    There can be 6 unique edges in a triad (order-3 DiGraph) (so 2^^6=64 unique
-    triads given 3 nodes). These 64 triads each display exactly 1 of 16
-    topologies of triads (topologies can be permuted). These topologies are
-    identified by the following notation:
-
-    {m}{a}{n}{type} (for example: 111D, 210, 102)
-
-    Here:
-
-    {m}     = number of mutual ties (takes 0, 1, 2, 3); a mutual tie is (0,1)
-              AND (1,0)
-    {a}     = number of asymmetric ties (takes 0, 1, 2, 3); an asymmetric tie
-              is (0,1) BUT NOT (1,0) or vice versa
-    {n}     = number of null ties (takes 0, 1, 2, 3); a null tie is NEITHER
-              (0,1) NOR (1,0)
-    {type}  = a letter (takes U, D, C, T) corresponding to up, down, cyclical
-              and transitive. This is only used for topologies that can have
-              more than one form (eg: 021D and 021U).
 
-    References
-    ----------
-    .. [1] Snijders, T. (2012). "Transitivity and triads." University of
-        Oxford.
-        https://web.archive.org/web/20170830032057/http://www.stats.ox.ac.uk/~snijders/Trans_Triads_ha.pdf
-    """
-    if not is_triad(G):
-        raise nx.NetworkXAlgorithmError("G is not a triad (order-3 DiGraph)")
-    num_edges = len(G.edges())
-    if num_edges == 0:
-        return "003"
-    elif num_edges == 1:
-        return "012"
-    elif num_edges == 2:
-        e1, e2 = G.edges()
-        if set(e1) == set(e2):
-            return "102"
-        elif e1[0] == e2[0]:
-            return "021D"
-        elif e1[1] == e2[1]:
-            return "021U"
-        elif e1[1] == e2[0] or e2[1] == e1[0]:
-            return "021C"
-    elif num_edges == 3:
-        for e1, e2, e3 in permutations(G.edges(), 3):
-            if set(e1) == set(e2):
-                if e3[0] in e1:
-                    return "111U"
-                # e3[1] in e1:
-                return "111D"
-            elif set(e1).symmetric_difference(set(e2)) == set(e3):
-                if {e1[0], e2[0], e3[0]} == {e1[0], e2[0], e3[0]} == set(G.nodes()):
-                    return "030C"
-                # e3 == (e1[0], e2[1]) and e2 == (e1[1], e3[1]):
-                return "030T"
-    elif num_edges == 4:
-        for e1, e2, e3, e4 in permutations(G.edges(), 4):
-            if set(e1) == set(e2):
-                # identify pair of symmetric edges (which necessarily exists)
-                if set(e3) == set(e4):
-                    return "201"
-                if {e3[0]} == {e4[0]} == set(e3).intersection(set(e4)):
-                    return "120D"
-                if {e3[1]} == {e4[1]} == set(e3).intersection(set(e4)):
-                    return "120U"
-                if e3[1] == e4[0]:
-                    return "120C"
-    elif num_edges == 5:
-        return "210"
-    elif num_edges == 6:
-        return "300"
-
-
-@not_implemented_for("undirected")
-@py_random_state(1)
-@nx._dispatch
-def random_triad(G, seed=None):
-    """Returns a random triad from a directed graph.
+@nx._dispatchable(graphs=None, returns_graph=True)
+def from_edgelist(edgelist, create_using=None):
+    """Returns a graph from a list of edges.
 
     Parameters
     ----------
-    G : digraph
-       A NetworkX DiGraph
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-
-    Returns
-    -------
-    G2 : subgraph
-       A randomly selected triad (order-3 NetworkX DiGraph)
+    edgelist : list or iterator
+      Edge tuples
 
-    Raises
-    ------
-    NetworkXError
-        If the input Graph has less than 3 nodes.
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+        Graph type to create. If graph instance, then cleared before populated.
 
     Examples
     --------
-    >>> G = nx.DiGraph([(1, 2), (1, 3), (2, 3), (3, 1), (5, 6), (5, 4), (6, 7)])
-    >>> triad = nx.random_triad(G, seed=1)
-    >>> triad.edges
-    OutEdgeView([(1, 2)])
+    >>> edgelist = [(0, 1)]  # single edge (0,1)
+    >>> G = nx.from_edgelist(edgelist)
+
+    or
+
+    >>> G = nx.Graph(edgelist)  # use Graph constructor
 
     """
-    if len(G) < 3:
-        raise nx.NetworkXError(
-            f"G needs at least 3 nodes to form a triad; (it has {len(G)} nodes)"
-        )
-    nodes = seed.sample(list(G.nodes()), 3)
-    G2 = G.subgraph(nodes)
-    return G2
+    G = nx.empty_graph(0, create_using)
+    G.add_edges_from(edgelist)
+    return G
```

### Comparing `networkx-3.2rc0/networkx/algorithms/vitality.py` & `networkx-3.3rc0/networkx/algorithms/vitality.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from functools import partial
 
 import networkx as nx
 
 __all__ = ["closeness_vitality"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def closeness_vitality(G, node=None, weight=None, wiener_index=None):
     """Returns the closeness vitality for nodes in the graph.
 
     The *closeness vitality* of a node, defined in Section 3.6.2 of [1],
     is the change in the sum of distances between all node pairs when
     excluding that node.
```

### Comparing `networkx-3.2rc0/networkx/algorithms/voronoi.py` & `networkx-3.3rc0/networkx/algorithms/voronoi.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Functions for computing the Voronoi cells of a graph."""
 import networkx as nx
 from networkx.utils import groups
 
 __all__ = ["voronoi_cells"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def voronoi_cells(G, center_nodes, weight="weight"):
     """Returns the Voronoi cells centered at `center_nodes` with respect
     to the shortest-path distance metric.
 
     If $C$ is a set of nodes in the graph and $c$ is an element of $C$,
     the *Voronoi cell* centered at a node $c$ is the set of all nodes
     $v$ that are closer to $c$ than to any other center node in $C$ with
```

### Comparing `networkx-3.2rc0/networkx/algorithms/walks.py` & `networkx-3.3rc0/networkx/algorithms/walks.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 """
 
 import networkx as nx
 
 __all__ = ["number_of_walks"]
 
 
-@nx._dispatch
+@nx._dispatchable
 def number_of_walks(G, walk_length):
     """Returns the number of walks connecting each pair of nodes in `G`
 
     A *walk* is a sequence of nodes in which each adjacent pair of nodes
     in the sequence is adjacent in the graph. A walk can repeat the same
     edge and go in the opposite direction just as people can walk on a
     set of paths, but standing still is not counted as part of the walk.
@@ -70,11 +70,11 @@
         raise ValueError(f"`walk_length` cannot be negative: {walk_length}")
 
     A = nx.adjacency_matrix(G, weight=None)
     # TODO: Use matrix_power from scipy.sparse when available
     # power = sp.sparse.linalg.matrix_power(A, walk_length)
     power = np.linalg.matrix_power(A.toarray(), walk_length)
     result = {
-        u: {v: power[u_idx, v_idx] for v_idx, v in enumerate(G)}
+        u: {v: power.item(u_idx, v_idx) for v_idx, v in enumerate(G)}
         for u_idx, u in enumerate(G)
     }
     return result
```

### Comparing `networkx-3.2rc0/networkx/classes/digraph.py` & `networkx-3.3rc0/networkx/classes/digraph.py`

 * *Files 0% similar despite different names*

```diff
@@ -1022,15 +1022,15 @@
             A view of edge attributes, usually it iterates over (u, v)
             or (u, v, d) tuples of edges, but can also be used for
             attribute lookup as `edges[u, v]['foo']`.
 
         Examples
         --------
         >>> G = nx.DiGraph()
-        >>> G.add_edge(1, 2, color='blue')
+        >>> G.add_edge(1, 2, color="blue")
         >>> G.in_edges()
         InEdgeView([(1, 2)])
         >>> G.in_edges(nbunch=2)
         InEdgeDataView([(1, 2)])
 
         See Also
         --------
```

### Comparing `networkx-3.2rc0/networkx/classes/function.py` & `networkx-3.3rc0/networkx/classes/function.py`

 * *Files 2% similar despite different names*

```diff
@@ -45,47 +45,63 @@
     "number_of_selfloops",
     "path_weight",
     "is_path",
 ]
 
 
 def nodes(G):
-    """Returns an iterator over the graph nodes."""
+    """Returns a NodeView over the graph nodes.
+
+    This function wraps the :func:`G.nodes <networkx.Graph.nodes>` property.
+    """
     return G.nodes()
 
 
 def edges(G, nbunch=None):
     """Returns an edge view of edges incident to nodes in nbunch.
 
     Return all edges if nbunch is unspecified or nbunch=None.
 
     For digraphs, edges=out_edges
+
+    This function wraps the :func:`G.edges <networkx.Graph.edges>` property.
     """
     return G.edges(nbunch)
 
 
 def degree(G, nbunch=None, weight=None):
     """Returns a degree view of single node or of nbunch of nodes.
     If nbunch is omitted, then return degrees of *all* nodes.
+
+    This function wraps the :func:`G.degree <networkx.Graph.degree>` property.
     """
     return G.degree(nbunch, weight)
 
 
 def neighbors(G, n):
-    """Returns a list of nodes connected to node n."""
+    """Returns an iterator over all neighbors of node n.
+
+    This function wraps the :func:`G.neighbors <networkx.Graph.neighbors>` function.
+    """
     return G.neighbors(n)
 
 
 def number_of_nodes(G):
-    """Returns the number of nodes in the graph."""
+    """Returns the number of nodes in the graph.
+
+    This function wraps the :func:`G.number_of_nodes <networkx.Graph.number_of_nodes>` function.
+    """
     return G.number_of_nodes()
 
 
 def number_of_edges(G):
-    """Returns the number of edges in the graph."""
+    """Returns the number of edges in the graph.
+
+    This function wraps the :func:`G.number_of_edges <networkx.Graph.number_of_edges>` function.
+    """
     return G.number_of_edges()
 
 
 def density(G):
     r"""Returns the density of a graph.
 
     The density for undirected graphs is
@@ -136,15 +152,15 @@
 
     Notes
     -----
     Note: the bins are width one, hence len(list) can be large
     (Order(number_of_edges))
     """
     counts = Counter(d for n, d in G.degree())
-    return [counts.get(i, 0) for i in range(max(counts) + 1)]
+    return [counts.get(i, 0) for i in range(max(counts) + 1 if counts else 0)]
 
 
 def is_directed(G):
     """Return True if graph is directed."""
     return G.is_directed()
 
 
@@ -789,39 +805,39 @@
     if name is not None:
         # `values` does not contain attribute names
         try:
             # if `values` is a dict using `.items()` => {edge: value}
             if G.is_multigraph():
                 for (u, v, key), value in values.items():
                     try:
-                        G[u][v][key][name] = value
+                        G._adj[u][v][key][name] = value
                     except KeyError:
                         pass
             else:
                 for (u, v), value in values.items():
                     try:
-                        G[u][v][name] = value
+                        G._adj[u][v][name] = value
                     except KeyError:
                         pass
         except AttributeError:
             # treat `values` as a constant
             for u, v, data in G.edges(data=True):
                 data[name] = values
     else:
         # `values` consists of doct-of-dict {edge: {attr: value}} shape
         if G.is_multigraph():
             for (u, v, key), d in values.items():
                 try:
-                    G[u][v][key].update(d)
+                    G._adj[u][v][key].update(d)
                 except KeyError:
                     pass
         else:
             for (u, v), d in values.items():
                 try:
-                    G[u][v].update(d)
+                    G._adj[u][v].update(d)
                 except KeyError:
                     pass
 
 
 def get_edge_attributes(G, name, default=None):
     """Get edge attributes from graph
 
@@ -898,19 +914,18 @@
         Graph to find neighbors.
 
     node : node
         The node whose neighbors will be returned.
 
     Returns
     -------
-    non_neighbors : iterator
-        Iterator of nodes in the graph that are not neighbors of the node.
+    non_neighbors : set
+        Set of nodes in the graph that are not neighbors of the node.
     """
-    nbors = set(neighbors(graph, node)) | {node}
-    return (nnode for nnode in graph if nnode not in nbors)
+    return graph._adj.keys() - graph._adj[node].keys() - {node}
 
 
 def non_edges(graph):
     """Returns the nonexistent edges in the graph.
 
     Parameters
     ----------
@@ -944,16 +959,16 @@
         A NetworkX undirected graph.
 
     u, v : nodes
         Nodes in the graph.
 
     Returns
     -------
-    cnbors : iterator
-        Iterator of common neighbors of u and v in the graph.
+    cnbors : set
+        Set of common neighbors of u and v in the graph.
 
     Raises
     ------
     NetworkXError
         If u or v is not a node in the graph.
 
     Examples
@@ -963,17 +978,15 @@
     [2, 3, 4]
     """
     if u not in G:
         raise nx.NetworkXError("u is not in the graph.")
     if v not in G:
         raise nx.NetworkXError("v is not in the graph.")
 
-    # Return a generator explicitly instead of yielding so that the above
-    # checks are executed eagerly.
-    return (w for w in G[u] if w in G[v] and w not in (u, v))
+    return G._adj[u].keys() & G._adj[v].keys() - {u, v}
 
 
 def is_weighted(G, edge=None, weight="weight"):
     """Returns True if `G` has weighted edges.
 
     Parameters
     ----------
@@ -1021,14 +1034,15 @@
     if is_empty(G):
         # Special handling required since: all([]) == True
         return False
 
     return all(weight in data for u, v, data in G.edges(data=True))
 
 
+@nx._dispatchable(edge_attrs="weight")
 def is_negatively_weighted(G, edge=None, weight="weight"):
     """Returns True if `G` has negatively weighted edges.
 
     Parameters
     ----------
     G : graph
         A NetworkX graph.
@@ -1094,15 +1108,15 @@
     Notes
     -----
     An empty graph can have nodes but not edges. The empty graph with zero
     nodes is known as the null graph. This is an $O(n)$ operation where n
     is the number of nodes in the graph.
 
     """
-    return not any(G.adj.values())
+    return not any(G._adj.values())
 
 
 def nodes_with_selfloops(G):
     """Returns an iterator over nodes with self loops.
 
     A node with a self loop has an edge with both ends adjacent
     to that node.
@@ -1121,15 +1135,15 @@
     >>> G = nx.Graph()  # or DiGraph, MultiGraph, MultiDiGraph, etc
     >>> G.add_edge(1, 1)
     >>> G.add_edge(1, 2)
     >>> list(nx.nodes_with_selfloops(G))
     [1]
 
     """
-    return (n for n, nbrs in G.adj.items() if n in nbrs)
+    return (n for n, nbrs in G._adj.items() if n in nbrs)
 
 
 def selfloop_edges(G, data=False, keys=False, default=None):
     """Returns an iterator over selfloop edges.
 
     A selfloop edge has the same node at both ends.
 
@@ -1171,64 +1185,67 @@
     [(1, 1, 0, {})]
     """
     if data is True:
         if G.is_multigraph():
             if keys is True:
                 return (
                     (n, n, k, d)
-                    for n, nbrs in G.adj.items()
+                    for n, nbrs in G._adj.items()
                     if n in nbrs
                     for k, d in nbrs[n].items()
                 )
             else:
                 return (
                     (n, n, d)
-                    for n, nbrs in G.adj.items()
+                    for n, nbrs in G._adj.items()
                     if n in nbrs
                     for d in nbrs[n].values()
                 )
         else:
-            return ((n, n, nbrs[n]) for n, nbrs in G.adj.items() if n in nbrs)
+            return ((n, n, nbrs[n]) for n, nbrs in G._adj.items() if n in nbrs)
     elif data is not False:
         if G.is_multigraph():
             if keys is True:
                 return (
                     (n, n, k, d.get(data, default))
-                    for n, nbrs in G.adj.items()
+                    for n, nbrs in G._adj.items()
                     if n in nbrs
                     for k, d in nbrs[n].items()
                 )
             else:
                 return (
                     (n, n, d.get(data, default))
-                    for n, nbrs in G.adj.items()
+                    for n, nbrs in G._adj.items()
                     if n in nbrs
                     for d in nbrs[n].values()
                 )
         else:
             return (
                 (n, n, nbrs[n].get(data, default))
-                for n, nbrs in G.adj.items()
+                for n, nbrs in G._adj.items()
                 if n in nbrs
             )
     else:
         if G.is_multigraph():
             if keys is True:
                 return (
-                    (n, n, k) for n, nbrs in G.adj.items() if n in nbrs for k in nbrs[n]
+                    (n, n, k)
+                    for n, nbrs in G._adj.items()
+                    if n in nbrs
+                    for k in nbrs[n]
                 )
             else:
                 return (
                     (n, n)
-                    for n, nbrs in G.adj.items()
+                    for n, nbrs in G._adj.items()
                     if n in nbrs
                     for i in range(len(nbrs[n]))  # for easy edge removal (#4068)
                 )
         else:
-            return ((n, n) for n, nbrs in G.adj.items() if n in nbrs)
+            return ((n, n) for n, nbrs in G._adj.items() if n in nbrs)
 
 
 def number_of_selfloops(G):
     """Returns the number of selfloop edges.
 
     A selfloop edge has the same node at both ends.
 
@@ -1268,15 +1285,18 @@
 
     Returns
     -------
     bool
         True if `path` is a valid path in `G`
 
     """
-    return all((node in G and nbr in G[node]) for node, nbr in nx.utils.pairwise(path))
+    try:
+        return all(nbr in G._adj[node] for node, nbr in nx.utils.pairwise(path))
+    except (KeyError, TypeError):
+        return False
 
 
 def path_weight(G, path, weight):
     """Returns total cost associated with specified path and weight
 
     Parameters
     ----------
@@ -1303,11 +1323,11 @@
     multigraph = G.is_multigraph()
     cost = 0
 
     if not nx.is_path(G, path):
         raise nx.NetworkXNoPath("path does not exist")
     for node, nbr in nx.utils.pairwise(path):
         if multigraph:
-            cost += min(v[weight] for v in G[node][nbr].values())
+            cost += min(v[weight] for v in G._adj[node][nbr].values())
         else:
-            cost += G[node][nbr][weight]
+            cost += G._adj[node][nbr][weight]
     return cost
```

### Comparing `networkx-3.2rc0/networkx/classes/graph.py` & `networkx-3.3rc0/networkx/classes/graph.py`

 * *Files 1% similar despite different names*

```diff
@@ -1207,28 +1207,20 @@
         >>> adj = {1: {2, 3}, 2: {1, 3}, 3: {1, 2}}
         >>> e = [(u, v) for u, nbrs in adj.items() for v in nbrs]
         >>> G.update(edges=e, nodes=adj)
 
         >>> DG = nx.DiGraph()
         >>> # dict-of-dict-of-attribute
         >>> adj = {1: {2: 1.3, 3: 0.7}, 2: {1: 1.4}, 3: {1: 0.7}}
-        >>> e = [
-        ...     (u, v, {"weight": d})
-        ...     for u, nbrs in adj.items()
-        ...     for v, d in nbrs.items()
-        ... ]
+        >>> e = [(u, v, {"weight": d}) for u, nbrs in adj.items() for v, d in nbrs.items()]
         >>> DG.update(edges=e, nodes=adj)
 
         >>> # dict-of-dict-of-dict
         >>> adj = {1: {2: {"weight": 1.3}, 3: {"color": 0.7, "weight": 1.2}}}
-        >>> e = [
-        ...     (u, v, {"weight": d})
-        ...     for u, nbrs in adj.items()
-        ...     for v, d in nbrs.items()
-        ... ]
+        >>> e = [(u, v, {"weight": d}) for u, nbrs in adj.items() for v, d in nbrs.items()]
         >>> DG.update(edges=e, nodes=adj)
 
         >>> # predecessor adjacency (dict-of-set)
         >>> pred = {1: {2, 3}, 2: {3}, 3: {3}}
         >>> e = [(v, u) for u, nbrs in pred.items() for v in nbrs]
 
         >>> # MultiGraph dict-of-dict-of-dict-of-attribute
@@ -1543,16 +1535,16 @@
         >>> G = nx.path_graph(4)  # or DiGraph, MultiGraph, MultiDiGraph, etc
         >>> G.clear_edges()
         >>> list(G.nodes)
         [0, 1, 2, 3]
         >>> list(G.edges)
         []
         """
-        for neighbours_dict in self._adj.values():
-            neighbours_dict.clear()
+        for nbr_dict in self._adj.values():
+            nbr_dict.clear()
 
     def is_multigraph(self):
         """Returns True if graph is a multigraph, False otherwise."""
         return False
 
     def is_directed(self):
         """Returns True if graph is directed, False otherwise."""
@@ -1796,22 +1788,30 @@
 
         ::
 
             # Create a subgraph SG based on a (possibly multigraph) G
             SG = G.__class__()
             SG.add_nodes_from((n, G.nodes[n]) for n in largest_wcc)
             if SG.is_multigraph():
-                SG.add_edges_from((n, nbr, key, d)
-                    for n, nbrs in G.adj.items() if n in largest_wcc
-                    for nbr, keydict in nbrs.items() if nbr in largest_wcc
-                    for key, d in keydict.items())
+                SG.add_edges_from(
+                    (n, nbr, key, d)
+                    for n, nbrs in G.adj.items()
+                    if n in largest_wcc
+                    for nbr, keydict in nbrs.items()
+                    if nbr in largest_wcc
+                    for key, d in keydict.items()
+                )
             else:
-                SG.add_edges_from((n, nbr, d)
-                    for n, nbrs in G.adj.items() if n in largest_wcc
-                    for nbr, d in nbrs.items() if nbr in largest_wcc)
+                SG.add_edges_from(
+                    (n, nbr, d)
+                    for n, nbrs in G.adj.items()
+                    if n in largest_wcc
+                    for nbr, d in nbrs.items()
+                    if nbr in largest_wcc
+                )
             SG.graph.update(G.graph)
 
         Examples
         --------
         >>> G = nx.path_graph(4)  # or DiGraph, MultiGraph, MultiDiGraph, etc
         >>> H = G.subgraph([0, 1, 2])
         >>> list(H.edges)
```

### Comparing `networkx-3.2rc0/networkx/classes/graphviews.py` & `networkx-3.3rc0/networkx/classes/graphviews.py`

 * *Files 1% similar despite different names*

```diff
@@ -176,31 +176,33 @@
     >>> G = nx.path_graph(6)
 
     Filter functions operate on the node, and return `True` if the node should
     appear in the view:
 
     >>> def filter_node(n1):
     ...     return n1 != 5
-    ...
     >>> view = nx.subgraph_view(G, filter_node=filter_node)
     >>> view.nodes()
     NodeView((0, 1, 2, 3, 4))
 
     We can use a closure pattern to filter graph elements based on additional
     data --- for example, filtering on edge data attached to the graph:
 
     >>> G[3][4]["cross_me"] = False
     >>> def filter_edge(n1, n2):
     ...     return G[n1][n2].get("cross_me", True)
-    ...
     >>> view = nx.subgraph_view(G, filter_edge=filter_edge)
     >>> view.edges()
     EdgeView([(0, 1), (1, 2), (2, 3), (4, 5)])
 
-    >>> view = nx.subgraph_view(G, filter_node=filter_node, filter_edge=filter_edge,)
+    >>> view = nx.subgraph_view(
+    ...     G,
+    ...     filter_node=filter_node,
+    ...     filter_edge=filter_edge,
+    ... )
     >>> view.nodes()
     NodeView((0, 1, 2, 3, 4))
     >>> view.edges()
     EdgeView([(0, 1), (1, 2), (2, 3)])
     """
     newG = nx.freeze(G.__class__())
     newG._NODE_OK = filter_node
```

### Comparing `networkx-3.2rc0/networkx/classes/multidigraph.py` & `networkx-3.3rc0/networkx/classes/multidigraph.py`

 * *Files 1% similar despite different names*

```diff
@@ -635,15 +635,15 @@
         For directed graphs this returns the out-edges.
 
         Examples
         --------
         >>> G = nx.MultiDiGraph()
         >>> nx.add_path(G, [0, 1, 2])
         >>> key = G.add_edge(2, 3, weight=5)
-        >>> key2 = G.add_edge(1, 2) # second edge between these nodes
+        >>> key2 = G.add_edge(1, 2)  # second edge between these nodes
         >>> [e for e in G.edges()]
         [(0, 1), (1, 2), (1, 2), (2, 3)]
         >>> list(G.edges(data=True))  # default data is {} (empty dict)
         [(0, 1, {}), (1, 2, {}), (1, 2, {}), (2, 3, {'weight': 5})]
         >>> list(G.edges(data="weight", default=1))
         [(0, 1, 1), (1, 2, 1), (1, 2, 1), (2, 3, 5)]
         >>> list(G.edges(keys=True))  # default keys are integers
@@ -742,17 +742,17 @@
         --------
         >>> G = nx.MultiDiGraph()
         >>> nx.add_path(G, [0, 1, 2, 3])
         >>> G.degree(0)  # node 0 with degree 1
         1
         >>> list(G.degree([0, 1, 2]))
         [(0, 1), (1, 2), (2, 2)]
-        >>> G.add_edge(0, 1) # parallel edge
+        >>> G.add_edge(0, 1)  # parallel edge
         1
-        >>> list(G.degree([0, 1, 2])) # parallel edges are counted
+        >>> list(G.degree([0, 1, 2]))  # parallel edges are counted
         [(0, 2), (1, 3), (2, 2)]
 
         """
         return DiMultiDegreeView(self)
 
     @cached_property
     def in_degree(self):
@@ -793,17 +793,17 @@
         --------
         >>> G = nx.MultiDiGraph()
         >>> nx.add_path(G, [0, 1, 2, 3])
         >>> G.in_degree(0)  # node 0 with degree 0
         0
         >>> list(G.in_degree([0, 1, 2]))
         [(0, 0), (1, 1), (2, 1)]
-        >>> G.add_edge(0, 1) # parallel edge
+        >>> G.add_edge(0, 1)  # parallel edge
         1
-        >>> list(G.in_degree([0, 1, 2])) # parallel edges counted
+        >>> list(G.in_degree([0, 1, 2]))  # parallel edges counted
         [(0, 0), (1, 2), (2, 1)]
 
         """
         return InMultiDegreeView(self)
 
     @cached_property
     def out_degree(self):
@@ -843,17 +843,17 @@
         --------
         >>> G = nx.MultiDiGraph()
         >>> nx.add_path(G, [0, 1, 2, 3])
         >>> G.out_degree(0)  # node 0 with degree 1
         1
         >>> list(G.out_degree([0, 1, 2]))
         [(0, 1), (1, 1), (2, 1)]
-        >>> G.add_edge(0, 1) # parallel edge
+        >>> G.add_edge(0, 1)  # parallel edge
         1
-        >>> list(G.out_degree([0, 1, 2])) # counts parallel edges
+        >>> list(G.out_degree([0, 1, 2]))  # counts parallel edges
         [(0, 2), (1, 1), (2, 1)]
 
         """
         return OutMultiDegreeView(self)
 
     def is_multigraph(self):
         """Returns True if graph is a multigraph, False otherwise."""
```

### Comparing `networkx-3.2rc0/networkx/classes/multigraph.py` & `networkx-3.3rc0/networkx/classes/multigraph.py`

 * *Files identical despite different names*

```diff
@@ -386,15 +386,15 @@
         Examples
         --------
         >>> e = [(1, 2), (1, 2), (1, 3), (3, 4)]  # list of edges
         >>> G = nx.MultiGraph(e)
         >>> G.edges[1, 2, 0]["weight"] = 3
         >>> result = set()
         >>> for edgekey, data in G[1][2].items():
-        ...     result.add(data.get('weight', 1))
+        ...     result.add(data.get("weight", 1))
         >>> result
         {1, 3}
 
         For directed graphs, `G.adj` holds outgoing (successor) info.
         """
         return MultiAdjacencyView(self._adj)
```

### Comparing `networkx-3.2rc0/networkx/classes/reportviews.py` & `networkx-3.3rc0/networkx/classes/reportviews.py`

 * *Files 0% similar despite different names*

```diff
@@ -235,19 +235,21 @@
         See Also
         --------
         NodeDataView
 
         Examples
         --------
         >>> G = nx.Graph()
-        >>> G.add_nodes_from([
-        ...     (0, {"color": "red", "weight": 10}),
-        ...     (1, {"color": "blue"}),
-        ...     (2, {"color": "yellow", "weight": 2})
-        ... ])
+        >>> G.add_nodes_from(
+        ...     [
+        ...         (0, {"color": "red", "weight": 10}),
+        ...         (1, {"color": "blue"}),
+        ...         (2, {"color": "yellow", "weight": 2}),
+        ...     ]
+        ... )
 
         Accessing node data with ``data=True`` (the default) returns a
         NodeDataView mapping each node to all of its attributes:
 
         >>> G.nodes.data()
         NodeDataView({0: {'color': 'red', 'weight': 10}, 1: {'color': 'blue'}, 2: {'color': 'yellow', 'weight': 2}})
 
@@ -1078,15 +1080,18 @@
     def __getitem__(self, e):
         if isinstance(e, slice):
             raise nx.NetworkXError(
                 f"{type(self).__name__} does not support slicing, "
                 f"try list(G.edges)[{e.start}:{e.stop}:{e.step}]"
             )
         u, v = e
-        return self._adjdict[u][v]
+        try:
+            return self._adjdict[u][v]
+        except KeyError as ex:  # Customize msg to indicate exception origin
+            raise KeyError(f"The edge {e} is not in the graph.")
 
     # EdgeDataView methods
     def __call__(self, nbunch=None, data=False, *, default=None):
         if nbunch is None and data is False:
             return self
         return self.dataview(self, nbunch, data, default=default)
 
@@ -1125,19 +1130,21 @@
         OutEdgeDataView
         MultiEdgeDataView
         OutMultiEdgeDataView
 
         Examples
         --------
         >>> G = nx.Graph()
-        >>> G.add_edges_from([
-        ...     (0, 1, {"dist": 3, "capacity": 20}),
-        ...     (1, 2, {"dist": 4}),
-        ...     (2, 0, {"dist": 5})
-        ... ])
+        >>> G.add_edges_from(
+        ...     [
+        ...         (0, 1, {"dist": 3, "capacity": 20}),
+        ...         (1, 2, {"dist": 4}),
+        ...         (2, 0, {"dist": 5}),
+        ...     ]
+        ... )
 
         Accessing edge data with ``data=True`` (the default) returns an
         edge data view object listing each edge with all of its attributes:
 
         >>> G.edges.data()
         EdgeDataView([(0, 1, {'dist': 3, 'capacity': 20}), (0, 2, {'dist': 5}), (1, 2, {'dist': 4})])
```

### Comparing `networkx-3.2rc0/networkx/classes/tests/dispatch_interface.py` & `networkx-3.3rc0/networkx/classes/tests/dispatch_interface.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 # A full test of all dispatchable algorithms is performed by
 # modifying the pytest invocation and setting an environment variable
 # NETWORKX_TEST_BACKEND=nx-loopback pytest
 # This is comprehensive, but only tests the `test_override_dispatch`
 # function in networkx.classes.backends.
 
-# To test the `_dispatch` function directly, several tests scattered throughout
+# To test the `_dispatchable` function directly, several tests scattered throughout
 # NetworkX have been augmented to test normal and dispatch mode.
 # Searching for `dispatch_interface` should locate the specific tests.
 
 import networkx as nx
 from networkx import DiGraph, Graph, MultiDiGraph, MultiGraph, PlanarEmbedding
 from networkx.classes.reportviews import NodeView
```

### Comparing `networkx-3.2rc0/networkx/classes/tests/historical_tests.py` & `networkx-3.3rc0/networkx/classes/tests/historical_tests.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_backends.py` & `networkx-3.3rc0/networkx/classes/tests/test_backends.py`

 * *Files 22% similar despite different names*

```diff
@@ -13,22 +13,30 @@
     nx.pagerank(G)
     nx.pagerank(G=G)
     with pytest.raises(TypeError):
         nx.pagerank()
 
 
 def test_pickle():
+    count = 0
     for name, func in nx.utils.backends._registered_algorithms.items():
-        assert pickle.loads(pickle.dumps(func)) is func
+        try:
+            # Some functions can't be pickled, but it's not b/c of _dispatchable
+            pickled = pickle.dumps(func)
+        except pickle.PicklingError:
+            continue
+        assert pickle.loads(pickled) is func
+        count += 1
+    assert count > 0
     assert pickle.loads(pickle.dumps(nx.inverse_line_graph)) is nx.inverse_line_graph
 
 
 @pytest.mark.skipif(
-    "not nx._dispatch._automatic_backends "
-    "or nx._dispatch._automatic_backends[0] != 'nx-loopback'"
+    "not nx.config['backend_priority'] "
+    "or nx.config['backend_priority'][0] != 'nx-loopback'"
 )
 def test_graph_converter_needs_backend():
     # When testing, `nx.from_scipy_sparse_array` will *always* call the backend
     # implementation if it's implemented. If `backend=` isn't given, then the result
     # will be converted back to NetworkX via `convert_to_nx`.
     # If not testing, then calling `nx.from_scipy_sparse_array` w/o `backend=` will
     # always call the original version. `backend=` is *required* to call the backend.
@@ -41,17 +49,17 @@
 
     side_effects = []
 
     def from_scipy_sparse_array(self, *args, **kwargs):
         side_effects.append(1)  # Just to prove this was called
         return self.convert_from_nx(
             self.__getattr__("from_scipy_sparse_array")(*args, **kwargs),
-            preserve_edge_attrs=None,
-            preserve_node_attrs=None,
-            preserve_graph_attrs=None,
+            preserve_edge_attrs=True,
+            preserve_node_attrs=True,
+            preserve_graph_attrs=True,
         )
 
     @staticmethod
     def convert_to_nx(obj, *, name=None):
         if type(obj) is nx.Graph:
             return obj
         return nx.Graph(obj)
@@ -70,7 +78,11 @@
         )
         assert side_effects == [1, 1]
     finally:
         LoopbackDispatcher.convert_to_nx = staticmethod(orig_convert_to_nx)
         del LoopbackDispatcher.from_scipy_sparse_array
     with pytest.raises(ImportError, match="Unable to load"):
         nx.from_scipy_sparse_array(A, backend="bad-backend-name")
+
+
+def test_dispatchable_are_functions():
+    assert type(nx.pagerank) is type(nx.pagerank.orig_func)
```

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_coreviews.py` & `networkx-3.3rc0/networkx/classes/tests/test_coreviews.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_digraph.py` & `networkx-3.3rc0/networkx/classes/tests/test_digraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_digraph_historical.py` & `networkx-3.3rc0/networkx/classes/tests/test_digraph_historical.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_filters.py` & `networkx-3.3rc0/networkx/classes/tests/test_filters.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_function.py` & `networkx-3.3rc0/networkx/classes/tests/test_function.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,14 +2,19 @@
 
 import pytest
 
 import networkx as nx
 from networkx.utils import edges_equal, nodes_equal
 
 
+def test_degree_histogram_empty():
+    G = nx.Graph()
+    assert nx.degree_histogram(G) == []
+
+
 class TestFunction:
     def setup_method(self):
         self.G = nx.Graph({0: [1, 2, 3], 1: [1, 2, 0], 4: []}, name="Test")
         self.Gdegree = {0: 3, 1: 2, 2: 2, 3: 1, 4: 0}
         self.Gnodes = list(range(5))
         self.Gedges = [(0, 1), (0, 2), (0, 3), (1, 0), (1, 1), (1, 2)]
         self.DG = nx.DiGraph({0: [1, 2, 3], 1: [1, 2, 0], 4: []})
@@ -293,36 +298,36 @@
         graph = nx.star_graph(99)
         nbors = list(nx.neighbors(graph, 0))
         assert len(nbors) == 99
 
     def test_non_neighbors(self):
         graph = nx.complete_graph(100)
         pop = random.sample(list(graph), 1)
-        nbors = list(nx.non_neighbors(graph, pop[0]))
+        nbors = nx.non_neighbors(graph, pop[0])
         # should be all the other vertices in the graph
         assert len(nbors) == 0
 
         graph = nx.path_graph(100)
         node = random.sample(list(graph), 1)[0]
-        nbors = list(nx.non_neighbors(graph, node))
+        nbors = nx.non_neighbors(graph, node)
         # should be all the other vertices in the graph
         if node != 0 and node != 99:
             assert len(nbors) == 97
         else:
             assert len(nbors) == 98
 
         # create a star graph with 99 outer nodes
         graph = nx.star_graph(99)
-        nbors = list(nx.non_neighbors(graph, 0))
+        nbors = nx.non_neighbors(graph, 0)
         assert len(nbors) == 0
 
         # disconnected graph
         graph = nx.Graph()
         graph.add_nodes_from(range(10))
-        nbors = list(nx.non_neighbors(graph, 0))
+        nbors = nx.non_neighbors(graph, 0)
         assert len(nbors) == 9
 
     def test_non_edges(self):
         # All possible edges exist
         graph = nx.complete_graph(5)
         nedges = list(nx.non_edges(graph))
         assert len(nedges) == 0
```

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_graph.py` & `networkx-3.3rc0/networkx/classes/tests/test_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_graphviews.py` & `networkx-3.3rc0/networkx/classes/tests/test_graphviews.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_multidigraph.py` & `networkx-3.3rc0/networkx/classes/tests/test_multidigraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_multigraph.py` & `networkx-3.3rc0/networkx/classes/tests/test_multigraph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_reportviews.py` & `networkx-3.3rc0/networkx/classes/tests/test_reportviews.py`

 * *Files 0% similar despite different names*

```diff
@@ -592,17 +592,21 @@
     def test_getitem(self):
         G = self.G.copy()
         ev = G.edges
         G.edges[0, 1]["foo"] = "bar"
         assert ev[0, 1] == {"foo": "bar"}
 
         # slicing
-        with pytest.raises(nx.NetworkXError):
+        with pytest.raises(nx.NetworkXError, match=".*does not support slicing"):
             G.edges[0:5]
 
+        # Invalid edge
+        with pytest.raises(KeyError, match=r".*edge.*is not in the graph."):
+            G.edges[0, 9]
+
     def test_call(self):
         ev = self.eview(self.G)
         assert id(ev) == id(ev())
         assert id(ev) == id(ev(data=False))
         assert id(ev) != id(ev(data=True))
         assert id(ev) != id(ev(nbunch=1))
```

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_special.py` & `networkx-3.3rc0/networkx/classes/tests/test_special.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/classes/tests/test_subgraphviews.py` & `networkx-3.3rc0/networkx/classes/tests/test_subgraphviews.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/conftest.py` & `networkx-3.3rc0/networkx/conftest.py`

 * *Files 26% similar despite different names*

```diff
@@ -41,38 +41,43 @@
 
 
 def pytest_configure(config):
     config.addinivalue_line("markers", "slow: mark test as slow to run")
     backend = config.getoption("--backend")
     if backend is None:
         backend = os.environ.get("NETWORKX_TEST_BACKEND")
+    # nx-loopback backend is only available when testing
+    backends = entry_points(name="nx-loopback", group="networkx.backends")
+    if backends:
+        networkx.utils.backends.backends["nx-loopback"] = next(iter(backends))
+    else:
+        warnings.warn(
+            "\n\n             WARNING: Mixed NetworkX configuration! \n\n"
+            "        This environment has mixed configuration for networkx.\n"
+            "        The test object nx-loopback is not configured correctly.\n"
+            "        You should not be seeing this message.\n"
+            "        Try `pip install -e .`, or change your PYTHONPATH\n"
+            "        Make sure python finds the networkx repo you are testing\n\n"
+        )
     if backend:
-        networkx.utils.backends._dispatch._automatic_backends = [backend]
+        networkx.config["backend_priority"] = [backend]
         fallback_to_nx = config.getoption("--fallback-to-nx")
         if not fallback_to_nx:
             fallback_to_nx = os.environ.get("NETWORKX_FALLBACK_TO_NX")
-        networkx.utils.backends._dispatch._fallback_to_nx = bool(fallback_to_nx)
-    # nx-loopback backend is only available when testing
-    if sys.version_info < (3, 10):
-        backends = (
-            ep for ep in entry_points()["networkx.backends"] if ep.name == "nx-loopback"
-        )
-    else:
-        backends = entry_points(name="nx-loopback", group="networkx.backends")
-    networkx.utils.backends.backends["nx-loopback"] = next(iter(backends))
+        networkx.utils.backends._dispatchable._fallback_to_nx = bool(fallback_to_nx)
 
 
 def pytest_collection_modifyitems(config, items):
     # Setting this to True here allows tests to be set up before dispatching
     # any function call to a backend.
-    networkx.utils.backends._dispatch._is_testing = True
-    if automatic_backends := networkx.utils.backends._dispatch._automatic_backends:
+    networkx.utils.backends._dispatchable._is_testing = True
+    if backend_priority := networkx.config["backend_priority"]:
         # Allow pluggable backends to add markers to tests (such as skip or xfail)
         # when running in auto-conversion test mode
-        backend = networkx.utils.backends.backends[automatic_backends[0]].load()
+        backend = networkx.utils.backends.backends[backend_priority[0]].load()
         if hasattr(backend, "on_start_tests"):
             getattr(backend, "on_start_tests")(items)
 
     if config.getoption("--runslow"):
         # --runslow given in cli: do not skip slow tests
         return
     skip_slow = pytest.mark.skip(reason="need --runslow option to run")
@@ -81,25 +86,22 @@
             item.add_marker(skip_slow)
 
 
 # TODO: The warnings below need to be dealt with, but for now we silence them.
 @pytest.fixture(autouse=True)
 def set_warnings():
     warnings.filterwarnings(
-        "ignore", category=DeprecationWarning, message="nx.nx_pydot"
-    )
-    warnings.filterwarnings(
         "ignore",
-        category=DeprecationWarning,
-        message="single_target_shortest_path_length will",
+        category=FutureWarning,
+        message="\n\nsingle_target_shortest_path_length",
     )
     warnings.filterwarnings(
         "ignore",
-        category=DeprecationWarning,
-        message="shortest_path for all_pairs",
+        category=FutureWarning,
+        message="\n\nshortest_path",
     )
     warnings.filterwarnings(
         "ignore", category=DeprecationWarning, message="\nforest_str is deprecated"
     )
     warnings.filterwarnings(
         "ignore", category=DeprecationWarning, message="\n\nrandom_tree"
     )
@@ -111,33 +113,56 @@
         category=DeprecationWarning,
         message="MultiDiGraph_EdgeKey has been deprecated",
     )
     warnings.filterwarnings(
         "ignore", category=DeprecationWarning, message="\n\nThe `normalized`"
     )
     warnings.filterwarnings(
-        "ignore", category=DeprecationWarning, message="function `join` is deprecated"
+        "ignore",
+        category=DeprecationWarning,
+        message="The function `join` is deprecated",
     )
     warnings.filterwarnings(
         "ignore",
         category=DeprecationWarning,
         message="\n\nstrongly_connected_components_recursive",
     )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\nall_triplets"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\nrandom_triad"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="minimal_d_separator"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="d_separated"
+    )
+    warnings.filterwarnings("ignore", category=DeprecationWarning, message="\n\nk_core")
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\nk_shell"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\nk_crust"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\nk_corona"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message="\n\ntotal_spanning_tree_weight"
+    )
+    warnings.filterwarnings(
+        "ignore", category=DeprecationWarning, message=r"\n\nThe 'create=matrix'"
+    )
 
 
 @pytest.fixture(autouse=True)
 def add_nx(doctest_namespace):
     doctest_namespace["nx"] = networkx
-    # TODO: remove the try-except block when we require numpy >= 2
-    try:
-        import numpy as np
-
-        np.set_printoptions(legacy="1.21")
-    except ImportError:
-        pass
 
 
 # What dependencies are installed?
 
 try:
     import numpy
 
@@ -194,14 +219,16 @@
 
 needs_numpy = [
     "algorithms/approximation/traveling_salesman.py",
     "algorithms/centrality/current_flow_closeness.py",
     "algorithms/node_classification.py",
     "algorithms/non_randomness.py",
     "algorithms/shortest_paths/dense.py",
+    "algorithms/tree/mst.py",
+    "generators/expanders.py",
     "linalg/bethehessianmatrix.py",
     "linalg/laplacianmatrix.py",
     "utils/misc.py",
     "algorithms/centrality/laplacian.py",
 ]
 needs_scipy = [
     "algorithms/approximation/traveling_salesman.py",
@@ -220,14 +247,15 @@
     "algorithms/link_analysis/hits_alg.py",
     "algorithms/link_analysis/pagerank_alg.py",
     "algorithms/node_classification.py",
     "algorithms/similarity.py",
     "convert_matrix.py",
     "drawing/layout.py",
     "generators/spectral_graph_forge.py",
+    "generators/expanders.py",
     "linalg/algebraicconnectivity.py",
     "linalg/attrmatrix.py",
     "linalg/bethehessianmatrix.py",
     "linalg/graphmatrix.py",
     "linalg/modularitymatrix.py",
     "linalg/spectrum.py",
     "utils/rcm.py",
```

### Comparing `networkx-3.2rc0/networkx/convert.py` & `networkx-3.3rc0/networkx/generators/directed.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,496 +1,501 @@
-"""Functions to convert NetworkX graphs to and from other formats.
+"""
+Generators for some directed graphs, including growing network (GN) graphs and
+scale-free graphs.
 
-The preferred way of converting data to a NetworkX graph is through the
-graph constructor.  The constructor calls the to_networkx_graph() function
-which attempts to guess the input type and convert it automatically.
-
-Examples
---------
-Create a graph with a single edge from a dictionary of dictionaries
-
->>> d = {0: {1: 1}}  # dict-of-dicts single edge (0,1)
->>> G = nx.Graph(d)
-
-See Also
---------
-nx_agraph, nx_pydot
 """
-import warnings
-from collections.abc import Collection, Generator, Iterator
+
+import numbers
+from collections import Counter
 
 import networkx as nx
+from networkx.generators.classic import empty_graph
+from networkx.utils import discrete_sequence, py_random_state, weighted_choice
 
 __all__ = [
-    "to_networkx_graph",
-    "from_dict_of_dicts",
-    "to_dict_of_dicts",
-    "from_dict_of_lists",
-    "to_dict_of_lists",
-    "from_edgelist",
-    "to_edgelist",
+    "gn_graph",
+    "gnc_graph",
+    "gnr_graph",
+    "random_k_out_graph",
+    "scale_free_graph",
 ]
 
 
-def to_networkx_graph(data, create_using=None, multigraph_input=False):
-    """Make a NetworkX graph from a known data structure.
-
-    The preferred way to call this is automatically
-    from the class constructor
-
-    >>> d = {0: {1: {"weight": 1}}}  # dict-of-dicts single edge (0,1)
-    >>> G = nx.Graph(d)
-
-    instead of the equivalent
+@py_random_state(3)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def gn_graph(n, kernel=None, create_using=None, seed=None):
+    """Returns the growing network (GN) digraph with `n` nodes.
+
+    The GN graph is built by adding nodes one at a time with a link to one
+    previously added node.  The target node for the link is chosen with
+    probability based on degree.  The default attachment kernel is a linear
+    function of the degree of a node.
 
-    >>> G = nx.from_dict_of_dicts(d)
+    The graph is always a (directed) tree.
 
     Parameters
     ----------
-    data : object to be converted
-
-        Current known types are:
-         any NetworkX graph
-         dict-of-dicts
-         dict-of-lists
-         container (e.g. set, list, tuple) of edges
-         iterator (e.g. itertools.chain) that produces edges
-         generator of edges
-         Pandas DataFrame (row per edge)
-         2D numpy array
-         scipy sparse array
-         pygraphviz agraph
-
-    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+    n : int
+        The number of nodes for the generated graph.
+    kernel : function
+        The attachment kernel.
+    create_using : NetworkX graph constructor, optional (default DiGraph)
         Graph type to create. If graph instance, then cleared before populated.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
-    multigraph_input : bool (default False)
-        If True and  data is a dict_of_dicts,
-        try to create a multigraph assuming dict_of_dict_of_lists.
-        If data and create_using are both multigraphs then create
-        a multigraph from a multigraph.
-
-    """
-    # NX graph
-    if hasattr(data, "adj"):
-        try:
-            result = from_dict_of_dicts(
-                data.adj,
-                create_using=create_using,
-                multigraph_input=data.is_multigraph(),
-            )
-            # data.graph should be dict-like
-            result.graph.update(data.graph)
-            # data.nodes should be dict-like
-            # result.add_node_from(data.nodes.items()) possible but
-            # for custom node_attr_dict_factory which may be hashable
-            # will be unexpected behavior
-            for n, dd in data.nodes.items():
-                result._node[n].update(dd)
-            return result
-        except Exception as err:
-            raise nx.NetworkXError("Input is not a correct NetworkX graph.") from err
-
-    # pygraphviz  agraph
-    if hasattr(data, "is_strict"):
-        try:
-            return nx.nx_agraph.from_agraph(data, create_using=create_using)
-        except Exception as err:
-            raise nx.NetworkXError("Input is not a correct pygraphviz graph.") from err
-
-    # dict of dicts/lists
-    if isinstance(data, dict):
-        try:
-            return from_dict_of_dicts(
-                data, create_using=create_using, multigraph_input=multigraph_input
-            )
-        except Exception as err1:
-            if multigraph_input is True:
-                raise nx.NetworkXError(
-                    f"converting multigraph_input raised:\n{type(err1)}: {err1}"
-                )
-            try:
-                return from_dict_of_lists(data, create_using=create_using)
-            except Exception as err2:
-                raise TypeError("Input is not known type.") from err2
-
-    # Pandas DataFrame
-    try:
-        import pandas as pd
-
-        if isinstance(data, pd.DataFrame):
-            if data.shape[0] == data.shape[1]:
-                try:
-                    return nx.from_pandas_adjacency(data, create_using=create_using)
-                except Exception as err:
-                    msg = "Input is not a correct Pandas DataFrame adjacency matrix."
-                    raise nx.NetworkXError(msg) from err
-            else:
-                try:
-                    return nx.from_pandas_edgelist(
-                        data, edge_attr=True, create_using=create_using
-                    )
-                except Exception as err:
-                    msg = "Input is not a correct Pandas DataFrame edge-list."
-                    raise nx.NetworkXError(msg) from err
-    except ImportError:
-        warnings.warn("pandas not found, skipping conversion test.", ImportWarning)
-
-    # numpy array
-    try:
-        import numpy as np
-
-        if isinstance(data, np.ndarray):
-            try:
-                return nx.from_numpy_array(data, create_using=create_using)
-            except Exception as err:
-                raise nx.NetworkXError(
-                    f"Failed to interpret array as an adjacency matrix."
-                ) from err
-    except ImportError:
-        warnings.warn("numpy not found, skipping conversion test.", ImportWarning)
-
-    # scipy sparse array - any format
-    try:
-        import scipy
-
-        if hasattr(data, "format"):
-            try:
-                return nx.from_scipy_sparse_array(data, create_using=create_using)
-            except Exception as err:
-                raise nx.NetworkXError(
-                    "Input is not a correct scipy sparse array type."
-                ) from err
-    except ImportError:
-        warnings.warn("scipy not found, skipping conversion test.", ImportWarning)
-
-    # Note: most general check - should remain last in order of execution
-    # Includes containers (e.g. list, set, dict, etc.), generators, and
-    # iterators (e.g. itertools.chain) of edges
-
-    if isinstance(data, (Collection, Generator, Iterator)):
-        try:
-            return from_edgelist(data, create_using=create_using)
-        except Exception as err:
-            raise nx.NetworkXError("Input is not a valid edge list") from err
-
-    raise nx.NetworkXError("Input is not a known data type for conversion.")
-
-
-@nx._dispatch
-def to_dict_of_lists(G, nodelist=None):
-    """Returns adjacency representation of graph as a dictionary of lists.
+    Examples
+    --------
+    To create the undirected GN graph, use the :meth:`~DiGraph.to_directed`
+    method::
 
-    Parameters
-    ----------
-    G : graph
-       A NetworkX graph
+    >>> D = nx.gn_graph(10)  # the GN graph
+    >>> G = D.to_undirected()  # the undirected version
 
-    nodelist : list
-       Use only nodes specified in nodelist
+    To specify an attachment kernel, use the `kernel` keyword argument::
 
-    Notes
-    -----
-    Completely ignores edge data for MultiGraph and MultiDiGraph.
+    >>> D = nx.gn_graph(10, kernel=lambda x: x**1.5)  # A_k = k^1.5
 
+    References
+    ----------
+    .. [1] P. L. Krapivsky and S. Redner,
+           Organization of Growing Random Networks,
+           Phys. Rev. E, 63, 066123, 2001.
     """
-    if nodelist is None:
-        nodelist = G
+    G = empty_graph(1, create_using, default=nx.DiGraph)
+    if not G.is_directed():
+        raise nx.NetworkXError("create_using must indicate a Directed Graph")
+
+    if kernel is None:
+
+        def kernel(x):
+            return x
+
+    if n == 1:
+        return G
+
+    G.add_edge(1, 0)  # get started
+    ds = [1, 1]  # degree sequence
+
+    for source in range(2, n):
+        # compute distribution from kernel and degree
+        dist = [kernel(d) for d in ds]
+        # choose target from discrete distribution
+        target = discrete_sequence(1, distribution=dist, seed=seed)[0]
+        G.add_edge(source, target)
+        ds.append(1)  # the source has only one link (degree one)
+        ds[target] += 1  # add one to the target link degree
+    return G
 
-    d = {}
-    for n in nodelist:
-        d[n] = [nbr for nbr in G.neighbors(n) if nbr in nodelist]
-    return d
 
+@py_random_state(3)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def gnr_graph(n, p, create_using=None, seed=None):
+    """Returns the growing network with redirection (GNR) digraph with `n`
+    nodes and redirection probability `p`.
+
+    The GNR graph is built by adding nodes one at a time with a link to one
+    previously added node.  The previous target node is chosen uniformly at
+    random.  With probability `p` the link is instead "redirected" to the
+    successor node of the target.
 
-@nx._dispatch(graphs=None)
-def from_dict_of_lists(d, create_using=None):
-    """Returns a graph from a dictionary of lists.
+    The graph is always a (directed) tree.
 
     Parameters
     ----------
-    d : dictionary of lists
-      A dictionary of lists adjacency representation.
-
-    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+    n : int
+        The number of nodes for the generated graph.
+    p : float
+        The redirection probability.
+    create_using : NetworkX graph constructor, optional (default DiGraph)
         Graph type to create. If graph instance, then cleared before populated.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
     Examples
     --------
-    >>> dol = {0: [1]}  # single edge (0,1)
-    >>> G = nx.from_dict_of_lists(dol)
+    To create the undirected GNR graph, use the :meth:`~DiGraph.to_directed`
+    method::
 
-    or
-
-    >>> G = nx.Graph(dol)  # use Graph constructor
+    >>> D = nx.gnr_graph(10, 0.5)  # the GNR graph
+    >>> G = D.to_undirected()  # the undirected version
 
+    References
+    ----------
+    .. [1] P. L. Krapivsky and S. Redner,
+           Organization of Growing Random Networks,
+           Phys. Rev. E, 63, 066123, 2001.
     """
-    G = nx.empty_graph(0, create_using)
-    G.add_nodes_from(d)
-    if G.is_multigraph() and not G.is_directed():
-        # a dict_of_lists can't show multiedges.  BUT for undirected graphs,
-        # each edge shows up twice in the dict_of_lists.
-        # So we need to treat this case separately.
-        seen = {}
-        for node, nbrlist in d.items():
-            for nbr in nbrlist:
-                if nbr not in seen:
-                    G.add_edge(node, nbr)
-            seen[node] = 1  # don't allow reverse edge to show up
-    else:
-        G.add_edges_from(
-            ((node, nbr) for node, nbrlist in d.items() for nbr in nbrlist)
-        )
+    G = empty_graph(1, create_using, default=nx.DiGraph)
+    if not G.is_directed():
+        raise nx.NetworkXError("create_using must indicate a Directed Graph")
+
+    if n == 1:
+        return G
+
+    for source in range(1, n):
+        target = seed.randrange(0, source)
+        if seed.random() < p and target != 0:
+            target = next(G.successors(target))
+        G.add_edge(source, target)
     return G
 
 
-def to_dict_of_dicts(G, nodelist=None, edge_data=None):
-    """Returns adjacency representation of graph as a dictionary of dictionaries.
+@py_random_state(2)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def gnc_graph(n, create_using=None, seed=None):
+    """Returns the growing network with copying (GNC) digraph with `n` nodes.
+
+    The GNC graph is built by adding nodes one at a time with a link to one
+    previously added node (chosen uniformly at random) and to all of that
+    node's successors.
 
     Parameters
     ----------
-    G : graph
-       A NetworkX graph
+    n : int
+        The number of nodes for the generated graph.
+    create_using : NetworkX graph constructor, optional (default DiGraph)
+        Graph type to create. If graph instance, then cleared before populated.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
+
+    References
+    ----------
+    .. [1] P. L. Krapivsky and S. Redner,
+           Network Growth by Copying,
+           Phys. Rev. E, 71, 036118, 2005k.},
+    """
+    G = empty_graph(1, create_using, default=nx.DiGraph)
+    if not G.is_directed():
+        raise nx.NetworkXError("create_using must indicate a Directed Graph")
+
+    if n == 1:
+        return G
+
+    for source in range(1, n):
+        target = seed.randrange(0, source)
+        for succ in G.successors(target):
+            G.add_edge(source, succ)
+        G.add_edge(source, target)
+    return G
+
 
-    nodelist : list
-       Use only nodes specified in nodelist
+@py_random_state(6)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def scale_free_graph(
+    n,
+    alpha=0.41,
+    beta=0.54,
+    gamma=0.05,
+    delta_in=0.2,
+    delta_out=0,
+    seed=None,
+    initial_graph=None,
+):
+    """Returns a scale-free directed graph.
 
-    edge_data : scalar, optional
-       If provided, the value of the dictionary will be set to `edge_data` for
-       all edges. Usual values could be `1` or `True`. If `edge_data` is
-       `None` (the default), the edgedata in `G` is used, resulting in a
-       dict-of-dict-of-dicts. If `G` is a MultiGraph, the result will be a
-       dict-of-dict-of-dict-of-dicts. See Notes for an approach to customize
-       handling edge data. `edge_data` should *not* be a container.
+    Parameters
+    ----------
+    n : integer
+        Number of nodes in graph
+    alpha : float
+        Probability for adding a new node connected to an existing node
+        chosen randomly according to the in-degree distribution.
+    beta : float
+        Probability for adding an edge between two existing nodes.
+        One existing node is chosen randomly according the in-degree
+        distribution and the other chosen randomly according to the out-degree
+        distribution.
+    gamma : float
+        Probability for adding a new node connected to an existing node
+        chosen randomly according to the out-degree distribution.
+    delta_in : float
+        Bias for choosing nodes from in-degree distribution.
+    delta_out : float
+        Bias for choosing nodes from out-degree distribution.
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
+    initial_graph : MultiDiGraph instance, optional
+        Build the scale-free graph starting from this initial MultiDiGraph,
+        if provided.
 
     Returns
     -------
-    dod : dict
-       A nested dictionary representation of `G`. Note that the level of
-       nesting depends on the type of `G` and the value of `edge_data`
-       (see Examples).
+    MultiDiGraph
 
-    See Also
+    Examples
     --------
-    from_dict_of_dicts, to_dict_of_lists
+    Create a scale-free graph on one hundred nodes::
+
+    >>> G = nx.scale_free_graph(100)
 
     Notes
     -----
-    For a more custom approach to handling edge data, try::
+    The sum of `alpha`, `beta`, and `gamma` must be 1.
 
-        dod = {
-            n: {
-                nbr: custom(n, nbr, dd) for nbr, dd in nbrdict.items()
-            }
-            for n, nbrdict in G.adj.items()
-        }
+    References
+    ----------
+    .. [1] B. Bollobás, C. Borgs, J. Chayes, and O. Riordan,
+           Directed scale-free graphs,
+           Proceedings of the fourteenth annual ACM-SIAM Symposium on
+           Discrete Algorithms, 132--139, 2003.
+    """
 
-    where `custom` returns the desired edge data for each edge between `n` and
-    `nbr`, given existing edge data `dd`.
+    def _choose_node(candidates, node_list, delta):
+        if delta > 0:
+            bias_sum = len(node_list) * delta
+            p_delta = bias_sum / (bias_sum + len(candidates))
+            if seed.random() < p_delta:
+                return seed.choice(node_list)
+        return seed.choice(candidates)
+
+    if initial_graph is not None and hasattr(initial_graph, "_adj"):
+        if not isinstance(initial_graph, nx.MultiDiGraph):
+            raise nx.NetworkXError("initial_graph must be a MultiDiGraph.")
+        G = initial_graph
+    else:
+        # Start with 3-cycle
+        G = nx.MultiDiGraph([(0, 1), (1, 2), (2, 0)])
+
+    if alpha <= 0:
+        raise ValueError("alpha must be > 0.")
+    if beta <= 0:
+        raise ValueError("beta must be > 0.")
+    if gamma <= 0:
+        raise ValueError("gamma must be > 0.")
+
+    if abs(alpha + beta + gamma - 1.0) >= 1e-9:
+        raise ValueError("alpha+beta+gamma must equal 1.")
+
+    if delta_in < 0:
+        raise ValueError("delta_in must be >= 0.")
+
+    if delta_out < 0:
+        raise ValueError("delta_out must be >= 0.")
+
+    # pre-populate degree states
+    vs = sum((count * [idx] for idx, count in G.out_degree()), [])
+    ws = sum((count * [idx] for idx, count in G.in_degree()), [])
+
+    # pre-populate node state
+    node_list = list(G.nodes())
+
+    # see if there already are number-based nodes
+    numeric_nodes = [n for n in node_list if isinstance(n, numbers.Number)]
+    if len(numeric_nodes) > 0:
+        # set cursor for new nodes appropriately
+        cursor = max(int(n.real) for n in numeric_nodes) + 1
+    else:
+        # or start at zero
+        cursor = 0
+
+    while len(G) < n:
+        r = seed.random()
+
+        # random choice in alpha,beta,gamma ranges
+        if r < alpha:
+            # alpha
+            # add new node v
+            v = cursor
+            cursor += 1
+            # also add to node state
+            node_list.append(v)
+            # choose w according to in-degree and delta_in
+            w = _choose_node(ws, node_list, delta_in)
+
+        elif r < alpha + beta:
+            # beta
+            # choose v according to out-degree and delta_out
+            v = _choose_node(vs, node_list, delta_out)
+            # choose w according to in-degree and delta_in
+            w = _choose_node(ws, node_list, delta_in)
+
+        else:
+            # gamma
+            # choose v according to out-degree and delta_out
+            v = _choose_node(vs, node_list, delta_out)
+            # add new node w
+            w = cursor
+            cursor += 1
+            # also add to node state
+            node_list.append(w)
+
+        # add edge to graph
+        G.add_edge(v, w)
+
+        # update degree states
+        vs.append(v)
+        ws.append(w)
+
+    return G
 
-    Examples
-    --------
-    >>> G = nx.path_graph(3)
-    >>> nx.to_dict_of_dicts(G)
-    {0: {1: {}}, 1: {0: {}, 2: {}}, 2: {1: {}}}
-
-    Edge data is preserved by default (``edge_data=None``), resulting
-    in dict-of-dict-of-dicts where the innermost dictionary contains the
-    edge data:
-
-    >>> G = nx.Graph()
-    >>> G.add_edges_from(
-    ...     [
-    ...         (0, 1, {'weight': 1.0}),
-    ...         (1, 2, {'weight': 2.0}),
-    ...         (2, 0, {'weight': 1.0}),
-    ...     ]
-    ... )
-    >>> d = nx.to_dict_of_dicts(G)
-    >>> d  # doctest: +SKIP
-    {0: {1: {'weight': 1.0}, 2: {'weight': 1.0}},
-     1: {0: {'weight': 1.0}, 2: {'weight': 2.0}},
-     2: {1: {'weight': 2.0}, 0: {'weight': 1.0}}}
-    >>> d[1][2]['weight']
-    2.0
-
-    If `edge_data` is not `None`, edge data in the original graph (if any) is
-    replaced:
-
-    >>> d = nx.to_dict_of_dicts(G, edge_data=1)
-    >>> d
-    {0: {1: 1, 2: 1}, 1: {0: 1, 2: 1}, 2: {1: 1, 0: 1}}
-    >>> d[1][2]
-    1
-
-    This also applies to MultiGraphs: edge data is preserved by default:
-
-    >>> G = nx.MultiGraph()
-    >>> G.add_edge(0, 1, key='a', weight=1.0)
-    'a'
-    >>> G.add_edge(0, 1, key='b', weight=5.0)
-    'b'
-    >>> d = nx.to_dict_of_dicts(G)
-    >>> d  # doctest: +SKIP
-    {0: {1: {'a': {'weight': 1.0}, 'b': {'weight': 5.0}}},
-     1: {0: {'a': {'weight': 1.0}, 'b': {'weight': 5.0}}}}
-    >>> d[0][1]['b']['weight']
-    5.0
-
-    But multi edge data is lost if `edge_data` is not `None`:
-
-    >>> d = nx.to_dict_of_dicts(G, edge_data=10)
-    >>> d
-    {0: {1: 10}, 1: {0: 10}}
-    """
-    dod = {}
-    if nodelist is None:
-        if edge_data is None:
-            for u, nbrdict in G.adjacency():
-                dod[u] = nbrdict.copy()
-        else:  # edge_data is not None
-            for u, nbrdict in G.adjacency():
-                dod[u] = dod.fromkeys(nbrdict, edge_data)
-    else:  # nodelist is not None
-        if edge_data is None:
-            for u in nodelist:
-                dod[u] = {}
-                for v, data in ((v, data) for v, data in G[u].items() if v in nodelist):
-                    dod[u][v] = data
-        else:  # nodelist and edge_data are not None
-            for u in nodelist:
-                dod[u] = {}
-                for v in (v for v in G[u] if v in nodelist):
-                    dod[u][v] = edge_data
-    return dod
-
-
-@nx._dispatch(graphs=None)
-def from_dict_of_dicts(d, create_using=None, multigraph_input=False):
-    """Returns a graph from a dictionary of dictionaries.
+
+@py_random_state(4)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def random_uniform_k_out_graph(n, k, self_loops=True, with_replacement=True, seed=None):
+    """Returns a random `k`-out graph with uniform attachment.
+
+    A random `k`-out graph with uniform attachment is a multidigraph
+    generated by the following algorithm. For each node *u*, choose
+    `k` nodes *v* uniformly at random (with replacement). Add a
+    directed edge joining *u* to *v*.
 
     Parameters
     ----------
-    d : dictionary of dictionaries
-      A dictionary of dictionaries adjacency representation.
+    n : int
+        The number of nodes in the returned graph.
 
-    create_using : NetworkX graph constructor, optional (default=nx.Graph)
-        Graph type to create. If graph instance, then cleared before populated.
+    k : int
+        The out-degree of each node in the returned graph.
 
-    multigraph_input : bool (default False)
-       When True, the dict `d` is assumed
-       to be a dict-of-dict-of-dict-of-dict structure keyed by
-       node to neighbor to edge keys to edge data for multi-edges.
-       Otherwise this routine assumes dict-of-dict-of-dict keyed by
-       node to neighbor to edge data.
+    self_loops : bool
+        If True, self-loops are allowed when generating the graph.
 
-    Examples
+    with_replacement : bool
+        If True, neighbors are chosen with replacement and the
+        returned graph will be a directed multigraph. Otherwise,
+        neighbors are chosen without replacement and the returned graph
+        will be a directed graph.
+
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
+
+    Returns
+    -------
+    NetworkX graph
+        A `k`-out-regular directed graph generated according to the
+        above algorithm. It will be a multigraph if and only if
+        `with_replacement` is True.
+
+    Raises
+    ------
+    ValueError
+        If `with_replacement` is False and `k` is greater than
+        `n`.
+
+    See also
     --------
-    >>> dod = {0: {1: {"weight": 1}}}  # single edge (0,1)
-    >>> G = nx.from_dict_of_dicts(dod)
+    random_k_out_graph
 
-    or
+    Notes
+    -----
+    The return digraph or multidigraph may not be strongly connected, or
+    even weakly connected.
 
-    >>> G = nx.Graph(dod)  # use Graph constructor
+    If `with_replacement` is True, this function is similar to
+    :func:`random_k_out_graph`, if that function had parameter `alpha`
+    set to positive infinity.
 
     """
-    G = nx.empty_graph(0, create_using)
-    G.add_nodes_from(d)
-    # does dict d represent a MultiGraph or MultiDiGraph?
-    if multigraph_input:
-        if G.is_directed():
-            if G.is_multigraph():
-                G.add_edges_from(
-                    (u, v, key, data)
-                    for u, nbrs in d.items()
-                    for v, datadict in nbrs.items()
-                    for key, data in datadict.items()
-                )
-            else:
-                G.add_edges_from(
-                    (u, v, data)
-                    for u, nbrs in d.items()
-                    for v, datadict in nbrs.items()
-                    for key, data in datadict.items()
-                )
-        else:  # Undirected
-            if G.is_multigraph():
-                seen = set()  # don't add both directions of undirected graph
-                for u, nbrs in d.items():
-                    for v, datadict in nbrs.items():
-                        if (u, v) not in seen:
-                            G.add_edges_from(
-                                (u, v, key, data) for key, data in datadict.items()
-                            )
-                            seen.add((v, u))
-            else:
-                seen = set()  # don't add both directions of undirected graph
-                for u, nbrs in d.items():
-                    for v, datadict in nbrs.items():
-                        if (u, v) not in seen:
-                            G.add_edges_from(
-                                (u, v, data) for key, data in datadict.items()
-                            )
-                            seen.add((v, u))
-
-    else:  # not a multigraph to multigraph transfer
-        if G.is_multigraph() and not G.is_directed():
-            # d can have both representations u-v, v-u in dict.  Only add one.
-            # We don't need this check for digraphs since we add both directions,
-            # or for Graph() since it is done implicitly (parallel edges not allowed)
-            seen = set()
-            for u, nbrs in d.items():
-                for v, data in nbrs.items():
-                    if (u, v) not in seen:
-                        G.add_edge(u, v, key=0)
-                        G[u][v][0].update(data)
-                    seen.add((v, u))
-        else:
-            G.add_edges_from(
-                ((u, v, data) for u, nbrs in d.items() for v, data in nbrs.items())
-            )
-    return G
-
+    if with_replacement:
+        create_using = nx.MultiDiGraph()
 
-@nx._dispatch(preserve_edge_attrs=True)
-def to_edgelist(G, nodelist=None):
-    """Returns a list of edges in the graph.
+        def sample(v, nodes):
+            if not self_loops:
+                nodes = nodes - {v}
+            return (seed.choice(list(nodes)) for i in range(k))
 
-    Parameters
-    ----------
-    G : graph
-       A NetworkX graph
+    else:
+        create_using = nx.DiGraph()
 
-    nodelist : list
-       Use only nodes specified in nodelist
+        def sample(v, nodes):
+            if not self_loops:
+                nodes = nodes - {v}
+            return seed.sample(list(nodes), k)
+
+    G = nx.empty_graph(n, create_using)
+    nodes = set(G)
+    for u in G:
+        G.add_edges_from((u, v) for v in sample(u, nodes))
+    return G
 
-    """
-    if nodelist is None:
-        return G.edges(data=True)
-    return G.edges(nodelist, data=True)
 
+@py_random_state(4)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def random_k_out_graph(n, k, alpha, self_loops=True, seed=None):
+    """Returns a random `k`-out graph with preferential attachment.
+
+    A random `k`-out graph with preferential attachment is a
+    multidigraph generated by the following algorithm.
+
+    1. Begin with an empty digraph, and initially set each node to have
+       weight `alpha`.
+    2. Choose a node `u` with out-degree less than `k` uniformly at
+       random.
+    3. Choose a node `v` from with probability proportional to its
+       weight.
+    4. Add a directed edge from `u` to `v`, and increase the weight
+       of `v` by one.
+    5. If each node has out-degree `k`, halt, otherwise repeat from
+       step 2.
 
-@nx._dispatch(graphs=None)
-def from_edgelist(edgelist, create_using=None):
-    """Returns a graph from a list of edges.
+    For more information on this model of random graph, see [1].
 
     Parameters
     ----------
-    edgelist : list or iterator
-      Edge tuples
+    n : int
+        The number of nodes in the returned graph.
 
-    create_using : NetworkX graph constructor, optional (default=nx.Graph)
-        Graph type to create. If graph instance, then cleared before populated.
+    k : int
+        The out-degree of each node in the returned graph.
 
-    Examples
-    --------
-    >>> edgelist = [(0, 1)]  # single edge (0,1)
-    >>> G = nx.from_edgelist(edgelist)
+    alpha : float
+        A positive :class:`float` representing the initial weight of
+        each vertex. A higher number means that in step 3 above, nodes
+        will be chosen more like a true uniformly random sample, and a
+        lower number means that nodes are more likely to be chosen as
+        their in-degree increases. If this parameter is not positive, a
+        :exc:`ValueError` is raised.
+
+    self_loops : bool
+        If True, self-loops are allowed when generating the graph.
+
+    seed : integer, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
 
-    or
+    Returns
+    -------
+    :class:`~networkx.classes.MultiDiGraph`
+        A `k`-out-regular multidigraph generated according to the above
+        algorithm.
+
+    Raises
+    ------
+    ValueError
+        If `alpha` is not positive.
 
-    >>> G = nx.Graph(edgelist)  # use Graph constructor
+    Notes
+    -----
+    The returned multidigraph may not be strongly connected, or even
+    weakly connected.
+
+    References
+    ----------
+    [1]: Peterson, Nicholas R., and Boris Pittel.
+         "Distance between two random `k`-out digraphs, with and without
+         preferential attachment."
+         arXiv preprint arXiv:1311.5961 (2013).
+         <https://arxiv.org/abs/1311.5961>
 
     """
-    G = nx.empty_graph(0, create_using)
-    G.add_edges_from(edgelist)
+    if alpha < 0:
+        raise ValueError("alpha must be positive")
+    G = nx.empty_graph(n, create_using=nx.MultiDiGraph)
+    weights = Counter({v: alpha for v in G})
+    for i in range(k * n):
+        u = seed.choice([v for v, d in G.out_degree() if d < k])
+        # If self-loops are not allowed, make the source node `u` have
+        # weight zero.
+        if not self_loops:
+            adjustment = Counter({u: weights[u]})
+        else:
+            adjustment = Counter()
+        v = weighted_choice(weights - adjustment, seed=seed)
+        G.add_edge(u, v)
+        weights[v] += 1
     return G
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `networkx-3.2rc0/networkx/convert_matrix.py` & `networkx-3.3rc0/networkx/convert_matrix.py`

 * *Files 3% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     "from_scipy_sparse_array",
     "to_scipy_sparse_array",
     "from_numpy_array",
     "to_numpy_array",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def to_pandas_adjacency(
     G,
     nodelist=None,
     dtype=None,
     order=None,
     multigraph_weight=sum,
     weight="weight",
@@ -97,28 +97,29 @@
     When `nodelist` does not contain every node in `G`, the matrix is built
     from the subgraph of `G` that is induced by the nodes in `nodelist`.
 
     The convention used for self-loop edges in graphs is to assign the
     diagonal matrix entry value to the weight attribute of the edge
     (or the number 1 if the edge has no weight attribute).  If the
     alternate convention of doubling the edge weight is desired the
-    resulting Pandas DataFrame can be modified as follows:
+    resulting Pandas DataFrame can be modified as follows::
 
-    >>> import pandas as pd
-    >>> pd.options.display.max_columns = 20
-    >>> import numpy as np
-    >>> G = nx.Graph([(1, 1)])
-    >>> df = nx.to_pandas_adjacency(G, dtype=int)
-    >>> df
-       1
-    1  1
-    >>> df.values[np.diag_indices_from(df)] *= 2
-    >>> df
-       1
-    1  2
+        >>> import pandas as pd
+        >>> G = nx.Graph([(1, 1), (2, 2)])
+        >>> df = nx.to_pandas_adjacency(G)
+        >>> df
+             1    2
+        1  1.0  0.0
+        2  0.0  1.0
+        >>> diag_idx = list(range(len(df)))
+        >>> df.iloc[diag_idx, diag_idx] *= 2
+        >>> df
+             1    2
+        1  2.0  0.0
+        2  0.0  2.0
 
     Examples
     --------
     >>> G = nx.MultiDiGraph()
     >>> G.add_edge(0, 1, weight=2)
     0
     >>> G.add_edge(1, 0)
@@ -146,15 +147,15 @@
         nonedge=nonedge,
     )
     if nodelist is None:
         nodelist = list(G)
     return pd.DataFrame(data=M, index=nodelist, columns=nodelist)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_pandas_adjacency(df, create_using=None):
     r"""Returns a graph from Pandas DataFrame.
 
     The Pandas DataFrame is interpreted as an adjacency matrix for the graph.
 
     Parameters
     ----------
@@ -168,14 +169,22 @@
     -----
     For directed graphs, explicitly mention create_using=nx.DiGraph,
     and entry i,j of df corresponds to an edge from i to j.
 
     If `df` has a single data type for each entry it will be converted to an
     appropriate Python data type.
 
+    If you have node attributes stored in a separate dataframe `df_nodes`,
+    you can load those attributes to the graph `G` using the following code:
+
+    ```
+    df_nodes = pd.DataFrame({"node_id": [1, 2, 3], "attribute1": ["A", "B", "C"]})
+    G.add_nodes_from((n, dict(d)) for n, d in df_nodes.iterrows())
+    ```
+
     If `df` has a user-specified compound data type the names
     of the data fields will be used as attribute keys in the resulting
     NetworkX graph.
 
     See Also
     --------
     to_pandas_adjacency
@@ -207,15 +216,15 @@
     A = df.values
     G = from_numpy_array(A, create_using=create_using)
 
     nx.relabel.relabel_nodes(G, dict(enumerate(df.columns)), copy=False)
     return G
 
 
-@nx._dispatch(preserve_edge_attrs=True)
+@nx._dispatchable(preserve_edge_attrs=True)
 def to_pandas_edgelist(
     G,
     source="source",
     target="target",
     nodelist=None,
     dtype=None,
     edge_key=None,
@@ -261,17 +270,17 @@
     ... )
     >>> df = nx.to_pandas_edgelist(G, nodelist=["A", "C"])
     >>> df[["source", "target", "cost", "weight"]]
       source target  cost  weight
     0      A      B     1       7
     1      C      E     9      10
 
-    >>> G = nx.MultiGraph([('A', 'B', {'cost': 1}), ('A', 'B', {'cost': 9})])
-    >>> df = nx.to_pandas_edgelist(G, nodelist=['A', 'C'], edge_key='ekey')
-    >>> df[['source', 'target', 'cost', 'ekey']]
+    >>> G = nx.MultiGraph([("A", "B", {"cost": 1}), ("A", "B", {"cost": 9})])
+    >>> df = nx.to_pandas_edgelist(G, nodelist=["A", "C"], edge_key="ekey")
+    >>> df[["source", "target", "cost", "ekey"]]
       source target  cost  ekey
     0      A      B     1     0
     1      A      B     9     1
 
     """
     import pandas as pd
 
@@ -299,15 +308,15 @@
     else:
         edgelistdict = {source: source_nodes, target: target_nodes}
 
     edgelistdict.update(edge_attr)
     return pd.DataFrame(edgelistdict, dtype=dtype)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_pandas_edgelist(
     df,
     source="source",
     target="target",
     edge_attr=None,
     create_using=None,
     edge_key=None,
@@ -347,14 +356,22 @@
         Graph type to create. If graph instance, then cleared before populated.
 
     edge_key : str or None, optional (default=None)
         A valid column name for the edge keys (for a MultiGraph). The values in
         this column are used for the edge keys when adding edges if create_using
         is a multigraph.
 
+    If you have node attributes stored in a separate dataframe `df_nodes`,
+    you can load those attributes to the graph `G` using the following code:
+
+    ```
+    df_nodes = pd.DataFrame({"node_id": [1, 2, 3], "attribute1": ["A", "B", "C"]})
+    G.add_nodes_from((n, dict(d)) for n, d in df_nodes.iterrows())
+    ```
+
     See Also
     --------
     to_pandas_edgelist
 
     Examples
     --------
     Simple integer weights on edges:
@@ -422,15 +439,15 @@
     reserved_columns = [source, target]
 
     # Additional columns requested
     attr_col_headings = []
     attribute_data = []
     if edge_attr is True:
         attr_col_headings = [c for c in df.columns if c not in reserved_columns]
-    elif isinstance(edge_attr, (list, tuple)):
+    elif isinstance(edge_attr, list | tuple):
         attr_col_headings = edge_attr
     else:
         attr_col_headings = [edge_attr]
     if len(attr_col_headings) == 0:
         raise nx.NetworkXError(
             f"Invalid edge_attr argument: No columns found with name: {attr_col_headings}"
         )
@@ -463,15 +480,15 @@
         for s, t, attrs in zip(df[source], df[target], attribute_data):
             g.add_edge(s, t)
             g[s][t].update(zip(attr_col_headings, attrs))
 
     return g
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def to_scipy_sparse_array(G, nodelist=None, dtype=None, weight="weight", format="csr"):
     """Returns the graph adjacency matrix as a SciPy sparse array.
 
     Parameters
     ----------
     G : graph
         The NetworkX graph used to construct the sparse matrix.
@@ -603,47 +620,50 @@
 
 def _csr_gen_triples(A):
     """Converts a SciPy sparse array in **Compressed Sparse Row** format to
     an iterable of weighted edge triples.
 
     """
     nrows = A.shape[0]
-    data, indices, indptr = A.data, A.indices, A.indptr
-    for i in range(nrows):
-        for j in range(indptr[i], indptr[i + 1]):
-            yield i, int(indices[j]), data[j]
+    indptr, dst_indices, data = A.indptr, A.indices, A.data
+    import numpy as np
+
+    src_indices = np.repeat(np.arange(nrows), np.diff(indptr))
+    return zip(src_indices.tolist(), dst_indices.tolist(), A.data.tolist())
 
 
 def _csc_gen_triples(A):
     """Converts a SciPy sparse array in **Compressed Sparse Column** format to
     an iterable of weighted edge triples.
 
     """
     ncols = A.shape[1]
-    data, indices, indptr = A.data, A.indices, A.indptr
-    for i in range(ncols):
-        for j in range(indptr[i], indptr[i + 1]):
-            yield int(indices[j]), i, data[j]
+    indptr, src_indices, data = A.indptr, A.indices, A.data
+    import numpy as np
+
+    dst_indices = np.repeat(np.arange(ncols), np.diff(indptr))
+    return zip(src_indices.tolist(), dst_indices.tolist(), A.data.tolist())
 
 
 def _coo_gen_triples(A):
     """Converts a SciPy sparse array in **Coordinate** format to an iterable
     of weighted edge triples.
 
     """
-    return ((int(i), int(j), d) for i, j, d in zip(A.row, A.col, A.data))
+    return zip(A.row.tolist(), A.col.tolist(), A.data.tolist())
 
 
 def _dok_gen_triples(A):
     """Converts a SciPy sparse array in **Dictionary of Keys** format to an
     iterable of weighted edge triples.
 
     """
     for (r, c), v in A.items():
-        yield r, c, v
+        # Use `v.item()` to convert a NumPy scalar to the appropriate Python scalar
+        yield int(r), int(c), v.item()
 
 
 def _generate_weighted_edges(A):
     """Returns an iterable over (u, v, w) triples, where u and v are adjacent
     vertices and w is the weight of the edge joining u and v.
 
     `A` is a SciPy sparse array (in any format).
@@ -655,15 +675,15 @@
         return _csc_gen_triples(A)
     if A.format == "dok":
         return _dok_gen_triples(A)
     # If A is in any other format (including COO), convert it to COO format.
     return _coo_gen_triples(A.tocoo())
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_scipy_sparse_array(
     A, parallel_edges=False, create_using=None, edge_attribute="weight"
 ):
     """Creates a new graph from an adjacency matrix given as a SciPy sparse
     array.
 
     Parameters
@@ -716,17 +736,15 @@
     AtlasView({0: {'weight': 2}})
 
     If `create_using` indicates a multigraph and the matrix has only integer
     entries and `parallel_edges` is True, then the entries will be treated
     as the number of parallel edges joining those two vertices:
 
     >>> A = sp.sparse.csr_array([[1, 1], [1, 2]])
-    >>> G = nx.from_scipy_sparse_array(
-    ...     A, parallel_edges=True, create_using=nx.MultiGraph
-    ... )
+    >>> G = nx.from_scipy_sparse_array(A, parallel_edges=True, create_using=nx.MultiGraph)
     >>> G[1][1]
     AtlasView({0: {'weight': 1}, 1: {'weight': 1}})
 
     """
     G = nx.empty_graph(0, create_using)
     n, m = A.shape
     if n != m:
@@ -760,15 +778,15 @@
     # when `G.add_weighted_edges_from()` is invoked below.
     if G.is_multigraph() and not G.is_directed():
         triples = ((u, v, d) for u, v, d in triples if u <= v)
     G.add_weighted_edges_from(triples, weight=edge_attribute)
     return G
 
 
-@nx._dispatch(edge_attrs="weight")  # edge attrs may also be obtained from `dtype`
+@nx._dispatchable(edge_attrs="weight")  # edge attrs may also be obtained from `dtype`
 def to_numpy_array(
     G,
     nodelist=None,
     dtype=None,
     order=None,
     multigraph_weight=sum,
     weight="weight",
@@ -914,15 +932,15 @@
     makes it much clearer to differentiate such 0-weighted edges and actual nonedge values.
 
     >>> G = nx.Graph()
     >>> G.add_edge(3, 1, weight=2)
     >>> G.add_edge(2, 0, weight=0)
     >>> G.add_edge(2, 1, weight=0)
     >>> G.add_edge(3, 0, weight=1)
-    >>> nx.to_numpy_array(G, nonedge=-1.)
+    >>> nx.to_numpy_array(G, nonedge=-1.0)
     array([[-1.,  2., -1.,  1.],
            [ 2., -1.,  0., -1.],
            [-1.,  0., -1.,  0.],
            [ 1., -1.,  0., -1.]])
     """
     import numpy as np
 
@@ -999,15 +1017,15 @@
     A[i, j] = wts
     if not G.is_directed():
         A[j, i] = wts
 
     return A
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_numpy_array(A, parallel_edges=False, create_using=None, edge_attr="weight"):
     """Returns a graph from a 2D NumPy array.
 
     The 2D NumPy array is interpreted as an adjacency matrix for the graph.
 
     Parameters
     ----------
@@ -1133,20 +1151,20 @@
         fields = sorted(
             (offset, dtype, name) for name, (dtype, offset) in A.dtype.fields.items()
         )
         triples = (
             (
                 u,
                 v,
-                {
+                {}
+                if edge_attr in [False, None]
+                else {
                     name: kind_to_python_type[dtype.kind](val)
                     for (_, dtype, name), val in zip(fields, A[u, v])
-                }
-                if edge_attr
-                else {},
+                },
             )
             for u, v in edges
         )
     # If the entries in the adjacency matrix are integers, the graph is a
     # multigraph, and parallel_edges is True, then create parallel edges, each
     # with weight 1, for each entry in the adjacency matrix. Otherwise, create
     # one edge for each positive entry in the adjacency matrix and set the
@@ -1155,25 +1173,25 @@
         chain = itertools.chain.from_iterable
         # The following line is equivalent to:
         #
         #     for (u, v) in edges:
         #         for d in range(A[u, v]):
         #             G.add_edge(u, v, weight=1)
         #
-        if edge_attr:
+        if edge_attr in [False, None]:
+            triples = chain(((u, v, {}) for d in range(A[u, v])) for (u, v) in edges)
+        else:
             triples = chain(
                 ((u, v, {edge_attr: 1}) for d in range(A[u, v])) for (u, v) in edges
             )
-        else:
-            triples = chain(((u, v, {}) for d in range(A[u, v])) for (u, v) in edges)
     else:  # basic data type
-        if edge_attr:
-            triples = ((u, v, {edge_attr: python_type(A[u, v])}) for u, v in edges)
-        else:
+        if edge_attr in [False, None]:
             triples = ((u, v, {}) for u, v in edges)
+        else:
+            triples = ((u, v, {edge_attr: python_type(A[u, v])}) for u, v in edges)
     # If we are creating an undirected multigraph, only add the edges from the
     # upper triangle of the matrix. Otherwise, add all the edges. This relies
     # on the fact that the vertices created in the
     # `_generated_weighted_edges()` function are actually the row/column
     # indices for the matrix `A`.
     #
     # Without this check, we run into a problem where each edge is added twice
```

### Comparing `networkx-3.2rc0/networkx/drawing/layout.py` & `networkx-3.3rc0/networkx/drawing/layout.py`

 * *Files 3% similar despite different names*

```diff
@@ -28,14 +28,15 @@
     "shell_layout",
     "spring_layout",
     "spectral_layout",
     "planar_layout",
     "fruchterman_reingold_layout",
     "spiral_layout",
     "multipartite_layout",
+    "bfs_layout",
     "arf_layout",
 ]
 
 
 def _process_params(G, center, dim):
     # Some boilerplate code.
     import numpy as np
@@ -1026,16 +1027,17 @@
     """Position nodes in layers of straight lines.
 
     Parameters
     ----------
     G : NetworkX graph or list of nodes
         A position will be assigned to every node in G.
 
-    subset_key : string (default='subset')
-        Key of node data to be used as layer subset.
+    subset_key : string or dict (default='subset')
+        If a string, the key of node data in G that holds the node subset.
+        If a dict, keyed by layer number to the nodes in that layer/subset.
 
     align : string (default='vertical')
         The alignment of nodes. Vertical or horizontal.
 
     scale : number (default: 1)
         Scale factor for positions.
 
@@ -1048,14 +1050,20 @@
         A dictionary of positions keyed by node.
 
     Examples
     --------
     >>> G = nx.complete_multipartite_graph(28, 16, 10)
     >>> pos = nx.multipartite_layout(G)
 
+    or use a dict to provide the layers of the layout
+
+    >>> G = nx.Graph([(0, 1), (1, 2), (1, 3), (3, 4)])
+    >>> layers = {"a": [0], "b": [1], "c": [2, 3], "d": [4]}
+    >>> pos = nx.multipartite_layout(G, subset_key=layers)
+
     Notes
     -----
     This algorithm currently only works in two dimensions and does not
     try to minimize edge crossings.
 
     Network does not need to be a complete multipartite graph. As long as nodes
     have subset_key data, they will be placed in the corresponding layers.
@@ -1067,33 +1075,39 @@
         msg = "align must be either vertical or horizontal."
         raise ValueError(msg)
 
     G, center = _process_params(G, center=center, dim=2)
     if len(G) == 0:
         return {}
 
-    layers = {}
-    for v, data in G.nodes(data=True):
-        try:
-            layer = data[subset_key]
-        except KeyError:
-            msg = "all nodes must have subset_key (default='subset') as data"
-            raise ValueError(msg)
-        layers[layer] = [v] + layers.get(layer, [])
+    try:
+        # check if subset_key is dict-like
+        if len(G) != sum(len(nodes) for nodes in subset_key.values()):
+            raise nx.NetworkXError(
+                "all nodes must be in one subset of `subset_key` dict"
+            )
+    except AttributeError:
+        # subset_key is not a dict, hence a string
+        node_to_subset = nx.get_node_attributes(G, subset_key)
+        if len(node_to_subset) != len(G):
+            raise nx.NetworkXError(
+                f"all nodes need a subset_key attribute: {subset_key}"
+            )
+        subset_key = nx.utils.groups(node_to_subset)
 
     # Sort by layer, if possible
     try:
-        layers = sorted(layers.items())
+        layers = dict(sorted(subset_key.items()))
     except TypeError:
-        layers = list(layers.items())
+        layers = subset_key
 
     pos = None
     nodes = []
     width = len(layers)
-    for i, (_, layer) in enumerate(layers):
+    for i, layer in enumerate(layers.values()):
         height = len(layer)
         xs = np.repeat(i, height)
         ys = np.arange(0, height, dtype=float)
         offset = ((width - 1) / 2, (height - 1) / 2)
         layer_pos = np.column_stack([xs, ys]) - offset
         if pos is None:
             pos = layer_pos
@@ -1291,7 +1305,54 @@
     import numpy as np
 
     if not pos:  # empty_graph
         return {}
     pos_v = np.array(list(pos.values()))
     pos_v = rescale_layout(pos_v, scale=scale)
     return dict(zip(pos, pos_v))
+
+
+def bfs_layout(G, start, *, align="vertical", scale=1, center=None):
+    """Position nodes according to breadth-first search algorithm.
+
+    Parameters
+    ----------
+    G : NetworkX graph
+        A position will be assigned to every node in G.
+
+    start : node in `G`
+        Starting node for bfs
+
+    center : array-like or None
+        Coordinate pair around which to center the layout.
+
+    Returns
+    -------
+    pos : dict
+        A dictionary of positions keyed by node.
+
+    Examples
+    --------
+    >>> G = nx.path_graph(4)
+    >>> pos = nx.bfs_layout(G, 0)
+
+    Notes
+    -----
+    This algorithm currently only works in two dimensions and does not
+    try to minimize edge crossings.
+
+    """
+    G, center = _process_params(G, center, 2)
+
+    # Compute layers with BFS
+    layers = dict(enumerate(nx.bfs_layers(G, start)))
+
+    if len(G) != sum(len(nodes) for nodes in layers.values()):
+        raise nx.NetworkXError(
+            "bfs_layout didn't include all nodes. Perhaps use input graph:\n"
+            "        G.subgraph(nx.node_connected_component(G, start))"
+        )
+
+    # Compute node positions with multipartite_layout
+    return multipartite_layout(
+        G, subset_key=layers, align=align, scale=scale, center=center
+    )
```

### Comparing `networkx-3.2rc0/networkx/drawing/nx_agraph.py` & `networkx-3.3rc0/networkx/drawing/nx_agraph.py`

 * *Files 0% similar despite different names*

```diff
@@ -29,15 +29,15 @@
     "read_dot",
     "graphviz_layout",
     "pygraphviz_layout",
     "view_pygraphviz",
 ]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_agraph(A, create_using=None):
     """Returns a NetworkX Graph or DiGraph from a PyGraphviz graph.
 
     Parameters
     ----------
     A : PyGraphviz AGraph
       A graph created with PyGraphviz
@@ -129,17 +129,15 @@
     to copy properties attached to the graph (see from_agraph)
     and then updated with the calling arguments if any.
 
     """
     try:
         import pygraphviz
     except ImportError as err:
-        raise ImportError(
-            "requires pygraphviz " "http://pygraphviz.github.io/"
-        ) from err
+        raise ImportError("requires pygraphviz http://pygraphviz.github.io/") from err
     directed = N.is_directed()
     strict = nx.number_of_selfloops(N) == 0 and not N.is_multigraph()
 
     for node in N:
         if "pos" in N.nodes[node]:
             N.nodes[node]["pos"] = "{},{}!".format(
                 N.nodes[node]["pos"][0], N.nodes[node]["pos"][1]
@@ -201,28 +199,28 @@
     """
     A = to_agraph(G)
     A.write(path)
     A.clear()
     return
 
 
-@nx._dispatch(name="agraph_read_dot", graphs=None)
+@nx._dispatchable(name="agraph_read_dot", graphs=None, returns_graph=True)
 def read_dot(path):
     """Returns a NetworkX graph from a dot file on path.
 
     Parameters
     ----------
     path : file or string
        File name or file handle to read.
     """
     try:
         import pygraphviz
     except ImportError as err:
         raise ImportError(
-            "read_dot() requires pygraphviz " "http://pygraphviz.github.io/"
+            "read_dot() requires pygraphviz http://pygraphviz.github.io/"
         ) from err
     A = pygraphviz.AGraph(file=path)
     gr = from_agraph(A)
     A.clear()
     return gr
 
 
@@ -299,17 +297,15 @@
 
     Note that some graphviz layouts are not guaranteed to be deterministic,
     see https://gitlab.com/graphviz/graphviz/-/issues/1767 for more info.
     """
     try:
         import pygraphviz
     except ImportError as err:
-        raise ImportError(
-            "requires pygraphviz " "http://pygraphviz.github.io/"
-        ) from err
+        raise ImportError("requires pygraphviz http://pygraphviz.github.io/") from err
     if root is not None:
         args += f"-Groot={root}"
     A = to_agraph(G)
     A.layout(prog=prog, args=args)
     node_pos = {}
     for n in G:
         node = pygraphviz.Node(A, n)
```

### Comparing `networkx-3.2rc0/networkx/drawing/nx_latex.py` & `networkx-3.3rc0/networkx/drawing/nx_latex.py`

 * *Files 0% similar despite different names*

```diff
@@ -435,15 +435,15 @@
             edge_label_options,
         )
     else:  # iterator of graphs
         sbf = subfigure_wrapper
         size = 1 / n_rows
 
         N = len(Gbunch)
-        if isinstance(pos, (str, dict)):
+        if isinstance(pos, str | dict):
             pos = [pos] * N
         if sub_captions is None:
             sub_captions = [""] * N
         if sub_labels is None:
             sub_labels = [""] * N
         if not (len(Gbunch) == len(pos) == len(sub_captions) == len(sub_labels)):
             raise nx.NetworkXError(
```

### Comparing `networkx-3.2rc0/networkx/drawing/nx_pydot.py` & `networkx-3.3rc0/networkx/drawing/nx_pydot.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,15 +15,14 @@
 
 See Also
 --------
  - pydot:         https://github.com/erocarrera/pydot
  - Graphviz:      https://www.graphviz.org
  - DOT Language:  http://www.graphviz.org/doc/info/lang.html
 """
-import warnings
 from locale import getpreferredencoding
 
 import networkx as nx
 from networkx.utils import open_file
 
 __all__ = [
     "write_dot",
@@ -37,28 +36,21 @@
 
 @open_file(1, mode="w")
 def write_dot(G, path):
     """Write NetworkX graph G to Graphviz dot format on path.
 
     Path can be a string or a file handle.
     """
-    msg = (
-        "nx.nx_pydot.write_dot depends on the pydot package, which has "
-        "known issues and is not actively maintained. Consider using "
-        "nx.nx_agraph.write_dot instead.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
     P = to_pydot(G)
     path.write(P.to_string())
     return
 
 
 @open_file(0, mode="r")
-@nx._dispatch(name="pydot_read_dot", graphs=None)
+@nx._dispatchable(name="pydot_read_dot", graphs=None, returns_graph=True)
 def read_dot(path):
     """Returns a NetworkX :class:`MultiGraph` or :class:`MultiDiGraph` from the
     dot file with the passed path.
 
     If this file contains multiple graphs, only the first such graph is
     returned. All graphs _except_ the first are silently ignored.
 
@@ -75,32 +67,24 @@
     Notes
     -----
     Use `G = nx.Graph(nx.nx_pydot.read_dot(path))` to return a :class:`Graph` instead of a
     :class:`MultiGraph`.
     """
     import pydot
 
-    msg = (
-        "nx.nx_pydot.read_dot depends on the pydot package, which has "
-        "known issues and is not actively maintained. Consider using "
-        "nx.nx_agraph.read_dot instead.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
-
     data = path.read()
 
     # List of one or more "pydot.Dot" instances deserialized from this file.
     P_list = pydot.graph_from_dot_data(data)
 
     # Convert only the first such instance into a NetworkX graph.
     return from_pydot(P_list[0])
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_pydot(P):
     """Returns a NetworkX graph from a Pydot graph.
 
     Parameters
     ----------
     P : Pydot graph
       A graph created with Pydot
@@ -116,20 +100,14 @@
     >>> A = nx.nx_pydot.to_pydot(K5)
     >>> G = nx.nx_pydot.from_pydot(A)  # return MultiGraph
 
     # make a Graph instead of MultiGraph
     >>> G = nx.Graph(nx.nx_pydot.from_pydot(A))
 
     """
-    msg = (
-        "nx.nx_pydot.from_pydot depends on the pydot package, which has "
-        "known issues and is not actively maintained.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
 
     if P.get_strict(None):  # pydot bug: get_strict() shouldn't take argument
         multiedges = False
     else:
         multiedges = True
 
     if P.get_type() == "graph":  # undirected
@@ -216,21 +194,14 @@
 
     Notes
     -----
 
     """
     import pydot
 
-    msg = (
-        "nx.nx_pydot.to_pydot depends on the pydot package, which has "
-        "known issues and is not actively maintained.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
-
     # set Graphviz graph type
     if N.is_directed():
         graph_type = "digraph"
     else:
         graph_type = "graph"
     strict = nx.number_of_selfloops(N) == 0 and not N.is_multigraph()
 
@@ -344,22 +315,14 @@
     >>> pos = nx.nx_pydot.graphviz_layout(G)
     >>> pos = nx.nx_pydot.graphviz_layout(G, prog="dot")
 
     Notes
     -----
     This is a wrapper for pydot_layout.
     """
-    msg = (
-        "nx.nx_pydot.graphviz_layout depends on the pydot package, which has "
-        "known issues and is not actively maintained. Consider using "
-        "nx.nx_agraph.graphviz_layout instead.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
-
     return pydot_layout(G=G, prog=prog, root=root)
 
 
 def pydot_layout(G, prog="neato", root=None):
     """Create node positions using :mod:`pydot` and Graphviz.
 
     Parameters
@@ -388,27 +351,21 @@
     -----
     If you use complex node objects, they may have the same string
     representation and GraphViz could treat them as the same node.
     The layout may assign both nodes a single location. See Issue #1568
     If this occurs in your case, consider relabeling the nodes just
     for the layout computation using something similar to::
 
-        H = nx.convert_node_labels_to_integers(G, label_attribute='node_label')
-        H_layout = nx.nx_pydot.pydot_layout(G, prog='dot')
-        G_layout = {H.nodes[n]['node_label']: p for n, p in H_layout.items()}
+        H = nx.convert_node_labels_to_integers(G, label_attribute="node_label")
+        H_layout = nx.nx_pydot.pydot_layout(G, prog="dot")
+        G_layout = {H.nodes[n]["node_label"]: p for n, p in H_layout.items()}
 
     """
     import pydot
 
-    msg = (
-        "nx.nx_pydot.pydot_layout depends on the pydot package, which has "
-        "known issues and is not actively maintained.\n\n"
-        "See https://github.com/networkx/networkx/issues/5723"
-    )
-    warnings.warn(msg, DeprecationWarning, stacklevel=2)
     P = to_pydot(G)
     if root is not None:
         P.set("root", str(root))
 
     # List of low-level bytes comprising a string in the dot language converted
     # from the passed graph with the passed external GraphViz command.
     D_bytes = P.create_dot(prog=prog)
```

### Comparing `networkx-3.2rc0/networkx/drawing/nx_pylab.py` & `networkx-3.3rc0/networkx/drawing/nx_pylab.py`

 * *Files 18% similar despite different names*

```diff
@@ -12,14 +12,16 @@
 
 See Also
 --------
  - :doc:`matplotlib <matplotlib:index>`
  - :func:`matplotlib.pyplot.scatter`
  - :obj:`matplotlib.patches.FancyArrowPatch`
 """
+import collections
+import itertools
 from numbers import Number
 
 import networkx as nx
 from networkx.drawing.layout import (
     circular_layout,
     kamada_kawai_layout,
     planar_layout,
@@ -237,14 +239,19 @@
 
     font_family : string (default='sans-serif')
         Font family
 
     label : string, optional
         Label for graph legend
 
+    hide_ticks : bool, optional
+        Hide ticks of axes. When `True` (the default), ticks and ticklabels
+        are removed from the axes. To set ticks and tick labels to the pyplot default,
+        use ``hide_ticks=False``.
+
     kwds : optional keywords
         See networkx.draw_networkx_nodes(), networkx.draw_networkx_edges(), and
         networkx.draw_networkx_labels() for a description of optional keywords.
 
     Notes
     -----
     For directed graphs, arrows  are drawn at the head end.  Arrows can be
@@ -320,14 +327,15 @@
     vmin=None,
     vmax=None,
     ax=None,
     linewidths=None,
     edgecolors=None,
     label=None,
     margins=None,
+    hide_ticks=True,
 ):
     """Draw the nodes of the graph G.
 
     This draws only the nodes of the graph G.
 
     Parameters
     ----------
@@ -384,14 +392,19 @@
 
     margins : float or 2-tuple, optional
         Sets the padding for axis autoscaling. Increase margin to prevent
         clipping for nodes that are near the edges of an image. Values should
         be in the range ``[0, 1]``. See :meth:`matplotlib.axes.Axes.margins`
         for details. The default is `None`, which uses the Matplotlib default.
 
+    hide_ticks : bool, optional
+        Hide ticks of axes. When `True` (the default), ticks and ticklabels
+        are removed from the axes. To set ticks and tick labels to the pyplot default,
+        use ``hide_ticks=False``.
+
     Returns
     -------
     matplotlib.collections.PathCollection
         `PathCollection` of the nodes.
 
     Examples
     --------
@@ -444,33 +457,225 @@
         vmin=vmin,
         vmax=vmax,
         alpha=alpha,
         linewidths=linewidths,
         edgecolors=edgecolors,
         label=label,
     )
-    ax.tick_params(
-        axis="both",
-        which="both",
-        bottom=False,
-        left=False,
-        labelbottom=False,
-        labelleft=False,
-    )
+    if hide_ticks:
+        ax.tick_params(
+            axis="both",
+            which="both",
+            bottom=False,
+            left=False,
+            labelbottom=False,
+            labelleft=False,
+        )
 
     if margins is not None:
         if isinstance(margins, Iterable):
             ax.margins(*margins)
         else:
             ax.margins(margins)
 
     node_collection.set_zorder(2)
     return node_collection
 
 
+class FancyArrowFactory:
+    """Draw arrows with `matplotlib.patches.FancyarrowPatch`"""
+
+    class ConnectionStyleFactory:
+        def __init__(self, connectionstyles, selfloop_height, ax=None):
+            import matplotlib as mpl
+            import matplotlib.path  # call as mpl.path
+            import numpy as np
+
+            self.ax = ax
+            self.mpl = mpl
+            self.np = np
+            self.base_connection_styles = [
+                mpl.patches.ConnectionStyle(cs) for cs in connectionstyles
+            ]
+            self.n = len(self.base_connection_styles)
+            self.selfloop_height = selfloop_height
+
+        def curved(self, edge_index):
+            return self.base_connection_styles[edge_index % self.n]
+
+        def self_loop(self, edge_index):
+            def self_loop_connection(posA, posB, *args, **kwargs):
+                if not self.np.all(posA == posB):
+                    raise nx.NetworkXError(
+                        "`self_loop` connection style method"
+                        "is only to be used for self-loops"
+                    )
+                # this is called with _screen space_ values
+                # so convert back to data space
+                data_loc = self.ax.transData.inverted().transform(posA)
+                v_shift = 0.1 * self.selfloop_height
+                h_shift = v_shift * 0.5
+                # put the top of the loop first so arrow is not hidden by node
+                path = self.np.asarray(
+                    [
+                        # 1
+                        [0, v_shift],
+                        # 4 4 4
+                        [h_shift, v_shift],
+                        [h_shift, 0],
+                        [0, 0],
+                        # 4 4 4
+                        [-h_shift, 0],
+                        [-h_shift, v_shift],
+                        [0, v_shift],
+                    ]
+                )
+                # Rotate self loop 90 deg. if more than 1
+                # This will allow for maximum of 4 visible self loops
+                if edge_index % 4:
+                    x, y = path.T
+                    for _ in range(edge_index % 4):
+                        x, y = y, -x
+                    path = self.np.array([x, y]).T
+                return self.mpl.path.Path(
+                    self.ax.transData.transform(data_loc + path), [1, 4, 4, 4, 4, 4, 4]
+                )
+
+            return self_loop_connection
+
+    def __init__(
+        self,
+        edge_pos,
+        edgelist,
+        nodelist,
+        edge_indices,
+        node_size,
+        selfloop_height,
+        connectionstyle="arc3",
+        node_shape="o",
+        arrowstyle="-",
+        arrowsize=10,
+        edge_color="k",
+        alpha=None,
+        linewidth=1.0,
+        style="solid",
+        min_source_margin=0,
+        min_target_margin=0,
+        ax=None,
+    ):
+        import matplotlib as mpl
+        import matplotlib.patches  # call as mpl.patches
+        import matplotlib.pyplot as plt
+        import numpy as np
+
+        if isinstance(connectionstyle, str):
+            connectionstyle = [connectionstyle]
+        elif np.iterable(connectionstyle):
+            connectionstyle = list(connectionstyle)
+        else:
+            msg = "ConnectionStyleFactory arg `connectionstyle` must be str or iterable"
+            raise nx.NetworkXError(msg)
+        self.ax = ax
+        self.mpl = mpl
+        self.np = np
+        self.edge_pos = edge_pos
+        self.edgelist = edgelist
+        self.nodelist = nodelist
+        self.node_shape = node_shape
+        self.min_source_margin = min_source_margin
+        self.min_target_margin = min_target_margin
+        self.edge_indices = edge_indices
+        self.node_size = node_size
+        self.connectionstyle_factory = self.ConnectionStyleFactory(
+            connectionstyle, selfloop_height, ax
+        )
+        self.arrowstyle = arrowstyle
+        self.arrowsize = arrowsize
+        self.arrow_colors = mpl.colors.colorConverter.to_rgba_array(edge_color, alpha)
+        self.linewidth = linewidth
+        self.style = style
+        if isinstance(arrowsize, list) and len(arrowsize) != len(edge_pos):
+            raise ValueError("arrowsize should have the same length as edgelist")
+
+    def __call__(self, i):
+        (x1, y1), (x2, y2) = self.edge_pos[i]
+        shrink_source = 0  # space from source to tail
+        shrink_target = 0  # space from  head to target
+        if self.np.iterable(self.node_size):  # many node sizes
+            source, target = self.edgelist[i][:2]
+            source_node_size = self.node_size[self.nodelist.index(source)]
+            target_node_size = self.node_size[self.nodelist.index(target)]
+            shrink_source = self.to_marker_edge(source_node_size, self.node_shape)
+            shrink_target = self.to_marker_edge(target_node_size, self.node_shape)
+        else:
+            shrink_source = self.to_marker_edge(self.node_size, self.node_shape)
+            shrink_target = shrink_source
+        shrink_source = max(shrink_source, self.min_source_margin)
+        shrink_target = max(shrink_target, self.min_target_margin)
+
+        # scale factor of arrow head
+        if isinstance(self.arrowsize, list):
+            mutation_scale = self.arrowsize[i]
+        else:
+            mutation_scale = self.arrowsize
+
+        if len(self.arrow_colors) > i:
+            arrow_color = self.arrow_colors[i]
+        elif len(self.arrow_colors) == 1:
+            arrow_color = self.arrow_colors[0]
+        else:  # Cycle through colors
+            arrow_color = self.arrow_colors[i % len(self.arrow_colors)]
+
+        if self.np.iterable(self.linewidth):
+            if len(self.linewidth) > i:
+                linewidth = self.linewidth[i]
+            else:
+                linewidth = self.linewidth[i % len(self.linewidth)]
+        else:
+            linewidth = self.linewidth
+
+        if (
+            self.np.iterable(self.style)
+            and not isinstance(self.style, str)
+            and not isinstance(self.style, tuple)
+        ):
+            if len(self.style) > i:
+                linestyle = self.style[i]
+            else:  # Cycle through styles
+                linestyle = self.style[i % len(self.style)]
+        else:
+            linestyle = self.style
+
+        if x1 == x2 and y1 == y2:
+            connectionstyle = self.connectionstyle_factory.self_loop(
+                self.edge_indices[i]
+            )
+        else:
+            connectionstyle = self.connectionstyle_factory.curved(self.edge_indices[i])
+        return self.mpl.patches.FancyArrowPatch(
+            (x1, y1),
+            (x2, y2),
+            arrowstyle=self.arrowstyle,
+            shrinkA=shrink_source,
+            shrinkB=shrink_target,
+            mutation_scale=mutation_scale,
+            color=arrow_color,
+            linewidth=linewidth,
+            connectionstyle=connectionstyle,
+            linestyle=linestyle,
+            zorder=1,  # arrows go behind nodes
+        )
+
+    def to_marker_edge(self, marker_size, marker):
+        if marker in "s^>v<d":  # `large` markers need extra space
+            return self.np.sqrt(2 * marker_size) / 2
+        else:
+            return self.np.sqrt(marker_size) / 2
+
+
 def draw_networkx_edges(
     G,
     pos,
     edgelist=None,
     width=1.0,
     edge_color="k",
     style="solid",
@@ -485,14 +690,15 @@
     label=None,
     node_size=300,
     nodelist=None,
     node_shape="o",
     connectionstyle="arc3",
     min_source_margin=0,
     min_target_margin=0,
+    hide_ticks=True,
 ):
     r"""Draw the edges of the graph G.
 
     This draws only the edges of the graph G.
 
     Parameters
     ----------
@@ -557,19 +763,20 @@
         See `matplotlib.patches.ArrowStyle` for more options.
 
     arrowsize : int (default=10)
         For directed graphs, choose the size of the arrow head's length and
         width. See `matplotlib.patches.FancyArrowPatch` for attribute
         `mutation_scale` for more info.
 
-    connectionstyle : string (default="arc3")
+    connectionstyle : string or iterable of strings (default="arc3")
         Pass the connectionstyle parameter to create curved arc of rounding
         radius rad. For example, connectionstyle='arc3,rad=0.2'.
         See `matplotlib.patches.ConnectionStyle` and
         `matplotlib.patches.FancyArrowPatch` for more info.
+        If Iterable, index indicates i'th edge key of MultiGraph
 
     node_size : scalar or array (default=300)
         Size of nodes. Though the nodes are not drawn with this function, the
         node size is used in determining edge positioning.
 
     nodelist : list, optional (default=G.nodes())
        This provides the node order for the `node_size` array (if it is an array).
@@ -583,14 +790,19 @@
 
     min_source_margin : int (default=0)
         The minimum margin (gap) at the beginning of the edge at the source.
 
     min_target_margin : int (default=0)
         The minimum margin (gap) at the end of the edge at the target.
 
+    hide_ticks : bool, optional
+        Hide ticks of axes. When `True` (the default), ticks and ticklabels
+        are removed from the axes. To set ticks and tick labels to the pyplot default,
+        use ``hide_ticks=False``.
+
     Returns
     -------
      matplotlib.collections.LineCollection or a list of matplotlib.patches.FancyArrowPatch
         If ``arrows=True``, a list of FancyArrowPatches is returned.
         If ``arrows=False``, a LineCollection is returned.
         If ``arrows=None`` (the default), then a LineCollection is returned if
         `G` is undirected, otherwise returns a list of FancyArrowPatches.
@@ -641,85 +853,94 @@
     draw
     draw_networkx
     draw_networkx_nodes
     draw_networkx_labels
     draw_networkx_edge_labels
 
     """
+    import warnings
+
     import matplotlib as mpl
     import matplotlib.collections  # call as mpl.collections
     import matplotlib.colors  # call as mpl.colors
-    import matplotlib.patches  # call as mpl.patches
-    import matplotlib.path  # call as mpl.path
     import matplotlib.pyplot as plt
     import numpy as np
 
     # The default behavior is to use LineCollection to draw edges for
     # undirected graphs (for performance reasons) and use FancyArrowPatches
     # for directed graphs.
     # The `arrows` keyword can be used to override the default behavior
-    use_linecollection = not G.is_directed()
-    if arrows in (True, False):
+    if arrows is None:
+        use_linecollection = not (G.is_directed() or G.is_multigraph())
+    else:
+        if not isinstance(arrows, bool):
+            raise TypeError("Argument `arrows` must be of type bool or None")
         use_linecollection = not arrows
 
+    if isinstance(connectionstyle, str):
+        connectionstyle = [connectionstyle]
+    elif np.iterable(connectionstyle):
+        connectionstyle = list(connectionstyle)
+    else:
+        msg = "draw_networkx_edges arg `connectionstyle` must be str or iterable"
+        raise nx.NetworkXError(msg)
+
     # Some kwargs only apply to FancyArrowPatches. Warn users when they use
     # non-default values for these kwargs when LineCollection is being used
     # instead of silently ignoring the specified option
-    if use_linecollection and any(
-        [
-            arrowstyle is not None,
-            arrowsize != 10,
-            connectionstyle != "arc3",
-            min_source_margin != 0,
-            min_target_margin != 0,
-        ]
-    ):
-        import warnings
-
+    if use_linecollection:
         msg = (
             "\n\nThe {0} keyword argument is not applicable when drawing edges\n"
             "with LineCollection.\n\n"
             "To make this warning go away, either specify `arrows=True` to\n"
-            "force FancyArrowPatches or use the default value for {0}.\n"
+            "force FancyArrowPatches or use the default values.\n"
             "Note that using FancyArrowPatches may be slow for large graphs.\n"
         )
         if arrowstyle is not None:
-            msg = msg.format("arrowstyle")
+            warnings.warn(msg.format("arrowstyle"), category=UserWarning, stacklevel=2)
         if arrowsize != 10:
-            msg = msg.format("arrowsize")
-        if connectionstyle != "arc3":
-            msg = msg.format("connectionstyle")
+            warnings.warn(msg.format("arrowsize"), category=UserWarning, stacklevel=2)
         if min_source_margin != 0:
-            msg = msg.format("min_source_margin")
+            warnings.warn(
+                msg.format("min_source_margin"), category=UserWarning, stacklevel=2
+            )
         if min_target_margin != 0:
-            msg = msg.format("min_target_margin")
-        warnings.warn(msg, category=UserWarning, stacklevel=2)
-
-    if arrowstyle == None:
-        if G.is_directed():
-            arrowstyle = "-|>"
-        else:
-            arrowstyle = "-"
+            warnings.warn(
+                msg.format("min_target_margin"), category=UserWarning, stacklevel=2
+            )
+        if any(cs != "arc3" for cs in connectionstyle):
+            warnings.warn(
+                msg.format("connectionstyle"), category=UserWarning, stacklevel=2
+            )
+
+    # NOTE: Arrowstyle modification must occur after the warnings section
+    if arrowstyle is None:
+        arrowstyle = "-|>" if G.is_directed() else "-"
 
     if ax is None:
         ax = plt.gca()
 
     if edgelist is None:
-        edgelist = list(G.edges())
+        edgelist = list(G.edges)  # (u, v, k) for multigraph (u, v) otherwise
 
-    if len(edgelist) == 0:  # no edges!
+    if len(edgelist):
+        if G.is_multigraph():
+            key_count = collections.defaultdict(lambda: itertools.count(0))
+            edge_indices = [next(key_count[tuple(e[:2])]) for e in edgelist]
+        else:
+            edge_indices = [0] * len(edgelist)
+    else:  # no edges!
         return []
 
     if nodelist is None:
         nodelist = list(G.nodes())
 
     # FancyArrowPatch handles color=None different from LineCollection
     if edge_color is None:
         edge_color = "k"
-    edgelist_tuple = list(map(tuple, edgelist))
 
     # set edge positions
     edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist])
 
     # Check if edge_color is an array of floats and map to edge_cmap.
     # This is the only case handled differently from matplotlib
     if (
@@ -734,201 +955,96 @@
         if edge_vmin is None:
             edge_vmin = min(edge_color)
         if edge_vmax is None:
             edge_vmax = max(edge_color)
         color_normal = mpl.colors.Normalize(vmin=edge_vmin, vmax=edge_vmax)
         edge_color = [edge_cmap(color_normal(e)) for e in edge_color]
 
-    def _draw_networkx_edges_line_collection():
+    # compute initial view
+    minx = np.amin(np.ravel(edge_pos[:, :, 0]))
+    maxx = np.amax(np.ravel(edge_pos[:, :, 0]))
+    miny = np.amin(np.ravel(edge_pos[:, :, 1]))
+    maxy = np.amax(np.ravel(edge_pos[:, :, 1]))
+    w = maxx - minx
+    h = maxy - miny
+
+    # Self-loops are scaled by view extent, except in cases the extent
+    # is 0, e.g. for a single node. In this case, fall back to scaling
+    # by the maximum node size
+    selfloop_height = h if h != 0 else 0.005 * np.array(node_size).max()
+    fancy_arrow_factory = FancyArrowFactory(
+        edge_pos,
+        edgelist,
+        nodelist,
+        edge_indices,
+        node_size,
+        selfloop_height,
+        connectionstyle,
+        node_shape,
+        arrowstyle,
+        arrowsize,
+        edge_color,
+        alpha,
+        width,
+        style,
+        min_source_margin,
+        min_target_margin,
+        ax=ax,
+    )
+
+    # Draw the edges
+    if use_linecollection:
         edge_collection = mpl.collections.LineCollection(
             edge_pos,
             colors=edge_color,
             linewidths=width,
             antialiaseds=(1,),
             linestyle=style,
             alpha=alpha,
         )
         edge_collection.set_cmap(edge_cmap)
         edge_collection.set_clim(edge_vmin, edge_vmax)
         edge_collection.set_zorder(1)  # edges go behind nodes
         edge_collection.set_label(label)
         ax.add_collection(edge_collection)
+        edge_viz_obj = edge_collection
 
-        return edge_collection
-
-    def _draw_networkx_edges_fancy_arrow_patch():
-        # Note: Waiting for someone to implement arrow to intersection with
-        # marker.  Meanwhile, this works well for polygons with more than 4
-        # sides and circle.
-
-        def to_marker_edge(marker_size, marker):
-            if marker in "s^>v<d":  # `large` markers need extra space
-                return np.sqrt(2 * marker_size) / 2
-            else:
-                return np.sqrt(marker_size) / 2
-
-        # Draw arrows with `matplotlib.patches.FancyarrowPatch`
-        arrow_collection = []
-
-        if isinstance(arrowsize, list):
-            if len(arrowsize) != len(edge_pos):
-                raise ValueError("arrowsize should have the same length as edgelist")
-        else:
-            mutation_scale = arrowsize  # scale factor of arrow head
-
-        base_connection_style = mpl.patches.ConnectionStyle(connectionstyle)
-
-        # Fallback for self-loop scale. Left outside of _connectionstyle so it is
-        # only computed once
-        max_nodesize = np.array(node_size).max()
-
-        def _connectionstyle(posA, posB, *args, **kwargs):
-            # check if we need to do a self-loop
-            if np.all(posA == posB):
-                # Self-loops are scaled by view extent, except in cases the extent
-                # is 0, e.g. for a single node. In this case, fall back to scaling
-                # by the maximum node size
-                selfloop_ht = 0.005 * max_nodesize if h == 0 else h
-                # this is called with _screen space_ values so convert back
-                # to data space
-                data_loc = ax.transData.inverted().transform(posA)
-                v_shift = 0.1 * selfloop_ht
-                h_shift = v_shift * 0.5
-                # put the top of the loop first so arrow is not hidden by node
-                path = [
-                    # 1
-                    data_loc + np.asarray([0, v_shift]),
-                    # 4 4 4
-                    data_loc + np.asarray([h_shift, v_shift]),
-                    data_loc + np.asarray([h_shift, 0]),
-                    data_loc,
-                    # 4 4 4
-                    data_loc + np.asarray([-h_shift, 0]),
-                    data_loc + np.asarray([-h_shift, v_shift]),
-                    data_loc + np.asarray([0, v_shift]),
-                ]
-
-                ret = mpl.path.Path(ax.transData.transform(path), [1, 4, 4, 4, 4, 4, 4])
-            # if not, fall back to the user specified behavior
-            else:
-                ret = base_connection_style(posA, posB, *args, **kwargs)
-
-            return ret
-
-        # FancyArrowPatch doesn't handle color strings
-        arrow_colors = mpl.colors.colorConverter.to_rgba_array(edge_color, alpha)
-        for i, (src, dst) in zip(fancy_edges_indices, edge_pos):
-            x1, y1 = src
-            x2, y2 = dst
-            shrink_source = 0  # space from source to tail
-            shrink_target = 0  # space from  head to target
-
-            if isinstance(arrowsize, list):
-                # Scale each factor of each arrow based on arrowsize list
-                mutation_scale = arrowsize[i]
-
-            if np.iterable(node_size):  # many node sizes
-                source, target = edgelist[i][:2]
-                source_node_size = node_size[nodelist.index(source)]
-                target_node_size = node_size[nodelist.index(target)]
-                shrink_source = to_marker_edge(source_node_size, node_shape)
-                shrink_target = to_marker_edge(target_node_size, node_shape)
-            else:
-                shrink_source = shrink_target = to_marker_edge(node_size, node_shape)
-
-            if shrink_source < min_source_margin:
-                shrink_source = min_source_margin
-
-            if shrink_target < min_target_margin:
-                shrink_target = min_target_margin
-
-            if len(arrow_colors) > i:
-                arrow_color = arrow_colors[i]
-            elif len(arrow_colors) == 1:
-                arrow_color = arrow_colors[0]
-            else:  # Cycle through colors
-                arrow_color = arrow_colors[i % len(arrow_colors)]
-
-            if np.iterable(width):
-                if len(width) > i:
-                    line_width = width[i]
-                else:
-                    line_width = width[i % len(width)]
-            else:
-                line_width = width
-
-            if (
-                np.iterable(style)
-                and not isinstance(style, str)
-                and not isinstance(style, tuple)
-            ):
-                if len(style) > i:
-                    linestyle = style[i]
-                else:  # Cycle through styles
-                    linestyle = style[i % len(style)]
-            else:
-                linestyle = style
-
-            arrow = mpl.patches.FancyArrowPatch(
-                (x1, y1),
-                (x2, y2),
-                arrowstyle=arrowstyle,
-                shrinkA=shrink_source,
-                shrinkB=shrink_target,
-                mutation_scale=mutation_scale,
-                color=arrow_color,
-                linewidth=line_width,
-                connectionstyle=_connectionstyle,
-                linestyle=linestyle,
-                zorder=1,
-            )  # arrows go behind nodes
-
-            arrow_collection.append(arrow)
-            ax.add_patch(arrow)
-
-        return arrow_collection
-
-    # compute initial view
-    minx = np.amin(np.ravel(edge_pos[:, :, 0]))
-    maxx = np.amax(np.ravel(edge_pos[:, :, 0]))
-    miny = np.amin(np.ravel(edge_pos[:, :, 1]))
-    maxy = np.amax(np.ravel(edge_pos[:, :, 1]))
-    w = maxx - minx
-    h = maxy - miny
-
-    # Draw the edges
-    if use_linecollection:
-        edge_viz_obj = _draw_networkx_edges_line_collection()
         # Make sure selfloop edges are also drawn
+        # ---------------------------------------
         selfloops_to_draw = [loop for loop in nx.selfloop_edges(G) if loop in edgelist]
         if selfloops_to_draw:
-            fancy_edges_indices = [
-                edgelist_tuple.index(loop) for loop in selfloops_to_draw
-            ]
-            edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in selfloops_to_draw])
-            arrowstyle = "-"
-            _draw_networkx_edges_fancy_arrow_patch()
+            edgelist_tuple = list(map(tuple, edgelist))
+            arrow_collection = []
+            for loop in selfloops_to_draw:
+                i = edgelist_tuple.index(loop)
+                arrow = fancy_arrow_factory(i)
+                arrow_collection.append(arrow)
+                ax.add_patch(arrow)
     else:
-        fancy_edges_indices = range(len(edgelist))
-        edge_viz_obj = _draw_networkx_edges_fancy_arrow_patch()
+        edge_viz_obj = []
+        for i in range(len(edgelist)):
+            arrow = fancy_arrow_factory(i)
+            ax.add_patch(arrow)
+            edge_viz_obj.append(arrow)
 
     # update view after drawing
     padx, pady = 0.05 * w, 0.05 * h
     corners = (minx - padx, miny - pady), (maxx + padx, maxy + pady)
     ax.update_datalim(corners)
     ax.autoscale_view()
 
-    ax.tick_params(
-        axis="both",
-        which="both",
-        bottom=False,
-        left=False,
-        labelbottom=False,
-        labelleft=False,
-    )
+    if hide_ticks:
+        ax.tick_params(
+            axis="both",
+            which="both",
+            bottom=False,
+            left=False,
+            labelbottom=False,
+            labelleft=False,
+        )
 
     return edge_viz_obj
 
 
 def draw_networkx_labels(
     G,
     pos,
@@ -939,14 +1055,15 @@
     font_weight="normal",
     alpha=None,
     bbox=None,
     horizontalalignment="center",
     verticalalignment="center",
     ax=None,
     clip_on=True,
+    hide_ticks=True,
 ):
     """Draw node labels on the graph G.
 
     Parameters
     ----------
     G : graph
         A networkx graph
@@ -987,14 +1104,19 @@
 
     ax : Matplotlib Axes object, optional
         Draw the graph in the specified Matplotlib axes.
 
     clip_on : bool (default=True)
         Turn on clipping of node labels at axis boundaries
 
+    hide_ticks : bool, optional
+        Hide ticks of axes. When `True` (the default), ticks and ticklabels
+        are removed from the axes. To set ticks and tick labels to the pyplot default,
+        use ``hide_ticks=False``.
+
     Returns
     -------
     dict
         `dict` of labels keyed on the nodes
 
     Examples
     --------
@@ -1038,22 +1160,23 @@
             verticalalignment=verticalalignment,
             transform=ax.transData,
             bbox=bbox,
             clip_on=clip_on,
         )
         text_items[n] = t
 
-    ax.tick_params(
-        axis="both",
-        which="both",
-        bottom=False,
-        left=False,
-        labelbottom=False,
-        labelleft=False,
-    )
+    if hide_ticks:
+        ax.tick_params(
+            axis="both",
+            which="both",
+            bottom=False,
+            left=False,
+            labelbottom=False,
+            labelleft=False,
+        )
 
     return text_items
 
 
 def draw_networkx_edge_labels(
     G,
     pos,
@@ -1066,14 +1189,18 @@
     alpha=None,
     bbox=None,
     horizontalalignment="center",
     verticalalignment="center",
     ax=None,
     rotate=True,
     clip_on=True,
+    node_size=300,
+    nodelist=None,
+    connectionstyle="arc3",
+    hide_ticks=True,
 ):
     """Draw edge labels.
 
     Parameters
     ----------
     G : graph
         A networkx graph
@@ -1120,14 +1247,32 @@
 
     rotate : bool (default=True)
         Rotate edge labels to lie parallel to edges
 
     clip_on : bool (default=True)
         Turn on clipping of edge labels at axis boundaries
 
+    node_size : scalar or array (default=300)
+        Size of nodes.  If an array it must be the same length as nodelist.
+
+    nodelist : list, optional (default=G.nodes())
+       This provides the node order for the `node_size` array (if it is an array).
+
+    connectionstyle : string or iterable of strings (default="arc3")
+        Pass the connectionstyle parameter to create curved arc of rounding
+        radius rad. For example, connectionstyle='arc3,rad=0.2'.
+        See `matplotlib.patches.ConnectionStyle` and
+        `matplotlib.patches.FancyArrowPatch` for more info.
+        If Iterable, index indicates i'th edge key of MultiGraph
+
+    hide_ticks : bool, optional
+        Hide ticks of axes. When `True` (the default), ticks and ticklabels
+        are removed from the axes. To set ticks and tick labels to the pyplot default,
+        use ``hide_ticks=False``.
+
     Returns
     -------
     dict
         `dict` of labels keyed by edge
 
     Examples
     --------
@@ -1141,90 +1286,222 @@
     --------
     draw
     draw_networkx
     draw_networkx_nodes
     draw_networkx_edges
     draw_networkx_labels
     """
+    import matplotlib as mpl
     import matplotlib.pyplot as plt
     import numpy as np
 
+    class CurvedArrowText(mpl.text.Text):
+        def __init__(
+            self,
+            arrow,
+            *args,
+            label_pos=0.5,
+            labels_horizontal=False,
+            ax=None,
+            **kwargs,
+        ):
+            # Bind to FancyArrowPatch
+            self.arrow = arrow
+            # how far along the text should be on the curve,
+            # 0 is at start, 1 is at end etc.
+            self.label_pos = label_pos
+            self.labels_horizontal = labels_horizontal
+            if ax is None:
+                ax = plt.gca()
+            self.ax = ax
+            self.x, self.y, self.angle = self._update_text_pos_angle(arrow)
+
+            # Create text object
+            super().__init__(self.x, self.y, *args, rotation=self.angle, **kwargs)
+            # Bind to axis
+            self.ax.add_artist(self)
+
+        def _get_arrow_path_disp(self, arrow):
+            """
+            This is part of FancyArrowPatch._get_path_in_displaycoord
+            It omits the second part of the method where path is converted
+                to polygon based on width
+            The transform is taken from ax, not the object, as the object
+                has not been added yet, and doesn't have transform
+            """
+            dpi_cor = arrow._dpi_cor
+            # trans_data = arrow.get_transform()
+            trans_data = self.ax.transData
+            if arrow._posA_posB is not None:
+                posA = arrow._convert_xy_units(arrow._posA_posB[0])
+                posB = arrow._convert_xy_units(arrow._posA_posB[1])
+                (posA, posB) = trans_data.transform((posA, posB))
+                _path = arrow.get_connectionstyle()(
+                    posA,
+                    posB,
+                    patchA=arrow.patchA,
+                    patchB=arrow.patchB,
+                    shrinkA=arrow.shrinkA * dpi_cor,
+                    shrinkB=arrow.shrinkB * dpi_cor,
+                )
+            else:
+                _path = trans_data.transform_path(arrow._path_original)
+            # Return is in display coordinates
+            return _path
+
+        def _update_text_pos_angle(self, arrow):
+            # Fractional label position
+            path_disp = self._get_arrow_path_disp(arrow)
+            (x1, y1), (cx, cy), (x2, y2) = path_disp.vertices
+            # Text position at a proportion t along the line in display coords
+            # default is 0.5 so text appears at the halfway point
+            t = self.label_pos
+            tt = 1 - t
+            x = tt**2 * x1 + 2 * t * tt * cx + t**2 * x2
+            y = tt**2 * y1 + 2 * t * tt * cy + t**2 * y2
+            if self.labels_horizontal:
+                # Horizontal text labels
+                angle = 0
+            else:
+                # Labels parallel to curve
+                change_x = 2 * tt * (cx - x1) + 2 * t * (x2 - cx)
+                change_y = 2 * tt * (cy - y1) + 2 * t * (y2 - cy)
+                angle = (np.arctan2(change_y, change_x) / (2 * np.pi)) * 360
+                # Text is "right way up"
+                if angle > 90:
+                    angle -= 180
+                if angle < -90:
+                    angle += 180
+            (x, y) = self.ax.transData.inverted().transform((x, y))
+            return x, y, angle
+
+        def draw(self, renderer):
+            # recalculate the text position and angle
+            self.x, self.y, self.angle = self._update_text_pos_angle(self.arrow)
+            self.set_position((self.x, self.y))
+            self.set_rotation(self.angle)
+            # redraw text
+            super().draw(renderer)
+
+    # use default box of white with white border
+    if bbox is None:
+        bbox = {"boxstyle": "round", "ec": (1.0, 1.0, 1.0), "fc": (1.0, 1.0, 1.0)}
+
+    if isinstance(connectionstyle, str):
+        connectionstyle = [connectionstyle]
+    elif np.iterable(connectionstyle):
+        connectionstyle = list(connectionstyle)
+    else:
+        raise nx.NetworkXError(
+            "draw_networkx_edges arg `connectionstyle` must be"
+            "string or iterable of strings"
+        )
+
     if ax is None:
         ax = plt.gca()
+
     if edge_labels is None:
-        labels = {(u, v): d for u, v, d in G.edges(data=True)}
+        kwds = {"keys": True} if G.is_multigraph() else {}
+        edge_labels = {tuple(edge): d for *edge, d in G.edges(data=True, **kwds)}
+    # NOTHING TO PLOT
+    if not edge_labels:
+        return {}
+    edgelist, labels = zip(*edge_labels.items())
+
+    if nodelist is None:
+        nodelist = list(G.nodes())
+
+    # set edge positions
+    edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist])
+
+    if G.is_multigraph():
+        key_count = collections.defaultdict(lambda: itertools.count(0))
+        edge_indices = [next(key_count[tuple(e[:2])]) for e in edgelist]
     else:
-        labels = edge_labels
-        # Informative exception for multiedges
-        try:
-            (u, v) = next(iter(labels))  # ensures no edge key provided
-        except ValueError as err:
-            raise nx.NetworkXError(
-                "draw_networkx_edge_labels does not support multiedges."
-            ) from err
-        except StopIteration:
-            pass
+        edge_indices = [0] * len(edgelist)
 
-    text_items = {}
-    for (n1, n2), label in labels.items():
-        (x1, y1) = pos[n1]
-        (x2, y2) = pos[n2]
-        (x, y) = (
-            x1 * label_pos + x2 * (1.0 - label_pos),
-            y1 * label_pos + y2 * (1.0 - label_pos),
-        )
+    # Used to determine self loop mid-point
+    # Note, that this will not be accurate,
+    #   if not drawing edge_labels for all edges drawn
+    h = 0
+    if edge_labels:
+        miny = np.amin(np.ravel(edge_pos[:, :, 1]))
+        maxy = np.amax(np.ravel(edge_pos[:, :, 1]))
+        h = maxy - miny
+    selfloop_height = h if h != 0 else 0.005 * np.array(node_size).max()
+    fancy_arrow_factory = FancyArrowFactory(
+        edge_pos,
+        edgelist,
+        nodelist,
+        edge_indices,
+        node_size,
+        selfloop_height,
+        connectionstyle,
+        ax=ax,
+    )
 
-        if rotate:
-            # in degrees
-            angle = np.arctan2(y2 - y1, x2 - x1) / (2.0 * np.pi) * 360
-            # make label orientation "right-side-up"
-            if angle > 90:
-                angle -= 180
-            if angle < -90:
-                angle += 180
-            # transform data coordinate angle to screen coordinate angle
-            xy = np.array((x, y))
-            trans_angle = ax.transData.transform_angles(
-                np.array((angle,)), xy.reshape((1, 2))
-            )[0]
-        else:
-            trans_angle = 0.0
-        # use default box of white with white border
-        if bbox is None:
-            bbox = {"boxstyle": "round", "ec": (1.0, 1.0, 1.0), "fc": (1.0, 1.0, 1.0)}
+    text_items = {}
+    for i, (edge, label) in enumerate(zip(edgelist, labels)):
         if not isinstance(label, str):
             label = str(label)  # this makes "1" and 1 labeled the same
 
-        t = ax.text(
-            x,
-            y,
-            label,
-            size=font_size,
-            color=font_color,
-            family=font_family,
-            weight=font_weight,
-            alpha=alpha,
-            horizontalalignment=horizontalalignment,
-            verticalalignment=verticalalignment,
-            rotation=trans_angle,
-            transform=ax.transData,
-            bbox=bbox,
-            zorder=1,
-            clip_on=clip_on,
+        n1, n2 = edge[:2]
+        arrow = fancy_arrow_factory(i)
+        if n1 == n2:
+            connectionstyle_obj = arrow.get_connectionstyle()
+            posA = ax.transData.transform(pos[n1])
+            path_disp = connectionstyle_obj(posA, posA)
+            path_data = ax.transData.inverted().transform_path(path_disp)
+            x, y = path_data.vertices[0]
+            text_items[edge] = ax.text(
+                x,
+                y,
+                label,
+                size=font_size,
+                color=font_color,
+                family=font_family,
+                weight=font_weight,
+                alpha=alpha,
+                horizontalalignment=horizontalalignment,
+                verticalalignment=verticalalignment,
+                rotation=0,
+                transform=ax.transData,
+                bbox=bbox,
+                zorder=1,
+                clip_on=clip_on,
+            )
+        else:
+            text_items[edge] = CurvedArrowText(
+                arrow,
+                label,
+                size=font_size,
+                color=font_color,
+                family=font_family,
+                weight=font_weight,
+                alpha=alpha,
+                horizontalalignment=horizontalalignment,
+                verticalalignment=verticalalignment,
+                transform=ax.transData,
+                bbox=bbox,
+                zorder=1,
+                clip_on=clip_on,
+                label_pos=label_pos,
+                labels_horizontal=not rotate,
+                ax=ax,
+            )
+
+    if hide_ticks:
+        ax.tick_params(
+            axis="both",
+            which="both",
+            bottom=False,
+            left=False,
+            labelbottom=False,
+            labelleft=False,
         )
-        text_items[(n1, n2)] = t
-
-    ax.tick_params(
-        axis="both",
-        which="both",
-        bottom=False,
-        left=False,
-        labelbottom=False,
-        labelleft=False,
-    )
 
     return text_items
 
 
 def draw_circular(G, **kwargs):
     """Draw the graph `G` with a circular layout.
```

### Comparing `networkx-3.2rc0/networkx/drawing/tests/baseline/test_house_with_colors.png` & `networkx-3.3rc0/networkx/drawing/tests/baseline/test_house_with_colors.png`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/drawing/tests/test_agraph.py` & `networkx-3.3rc0/networkx/drawing/tests/test_agraph.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 """Unit tests for PyGraphviz interface."""
-import os
-import tempfile
+import warnings
 
 import pytest
 
 pygraphviz = pytest.importorskip("pygraphviz")
 
 
 import networkx as nx
@@ -20,35 +19,34 @@
         return G
 
     def assert_equal(self, G1, G2):
         assert nodes_equal(G1.nodes(), G2.nodes())
         assert edges_equal(G1.edges(), G2.edges())
         assert G1.graph["metal"] == G2.graph["metal"]
 
-    def agraph_checks(self, G):
+    @pytest.mark.parametrize(
+        "G", (nx.Graph(), nx.DiGraph(), nx.MultiGraph(), nx.MultiDiGraph())
+    )
+    def test_agraph_roundtripping(self, G, tmp_path):
         G = self.build_graph(G)
         A = nx.nx_agraph.to_agraph(G)
         H = nx.nx_agraph.from_agraph(A)
         self.assert_equal(G, H)
 
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.dot"
         nx.drawing.nx_agraph.write_dot(H, fname)
         Hin = nx.nx_agraph.read_dot(fname)
         self.assert_equal(H, Hin)
-        os.close(fd)
-        os.unlink(fname)
 
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "fh_test.dot"
         with open(fname, "w") as fh:
             nx.drawing.nx_agraph.write_dot(H, fh)
 
         with open(fname) as fh:
             Hin = nx.nx_agraph.read_dot(fh)
-        os.close(fd)
-        os.unlink(fname)
         self.assert_equal(H, Hin)
 
     def test_from_agraph_name(self):
         G = nx.Graph(name="test")
         A = nx.nx_agraph.to_agraph(G)
         H = nx.nx_agraph.from_agraph(A)
         assert G.name == "test"
@@ -70,26 +68,14 @@
         # Add edge (+ name, given by key) to the AGraph
         A.add_edge(0, 1, key="foo")
         # Verify a.name roundtrips out to 'key' in from_agraph
         H = nx.nx_agraph.from_agraph(A)
         assert isinstance(H, nx.Graph)
         assert ("0", "1", {"key": "foo"}) in H.edges(data=True)
 
-    def test_undirected(self):
-        self.agraph_checks(nx.Graph())
-
-    def test_directed(self):
-        self.agraph_checks(nx.DiGraph())
-
-    def test_multi_undirected(self):
-        self.agraph_checks(nx.MultiGraph())
-
-    def test_multi_directed(self):
-        self.agraph_checks(nx.MultiDiGraph())
-
     def test_to_agraph_with_nodedata(self):
         G = nx.Graph()
         G.add_node(1, color="red")
         A = nx.nx_agraph.to_agraph(G)
         assert dict(A.nodes()[0].attr) == {"color": "red"}
 
     @pytest.mark.parametrize("graph_class", (nx.Graph, nx.MultiGraph))
@@ -245,10 +231,10 @@
         # Test that no warnings are raised when Networkx graph
         # is converted to Pygraphviz graph and 'pos'
         # attribute is given
         G = nx.Graph()
         G.add_node(0, pos=(0, 0))
         G.add_node(1, pos=(1, 1))
         A = nx.nx_agraph.to_agraph(G)
-        with pytest.warns(None) as record:
+        with warnings.catch_warnings(record=True) as record:
             A.layout()
         assert len(record) == 0
```

### Comparing `networkx-3.2rc0/networkx/drawing/tests/test_latex.py` & `networkx-3.3rc0/networkx/drawing/tests/test_latex.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/drawing/tests/test_layout.py` & `networkx-3.3rc0/networkx/drawing/tests/test_layout.py`

 * *Files 6% similar despite different names*

```diff
@@ -448,22 +448,68 @@
     assert len(pos) == len(G)
 
 
 def test_multipartite_layout_layer_order():
     """Return the layers in sorted order if the layers of the multipartite
     graph are sortable. See gh-5691"""
     G = nx.Graph()
-    for node, layer in zip(("a", "b", "c", "d", "e"), (2, 3, 1, 2, 4)):
+    node_group = dict(zip(("a", "b", "c", "d", "e"), (2, 3, 1, 2, 4)))
+    for node, layer in node_group.items():
         G.add_node(node, subset=layer)
 
     # Horizontal alignment, therefore y-coord determines layers
     pos = nx.multipartite_layout(G, align="horizontal")
 
+    layers = nx.utils.groups(node_group)
+    pos_from_layers = nx.multipartite_layout(G, align="horizontal", subset_key=layers)
+    for (n1, p1), (n2, p2) in zip(pos.items(), pos_from_layers.items()):
+        assert n1 == n2 and (p1 == p2).all()
+
     # Nodes "a" and "d" are in the same layer
     assert pos["a"][-1] == pos["d"][-1]
     # positions should be sorted according to layer
     assert pos["c"][-1] < pos["a"][-1] < pos["b"][-1] < pos["e"][-1]
 
     # Make sure that multipartite_layout still works when layers are not sortable
     G.nodes["a"]["subset"] = "layer_0"  # Can't sort mixed strs/ints
     pos_nosort = nx.multipartite_layout(G)  # smoke test: this should not raise
     assert pos_nosort.keys() == pos.keys()
+
+
+def _num_nodes_per_bfs_layer(pos):
+    """Helper function to extract the number of nodes in each layer of bfs_layout"""
+    x = np.array(list(pos.values()))[:, 0]  # node positions in layered dimension
+    _, layer_count = np.unique(x, return_counts=True)
+    return layer_count
+
+
+@pytest.mark.parametrize("n", range(2, 7))
+def test_bfs_layout_complete_graph(n):
+    """The complete graph should result in two layers: the starting node and
+    a second layer containing all neighbors."""
+    G = nx.complete_graph(n)
+    pos = nx.bfs_layout(G, start=0)
+    assert np.array_equal(_num_nodes_per_bfs_layer(pos), [1, n - 1])
+
+
+def test_bfs_layout_barbell():
+    G = nx.barbell_graph(5, 3)
+    # Start in one of the "bells"
+    pos = nx.bfs_layout(G, start=0)
+    # start, bell-1, [1] * len(bar)+1, bell-1
+    expected_nodes_per_layer = [1, 4, 1, 1, 1, 1, 4]
+    assert np.array_equal(_num_nodes_per_bfs_layer(pos), expected_nodes_per_layer)
+    # Start in the other "bell" - expect same layer pattern
+    pos = nx.bfs_layout(G, start=12)
+    assert np.array_equal(_num_nodes_per_bfs_layer(pos), expected_nodes_per_layer)
+    # Starting in the center of the bar, expect layers to be symmetric
+    pos = nx.bfs_layout(G, start=6)
+    # Expected layers: {6 (start)}, {5, 7}, {4, 8}, {8 nodes from remainder of bells}
+    expected_nodes_per_layer = [1, 2, 2, 8]
+    assert np.array_equal(_num_nodes_per_bfs_layer(pos), expected_nodes_per_layer)
+
+
+def test_bfs_layout_disconnected():
+    G = nx.complete_graph(5)
+    G.add_edges_from([(10, 11), (11, 12)])
+    with pytest.raises(nx.NetworkXError, match="bfs_layout didn't include all nodes"):
+        nx.bfs_layout(G, start=0)
```

### Comparing `networkx-3.2rc0/networkx/drawing/tests/test_pydot.py` & `networkx-3.3rc0/networkx/drawing/tests/test_pydot.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 """Unit tests for pydot drawing functions."""
-import os
-import tempfile
 from io import StringIO
 
 import pytest
 
 import networkx as nx
 from networkx.utils import graphs_equal
 
 pydot = pytest.importorskip("pydot")
 
 
-@pytest.mark.xfail
 class TestPydot:
-    def pydot_checks(self, G, prog):
+    @pytest.mark.parametrize("G", (nx.Graph(), nx.DiGraph()))
+    @pytest.mark.parametrize("prog", ("neato", "dot"))
+    def test_pydot(self, G, prog, tmp_path):
         """
         Validate :mod:`pydot`-based usage of the passed NetworkX graph with the
         passed basename of an external GraphViz command (e.g., `dot`, `neato`).
         """
 
         # Set the name of this graph to... "G". Failing to do so will
         # subsequently trip an assertion expecting this name.
@@ -36,15 +35,15 @@
 
         # Convert this "pydot.Dot" instance back into a graph of the same type.
         G2 = G.__class__(nx.nx_pydot.from_pydot(P))
 
         # Validate the original and resulting graphs to be the same.
         assert graphs_equal(G, G2)
 
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "out.dot"
 
         # Serialize this "pydot.Dot" instance to a temporary file in dot format
         P.write_raw(fname)
 
         # Deserialize a list of new "pydot.Dot" instances back from this file.
         Pin_list = pydot.graph_from_dot_file(path=fname, encoding="utf-8")
 
@@ -75,23 +74,14 @@
         # Deserialize a new graph of the same type back from this file.
         Hin = nx.nx_pydot.read_dot(fname)
         Hin = G.__class__(Hin)
 
         # Validate the original and resulting graphs to be the same.
         assert graphs_equal(G, Hin)
 
-        os.close(fd)
-        os.unlink(fname)
-
-    def test_undirected(self):
-        self.pydot_checks(nx.Graph(), prog="neato")
-
-    def test_directed(self):
-        self.pydot_checks(nx.DiGraph(), prog="dot")
-
     def test_read_write(self):
         G = nx.MultiGraph()
         G.graph["name"] = "G"
         G.add_edge("1", "2", key="0")  # read assumes strings
         fh = StringIO()
         nx.nx_pydot.write_dot(G, fh)
         fh.seek(0)
```

### Comparing `networkx-3.2rc0/networkx/drawing/tests/test_pylab.py` & `networkx-3.3rc0/networkx/drawing/tests/test_pylab.py`

 * *Files 6% similar despite different names*

```diff
@@ -702,27 +702,71 @@
     G.add_edge(0, 0)
     fig, ax = plt.subplots()
     nx.draw(G, edgelist=[(0, 1), (1, 2)], ax=ax)  # Exclude self-loop from edgelist
     assert not ax.patches
     plt.delaxes(ax)
 
 
-def test_draw_networkx_edge_label_multiedge_exception():
-    """
-    draw_networkx_edge_labels should raise an informative error message when
-    the edge label includes keys
-    """
-    exception_msg = "draw_networkx_edge_labels does not support multiedges"
+@pytest.mark.parametrize(
+    ("G", "expected_n_edges"),
+    ([nx.DiGraph(), 2], [nx.MultiGraph(), 4], [nx.MultiDiGraph(), 4]),
+)
+def test_draw_networkx_edges_multiedge_connectionstyle(G, expected_n_edges):
+    """Draws edges correctly for 3 types of graphs and checks for valid length"""
+    for i, (u, v) in enumerate([(0, 1), (0, 1), (0, 1), (0, 2)]):
+        G.add_edge(u, v, weight=round(i / 3, 2))
+    pos = {n: (n, n) for n in G}
+    # Raises on insuficient connectionstyle length
+    for conn_style in [
+        "arc3,rad=0.1",
+        ["arc3,rad=0.1", "arc3,rad=0.1"],
+        ["arc3,rad=0.1", "arc3,rad=0.1", "arc3,rad=0.2"],
+    ]:
+        nx.draw_networkx_edges(G, pos, connectionstyle=conn_style)
+        arrows = nx.draw_networkx_edges(G, pos, connectionstyle=conn_style)
+        assert len(arrows) == expected_n_edges
+
+
+@pytest.mark.parametrize(
+    ("G", "expected_n_edges"),
+    ([nx.DiGraph(), 2], [nx.MultiGraph(), 4], [nx.MultiDiGraph(), 4]),
+)
+def test_draw_networkx_edge_labels_multiedge_connectionstyle(G, expected_n_edges):
+    """Draws labels correctly for 3 types of graphs and checks for valid length and class names"""
+    for i, (u, v) in enumerate([(0, 1), (0, 1), (0, 1), (0, 2)]):
+        G.add_edge(u, v, weight=round(i / 3, 2))
+    pos = {n: (n, n) for n in G}
+    # Raises on insuficient connectionstyle length
+    arrows = nx.draw_networkx_edges(
+        G, pos, connectionstyle=["arc3,rad=0.1", "arc3,rad=0.1", "arc3,rad=0.1"]
+    )
+    for conn_style in [
+        "arc3,rad=0.1",
+        ["arc3,rad=0.1", "arc3,rad=0.2"],
+        ["arc3,rad=0.1", "arc3,rad=0.1", "arc3,rad=0.1"],
+    ]:
+        text_items = nx.draw_networkx_edge_labels(G, pos, connectionstyle=conn_style)
+        assert len(text_items) == expected_n_edges
+        for ti in text_items.values():
+            assert ti.__class__.__name__ == "CurvedArrowText"
+
+
+def test_draw_networkx_edge_label_multiedge():
     G = nx.MultiGraph()
     G.add_edge(0, 1, weight=10)
     G.add_edge(0, 1, weight=20)
     edge_labels = nx.get_edge_attributes(G, "weight")  # Includes edge keys
     pos = {n: (n, n) for n in G}
-    with pytest.raises(nx.NetworkXError, match=exception_msg):
-        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
+    text_items = nx.draw_networkx_edge_labels(
+        G,
+        pos,
+        edge_labels=edge_labels,
+        connectionstyle=["arc3,rad=0.1", "arc3,rad=0.2"],
+    )
+    assert len(text_items) == 2
 
 
 def test_draw_networkx_edge_label_empty_dict():
     """Regression test for draw_networkx_edge_labels with empty dict. See
     gh-5372."""
     G = nx.path_graph(3)
     pos = {n: (n, n) for n in G.nodes}
@@ -785,7 +829,41 @@
     # Check that warnings are *not* raised in this case
     with warnings.catch_warnings():
         # Escalate warnings -> errors so tests fail if warnings are raised
         warnings.simplefilter("error")
         nx.draw_networkx_edges(G, pos, ax=ax, arrows=True, **fap_only_kwarg)
 
     plt.delaxes(ax)
+
+
+@pytest.mark.parametrize("draw_fn", (nx.draw, nx.draw_circular))
+def test_no_warning_on_default_draw_arrowstyle(draw_fn):
+    # See gh-7284
+    fig, ax = plt.subplots()
+    G = nx.cycle_graph(5)
+    with warnings.catch_warnings(record=True) as w:
+        draw_fn(G, ax=ax)
+    assert len(w) == 0
+
+    plt.delaxes(ax)
+
+
+@pytest.mark.parametrize("hide_ticks", [False, True])
+@pytest.mark.parametrize(
+    "method",
+    [
+        nx.draw_networkx,
+        nx.draw_networkx_edge_labels,
+        nx.draw_networkx_edges,
+        nx.draw_networkx_labels,
+        nx.draw_networkx_nodes,
+    ],
+)
+def test_hide_ticks(method, hide_ticks):
+    G = nx.path_graph(3)
+    pos = {n: (n, n) for n in G.nodes}
+    _, ax = plt.subplots()
+    method(G, pos=pos, ax=ax, hide_ticks=hide_ticks)
+    for axis in [ax.xaxis, ax.yaxis]:
+        assert bool(axis.get_ticklabels()) != hide_ticks
+
+    plt.delaxes(ax)
```

### Comparing `networkx-3.2rc0/networkx/exception.py` & `networkx-3.3rc0/networkx/exception.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/__init__.py` & `networkx-3.3rc0/networkx/generators/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 from networkx.generators.community import *
 from networkx.generators.degree_seq import *
 from networkx.generators.directed import *
 from networkx.generators.duplication import *
 from networkx.generators.ego import *
 from networkx.generators.expanders import *
 from networkx.generators.geometric import *
+from networkx.generators.harary_graph import *
 from networkx.generators.internet_as_graphs import *
 from networkx.generators.intersection import *
 from networkx.generators.interval_graph import *
 from networkx.generators.joint_degree_seq import *
 from networkx.generators.lattice import *
 from networkx.generators.line import *
 from networkx.generators.mycielski import *
```

### Comparing `networkx-3.2rc0/networkx/generators/atlas.dat.gz` & `networkx-3.3rc0/networkx/generators/atlas.dat.gz`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/atlas.py` & `networkx-3.3rc0/networkx/generators/atlas.py`

 * *Files 5% similar despite different names*

```diff
@@ -84,15 +84,15 @@
             G = nx.Graph()
             G.name = f"G{graph_index}"
             G.add_nodes_from(range(num_nodes))
             G.add_edges_from(tuple(map(int, e.split())) for e in edgelist)
             yield G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def graph_atlas(i):
     """Returns graph number `i` from the Graph Atlas.
 
     For more information, see :func:`.graph_atlas_g`.
 
     Parameters
     ----------
@@ -123,15 +123,15 @@
 
     """
     if not (0 <= i < NUM_GRAPHS):
         raise ValueError(f"index must be between 0 and {NUM_GRAPHS}")
     return next(islice(_generate_graphs(), i, None))
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def graph_atlas_g():
     """Returns the list of all graphs with up to seven nodes named in the
     Graph Atlas.
 
     The graphs are listed in increasing order by
 
     1. number of nodes,
```

### Comparing `networkx-3.2rc0/networkx/generators/classic.py` & `networkx-3.3rc0/networkx/generators/classic.py`

 * *Files 13% similar despite different names*

```diff
@@ -26,19 +26,21 @@
     "complete_multipartite_graph",
     "circular_ladder_graph",
     "circulant_graph",
     "cycle_graph",
     "dorogovtsev_goltsev_mendes_graph",
     "empty_graph",
     "full_rary_tree",
+    "kneser_graph",
     "ladder_graph",
     "lollipop_graph",
     "null_graph",
     "path_graph",
     "star_graph",
+    "tadpole_graph",
     "trivial_graph",
     "turan_graph",
     "wheel_graph",
 ]
 
 
 # -------------------------------------------------------------------
@@ -60,24 +62,28 @@
                 target = next(nodes)
                 parents.append(target)
                 yield source, target
             except StopIteration:
                 break
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def full_rary_tree(r, n, create_using=None):
     """Creates a full r-ary tree of `n` nodes.
 
     Sometimes called a k-ary, n-ary, or m-ary tree.
     "... all non-leaf nodes have exactly r children and all levels
     are full except for some rightmost position of the bottom level
     (if a leaf at the bottom level is missing, then so are all of the
     leaves to its right." [1]_
 
+    .. plot::
+
+        >>> nx.draw(nx.full_rary_tree(2, 10))
+
     Parameters
     ----------
     r : int
         branching factor of the tree
     n : int
         Number of nodes in the tree
     create_using : NetworkX graph constructor, optional (default=nx.Graph)
@@ -94,18 +100,69 @@
            James Andrew Storer,  Birkhauser Boston 2001, (page 225).
     """
     G = empty_graph(n, create_using)
     G.add_edges_from(_tree_edges(n, r))
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def kneser_graph(n, k):
+    """Returns the Kneser Graph with parameters `n` and `k`.
+
+    The Kneser Graph has nodes that are k-tuples (subsets) of the integers
+    between 0 and ``n-1``. Nodes are adjacent if their corresponding sets are disjoint.
+
+    Parameters
+    ----------
+    n: int
+        Number of integers from which to make node subsets.
+        Subsets are drawn from ``set(range(n))``.
+    k: int
+        Size of the subsets.
+
+    Returns
+    -------
+    G : NetworkX Graph
+
+    Examples
+    --------
+    >>> G = nx.kneser_graph(5, 2)
+    >>> G.number_of_nodes()
+    10
+    >>> G.number_of_edges()
+    15
+    >>> nx.is_isomorphic(G, nx.petersen_graph())
+    True
+    """
+    if n <= 0:
+        raise NetworkXError("n should be greater than zero")
+    if k <= 0 or k > n:
+        raise NetworkXError("k should be greater than zero and smaller than n")
+
+    G = nx.Graph()
+    # Create all k-subsets of [0, 1, ..., n-1]
+    subsets = list(itertools.combinations(range(n), k))
+
+    if 2 * k > n:
+        G.add_nodes_from(subsets)
+
+    universe = set(range(n))
+    comb = itertools.combinations  # only to make it all fit on one line
+    G.add_edges_from((s, t) for s in subsets for t in comb(universe - set(s), k))
+    return G
+
+
+@nx._dispatchable(graphs=None, returns_graph=True)
 def balanced_tree(r, h, create_using=None):
     """Returns the perfectly balanced `r`-ary tree of height `h`.
 
+    .. plot::
+
+        >>> nx.draw(nx.balanced_tree(2, 3))
+
     Parameters
     ----------
     r : int
         Branching factor of the tree; each node will have `r`
         children.
 
     h : int
@@ -140,18 +197,22 @@
     else:
         # This must be an integer if both `r` and `h` are integers. If
         # they are not, we force integer division anyway.
         n = (1 - r ** (h + 1)) // (1 - r)
     return full_rary_tree(r, n, create_using=create_using)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def barbell_graph(m1, m2, create_using=None):
     """Returns the Barbell Graph: two complete graphs connected by a path.
 
+    .. plot::
+
+        >>> nx.draw(nx.barbell_graph(4, 2))
+
     Parameters
     ----------
     m1 : int
         Size of the left and right barbells, must be greater than 2.
 
     m2 : int
         Length of the path connecting the barbells.
@@ -209,22 +270,26 @@
     G.add_edge(m1 - 1, m1)
     if m2 > 0:
         G.add_edge(m1 + m2 - 1, m1 + m2)
 
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def binomial_tree(n, create_using=None):
     """Returns the Binomial Tree of order n.
 
     The binomial tree of order 0 consists of a single node. A binomial tree of order k
     is defined recursively by linking two binomial trees of order k-1: the root of one is
     the leftmost child of the root of the other.
 
+    .. plot::
+
+        >>> nx.draw(nx.binomial_tree(3))
+
     Parameters
     ----------
     n : int
         Order of the binomial tree.
 
     create_using : NetworkX graph constructor, optional (default=nx.Graph)
        Graph type to create. If graph instance, then cleared before populated.
@@ -243,22 +308,26 @@
         edges = [(u + N, v + N) for (u, v) in G.edges()]
         G.add_edges_from(edges)
         G.add_edge(0, N)
         N *= 2
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def complete_graph(n, create_using=None):
     """Return the complete graph `K_n` with n nodes.
 
     A complete graph on `n` nodes means that all pairs
     of distinct nodes have an edge connecting them.
 
+    .. plot::
+
+        >>> nx.draw(nx.complete_graph(5))
+
     Parameters
     ----------
     n : int or iterable container of nodes
         If n is an integer, nodes are from range(n).
         If n is a container of nodes, those nodes appear in the graph.
         Warning: n is not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
@@ -287,38 +356,46 @@
             edges = itertools.permutations(nodes, 2)
         else:
             edges = itertools.combinations(nodes, 2)
         G.add_edges_from(edges)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def circular_ladder_graph(n, create_using=None):
     """Returns the circular ladder graph $CL_n$ of length n.
 
     $CL_n$ consists of two concentric n-cycles in which
     each of the n pairs of concentric nodes are joined by an edge.
 
     Node labels are the integers 0 to n-1
 
+    .. plot::
+
+        >>> nx.draw(nx.circular_ladder_graph(5))
+
     """
     G = ladder_graph(n, create_using)
     G.add_edge(0, n - 1)
     G.add_edge(n, 2 * n - 1)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def circulant_graph(n, offsets, create_using=None):
     r"""Returns the circulant graph $Ci_n(x_1, x_2, ..., x_m)$ with $n$ nodes.
 
     The circulant graph $Ci_n(x_1, ..., x_m)$ consists of $n$ nodes $0, ..., n-1$
     such that node $i$ is connected to nodes $(i + x) \mod n$ and $(i - x) \mod n$
     for all $x$ in $x_1, ..., x_m$. Thus $Ci_n(1)$ is a cycle graph.
 
+    .. plot::
+
+        >>> nx.draw(nx.circulant_graph(10, [1]))
+
     Parameters
     ----------
     n : integer
         The number of nodes in the graph.
     offsets : list of integers
         A list of node offsets, $x_1$ up to $x_m$, as described above.
     create_using : NetworkX graph constructor, optional (default=nx.Graph)
@@ -343,15 +420,14 @@
     ...     (3, 4),
     ...     (4, 5),
     ...     (5, 6),
     ...     (6, 7),
     ...     (7, 8),
     ...     (8, 9),
     ... ]
-    ...
     >>> sorted(edges) == sorted(G.edges())
     True
 
     Similarly, we can create the complete graph
     on 5 points with the set of offsets [1, 2]:
 
     >>> G = nx.circulant_graph(5, [1, 2])
@@ -363,34 +439,37 @@
     ...     (1, 2),
     ...     (1, 3),
     ...     (1, 4),
     ...     (2, 3),
     ...     (2, 4),
     ...     (3, 4),
     ... ]
-    ...
     >>> sorted(edges) == sorted(G.edges())
     True
 
     """
     G = empty_graph(n, create_using)
     for i in range(n):
         for j in offsets:
             G.add_edge(i, (i - j) % n)
             G.add_edge(i, (i + j) % n)
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def cycle_graph(n, create_using=None):
     """Returns the cycle graph $C_n$ of cyclically connected nodes.
 
     $C_n$ is a path with its two end-nodes connected.
 
+    .. plot::
+
+        >>> nx.draw(nx.cycle_graph(5))
+
     Parameters
     ----------
     n : int or iterable container of nodes
         If n is an integer, nodes are from `range(n)`.
         If n is a container of nodes, those nodes appear in the graph.
         Warning: n is not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
@@ -404,23 +483,27 @@
     """
     _, nodes = n
     G = empty_graph(nodes, create_using)
     G.add_edges_from(pairwise(nodes, cyclic=True))
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def dorogovtsev_goltsev_mendes_graph(n, create_using=None):
     """Returns the hierarchically constructed Dorogovtsev-Goltsev-Mendes graph.
 
     The Dorogovtsev-Goltsev-Mendes [1]_ procedure produces a scale-free graph
     deterministically with the following properties for a given `n`:
     - Total number of nodes = ``3 * (3**n + 1) / 2``
     - Total number of edges = ``3 ** (n + 1)``
 
+    .. plot::
+
+        >>> nx.draw(nx.dorogovtsev_goltsev_mendes_graph(3))
+
     Parameters
     ----------
     n : integer
        The generation number.
 
     create_using : NetworkX Graph, optional
        Graph type to be returned. Directed graphs and multi graphs are not
@@ -462,19 +545,23 @@
         for j in range(number_of_edges_in_last_generation):
             G.add_edge(new_node, last_generation_edges[j][0])
             G.add_edge(new_node, last_generation_edges[j][1])
             new_node += 1
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def empty_graph(n=0, create_using=None, default=Graph):
     """Returns the empty graph with n nodes and zero edges.
 
+    .. plot::
+
+        >>> nx.draw(nx.empty_graph(5))
+
     Parameters
     ----------
     n : int or iterable container of nodes (default = 0)
         If n is an integer, nodes are from `range(n)`.
         If n is a container of nodes, those nodes appear in the graph.
     create_using : Graph Instance, Constructor or None
         Indicator of type of graph to return.
@@ -557,57 +644,70 @@
         G = create_using
 
     _, nodes = n
     G.add_nodes_from(nodes)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def ladder_graph(n, create_using=None):
     """Returns the Ladder graph of length n.
 
     This is two paths of n nodes, with
     each pair connected by a single edge.
 
     Node labels are the integers 0 to 2*n - 1.
 
+    .. plot::
+
+        >>> nx.draw(nx.ladder_graph(5))
+
     """
     G = empty_graph(2 * n, create_using)
     if G.is_directed():
         raise NetworkXError("Directed Graph not supported")
     G.add_edges_from(pairwise(range(n)))
     G.add_edges_from(pairwise(range(n, 2 * n)))
     G.add_edges_from((v, v + n) for v in range(n))
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number([0, 1])
-@nx._dispatch(graphs=None)
 def lollipop_graph(m, n, create_using=None):
-    """Returns the Lollipop Graph; `K_m` connected to `P_n`.
+    """Returns the Lollipop Graph; ``K_m`` connected to ``P_n``.
 
     This is the Barbell Graph without the right barbell.
 
+    .. plot::
+
+        >>> nx.draw(nx.lollipop_graph(3, 4))
+
     Parameters
     ----------
-    m, n : int or iterable container of nodes (default = 0)
-        If an integer, nodes are from `range(m)` and `range(m,m+n)`.
+    m, n : int or iterable container of nodes
+        If an integer, nodes are from ``range(m)`` and ``range(m, m+n)``.
         If a container of nodes, those nodes appear in the graph.
-        Warning: m and n are not checked for duplicates and if present the
+        Warning: `m` and `n` are not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
 
-        The nodes for m appear in the complete graph $K_m$ and the nodes
-        for n appear in the path $P_n$
+        The nodes for `m` appear in the complete graph $K_m$ and the nodes
+        for `n` appear in the path $P_n$
     create_using : NetworkX graph constructor, optional (default=nx.Graph)
        Graph type to create. If graph instance, then cleared before populated.
 
+    Returns
+    -------
+    Networkx graph
+       A complete graph with `m` nodes connected to a path of length `n`.
+
     Notes
     -----
-    The 2 subgraphs are joined via an edge (m-1, m).
-    If n=0, this is merely a complete graph.
+    The 2 subgraphs are joined via an edge ``(m-1, m)``.
+    If ``n=0``, this is merely a complete graph.
 
     (This graph is an extremal example in David Aldous and Jim
     Fill's etext on Random Walks on Graphs.)
 
     """
     m, m_nodes = m
     M = len(m_nodes)
@@ -634,30 +734,34 @@
 
     # connect ball to stick
     if M > 0 and N > 0:
         G.add_edge(m_nodes[-1], n_nodes[0])
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def null_graph(create_using=None):
     """Returns the Null graph with no nodes or edges.
 
     See empty_graph for the use of create_using.
 
     """
     G = empty_graph(0, create_using)
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def path_graph(n, create_using=None):
     """Returns the Path graph `P_n` of linearly connected nodes.
 
+    .. plot::
+
+        >>> nx.draw(nx.path_graph(5))
+
     Parameters
     ----------
     n : int or iterable
         If an integer, nodes are 0 to n - 1.
         If an iterable of nodes, in the order they appear in the path.
         Warning: n is not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
@@ -667,21 +771,25 @@
     """
     _, nodes = n
     G = empty_graph(nodes, create_using)
     G.add_edges_from(pairwise(nodes))
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def star_graph(n, create_using=None):
     """Return the star graph
 
     The star graph consists of one center node connected to n outer nodes.
 
+    .. plot::
+
+        >>> nx.draw(nx.star_graph(6))
+
     Parameters
     ----------
     n : int or iterable
         If an integer, node labels are 0 to n with center 0.
         If an iterable of nodes, the center is the first.
         Warning: n is not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
@@ -691,44 +799,116 @@
     Notes
     -----
     The graph has n+1 nodes for integer n.
     So star_graph(3) is the same as star_graph(range(4)).
     """
     n, nodes = n
     if isinstance(n, numbers.Integral):
-        nodes.append(n)  # there should be n+1 nodes
+        nodes.append(int(n))  # there should be n+1 nodes
     G = empty_graph(nodes, create_using)
     if G.is_directed():
         raise NetworkXError("Directed Graph not supported")
 
     if len(nodes) > 1:
         hub, *spokes = nodes
         G.add_edges_from((hub, node) for node in spokes)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
+@nodes_or_number([0, 1])
+def tadpole_graph(m, n, create_using=None):
+    """Returns the (m,n)-tadpole graph; ``C_m`` connected to ``P_n``.
+
+    This graph on m+n nodes connects a cycle of size `m` to a path of length `n`.
+    It looks like a tadpole. It is also called a kite graph or a dragon graph.
+
+    .. plot::
+
+        >>> nx.draw(nx.tadpole_graph(3, 5))
+
+    Parameters
+    ----------
+    m, n : int or iterable container of nodes
+        If an integer, nodes are from ``range(m)`` and ``range(m,m+n)``.
+        If a container of nodes, those nodes appear in the graph.
+        Warning: `m` and `n` are not checked for duplicates and if present the
+        resulting graph may not be as desired.
+
+        The nodes for `m` appear in the cycle graph $C_m$ and the nodes
+        for `n` appear in the path $P_n$.
+    create_using : NetworkX graph constructor, optional (default=nx.Graph)
+       Graph type to create. If graph instance, then cleared before populated.
+
+    Returns
+    -------
+    Networkx graph
+       A cycle of size `m` connected to a path of length `n`.
+
+    Raises
+    ------
+    NetworkXError
+        If ``m < 2``. The tadpole graph is undefined for ``m<2``.
+
+    Notes
+    -----
+    The 2 subgraphs are joined via an edge ``(m-1, m)``.
+    If ``n=0``, this is a cycle graph.
+    `m` and/or `n` can be a container of nodes instead of an integer.
+
+    """
+    m, m_nodes = m
+    M = len(m_nodes)
+    if M < 2:
+        raise NetworkXError("Invalid description: m should indicate at least 2 nodes")
+
+    n, n_nodes = n
+    if isinstance(m, numbers.Integral) and isinstance(n, numbers.Integral):
+        n_nodes = list(range(M, M + n))
+
+    # the circle
+    G = cycle_graph(m_nodes, create_using)
+    if G.is_directed():
+        raise NetworkXError("Directed Graph not supported")
+
+    # the stick
+    nx.add_path(G, [m_nodes[-1]] + list(n_nodes))
+
+    return G
+
+
+@nx._dispatchable(graphs=None, returns_graph=True)
 def trivial_graph(create_using=None):
-    """Return the Trivial graph with one node (with label 0) and no edges."""
+    """Return the Trivial graph with one node (with label 0) and no edges.
+
+    .. plot::
+
+        >>> nx.draw(nx.trivial_graph(), with_labels=True)
+
+    """
     G = empty_graph(1, create_using)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def turan_graph(n, r):
     r"""Return the Turan Graph
 
     The Turan Graph is a complete multipartite graph on $n$ nodes
     with $r$ disjoint subsets. That is, edges connect each node to
     every node not in its subset.
 
     Given $n$ and $r$, we create a complete multipartite graph with
     $r-(n \mod r)$ partitions of size $n/r$, rounded down, and
     $n \mod r$ partitions of size $n/r+1$, rounded down.
 
+    .. plot::
+
+        >>> nx.draw(nx.turan_graph(6, 2))
+
     Parameters
     ----------
     n : int
         The number of nodes.
     r : int
         The number of partitions.
         Must be less than or equal to n.
@@ -743,21 +923,25 @@
         raise NetworkXError("Must satisfy 1 <= r <= n")
 
     partitions = [n // r] * (r - (n % r)) + [n // r + 1] * (n % r)
     G = complete_multipartite_graph(*partitions)
     return G
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number(0)
-@nx._dispatch(graphs=None)
 def wheel_graph(n, create_using=None):
     """Return the wheel graph
 
     The wheel graph consists of a hub node connected to a cycle of (n-1) nodes.
 
+    .. plot::
+
+        >>> nx.draw(nx.wheel_graph(5))
+
     Parameters
     ----------
     n : int or iterable
         If an integer, node labels are 0 to n with center 0.
         If an iterable of nodes, the center is the first.
         Warning: n is not checked for duplicates and if present the
         resulting graph may not be as desired. Make sure you have no duplicates.
@@ -775,18 +959,22 @@
         hub, *rim = nodes
         G.add_edges_from((hub, node) for node in rim)
         if len(rim) > 1:
             G.add_edges_from(pairwise(rim, cyclic=True))
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def complete_multipartite_graph(*subset_sizes):
     """Returns the complete multipartite graph with the specified subset sizes.
 
+    .. plot::
+
+        >>> nx.draw(nx.complete_multipartite_graph(1, 2, 3))
+
     Parameters
     ----------
     subset_sizes : tuple of integers or tuple of node iterables
        The arguments can either all be integer number of nodes or they
        can all be iterables of nodes. If integers, they represent the
        number of nodes in each subset of the multipartite graph.
        If iterables, each is used to create the nodes for that subset.
@@ -843,14 +1031,17 @@
 
     # set up subsets of nodes
     try:
         extents = pairwise(itertools.accumulate((0,) + subset_sizes))
         subsets = [range(start, end) for start, end in extents]
     except TypeError:
         subsets = subset_sizes
+    else:
+        if any(size < 0 for size in subset_sizes):
+            raise NetworkXError(f"Negative number of nodes not valid: {subset_sizes}")
 
     # add nodes with subset attribute
     # while checking that ints are not mixed with iterables
     try:
         for i, subset in enumerate(subsets):
             G.add_nodes_from(subset, subset=i)
     except TypeError as err:
```

### Comparing `networkx-3.2rc0/networkx/generators/cographs.py` & `networkx-3.3rc0/networkx/generators/cographs.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 import networkx as nx
 from networkx.utils import py_random_state
 
 __all__ = ["random_cograph"]
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_cograph(n, seed=None):
     r"""Returns a random cograph with $2 ^ n$ nodes.
 
     A cograph is a graph containing no path on four vertices.
     Cographs or $P_4$-free graphs can be obtained from a single vertex
     by disjoint union and complementation operations.
```

### Comparing `networkx-3.2rc0/networkx/generators/community.py` & `networkx-3.3rc0/networkx/generators/community.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,15 +15,15 @@
     "ring_of_cliques",
     "windmill_graph",
     "stochastic_block_model",
     "LFR_benchmark_graph",
 ]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def caveman_graph(l, k):
     """Returns a caveman graph of `l` cliques of size `k`.
 
     Parameters
     ----------
     l : int
       Number of cliques
@@ -62,15 +62,15 @@
     if k > 1:
         for start in range(0, l * k, k):
             edges = itertools.combinations(range(start, start + k), 2)
             G.add_edges_from(edges)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def connected_caveman_graph(l, k):
     """Returns a connected caveman graph of `l` cliques of size `k`.
 
     The connected caveman graph is formed by creating `n` cliques of size
     `k`, then a single edge in each clique is rewired to a node in an
     adjacent clique.
 
@@ -106,26 +106,26 @@
     References
     ----------
     .. [1] Watts, D. J. 'Networks, Dynamics, and the Small-World Phenomenon.'
        Amer. J. Soc. 105, 493-527, 1999.
     """
     if k < 2:
         raise nx.NetworkXError(
-            "The size of cliques in a connected caveman graph " "must be at least 2."
+            "The size of cliques in a connected caveman graph must be at least 2."
         )
 
     G = nx.caveman_graph(l, k)
     for start in range(0, l * k, k):
         G.remove_edge(start, start + 1)
         G.add_edge(start, (start - 1) % (l * k))
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def relaxed_caveman_graph(l, k, p, seed=None):
     """Returns a relaxed caveman graph.
 
     A relaxed caveman graph starts with `l` cliques of size `k`.  Edges are
     then randomly rewired with probability `p` to link different cliques.
 
     Parameters
@@ -169,15 +169,15 @@
                 continue
             G.remove_edge(u, v)
             G.add_edge(u, x)
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_partition_graph(sizes, p_in, p_out, seed=None, directed=False):
     """Returns the random partition graph with a partition of sizes.
 
     A partition graph is a graph of communities with sizes defined by
     s in sizes. Nodes in the same group are connected with probability
     p_in and nodes of different groups are connected with probability
     p_out.
@@ -248,15 +248,15 @@
         directed=directed,
         selfloops=False,
         sparse=True,
     )
 
 
 @py_random_state(4)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def planted_partition_graph(l, k, p_in, p_out, seed=None, directed=False):
     """Returns the planted l-partition graph.
 
     This model partitions a graph with n=l*k vertices in
     l groups with k vertices each. Vertices of the same
     group are linked with a probability p_in, and vertices
     of different groups are linked with probability p_out.
@@ -281,15 +281,15 @@
     -------
     G : NetworkX Graph or DiGraph
       planted l-partition graph
 
     Raises
     ------
     NetworkXError
-      If p_in,p_out are not in [0,1] or
+      If `p_in`, `p_out` are not in `[0, 1]`
 
     Examples
     --------
     >>> G = nx.planted_partition_graph(4, 3, 0.5, 0.1, seed=42)
 
     See Also
     --------
@@ -304,15 +304,15 @@
     .. [2] Santo Fortunato 'Community Detection in Graphs' Physical Reports
        Volume 486, Issue 3-5 p. 75-174. https://arxiv.org/abs/0906.0612
     """
     return random_partition_graph([k] * l, p_in, p_out, seed=seed, directed=directed)
 
 
 @py_random_state(6)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def gaussian_random_partition_graph(n, s, v, p_in, p_out, directed=False, seed=None):
     """Generate a Gaussian random partition graph.
 
     A Gaussian random partition graph is created by creating k partitions
     each with a size drawn from a normal distribution with mean s and variance
     s/v. Nodes are connected within clusters with probability p_in and
     between clusters with probability p_out[1]
@@ -380,15 +380,15 @@
             sizes.append(n - assigned)
             break
         assigned += size
         sizes.append(size)
     return random_partition_graph(sizes, p_in, p_out, seed=seed, directed=directed)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def ring_of_cliques(num_cliques, clique_size):
     """Defines a "ring of cliques" graph.
 
     A ring of cliques graph is consisting of cliques, connected through single
     links. Each clique is a complete graph.
 
     Parameters
@@ -420,15 +420,15 @@
     Notes
     -----
     The `connected_caveman_graph` graph removes a link from each clique to
     connect it with the next clique. Instead, the `ring_of_cliques` graph
     simply adds the link without removing any link from the cliques.
     """
     if num_cliques < 2:
-        raise nx.NetworkXError("A ring of cliques must have at least " "two cliques")
+        raise nx.NetworkXError("A ring of cliques must have at least two cliques")
     if clique_size < 2:
         raise nx.NetworkXError("The cliques must have at least two nodes")
 
     G = nx.Graph()
     for i in range(num_cliques):
         edges = itertools.combinations(
             range(i * clique_size, i * clique_size + clique_size), 2
@@ -436,15 +436,15 @@
         G.add_edges_from(edges)
         G.add_edge(
             i * clique_size + 1, (i + 1) * clique_size % (num_cliques * clique_size)
         )
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def windmill_graph(n, k):
     """Generate a windmill graph.
     A windmill graph is a graph of `n` cliques each of size `k` that are all
     joined at one node.
     It can be thought of as taking a disjoint union of `n` cliques of size `k`,
     selecting one point from each, and contracting all of the selected points.
     Alternatively, one could generate `n` cliques of size `k-1` and one node
@@ -490,15 +490,15 @@
         )
     )
     G.add_edges_from((0, i) for i in range(k, G.number_of_nodes()))
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def stochastic_block_model(
     sizes, p, nodelist=None, seed=None, directed=False, selfloops=False, sparse=True
 ):
     """Returns a stochastic block model graph.
 
     This model partitions the nodes in blocks of arbitrary sizes, and places
     edges between pairs of nodes independently, with a probability that depends
@@ -547,21 +547,19 @@
     >>> probs = [[0.25, 0.05, 0.02], [0.05, 0.35, 0.07], [0.02, 0.07, 0.40]]
     >>> g = nx.stochastic_block_model(sizes, probs, seed=0)
     >>> len(g)
     450
     >>> H = nx.quotient_graph(g, g.graph["partition"], relabel=True)
     >>> for v in H.nodes(data=True):
     ...     print(round(v[1]["density"], 3))
-    ...
     0.245
     0.348
     0.405
     >>> for v in H.edges(data=True):
     ...     print(round(1.0 * v[2]["weight"] / (sizes[v[0]] * sizes[v[1]]), 3))
-    ...
     0.051
     0.022
     0.07
 
     See Also
     --------
     random_partition_graph
@@ -804,15 +802,15 @@
         if not free:
             return result
     msg = "Could not assign communities; try increasing min_community"
     raise nx.ExceededMaxIterations(msg)
 
 
 @py_random_state(11)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def LFR_benchmark_graph(
     n,
     tau1,
     tau2,
     mu,
     average_degree=None,
     min_degree=None,
@@ -1002,15 +1000,15 @@
     # Validate parameters for generating the degree sequence.
     if max_degree is None:
         max_degree = n
     elif not 0 < max_degree <= n:
         raise nx.NetworkXError("max_degree must be in the interval (0, n]")
     if not ((min_degree is None) ^ (average_degree is None)):
         raise nx.NetworkXError(
-            "Must assign exactly one of min_degree and" " average_degree"
+            "Must assign exactly one of min_degree and average_degree"
         )
     if min_degree is None:
         min_degree = _generate_min_degree(
             tau1, average_degree, max_degree, tol, max_iters
         )
 
     # Generate a degree sequence with a power law distribution.
```

### Comparing `networkx-3.2rc0/networkx/generators/degree_seq.py` & `networkx-3.3rc0/networkx/generators/degree_seq.py`

 * *Files 2% similar despite different names*

```diff
@@ -120,15 +120,15 @@
         seed.shuffle(stublist)
         out_stublist, in_stublist = stublist[:half], stublist[half:]
     G.add_edges_from(zip(out_stublist, in_stublist))
     return G
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def configuration_model(deg_sequence, create_using=None, seed=None):
     """Returns a random graph with the given degree sequence.
 
     The configuration model generates a random pseudograph (graph with
     parallel edges and self loops) by randomly assigning edges to
     match the given degree sequence.
 
@@ -223,15 +223,15 @@
 
     G = _configuration_model(deg_sequence, G, seed=seed)
 
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def directed_configuration_model(
     in_degree_sequence, out_degree_sequence, create_using=None, seed=None
 ):
     """Returns a directed_random graph with the given degree sequences.
 
     The configuration model generates a random directed pseudograph
     (graph with parallel edges and self loops) by randomly assigning
@@ -326,15 +326,15 @@
     )
 
     name = "directed configuration_model {} nodes {} edges"
     return G
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def expected_degree_graph(w, seed=None, selfloops=True):
     r"""Returns a random graph with given expected degrees.
 
     Given a sequence of expected degrees $W=(w_0,w_1,\ldots,w_{n-1})$
     of length $n$ this algorithm assigns an edge between node $u$ and
     node $v$ with probability
 
@@ -435,15 +435,15 @@
                 if seed.random() < q / p:
                     G.add_edge(mapping[u], mapping[v])
                 v += 1
                 p = q
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def havel_hakimi_graph(deg_sequence, create_using=None):
     """Returns a simple graph with given degree sequence constructed
     using the Havel-Hakimi algorithm.
 
     Parameters
     ----------
     deg_sequence: list of integers
@@ -528,15 +528,15 @@
             (stubval, stubtarget) = modstubs[i]
             num_degs[stubval].append(stubtarget)
             n += 1
 
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def directed_havel_hakimi_graph(in_deg_sequence, out_deg_sequence, create_using=None):
     """Returns a directed graph with the given degree sequences.
 
     Parameters
     ----------
     in_deg_sequence :  list of integers
         Each list entry corresponds to the in-degree of a node.
@@ -640,15 +640,15 @@
                 heapq.heappush(zeroheap, (stub[0], stub[2]))
         if freeout < 0:
             heapq.heappush(zeroheap, (freeout, target))
 
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def degree_sequence_tree(deg_sequence, create_using=None):
     """Make a tree for the given degree sequence.
 
     A tree has #nodes-#edges=1 so
     the degree sequence must have
     len(deg_sequence)-sum(deg_sequence)/2=1
     """
@@ -687,15 +687,15 @@
     # in case we added one too many
     if len(G) > len(deg_sequence):
         G.remove_node(0)
     return G
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_degree_sequence_graph(sequence, seed=None, tries=10):
     r"""Returns a simple random graph with the given degree sequence.
 
     If the maximum degree $d_m$ in the sequence is $O(m^{1/4})$ then the
     algorithm produces almost uniform random graphs in $O(m d_m)$ time
     where $m$ is the number of edges.
```

### Comparing `networkx-3.2rc0/networkx/generators/directed.py` & `networkx-3.3rc0/networkx/generators/internet_as_graphs.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,501 +1,441 @@
-"""
-Generators for some directed graphs, including growing network (GN) graphs and
-scale-free graphs.
-
-"""
-
-import numbers
-from collections import Counter
+"""Generates graphs resembling the Internet Autonomous System network"""
 
 import networkx as nx
-from networkx.generators.classic import empty_graph
-from networkx.utils import discrete_sequence, py_random_state, weighted_choice
-
-__all__ = [
-    "gn_graph",
-    "gnc_graph",
-    "gnr_graph",
-    "random_k_out_graph",
-    "scale_free_graph",
-]
-
-
-@py_random_state(3)
-@nx._dispatch(graphs=None)
-def gn_graph(n, kernel=None, create_using=None, seed=None):
-    """Returns the growing network (GN) digraph with `n` nodes.
-
-    The GN graph is built by adding nodes one at a time with a link to one
-    previously added node.  The target node for the link is chosen with
-    probability based on degree.  The default attachment kernel is a linear
-    function of the degree of a node.
-
-    The graph is always a (directed) tree.
-
-    Parameters
-    ----------
-    n : int
-        The number of nodes for the generated graph.
-    kernel : function
-        The attachment kernel.
-    create_using : NetworkX graph constructor, optional (default DiGraph)
-        Graph type to create. If graph instance, then cleared before populated.
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-
-    Examples
-    --------
-    To create the undirected GN graph, use the :meth:`~DiGraph.to_directed`
-    method::
-
-    >>> D = nx.gn_graph(10)  # the GN graph
-    >>> G = D.to_undirected()  # the undirected version
-
-    To specify an attachment kernel, use the `kernel` keyword argument::
-
-    >>> D = nx.gn_graph(10, kernel=lambda x: x ** 1.5)  # A_k = k^1.5
-
-    References
-    ----------
-    .. [1] P. L. Krapivsky and S. Redner,
-           Organization of Growing Random Networks,
-           Phys. Rev. E, 63, 066123, 2001.
-    """
-    G = empty_graph(1, create_using, default=nx.DiGraph)
-    if not G.is_directed():
-        raise nx.NetworkXError("create_using must indicate a Directed Graph")
-
-    if kernel is None:
-
-        def kernel(x):
-            return x
-
-    if n == 1:
-        return G
-
-    G.add_edge(1, 0)  # get started
-    ds = [1, 1]  # degree sequence
-
-    for source in range(2, n):
-        # compute distribution from kernel and degree
-        dist = [kernel(d) for d in ds]
-        # choose target from discrete distribution
-        target = discrete_sequence(1, distribution=dist, seed=seed)[0]
-        G.add_edge(source, target)
-        ds.append(1)  # the source has only one link (degree one)
-        ds[target] += 1  # add one to the target link degree
-    return G
-
-
-@py_random_state(3)
-@nx._dispatch(graphs=None)
-def gnr_graph(n, p, create_using=None, seed=None):
-    """Returns the growing network with redirection (GNR) digraph with `n`
-    nodes and redirection probability `p`.
-
-    The GNR graph is built by adding nodes one at a time with a link to one
-    previously added node.  The previous target node is chosen uniformly at
-    random.  With probability `p` the link is instead "redirected" to the
-    successor node of the target.
-
-    The graph is always a (directed) tree.
-
-    Parameters
-    ----------
-    n : int
-        The number of nodes for the generated graph.
-    p : float
-        The redirection probability.
-    create_using : NetworkX graph constructor, optional (default DiGraph)
-        Graph type to create. If graph instance, then cleared before populated.
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-
-    Examples
-    --------
-    To create the undirected GNR graph, use the :meth:`~DiGraph.to_directed`
-    method::
-
-    >>> D = nx.gnr_graph(10, 0.5)  # the GNR graph
-    >>> G = D.to_undirected()  # the undirected version
-
-    References
-    ----------
-    .. [1] P. L. Krapivsky and S. Redner,
-           Organization of Growing Random Networks,
-           Phys. Rev. E, 63, 066123, 2001.
-    """
-    G = empty_graph(1, create_using, default=nx.DiGraph)
-    if not G.is_directed():
-        raise nx.NetworkXError("create_using must indicate a Directed Graph")
-
-    if n == 1:
-        return G
-
-    for source in range(1, n):
-        target = seed.randrange(0, source)
-        if seed.random() < p and target != 0:
-            target = next(G.successors(target))
-        G.add_edge(source, target)
-    return G
-
-
-@py_random_state(2)
-@nx._dispatch(graphs=None)
-def gnc_graph(n, create_using=None, seed=None):
-    """Returns the growing network with copying (GNC) digraph with `n` nodes.
-
-    The GNC graph is built by adding nodes one at a time with a link to one
-    previously added node (chosen uniformly at random) and to all of that
-    node's successors.
-
-    Parameters
-    ----------
-    n : int
-        The number of nodes for the generated graph.
-    create_using : NetworkX graph constructor, optional (default DiGraph)
-        Graph type to create. If graph instance, then cleared before populated.
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-
-    References
-    ----------
-    .. [1] P. L. Krapivsky and S. Redner,
-           Network Growth by Copying,
-           Phys. Rev. E, 71, 036118, 2005k.},
-    """
-    G = empty_graph(1, create_using, default=nx.DiGraph)
-    if not G.is_directed():
-        raise nx.NetworkXError("create_using must indicate a Directed Graph")
-
-    if n == 1:
-        return G
-
-    for source in range(1, n):
-        target = seed.randrange(0, source)
-        for succ in G.successors(target):
-            G.add_edge(source, succ)
-        G.add_edge(source, target)
-    return G
+from networkx.utils import py_random_state
 
+__all__ = ["random_internet_as_graph"]
 
-@py_random_state(6)
-@nx._dispatch(graphs=None)
-def scale_free_graph(
-    n,
-    alpha=0.41,
-    beta=0.54,
-    gamma=0.05,
-    delta_in=0.2,
-    delta_out=0,
-    seed=None,
-    initial_graph=None,
-):
-    """Returns a scale-free directed graph.
-
-    Parameters
-    ----------
-    n : integer
-        Number of nodes in graph
-    alpha : float
-        Probability for adding a new node connected to an existing node
-        chosen randomly according to the in-degree distribution.
-    beta : float
-        Probability for adding an edge between two existing nodes.
-        One existing node is chosen randomly according the in-degree
-        distribution and the other chosen randomly according to the out-degree
-        distribution.
-    gamma : float
-        Probability for adding a new node connected to an existing node
-        chosen randomly according to the out-degree distribution.
-    delta_in : float
-        Bias for choosing nodes from in-degree distribution.
-    delta_out : float
-        Bias for choosing nodes from out-degree distribution.
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
-    initial_graph : MultiDiGraph instance, optional
-        Build the scale-free graph starting from this initial MultiDiGraph,
-        if provided.
-
-    Returns
-    -------
-    MultiDiGraph
 
-    Examples
-    --------
-    Create a scale-free graph on one hundred nodes::
+def uniform_int_from_avg(a, m, seed):
+    """Pick a random integer with uniform probability.
 
-    >>> G = nx.scale_free_graph(100)
+    Returns a random integer uniformly taken from a distribution with
+    minimum value 'a' and average value 'm', X~U(a,b), E[X]=m, X in N where
+    b = 2*m - a.
 
     Notes
     -----
-    The sum of `alpha`, `beta`, and `gamma` must be 1.
-
-    References
-    ----------
-    .. [1] B. Bollobás, C. Borgs, J. Chayes, and O. Riordan,
-           Directed scale-free graphs,
-           Proceedings of the fourteenth annual ACM-SIAM Symposium on
-           Discrete Algorithms, 132--139, 2003.
+    p = (b-floor(b))/2
+    X = X1 + X2; X1~U(a,floor(b)), X2~B(p)
+    E[X] = E[X1] + E[X2] = (floor(b)+a)/2 + (b-floor(b))/2 = (b+a)/2 = m
     """
 
-    def _choose_node(candidates, node_list, delta):
-        if delta > 0:
-            bias_sum = len(node_list) * delta
-            p_delta = bias_sum / (bias_sum + len(candidates))
-            if seed.random() < p_delta:
-                return seed.choice(node_list)
-        return seed.choice(candidates)
-
-    if initial_graph is not None and hasattr(initial_graph, "_adj"):
-        if not isinstance(initial_graph, nx.MultiDiGraph):
-            raise nx.NetworkXError("initial_graph must be a MultiDiGraph.")
-        G = initial_graph
-    else:
-        # Start with 3-cycle
-        G = nx.MultiDiGraph([(0, 1), (1, 2), (2, 0)])
+    from math import floor
 
-    if alpha <= 0:
-        raise ValueError("alpha must be > 0.")
-    if beta <= 0:
-        raise ValueError("beta must be > 0.")
-    if gamma <= 0:
-        raise ValueError("gamma must be > 0.")
-
-    if abs(alpha + beta + gamma - 1.0) >= 1e-9:
-        raise ValueError("alpha+beta+gamma must equal 1.")
-
-    if delta_in < 0:
-        raise ValueError("delta_in must be >= 0.")
-
-    if delta_out < 0:
-        raise ValueError("delta_out must be >= 0.")
-
-    # pre-populate degree states
-    vs = sum((count * [idx] for idx, count in G.out_degree()), [])
-    ws = sum((count * [idx] for idx, count in G.in_degree()), [])
-
-    # pre-populate node state
-    node_list = list(G.nodes())
-
-    # see if there already are number-based nodes
-    numeric_nodes = [n for n in node_list if isinstance(n, numbers.Number)]
-    if len(numeric_nodes) > 0:
-        # set cursor for new nodes appropriately
-        cursor = max(int(n.real) for n in numeric_nodes) + 1
+    assert m >= a
+    b = 2 * m - a
+    p = (b - floor(b)) / 2
+    X1 = round(seed.random() * (floor(b) - a) + a)
+    if seed.random() < p:
+        X2 = 1
     else:
-        # or start at zero
-        cursor = 0
+        X2 = 0
+    return X1 + X2
 
-    while len(G) < n:
-        r = seed.random()
 
-        # random choice in alpha,beta,gamma ranges
-        if r < alpha:
-            # alpha
-            # add new node v
-            v = cursor
-            cursor += 1
-            # also add to node state
-            node_list.append(v)
-            # choose w according to in-degree and delta_in
-            w = _choose_node(ws, node_list, delta_in)
-
-        elif r < alpha + beta:
-            # beta
-            # choose v according to out-degree and delta_out
-            v = _choose_node(vs, node_list, delta_out)
-            # choose w according to in-degree and delta_in
-            w = _choose_node(ws, node_list, delta_in)
+def choose_pref_attach(degs, seed):
+    """Pick a random value, with a probability given by its weight.
 
-        else:
-            # gamma
-            # choose v according to out-degree and delta_out
-            v = _choose_node(vs, node_list, delta_out)
-            # add new node w
-            w = cursor
-            cursor += 1
-            # also add to node state
-            node_list.append(w)
-
-        # add edge to graph
-        G.add_edge(v, w)
-
-        # update degree states
-        vs.append(v)
-        ws.append(w)
-
-    return G
-
-
-@py_random_state(4)
-@nx._dispatch(graphs=None)
-def random_uniform_k_out_graph(n, k, self_loops=True, with_replacement=True, seed=None):
-    """Returns a random `k`-out graph with uniform attachment.
-
-    A random `k`-out graph with uniform attachment is a multidigraph
-    generated by the following algorithm. For each node *u*, choose
-    `k` nodes *v* uniformly at random (with replacement). Add a
-    directed edge joining *u* to *v*.
+    Returns a random choice among degs keys, each of which has a
+    probability proportional to the corresponding dictionary value.
 
     Parameters
     ----------
-    n : int
-        The number of nodes in the returned graph.
-
-    k : int
-        The out-degree of each node in the returned graph.
-
-    self_loops : bool
-        If True, self-loops are allowed when generating the graph.
-
-    with_replacement : bool
-        If True, neighbors are chosen with replacement and the
-        returned graph will be a directed multigraph. Otherwise,
-        neighbors are chosen without replacement and the returned graph
-        will be a directed graph.
-
-    seed : integer, random_state, or None (default)
-        Indicator of random number generation state.
-        See :ref:`Randomness<randomness>`.
+    degs: dictionary
+        It contains the possible values (keys) and the corresponding
+        probabilities (values)
+    seed: random state
 
     Returns
     -------
-    NetworkX graph
-        A `k`-out-regular directed graph generated according to the
-        above algorithm. It will be a multigraph if and only if
-        `with_replacement` is True.
-
-    Raises
-    ------
-    ValueError
-        If `with_replacement` is False and `k` is greater than
-        `n`.
-
-    See also
-    --------
-    random_k_out_graph
-
-    Notes
-    -----
-    The return digraph or multidigraph may not be strongly connected, or
-    even weakly connected.
+    v: object
+        A key of degs or None if degs is empty
+    """
 
-    If `with_replacement` is True, this function is similar to
-    :func:`random_k_out_graph`, if that function had parameter `alpha`
-    set to positive infinity.
+    if len(degs) == 0:
+        return None
+    s = sum(degs.values())
+    if s == 0:
+        return seed.choice(list(degs.keys()))
+    v = seed.random() * s
+
+    nodes = list(degs.keys())
+    i = 0
+    acc = degs[nodes[i]]
+    while v > acc:
+        i += 1
+        acc += degs[nodes[i]]
+    return nodes[i]
+
+
+class AS_graph_generator:
+    """Generates random internet AS graphs."""
+
+    def __init__(self, n, seed):
+        """Initializes variables. Immediate numbers are taken from [1].
+
+        Parameters
+        ----------
+        n: integer
+            Number of graph nodes
+        seed: random state
+            Indicator of random number generation state.
+            See :ref:`Randomness<randomness>`.
+
+        Returns
+        -------
+        GG: AS_graph_generator object
+
+        References
+        ----------
+        [1] A. Elmokashfi, A. Kvalbein and C. Dovrolis, "On the Scalability of
+        BGP: The Role of Topology Growth," in IEEE Journal on Selected Areas
+        in Communications, vol. 28, no. 8, pp. 1250-1261, October 2010.
+        """
+
+        self.seed = seed
+        self.n_t = min(n, round(self.seed.random() * 2 + 4))  # num of T nodes
+        self.n_m = round(0.15 * n)  # number of M nodes
+        self.n_cp = round(0.05 * n)  # number of CP nodes
+        self.n_c = max(0, n - self.n_t - self.n_m - self.n_cp)  # number of C nodes
+
+        self.d_m = 2 + (2.5 * n) / 10000  # average multihoming degree for M nodes
+        self.d_cp = 2 + (1.5 * n) / 10000  # avg multihoming degree for CP nodes
+        self.d_c = 1 + (5 * n) / 100000  # average multihoming degree for C nodes
+
+        self.p_m_m = 1 + (2 * n) / 10000  # avg num of peer edges between M and M
+        self.p_cp_m = 0.2 + (2 * n) / 10000  # avg num of peer edges between CP, M
+        self.p_cp_cp = 0.05 + (2 * n) / 100000  # avg num of peer edges btwn CP, CP
+
+        self.t_m = 0.375  # probability M's provider is T
+        self.t_cp = 0.375  # probability CP's provider is T
+        self.t_c = 0.125  # probability C's provider is T
+
+    def t_graph(self):
+        """Generates the core mesh network of tier one nodes of a AS graph.
+
+        Returns
+        -------
+        G: Networkx Graph
+            Core network
+        """
+
+        self.G = nx.Graph()
+        for i in range(self.n_t):
+            self.G.add_node(i, type="T")
+            for r in self.regions:
+                self.regions[r].add(i)
+            for j in self.G.nodes():
+                if i != j:
+                    self.add_edge(i, j, "peer")
+            self.customers[i] = set()
+            self.providers[i] = set()
+        return self.G
+
+    def add_edge(self, i, j, kind):
+        if kind == "transit":
+            customer = str(i)
+        else:
+            customer = "none"
+        self.G.add_edge(i, j, type=kind, customer=customer)
 
-    """
-    if with_replacement:
-        create_using = nx.MultiDiGraph()
+    def choose_peer_pref_attach(self, node_list):
+        """Pick a node with a probability weighted by its peer degree.
 
-        def sample(v, nodes):
-            if not self_loops:
-                nodes = nodes - {v}
-            return (seed.choice(list(nodes)) for i in range(k))
+        Pick a node from node_list with preferential attachment
+        computed only on their peer degree
+        """
+
+        d = {}
+        for n in node_list:
+            d[n] = self.G.nodes[n]["peers"]
+        return choose_pref_attach(d, self.seed)
+
+    def choose_node_pref_attach(self, node_list):
+        """Pick a node with a probability weighted by its degree.
+
+        Pick a node from node_list with preferential attachment
+        computed on their degree
+        """
+
+        degs = dict(self.G.degree(node_list))
+        return choose_pref_attach(degs, self.seed)
+
+    def add_customer(self, i, j):
+        """Keep the dictionaries 'customers' and 'providers' consistent."""
+
+        self.customers[j].add(i)
+        self.providers[i].add(j)
+        for z in self.providers[j]:
+            self.customers[z].add(i)
+            self.providers[i].add(z)
+
+    def add_node(self, i, kind, reg2prob, avg_deg, t_edge_prob):
+        """Add a node and its customer transit edges to the graph.
+
+        Parameters
+        ----------
+        i: object
+            Identifier of the new node
+        kind: string
+            Type of the new node. Options are: 'M' for middle node, 'CP' for
+            content provider and 'C' for customer.
+        reg2prob: float
+            Probability the new node can be in two different regions.
+        avg_deg: float
+            Average number of transit nodes of which node i is customer.
+        t_edge_prob: float
+            Probability node i establish a customer transit edge with a tier
+            one (T) node
+
+        Returns
+        -------
+        i: object
+            Identifier of the new node
+        """
+
+        regs = 1  # regions in which node resides
+        if self.seed.random() < reg2prob:  # node is in two regions
+            regs = 2
+        node_options = set()
+
+        self.G.add_node(i, type=kind, peers=0)
+        self.customers[i] = set()
+        self.providers[i] = set()
+        self.nodes[kind].add(i)
+        for r in self.seed.sample(list(self.regions), regs):
+            node_options = node_options.union(self.regions[r])
+            self.regions[r].add(i)
+
+        edge_num = uniform_int_from_avg(1, avg_deg, self.seed)
+
+        t_options = node_options.intersection(self.nodes["T"])
+        m_options = node_options.intersection(self.nodes["M"])
+        if i in m_options:
+            m_options.remove(i)
+        d = 0
+        while d < edge_num and (len(t_options) > 0 or len(m_options) > 0):
+            if len(m_options) == 0 or (
+                len(t_options) > 0 and self.seed.random() < t_edge_prob
+            ):  # add edge to a T node
+                j = self.choose_node_pref_attach(t_options)
+                t_options.remove(j)
+            else:
+                j = self.choose_node_pref_attach(m_options)
+                m_options.remove(j)
+            self.add_edge(i, j, "transit")
+            self.add_customer(i, j)
+            d += 1
+
+        return i
+
+    def add_m_peering_link(self, m, to_kind):
+        """Add a peering link between two middle tier (M) nodes.
+
+        Target node j is drawn considering a preferential attachment based on
+        other M node peering degree.
+
+        Parameters
+        ----------
+        m: object
+            Node identifier
+        to_kind: string
+            type for target node j (must be always M)
+
+        Returns
+        -------
+        success: boolean
+        """
+
+        # candidates are of type 'M' and are not customers of m
+        node_options = self.nodes["M"].difference(self.customers[m])
+        # candidates are not providers of m
+        node_options = node_options.difference(self.providers[m])
+        # remove self
+        if m in node_options:
+            node_options.remove(m)
+
+        # remove candidates we are already connected to
+        for j in self.G.neighbors(m):
+            if j in node_options:
+                node_options.remove(j)
+
+        if len(node_options) > 0:
+            j = self.choose_peer_pref_attach(node_options)
+            self.add_edge(m, j, "peer")
+            self.G.nodes[m]["peers"] += 1
+            self.G.nodes[j]["peers"] += 1
+            return True
+        else:
+            return False
 
-    else:
-        create_using = nx.DiGraph()
+    def add_cp_peering_link(self, cp, to_kind):
+        """Add a peering link to a content provider (CP) node.
 
-        def sample(v, nodes):
-            if not self_loops:
-                nodes = nodes - {v}
-            return seed.sample(list(nodes), k)
-
-    G = nx.empty_graph(n, create_using)
-    nodes = set(G)
-    for u in G:
-        G.add_edges_from((u, v) for v in sample(u, nodes))
-    return G
+        Target node j can be CP or M and it is drawn uniformly among the nodes
+        belonging to the same region as cp.
 
+        Parameters
+        ----------
+        cp: object
+            Node identifier
+        to_kind: string
+            type for target node j (must be M or CP)
+
+        Returns
+        -------
+        success: boolean
+        """
+
+        node_options = set()
+        for r in self.regions:  # options include nodes in the same region(s)
+            if cp in self.regions[r]:
+                node_options = node_options.union(self.regions[r])
+
+        # options are restricted to the indicated kind ('M' or 'CP')
+        node_options = self.nodes[to_kind].intersection(node_options)
+
+        # remove self
+        if cp in node_options:
+            node_options.remove(cp)
+
+        # remove nodes that are cp's providers
+        node_options = node_options.difference(self.providers[cp])
+
+        # remove nodes we are already connected to
+        for j in self.G.neighbors(cp):
+            if j in node_options:
+                node_options.remove(j)
+
+        if len(node_options) > 0:
+            j = self.seed.sample(list(node_options), 1)[0]
+            self.add_edge(cp, j, "peer")
+            self.G.nodes[cp]["peers"] += 1
+            self.G.nodes[j]["peers"] += 1
+            return True
+        else:
+            return False
 
-@py_random_state(4)
-@nx._dispatch(graphs=None)
-def random_k_out_graph(n, k, alpha, self_loops=True, seed=None):
-    """Returns a random `k`-out graph with preferential attachment.
-
-    A random `k`-out graph with preferential attachment is a
-    multidigraph generated by the following algorithm.
-
-    1. Begin with an empty digraph, and initially set each node to have
-       weight `alpha`.
-    2. Choose a node `u` with out-degree less than `k` uniformly at
-       random.
-    3. Choose a node `v` from with probability proportional to its
-       weight.
-    4. Add a directed edge from `u` to `v`, and increase the weight
-       of `v` by one.
-    5. If each node has out-degree `k`, halt, otherwise repeat from
-       step 2.
+    def graph_regions(self, rn):
+        """Initializes AS network regions.
 
-    For more information on this model of random graph, see [1].
+        Parameters
+        ----------
+        rn: integer
+            Number of regions
+        """
+
+        self.regions = {}
+        for i in range(rn):
+            self.regions["REG" + str(i)] = set()
+
+    def add_peering_links(self, from_kind, to_kind):
+        """Utility function to add peering links among node groups."""
+        peer_link_method = None
+        if from_kind == "M":
+            peer_link_method = self.add_m_peering_link
+            m = self.p_m_m
+        if from_kind == "CP":
+            peer_link_method = self.add_cp_peering_link
+            if to_kind == "M":
+                m = self.p_cp_m
+            else:
+                m = self.p_cp_cp
+
+        for i in self.nodes[from_kind]:
+            num = uniform_int_from_avg(0, m, self.seed)
+            for _ in range(num):
+                peer_link_method(i, to_kind)
+
+    def generate(self):
+        """Generates a random AS network graph as described in [1].
+
+        Returns
+        -------
+        G: Graph object
+
+        Notes
+        -----
+        The process steps are the following: first we create the core network
+        of tier one nodes, then we add the middle tier (M), the content
+        provider (CP) and the customer (C) nodes along with their transit edges
+        (link i,j means i is customer of j). Finally we add peering links
+        between M nodes, between M and CP nodes and between CP node couples.
+        For a detailed description of the algorithm, please refer to [1].
+
+        References
+        ----------
+        [1] A. Elmokashfi, A. Kvalbein and C. Dovrolis, "On the Scalability of
+        BGP: The Role of Topology Growth," in IEEE Journal on Selected Areas
+        in Communications, vol. 28, no. 8, pp. 1250-1261, October 2010.
+        """
+
+        self.graph_regions(5)
+        self.customers = {}
+        self.providers = {}
+        self.nodes = {"T": set(), "M": set(), "CP": set(), "C": set()}
+
+        self.t_graph()
+        self.nodes["T"] = set(self.G.nodes())
+
+        i = len(self.nodes["T"])
+        for _ in range(self.n_m):
+            self.nodes["M"].add(self.add_node(i, "M", 0.2, self.d_m, self.t_m))
+            i += 1
+        for _ in range(self.n_cp):
+            self.nodes["CP"].add(self.add_node(i, "CP", 0.05, self.d_cp, self.t_cp))
+            i += 1
+        for _ in range(self.n_c):
+            self.nodes["C"].add(self.add_node(i, "C", 0, self.d_c, self.t_c))
+            i += 1
+
+        self.add_peering_links("M", "M")
+        self.add_peering_links("CP", "M")
+        self.add_peering_links("CP", "CP")
+
+        return self.G
+
+
+@py_random_state(1)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def random_internet_as_graph(n, seed=None):
+    """Generates a random undirected graph resembling the Internet AS network
 
     Parameters
     ----------
-    n : int
-        The number of nodes in the returned graph.
-
-    k : int
-        The out-degree of each node in the returned graph.
-
-    alpha : float
-        A positive :class:`float` representing the initial weight of
-        each vertex. A higher number means that in step 3 above, nodes
-        will be chosen more like a true uniformly random sample, and a
-        lower number means that nodes are more likely to be chosen as
-        their in-degree increases. If this parameter is not positive, a
-        :exc:`ValueError` is raised.
-
-    self_loops : bool
-        If True, self-loops are allowed when generating the graph.
-
+    n: integer in [1000, 10000]
+        Number of graph nodes
     seed : integer, random_state, or None (default)
         Indicator of random number generation state.
         See :ref:`Randomness<randomness>`.
 
     Returns
     -------
-    :class:`~networkx.classes.MultiDiGraph`
-        A `k`-out-regular multidigraph generated according to the above
-        algorithm.
-
-    Raises
-    ------
-    ValueError
-        If `alpha` is not positive.
+    G: Networkx Graph object
+        A randomly generated undirected graph
 
     Notes
     -----
-    The returned multidigraph may not be strongly connected, or even
-    weakly connected.
+    This algorithm returns an undirected graph resembling the Internet
+    Autonomous System (AS) network, it uses the approach by Elmokashfi et al.
+    [1]_ and it grants the properties described in the related paper [1]_.
+
+    Each node models an autonomous system, with an attribute 'type' specifying
+    its kind; tier-1 (T), mid-level (M), customer (C) or content-provider (CP).
+    Each edge models an ADV communication link (hence, bidirectional) with
+    attributes:
+
+      - type: transit|peer, the kind of commercial agreement between nodes;
+      - customer: <node id>, the identifier of the node acting as customer
+        ('none' if type is peer).
 
     References
     ----------
-    [1]: Peterson, Nicholas R., and Boris Pittel.
-         "Distance between two random `k`-out digraphs, with and without
-         preferential attachment."
-         arXiv preprint arXiv:1311.5961 (2013).
-         <https://arxiv.org/abs/1311.5961>
-
+    .. [1] A. Elmokashfi, A. Kvalbein and C. Dovrolis, "On the Scalability of
+       BGP: The Role of Topology Growth," in IEEE Journal on Selected Areas
+       in Communications, vol. 28, no. 8, pp. 1250-1261, October 2010.
     """
-    if alpha < 0:
-        raise ValueError("alpha must be positive")
-    G = nx.empty_graph(n, create_using=nx.MultiDiGraph)
-    weights = Counter({v: alpha for v in G})
-    for i in range(k * n):
-        u = seed.choice([v for v, d in G.out_degree() if d < k])
-        # If self-loops are not allowed, make the source node `u` have
-        # weight zero.
-        if not self_loops:
-            adjustment = Counter({u: weights[u]})
-        else:
-            adjustment = Counter()
-        v = weighted_choice(weights - adjustment, seed=seed)
-        G.add_edge(u, v)
-        weights[v] += 1
+
+    GG = AS_graph_generator(n, seed)
+    G = GG.generate()
     return G
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `networkx-3.2rc0/networkx/generators/duplication.py` & `networkx-3.3rc0/networkx/generators/duplication.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from networkx.exception import NetworkXError
 from networkx.utils import py_random_state
 
 __all__ = ["partial_duplication_graph", "duplication_divergence_graph"]
 
 
 @py_random_state(4)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def partial_duplication_graph(N, n, p, q, seed=None):
     """Returns a random graph using the partial duplication model.
 
     Parameters
     ----------
     N : int
         The total number of nodes in the final graph.
@@ -72,27 +72,27 @@
         # Pick a random vertex, u, already in the graph.
         src_node = seed.randint(0, new_node - 1)
 
         # Add a new vertex, v, to the graph.
         G.add_node(new_node)
 
         # For each neighbor of u...
-        for neighbor_node in list(nx.all_neighbors(G, src_node)):
+        for nbr_node in list(nx.all_neighbors(G, src_node)):
             # Add the neighbor to v with probability p.
             if seed.random() < p:
-                G.add_edge(new_node, neighbor_node)
+                G.add_edge(new_node, nbr_node)
 
         # Join v and u with probability q.
         if seed.random() < q:
             G.add_edge(new_node, src_node)
     return G
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def duplication_divergence_graph(n, p, seed=None):
     """Returns an undirected graph using the duplication-divergence model.
 
     A graph of `n` nodes is created by duplicating the initial nodes
     and retaining edges incident to the original nodes with a retention
     probability `p`.
```

### Comparing `networkx-3.2rc0/networkx/generators/ego.py` & `networkx-3.3rc0/networkx/generators/ego.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Ego graph.
 """
 __all__ = ["ego_graph"]
 
 import networkx as nx
 
 
-@nx._dispatch(edge_attrs="distance")
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def ego_graph(G, n, radius=1, center=True, undirected=False, distance=None):
     """Returns induced subgraph of neighbors centered at node n within
     a given radius.
 
     Parameters
     ----------
     G : graph
```

### Comparing `networkx-3.2rc0/networkx/generators/geometric.py` & `networkx-3.3rc0/networkx/generators/geometric.py`

 * *Files 19% similar despite different names*

```diff
@@ -12,18 +12,19 @@
     "geometric_edges",
     "geographical_threshold_graph",
     "navigable_small_world_graph",
     "random_geometric_graph",
     "soft_random_geometric_graph",
     "thresholded_random_geometric_graph",
     "waxman_graph",
+    "geometric_soft_configuration_graph",
 ]
 
 
-@nx._dispatch(node_attrs="pos_name")
+@nx._dispatchable(node_attrs="pos_name")
 def geometric_edges(G, radius, p=2, *, pos_name="pos"):
     """Returns edge list of node pairs within `radius` of each other.
 
     Parameters
     ----------
     G : networkx graph
         The graph from which to generate the edge list. The nodes in `G` should
@@ -52,19 +53,21 @@
 
     Examples
     --------
     Create a graph with nodes that have a "pos" attribute representing 2D
     coordinates.
 
     >>> G = nx.Graph()
-    >>> G.add_nodes_from([
-    ...     (0, {"pos": (0, 0)}),
-    ...     (1, {"pos": (3, 0)}),
-    ...     (2, {"pos": (8, 0)}),
-    ... ])
+    >>> G.add_nodes_from(
+    ...     [
+    ...         (0, {"pos": (0, 0)}),
+    ...         (1, {"pos": (3, 0)}),
+    ...         (2, {"pos": (8, 0)}),
+    ...     ]
+    ... )
     >>> nx.geometric_edges(G, radius=1)
     []
     >>> nx.geometric_edges(G, radius=4)
     [(0, 1)]
     >>> nx.geometric_edges(G, radius=6)
     [(0, 1), (1, 2)]
     >>> nx.geometric_edges(G, radius=9)
@@ -106,15 +109,15 @@
     kdtree = sp.spatial.cKDTree(coords)  # Cannot provide generator.
     edge_indexes = kdtree.query_pairs(radius, p)
     edges = [(nodes[u], nodes[v]) for u, v in sorted(edge_indexes)]
     return edges
 
 
 @py_random_state(5)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_geometric_graph(
     n, radius, dim=2, pos=None, p=2, seed=None, *, pos_name="pos"
 ):
     """Returns a random geometric graph in the unit cube of dimensions `dim`.
 
     The random geometric graph model places `n` nodes uniformly at
     random in the unit cube. Two nodes are joined by an edge if the
@@ -200,15 +203,15 @@
     nx.set_node_attributes(G, pos, pos_name)
 
     G.add_edges_from(_geometric_edges(G, radius, p, pos_name))
     return G
 
 
 @py_random_state(6)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def soft_random_geometric_graph(
     n, radius, dim=2, pos=None, p=2, p_dist=None, seed=None, *, pos_name="pos"
 ):
     r"""Returns a soft random geometric graph in the unit cube.
 
     The soft random geometric graph [1] model places `n` nodes uniformly at
     random in the unit cube in dimension `dim`. Two nodes of distance, `dist`,
@@ -330,15 +333,15 @@
         return seed.random() < p_dist(dist)
 
     G.add_edges_from(filter(should_join, _geometric_edges(G, radius, p, pos_name)))
     return G
 
 
 @py_random_state(7)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def geographical_threshold_graph(
     n,
     theta,
     dim=2,
     pos=None,
     weight=None,
     metric=None,
@@ -497,15 +500,15 @@
         return (u_weight + v_weight) * p_dist(metric(u_pos, v_pos)) >= theta
 
     G.add_edges_from(filter(should_join, combinations(G, 2)))
     return G
 
 
 @py_random_state(6)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def waxman_graph(
     n,
     beta=0.4,
     alpha=0.1,
     L=None,
     domain=(0, 0, 1, 1),
     metric=None,
@@ -630,15 +633,15 @@
         return seed.random() < beta * math.exp(-dist(*pair) / (alpha * L))
 
     G.add_edges_from(filter(should_join, combinations(G, 2)))
     return G
 
 
 @py_random_state(5)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def navigable_small_world_graph(n, p=1, q=1, r=2, dim=2, seed=None):
     r"""Returns a navigable small-world graph.
 
     A navigable small-world graph is a directed grid with additional long-range
     connections that are chosen randomly.
 
       [...] we begin with a set of nodes [...] that are identified with the set
@@ -682,15 +685,15 @@
        perspective. Proc. 32nd ACM Symposium on Theory of Computing, 2000.
     """
     if p < 1:
         raise nx.NetworkXException("p must be >= 1")
     if q < 0:
         raise nx.NetworkXException("q must be >= 0")
     if r < 0:
-        raise nx.NetworkXException("r must be >= 1")
+        raise nx.NetworkXException("r must be >= 0")
 
     G = nx.DiGraph()
     nodes = list(product(range(n), repeat=dim))
     for p1 in nodes:
         probs = [0]
         for p2 in nodes:
             if p1 == p2:
@@ -703,15 +706,15 @@
         for _ in range(q):
             target = nodes[bisect_left(cdf, seed.uniform(0, cdf[-1]))]
             G.add_edge(p1, target)
     return G
 
 
 @py_random_state(7)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def thresholded_random_geometric_graph(
     n,
     radius,
     theta,
     dim=2,
     pos=None,
     weight=None,
@@ -840,7 +843,205 @@
     edges = (
         (u, v)
         for u, v in _geometric_edges(G, radius, p, pos_name)
         if weight[u] + weight[v] >= theta
     )
     G.add_edges_from(edges)
     return G
+
+
+@py_random_state(5)
+@nx._dispatchable(graphs=None, returns_graph=True)
+def geometric_soft_configuration_graph(
+    *, beta, n=None, gamma=None, mean_degree=None, kappas=None, seed=None
+):
+    r"""Returns a random graph from the geometric soft configuration model.
+
+    The $\mathbb{S}^1$ model [1]_ is the geometric soft configuration model
+    which is able to explain many fundamental features of real networks such as
+    small-world property, heteregenous degree distributions, high level of
+    clustering, and self-similarity.
+
+    In the geometric soft configuration model, a node $i$ is assigned two hidden
+    variables: a hidden degree $\kappa_i$, quantifying its popularity, influence,
+    or importance, and an angular position $\theta_i$ in a circle abstracting the
+    similarity space, where angular distances between nodes are a proxy for their
+    similarity. Focusing on the angular position, this model is often called
+    the $\mathbb{S}^1$ model (a one-dimensional sphere). The circle's radius is
+    adjusted to $R = N/2\pi$, where $N$ is the number of nodes, so that the density
+    is set to 1 without loss of generality.
+
+    The connection probability between any pair of nodes increases with
+    the product of their hidden degrees (i.e., their combined popularities),
+    and decreases with the angular distance between the two nodes.
+    Specifically, nodes $i$ and $j$ are connected with the probability
+
+    $p_{ij} = \frac{1}{1 + \frac{d_{ij}^\beta}{\left(\mu \kappa_i \kappa_j\right)^{\max(1, \beta)}}}$
+
+    where $d_{ij} = R\Delta\theta_{ij}$ is the arc length of the circle between
+    nodes $i$ and $j$ separated by an angular distance $\Delta\theta_{ij}$.
+    Parameters $\mu$ and $\beta$ (also called inverse temperature) control the
+    average degree and the clustering coefficient, respectively.
+
+    It can be shown [2]_ that the model undergoes a structural phase transition
+    at $\beta=1$ so that for $\beta<1$ networks are unclustered in the thermodynamic
+    limit (when $N\to \infty$) whereas for $\beta>1$ the ensemble generates
+    networks with finite clustering coefficient.
+
+    The $\mathbb{S}^1$ model can be expressed as a purely geometric model
+    $\mathbb{H}^2$ in the hyperbolic plane [3]_ by mapping the hidden degree of
+    each node into a radial coordinate as
+
+    $r_i = \hat{R} - \frac{2 \max(1, \beta)}{\beta \zeta} \ln \left(\frac{\kappa_i}{\kappa_0}\right)$
+
+    where $\hat{R}$ is the radius of the hyperbolic disk and $\zeta$ is the curvature,
+
+    $\hat{R} = \frac{2}{\zeta} \ln \left(\frac{N}{\pi}\right)
+    - \frac{2\max(1, \beta)}{\beta \zeta} \ln (\mu \kappa_0^2)$
+
+    The connection probability then reads
+
+    $p_{ij} = \frac{1}{1 + \exp\left({\frac{\beta\zeta}{2} (x_{ij} - \hat{R})}\right)}$
+
+    where
+
+    $x_{ij} = r_i + r_j + \frac{2}{\zeta} \ln \frac{\Delta\theta_{ij}}{2}$
+
+    is a good approximation of the hyperbolic distance between two nodes separated
+    by an angular distance $\Delta\theta_{ij}$ with radial coordinates $r_i$ and $r_j$.
+    For $\beta > 1$, the curvature $\zeta = 1$, for $\beta < 1$, $\zeta = \beta^{-1}$.
+
+
+    Parameters
+    ----------
+    Either `n`, `gamma`, `mean_degree` are provided or `kappas`. The values of
+    `n`, `gamma`, `mean_degree` (if provided) are used to construct a random
+    kappa-dict keyed by node with values sampled from a power-law distribution.
+
+    beta : positive number
+        Inverse temperature, controlling the clustering coefficient.
+    n : int (default: None)
+        Size of the network (number of nodes).
+        If not provided, `kappas` must be provided and holds the nodes.
+    gamma : float (default: None)
+        Exponent of the power-law distribution for hidden degrees `kappas`.
+        If not provided, `kappas` must be provided directly.
+    mean_degree : float (default: None)
+        The mean degree in the network.
+        If not provided, `kappas` must be provided directly.
+    kappas : dict (default: None)
+        A dict keyed by node to its hidden degree value.
+        If not provided, random values are computed based on a power-law
+        distribution using `n`, `gamma` and `mean_degree`.
+    seed : int, random_state, or None (default)
+        Indicator of random number generation state.
+        See :ref:`Randomness<randomness>`.
+
+    Returns
+    -------
+    Graph
+        A random geometric soft configuration graph (undirected with no self-loops).
+        Each node has three node-attributes:
+
+        - ``kappa`` that represents the hidden degree.
+
+        - ``theta`` the position in the similarity space ($\mathbb{S}^1$) which is
+          also the angular position in the hyperbolic plane.
+
+        - ``radius`` the radial position in the hyperbolic plane
+          (based on the hidden degree).
+
+
+    Examples
+    --------
+    Generate a network with specified parameters:
+
+    >>> G = nx.geometric_soft_configuration_graph(beta=1.5, n=100, gamma=2.7, mean_degree=5)
+
+    Create a geometric soft configuration graph with 100 nodes. The $\beta$ parameter
+    is set to 1.5 and the exponent of the powerlaw distribution of the hidden
+    degrees is 2.7 with mean value of 5.
+
+    Generate a network with predefined hidden degrees:
+
+    >>> kappas = {i: 10 for i in range(100)}
+    >>> G = nx.geometric_soft_configuration_graph(beta=2.5, kappas=kappas)
+
+    Create a geometric soft configuration graph with 100 nodes. The $\beta$ parameter
+    is set to 2.5 and all nodes with hidden degree $\kappa=10$.
+
+
+    References
+    ----------
+    .. [1] Serrano, M. Á., Krioukov, D., & Boguñá, M. (2008). Self-similarity
+       of complex networks and hidden metric spaces. Physical review letters, 100(7), 078701.
+
+    .. [2] van der Kolk, J., Serrano, M. Á., & Boguñá, M. (2022). An anomalous
+       topological phase transition in spatial random graphs. Communications Physics, 5(1), 245.
+
+    .. [3] Krioukov, D., Papadopoulos, F., Kitsak, M., Vahdat, A., & Boguná, M. (2010).
+       Hyperbolic geometry of complex networks. Physical Review E, 82(3), 036106.
+
+    """
+    if beta <= 0:
+        raise nx.NetworkXError("The parameter beta cannot be smaller or equal to 0.")
+
+    if kappas is not None:
+        if not all((n is None, gamma is None, mean_degree is None)):
+            raise nx.NetworkXError(
+                "When kappas is input, n, gamma and mean_degree must not be."
+            )
+
+        n = len(kappas)
+        mean_degree = sum(kappas) / len(kappas)
+    else:
+        if any((n is None, gamma is None, mean_degree is None)):
+            raise nx.NetworkXError(
+                "Please provide either kappas, or all 3 of: n, gamma and mean_degree."
+            )
+
+        # Generate `n` hidden degrees from a powerlaw distribution
+        # with given exponent `gamma` and mean value `mean_degree`
+        gam_ratio = (gamma - 2) / (gamma - 1)
+        kappa_0 = mean_degree * gam_ratio * (1 - 1 / n) / (1 - 1 / n**gam_ratio)
+        base = 1 - 1 / n
+        power = 1 / (1 - gamma)
+        kappas = {i: kappa_0 * (1 - seed.random() * base) ** power for i in range(n)}
+
+    G = nx.Graph()
+    R = n / (2 * math.pi)
+
+    # Approximate values for mu in the thermodynamic limit (when n -> infinity)
+    if beta > 1:
+        mu = beta * math.sin(math.pi / beta) / (2 * math.pi * mean_degree)
+    elif beta == 1:
+        mu = 1 / (2 * mean_degree * math.log(n))
+    else:
+        mu = (1 - beta) / (2**beta * mean_degree * n ** (1 - beta))
+
+    # Generate random positions on a circle
+    thetas = {k: seed.uniform(0, 2 * math.pi) for k in kappas}
+
+    for u in kappas:
+        for v in list(G):
+            angle = math.pi - math.fabs(math.pi - math.fabs(thetas[u] - thetas[v]))
+            dij = math.pow(R * angle, beta)
+            mu_kappas = math.pow(mu * kappas[u] * kappas[v], max(1, beta))
+            p_ij = 1 / (1 + dij / mu_kappas)
+
+            # Create an edge with a certain connection probability
+            if seed.random() < p_ij:
+                G.add_edge(u, v)
+        G.add_node(u)
+
+    nx.set_node_attributes(G, thetas, "theta")
+    nx.set_node_attributes(G, kappas, "kappa")
+
+    # Map hidden degrees into the radial coordiantes
+    zeta = 1 if beta > 1 else 1 / beta
+    kappa_min = min(kappas.values())
+    R_c = 2 * max(1, beta) / (beta * zeta)
+    R_hat = (2 / zeta) * math.log(n / math.pi) - R_c * math.log(mu * kappa_min)
+    radii = {node: R_hat - R_c * math.log(kappa) for node, kappa in kappas.items()}
+    nx.set_node_attributes(G, radii, "radius")
+
+    return G
```

### Comparing `networkx-3.2rc0/networkx/generators/harary_graph.py` & `networkx-3.3rc0/networkx/generators/harary_graph.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 
 import networkx as nx
 from networkx.exception import NetworkXError
 
 __all__ = ["hnm_harary_graph", "hkn_harary_graph"]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def hnm_harary_graph(n, m, create_using=None):
     """Returns the Harary graph with given numbers of nodes and edges.
 
     The Harary graph $H_{n,m}$ is the graph that maximizes node connectivity
     with $n$ nodes and $m$ edges.
 
     This maximum node connectivity is known to be floor($2m/n$). [1]_
@@ -109,15 +109,15 @@
         for i in range(m - n * offset):
             # add the remaining m - n*offset edges between i and i+half
             H.add_edge(i, (i + half) % n)
 
     return H
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def hkn_harary_graph(k, n, create_using=None):
     """Returns the Harary graph with given node connectivity and node number.
 
     The Harary graph $H_{k,n}$ is the graph that minimizes the number of
     edges needed with given node connectivity $k$ and node number $n$.
 
     This smallest number of edges is known to be ceil($kn/2$) [1]_.
```

### Comparing `networkx-3.2rc0/networkx/generators/intersection.py` & `networkx-3.3rc0/networkx/generators/intersection.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,15 @@
     "uniform_random_intersection_graph",
     "k_random_intersection_graph",
     "general_random_intersection_graph",
 ]
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def uniform_random_intersection_graph(n, m, p, seed=None):
     """Returns a uniform random intersection graph.
 
     Parameters
     ----------
     n : int
         The number of nodes in the first bipartite set (nodes)
@@ -44,15 +44,15 @@
     from networkx.algorithms import bipartite
 
     G = bipartite.random_graph(n, m, p, seed)
     return nx.projected_graph(G, range(n))
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def k_random_intersection_graph(n, m, k, seed=None):
     """Returns a intersection graph with randomly chosen attribute sets for
     each node that are of equal size (k).
 
     Parameters
     ----------
     n : int
@@ -80,15 +80,15 @@
     for v in range(n):
         targets = seed.sample(mset, k)
         G.add_edges_from(zip([v] * len(targets), targets))
     return nx.projected_graph(G, range(n))
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def general_random_intersection_graph(n, m, p, seed=None):
     """Returns a random intersection graph with independent probabilities
     for connections between node and attribute sets.
 
     Parameters
     ----------
     n : int
```

### Comparing `networkx-3.2rc0/networkx/generators/interval_graph.py` & `networkx-3.3rc0/networkx/generators/interval_graph.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from collections.abc import Sequence
 
 import networkx as nx
 
 __all__ = ["interval_graph"]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def interval_graph(intervals):
     """Generates an interval graph for a list of intervals given.
 
     In graph theory, an interval graph is an undirected graph formed from a set
     of closed intervals on the real line, with a vertex for each interval
     and an edge between vertices whose intervals intersect.
     It is the intersection graph of the intervals.
@@ -49,17 +49,15 @@
     for interval in intervals:
         if not (isinstance(interval, Sequence) and len(interval) == 2):
             raise TypeError(
                 "Each interval must have length 2, and be a "
                 "collections.abc.Sequence such as tuple or list."
             )
         if interval[0] > interval[1]:
-            raise ValueError(
-                f"Interval must have lower value first. " f"Got {interval}"
-            )
+            raise ValueError(f"Interval must have lower value first. Got {interval}")
 
     graph = nx.Graph()
 
     tupled_intervals = [tuple(interval) for interval in intervals]
     graph.add_nodes_from(tupled_intervals)
 
     while tupled_intervals:
```

### Comparing `networkx-3.2rc0/networkx/generators/lattice.py` & `networkx-3.3rc0/networkx/generators/lattice.py`

 * *Files 4% similar despite different names*

```diff
@@ -28,16 +28,16 @@
     "grid_graph",
     "hypercube_graph",
     "triangular_lattice_graph",
     "hexagonal_lattice_graph",
 ]
 
 
+@nx._dispatchable(graphs=None, returns_graph=True)
 @nodes_or_number([0, 1])
-@nx._dispatch(graphs=None)
 def grid_2d_graph(m, n, periodic=False, create_using=None):
     """Returns the two-dimensional grid graph.
 
     The grid graph has each node connected to its four nearest neighbors.
 
     Parameters
     ----------
@@ -82,15 +82,15 @@
         G.add_edges_from(((i, first), (i, last)) for i in rows)
     # both directions for directed
     if G.is_directed():
         G.add_edges_from((v, u) for u, v in G.edges())
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def grid_graph(dim, periodic=False):
     """Returns the *n*-dimensional grid graph.
 
     The dimension *n* is the length of the list `dim` and the size in
     each dimension is the value of the corresponding list element.
 
     Parameters
@@ -139,15 +139,15 @@
         Gnew = next(func)(current_dim)
         G = cartesian_product(Gnew, G)
     # graph G is done but has labels of the form (1, (2, (3, 1))) so relabel
     H = relabel_nodes(G, flatten)
     return H
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def hypercube_graph(n):
     """Returns the *n*-dimensional hypercube graph.
 
     The nodes are the integers between 0 and ``2 ** n - 1``, inclusive.
 
     For more information on the hypercube graph, see the Wikipedia
     article `Hypercube graph`_.
@@ -166,15 +166,15 @@
         The hypercube graph of dimension *n*.
     """
     dim = n * [2]
     G = grid_graph(dim)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def triangular_lattice_graph(
     m, n, periodic=False, with_positions=True, create_using=None
 ):
     r"""Returns the $m$ by $n$ triangular lattice graph.
 
     The `triangular lattice graph`_ is a two-dimensional `grid graph`_ in
     which each square unit has a diagonal edge (each grid unit has a chord).
@@ -267,15 +267,15 @@
         else:
             yy = (h * j for i in cols for j in rows)
         pos = {(i, j): (x, y) for i, j, x, y in zip(ii, jj, xx, yy) if (i, j) in H}
         set_node_attributes(H, pos, "pos")
     return H
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def hexagonal_lattice_graph(
     m, n, periodic=False, with_positions=True, create_using=None
 ):
     """Returns an `m` by `n` hexagonal lattice graph.
 
     The *hexagonal lattice graph* is a graph whose nodes and edges are
     the `hexagonal tiling`_ of the plane.
```

### Comparing `networkx-3.2rc0/networkx/generators/mycielski.py` & `networkx-3.3rc0/networkx/generators/mycielski.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["mycielskian", "mycielski_graph"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def mycielskian(G, iterations=1):
     r"""Returns the Mycielskian of a simple, undirected graph G
 
     The Mycielskian of graph preserves a graph's triangle free
     property while increasing the chromatic number by 1.
 
     The Mycielski Operation on a graph, :math:`G=(V, E)`, constructs a new
@@ -64,15 +64,15 @@
         M.add_edges_from((u + n, v) for u, v in old_edges)
         M.add_node(2 * n)
         M.add_edges_from((u + n, 2 * n) for u in range(n))
 
     return M
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def mycielski_graph(n):
     """Generator for the n_th Mycielski Graph.
 
     The Mycielski family of graphs is an infinite set of graphs.
     :math:`M_1` is the singleton graph, :math:`M_2` is two vertices with an
     edge, and, for :math:`i > 2`, :math:`M_i` is the Mycielskian of
     :math:`M_{i-1}`.
@@ -97,14 +97,14 @@
     :math:`P_2` graph with an extra, isolated vertex. The second Mycielski
     graph is the :math:`P_2` graph, so the first two are hard coded.
     The remaining graphs are generated using the Mycielski operation.
 
     """
 
     if n < 1:
-        raise nx.NetworkXError("must satisfy n >= 0")
+        raise nx.NetworkXError("must satisfy n >= 1")
 
     if n == 1:
         return nx.empty_graph(1)
 
     else:
         return mycielskian(nx.path_graph(2), n - 2)
```

### Comparing `networkx-3.2rc0/networkx/generators/nonisomorphic_trees.py` & `networkx-3.3rc0/networkx/generators/nonisomorphic_trees.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,55 +8,75 @@
 """
 
 __all__ = ["nonisomorphic_trees", "number_of_nonisomorphic_trees"]
 
 import networkx as nx
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def nonisomorphic_trees(order, create="graph"):
-    """Returns a list of nonisomorphic trees
+    """Generates lists of nonisomorphic trees
 
     Parameters
     ----------
     order : int
-      order of the desired tree(s)
-
-    create : graph or matrix (default="Graph)
-      If graph is selected a list of trees will be returned,
-      if matrix is selected a list of adjacency matrix will
-      be returned
-
-    Returns
-    -------
-    G : List of NetworkX Graphs
-
-    M : List of Adjacency matrices
-
-    References
-    ----------
+       order of the desired tree(s)
 
+    create : one of {"graph", "matrix"} (default="graph")
+       If ``"graph"`` is selected a list of ``Graph`` instances will be returned,
+       if matrix is selected a list of adjacency matrices will be returned.
+
+       .. deprecated:: 3.3
+
+          The `create` argument is deprecated and will be removed in NetworkX
+          version 3.5. In the future, `nonisomorphic_trees` will yield graph
+          instances by default. To generate adjacency matrices, call
+          ``nx.to_numpy_array`` on the output, e.g.::
+
+             [nx.to_numpy_array(G) for G in nx.nonisomorphic_trees(N)]
+
+    Yields
+    ------
+    list
+       A list of nonisomorphic trees, in one of two formats depending on the
+       value of the `create` parameter:
+       - ``create="graph"``: yields a list of `networkx.Graph` instances
+       - ``create="matrix"``: yields a list of list-of-lists representing adjacency matrices
     """
 
     if order < 2:
         raise ValueError
     # start at the path graph rooted at its center
     layout = list(range(order // 2 + 1)) + list(range(1, (order + 1) // 2))
 
     while layout is not None:
         layout = _next_tree(layout)
         if layout is not None:
             if create == "graph":
                 yield _layout_to_graph(layout)
             elif create == "matrix":
+                import warnings
+
+                warnings.warn(
+                    (
+                        "\n\nThe 'create=matrix' argument of nonisomorphic_trees\n"
+                        "is deprecated and will be removed in version 3.5.\n"
+                        "Use ``nx.to_numpy_array`` to convert graphs to adjacency "
+                        "matrices, e.g.::\n\n"
+                        "   [nx.to_numpy_array(G) for G in nx.nonisomorphic_trees(N)]"
+                    ),
+                    category=DeprecationWarning,
+                    stacklevel=2,
+                )
+
                 yield _layout_to_matrix(layout)
             layout = _next_rooted_tree(layout)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def number_of_nonisomorphic_trees(order):
     """Returns the number of nonisomorphic trees
 
     Parameters
     ----------
     order : int
       order of the desired tree(s)
```

### Comparing `networkx-3.2rc0/networkx/generators/random_clustered.py` & `networkx-3.3rc0/networkx/generators/random_clustered.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import networkx as nx
 from networkx.utils import py_random_state
 
 __all__ = ["random_clustered_graph"]
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_clustered_graph(joint_degree_sequence, create_using=None, seed=None):
     r"""Generate a random graph with the given joint independent edge degree and
     triangle degree sequence.
 
     This uses a configuration model-like approach to generate a random graph
     (with parallel edges and self-loops) by randomly assigning edges to match
     the given joint degree sequence.
```

### Comparing `networkx-3.2rc0/networkx/generators/random_graphs.py` & `networkx-3.3rc0/networkx/generators/random_graphs.py`

 * *Files 3% similar despite different names*

```diff
@@ -33,15 +33,15 @@
     "random_powerlaw_tree",
     "random_powerlaw_tree_sequence",
     "random_kernel_graph",
 ]
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def fast_gnp_random_graph(n, p, seed=None, directed=False):
     """Returns a $G_{n,p}$ random graph, also known as an Erdős-Rényi graph or
     a binomial graph.
 
     Parameters
     ----------
     n : int
@@ -105,15 +105,15 @@
             v = v + 1
         if v < n:
             G.add_edge(v, w)
     return G
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def gnp_random_graph(n, p, seed=None, directed=False):
     """Returns a $G_{n,p}$ random graph, also known as an Erdős-Rényi graph
     or a binomial graph.
 
     The $G_{n,p}$ model chooses each of the possible edges with probability $p$.
 
     Parameters
@@ -170,15 +170,15 @@
 
 # add some aliases to common names
 binomial_graph = gnp_random_graph
 erdos_renyi_graph = gnp_random_graph
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def dense_gnm_random_graph(n, m, seed=None):
     """Returns a $G_{n,m}$ random graph.
 
     In the $G_{n,m}$ model, a graph is chosen uniformly at random from the set
     of all graphs with $n$ nodes and $m$ edges.
 
     This algorithm should be faster than :func:`gnm_random_graph` for dense
@@ -232,15 +232,15 @@
         v += 1
         if v == n:  # go to next row of adjacency matrix
             u += 1
             v = u + 1
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def gnm_random_graph(n, m, seed=None, directed=False):
     """Returns a $G_{n,m}$ random graph.
 
     In the $G_{n,m}$ model, a graph is chosen uniformly at random from the set
     of all graphs with $n$ nodes and $m$ edges.
 
     This algorithm should be faster than :func:`dense_gnm_random_graph` for
@@ -288,15 +288,15 @@
         else:
             G.add_edge(u, v)
             edge_count = edge_count + 1
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def newman_watts_strogatz_graph(n, k, p, seed=None):
     """Returns a Newman–Watts–Strogatz small-world graph.
 
     Parameters
     ----------
     n : int
         The number of nodes.
@@ -359,15 +359,15 @@
                     break  # skip this rewiring
             else:
                 G.add_edge(u, w)
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def watts_strogatz_graph(n, k, p, seed=None):
     """Returns a Watts–Strogatz small-world graph.
 
     Parameters
     ----------
     n : int
         The number of nodes
@@ -434,15 +434,15 @@
                 else:
                     G.remove_edge(u, v)
                     G.add_edge(u, w)
     return G
 
 
 @py_random_state(4)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def connected_watts_strogatz_graph(n, k, p, tries=100, seed=None):
     """Returns a connected Watts–Strogatz small-world graph.
 
     Attempts to generate a connected graph by repeated generation of
     Watts–Strogatz small-world graphs.  An exception is raised if the maximum
     number of tries is exceeded.
 
@@ -487,15 +487,15 @@
         G = watts_strogatz_graph(n, k, p, seed)
         if nx.is_connected(G):
             return G
     raise nx.NetworkXError("Maximum number of tries exceeded")
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_regular_graph(d, n, seed=None):
     r"""Returns a random $d$-regular graph on $n$ nodes.
 
     A regular graph is a graph where each node has the same number of neighbors.
 
     The resulting graph has no self-loops or parallel edges.
 
@@ -618,15 +618,15 @@
     while len(targets) < m:
         x = rng.choice(seq)
         targets.add(x)
     return targets
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def barabasi_albert_graph(n, m, seed=None, initial_graph=None):
     """Returns a random graph using Barabási–Albert preferential attachment
 
     A graph of $n$ nodes is grown by attaching new nodes each with $m$
     edges that are preferentially attached to existing nodes with high degree.
 
     Parameters
@@ -691,15 +691,15 @@
         repeated_nodes.extend([source] * m)
 
         source += 1
     return G
 
 
 @py_random_state(4)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def dual_barabasi_albert_graph(n, m1, m2, p, seed=None, initial_graph=None):
     """Returns a random graph using dual Barabási–Albert preferential attachment
 
     A graph of $n$ nodes is grown by attaching new nodes each with either $m_1$
     edges (with probability $p$) or $m_2$ edges (with probability $1-p$) that
     are preferentially attached to existing nodes with high degree.
 
@@ -791,15 +791,15 @@
         repeated_nodes.extend([source] * m)
 
         source += 1
     return G
 
 
 @py_random_state(4)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def extended_barabasi_albert_graph(n, m, p, q, seed=None):
     """Returns an extended Barabási–Albert model graph.
 
     An extended Barabási–Albert model graph is a random graph constructed
     using preferential attachment. The extended model allows new edges,
     rewired edges or new nodes. Based on the probabilities $p$ and $q$
     with $p + q < 1$, the growing behavior of the graph is determined as:
@@ -907,24 +907,24 @@
             # These nodes are the pivot nodes of the edges to rewire
             eligible_nodes = [nd for nd, deg in G.degree() if 0 < deg < clique_degree]
             for i in range(m):
                 # Choosing a random source node
                 node = seed.choice(eligible_nodes)
 
                 # The available nodes do have a neighbor at least.
-                neighbor_nodes = list(G[node])
+                nbr_nodes = list(G[node])
 
                 # Choosing the other end that will get detached
-                src_node = seed.choice(neighbor_nodes)
+                src_node = seed.choice(nbr_nodes)
 
                 # Picking a target node that is not 'node' or
                 # neighbor with 'node', with preferential attachment
-                neighbor_nodes.append(node)
+                nbr_nodes.append(node)
                 dest_node = seed.choice(
-                    [nd for nd in attachment_preference if nd not in neighbor_nodes]
+                    [nd for nd in attachment_preference if nd not in nbr_nodes]
                 )
                 # Rewire
                 G.remove_edge(node, src_node)
                 G.add_edge(node, dest_node)
 
                 # Adjusting the preferential attachment list
                 attachment_preference.remove(src_node)
@@ -952,15 +952,15 @@
             # The new node has m edges to it, plus itself: m + 1
             attachment_preference.extend([new_node] * (m + 1))
             new_node += 1
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def powerlaw_cluster_graph(n, m, p, seed=None):
     """Holme and Kim algorithm for growing graphs with powerlaw
     degree distribution and approximate average clustering.
 
     Parameters
     ----------
     n : int
@@ -1042,15 +1042,15 @@
 
         repeated_nodes.extend([source] * m)  # add source node to list m times
         source += 1
     return G
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_lobster(n, p1, p2, seed=None):
     """Returns a random lobster graph.
 
     A lobster is a tree that reduces to a caterpillar when pruning all
     leaf nodes. A caterpillar is a tree that reduces to a path graph
     when pruning all leaf nodes; setting `p2` to zero produces a caterpillar.
 
@@ -1093,15 +1093,15 @@
             while seed.random() < p2:  # add crunchy lobster bits
                 current_node += 1
                 L.add_edge(cat_node, current_node)
     return L  # voila, un lobster!
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_shell_graph(constructor, seed=None):
     """Returns a random shell graph for the constructor given.
 
     Parameters
     ----------
     constructor : list of three-tuples
         Represents the parameters for a shell, starting at the center
@@ -1151,15 +1151,15 @@
             else:
                 G.add_edge(u, v)
                 edge_count = edge_count + 1
     return G
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_powerlaw_tree(n, gamma=3, seed=None, tries=100):
     """Returns a tree with a power law degree distribution.
 
     Parameters
     ----------
     n : int
         The number of nodes.
@@ -1188,15 +1188,15 @@
     # This call may raise a NetworkXError if the number of tries is succeeded.
     seq = random_powerlaw_tree_sequence(n, gamma=gamma, seed=seed, tries=tries)
     G = degree_sequence_tree(seq)
     return G
 
 
 @py_random_state(2)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None)
 def random_powerlaw_tree_sequence(n, gamma=3, seed=None, tries=100):
     """Returns a degree sequence for a tree with a power law distribution.
 
     Parameters
     ----------
     n : int,
         The number of nodes.
@@ -1245,15 +1245,15 @@
 
     raise nx.NetworkXError(
         f"Exceeded max ({tries}) attempts for a valid tree sequence."
     )
 
 
 @py_random_state(3)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_kernel_graph(n, kernel_integral, kernel_root=None, seed=None):
     r"""Returns an random graph based on the specified kernel.
 
     The algorithm chooses each of the $[n(n-1)]/2$ possible edges with
     probability specified by a kernel $\kappa(x,y)$ [1]_.  The kernel
     $\kappa(x,y)$ must be a symmetric (in $x,y$), non-negative,
     bounded function.
```

### Comparing `networkx-3.2rc0/networkx/generators/small.py` & `networkx-3.3rc0/networkx/generators/small.py`

 * *Files 4% similar despite different names*

```diff
@@ -55,49 +55,64 @@
             if G.is_directed():
                 raise NetworkXError("Directed Graph not supported")
         return func(*args, **kwargs)
 
     return wrapper
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def LCF_graph(n, shift_list, repeats, create_using=None):
     """
     Return the cubic graph specified in LCF notation.
 
-    LCF notation (LCF=Lederberg-Coxeter-Fruchte) is a compressed
+    LCF (Lederberg-Coxeter-Fruchte) notation[1]_ is a compressed
     notation used in the generation of various cubic Hamiltonian
-    graphs of high symmetry. See, for example, dodecahedral_graph,
-    desargues_graph, heawood_graph and pappus_graph below.
+    graphs of high symmetry. See, for example, `dodecahedral_graph`,
+    `desargues_graph`, `heawood_graph` and `pappus_graph`.
 
-    n (number of nodes)
-      The starting graph is the n-cycle with nodes 0,...,n-1.
-      (The null graph is returned if n < 0.)
-
-    shift_list = [s1,s2,..,sk], a list of integer shifts mod n,
-
-    repeats
-      integer specifying the number of times that shifts in shift_list
-      are successively applied to each v_current in the n-cycle
-      to generate an edge between v_current and v_current+shift mod n.
-
-    For v1 cycling through the n-cycle a total of k*repeats
-    with shift cycling through shiftlist repeats times connect
-    v1 with v1+shift mod n
+    Nodes are drawn from ``range(n)``. Each node ``n_i`` is connected with
+    node ``n_i + shift % n`` where ``shift`` is given by cycling through
+    the input `shift_list` `repeat` s times.
 
+    Parameters
+    ----------
+    n : int
+       The starting graph is the `n`-cycle with nodes ``0, ..., n-1``.
+       The null graph is returned if `n` < 1.
+
+    shift_list : list
+       A list of integer shifts mod `n`, ``[s1, s2, .., sk]``
+
+    repeats : int
+       Integer specifying the number of times that shifts in `shift_list`
+       are successively applied to each current node in the n-cycle
+       to generate an edge between ``n_current`` and ``n_current + shift mod n``.
+
+    Returns
+    -------
+    G : Graph
+       A graph instance created from the specified LCF notation.
+
+    Examples
+    --------
     The utility graph $K_{3,3}$
 
     >>> G = nx.LCF_graph(6, [3, -3], 3)
+    >>> G.edges()
+    EdgeView([(0, 1), (0, 5), (0, 3), (1, 2), (1, 4), (2, 3), (2, 5), (3, 4), (4, 5)])
 
-    The Heawood graph
+    The Heawood graph:
 
     >>> G = nx.LCF_graph(14, [5, -5], 7)
+    >>> nx.is_isomorphic(G, nx.heawood_graph())
+    True
 
-    See http://mathworld.wolfram.com/LCFNotation.html for a description
-    and references.
+    References
+    ----------
+    .. [1] https://en.wikipedia.org/wiki/LCF_notation
 
     """
     if n <= 0:
         return empty_graph(0, create_using)
 
     # start with the n-cycle
     G = cycle_graph(n, create_using)
@@ -122,15 +137,15 @@
 
 # -------------------------------------------------------------------------------
 #   Various small and named graphs
 # -------------------------------------------------------------------------------
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def bull_graph(create_using=None):
     """
     Returns the Bull Graph
 
     The Bull Graph has 5 nodes and 5 edges. It is a planar undirected
     graph in the form of a triangle with two disjoint pendant edges [1]_
     The name comes from the triangle and pendant edges representing
@@ -156,15 +171,15 @@
         create_using=create_using,
     )
     G.name = "Bull Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def chvatal_graph(create_using=None):
     """
     Returns the Chvátal Graph
 
     The Chvátal Graph is an undirected graph with 12 nodes and 24 edges [1]_.
     It has 370 distinct (directed) Hamiltonian cycles, giving a unique generalized
     LCF notation of order 4, two of order 6 , and 43 of order 1 [2]_.
@@ -201,15 +216,15 @@
         create_using=create_using,
     )
     G.name = "Chvatal Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def cubical_graph(create_using=None):
     """
     Returns the 3-regular Platonic Cubical Graph
 
     The skeleton of the cube (the nodes and edges) form a graph, with 8
     nodes, and 12 edges. It is a special case of the hypercube graph.
     It is one of 5 Platonic graphs, each a skeleton of its
@@ -240,19 +255,19 @@
             4: [0, 5, 7],
             5: [3, 4, 6],
             6: [2, 5, 7],
             7: [1, 4, 6],
         },
         create_using=create_using,
     )
-    G.name = ("Platonic Cubical Graph",)
+    G.name = "Platonic Cubical Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def desargues_graph(create_using=None):
     """
     Returns the Desargues Graph
 
     The Desargues Graph is a non-planar, distance-transitive cubic graph
     with 20 nodes and 30 edges [1]_.
     It is a symmetric graph. It can be represented in LCF notation
@@ -275,15 +290,15 @@
     """
     G = LCF_graph(20, [5, -5, 9, -9], 5, create_using)
     G.name = "Desargues Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def diamond_graph(create_using=None):
     """
     Returns the Diamond graph
 
     The Diamond Graph is  planar undirected graph with 4 nodes and 5 edges.
     It is also sometimes known as the double triangle graph or kite graph [1]_.
 
@@ -304,15 +319,15 @@
     G = nx.from_dict_of_lists(
         {0: [1, 2], 1: [0, 2, 3], 2: [0, 1, 3], 3: [1, 2]}, create_using=create_using
     )
     G.name = "Diamond Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def dodecahedral_graph(create_using=None):
     """
     Returns the Platonic Dodecahedral graph.
 
     The dodecahedral graph has 20 nodes and 30 edges. The skeleton of the
     dodecahedron forms a graph. It is one of 5 Platonic graphs [1]_.
     It can be described in LCF notation as:
@@ -335,15 +350,15 @@
 
     """
     G = LCF_graph(20, [10, 7, 4, -4, -7, 10, -4, 7, -7, 4], 2, create_using)
     G.name = "Dodecahedral Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def frucht_graph(create_using=None):
     """
     Returns the Frucht Graph.
 
     The Frucht Graph is the smallest cubical graph whose
     automorphism group consists only of the identity element [1]_.
     It has 12 nodes and 18 edges and no nontrivial symmetries.
@@ -382,15 +397,15 @@
         ]
     )
 
     G.name = "Frucht Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def heawood_graph(create_using=None):
     """
     Returns the Heawood Graph, a (3,6) cage.
 
     The Heawood Graph is an undirected graph with 14 nodes and 21 edges,
     named after Percy John Heawood [1]_.
     It is cubic symmetric, nonplanar, Hamiltonian, and can be represented
@@ -416,15 +431,15 @@
 
     """
     G = LCF_graph(14, [5, -5], 7, create_using)
     G.name = "Heawood Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def hoffman_singleton_graph():
     """
     Returns the Hoffman-Singleton Graph.
 
     The Hoffman–Singleton graph is a symmetrical undirected graph
     with 50 nodes and 175 edges.
     All indices lie in ``Z % 5``: that is, the integers mod 5 [1]_.
@@ -460,15 +475,15 @@
                 G.add_edge(("pentagon", i, j), ("pentagram", k, (i * k + j) % 5))
     G = nx.convert_node_labels_to_integers(G)
     G.name = "Hoffman-Singleton Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def house_graph(create_using=None):
     """
     Returns the House graph (square with triangle on top)
 
     The house graph is a simple undirected graph with
     5 nodes and 6 edges [1]_.
 
@@ -491,15 +506,15 @@
         create_using=create_using,
     )
     G.name = "House Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def house_x_graph(create_using=None):
     """
     Returns the House graph with a cross inside the house square.
 
     The House X-graph is the House graph plus the two edges connecting diagonally
     opposite vertices of the square base. It is also one of the two graphs
     obtained by removing two edges from the pentatope graph [1]_.
@@ -521,15 +536,15 @@
     G = house_graph(create_using)
     G.add_edges_from([(0, 3), (1, 2)])
     G.name = "House-with-X-inside Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def icosahedral_graph(create_using=None):
     """
     Returns the Platonic Icosahedral graph.
 
     The icosahedral graph has 12 nodes and 30 edges. It is a Platonic graph
     whose nodes have the connectivity of the icosahedron. It is undirected,
     regular and Hamiltonian [1]_.
@@ -564,15 +579,15 @@
         create_using=create_using,
     )
     G.name = "Platonic Icosahedral Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def krackhardt_kite_graph(create_using=None):
     """
     Returns the Krackhardt Kite Social Network.
 
     A 10 actor social network introduced by David Krackhardt
     to illustrate different centrality measures [1]_.
 
@@ -614,15 +629,15 @@
         },
         create_using=create_using,
     )
     G.name = "Krackhardt Kite Social Network"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def moebius_kantor_graph(create_using=None):
     """
     Returns the Moebius-Kantor graph.
 
     The Möbius-Kantor graph is the cubic symmetric graph on 16 nodes.
     Its LCF notation is [5,-5]^8, and it is isomorphic to the generalized
     Petersen graph [1]_.
@@ -644,15 +659,15 @@
     """
     G = LCF_graph(16, [5, -5], 8, create_using)
     G.name = "Moebius-Kantor Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def octahedral_graph(create_using=None):
     """
     Returns the Platonic Octahedral graph.
 
     The octahedral graph is the 6-node 12-edge Platonic graph having the
     connectivity of the octahedron [1]_. If 6 couples go to a party,
     and each person shakes hands with every person except his or her partner,
@@ -679,15 +694,15 @@
         {0: [1, 2, 3, 4], 1: [2, 3, 5], 2: [4, 5], 3: [4, 5], 4: [5]},
         create_using=create_using,
     )
     G.name = "Platonic Octahedral Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def pappus_graph():
     """
     Returns the Pappus graph.
 
     The Pappus graph is a cubic symmetric distance-regular graph with 18 nodes
     and 27 edges. It is Hamiltonian and can be represented in LCF notation as
     [5,7,-7,7,-7,-5]^3 [1]_.
@@ -703,15 +718,15 @@
     """
     G = LCF_graph(18, [5, 7, -7, 7, -7, -5], 3)
     G.name = "Pappus Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def petersen_graph(create_using=None):
     """
     Returns the Petersen graph.
 
     The Peterson graph is a cubic, undirected graph with 10 nodes and 15 edges [1]_.
     Julius Petersen constructed the graph as the smallest counterexample
     against the claim that a connected bridgeless cubic graph
@@ -747,15 +762,15 @@
         },
         create_using=create_using,
     )
     G.name = "Petersen Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def sedgewick_maze_graph(create_using=None):
     """
     Return a small maze with a cycle.
 
     This is the maze used in Sedgewick, 3rd Edition, Part 5, Graph
     Algorithms, Chapter 18, e.g. Figure 18.2 and following [1]_.
     Nodes are numbered 0,..,7
@@ -780,15 +795,15 @@
     G.add_edges_from([[1, 7], [2, 6]])
     G.add_edges_from([[3, 4], [3, 5]])
     G.add_edges_from([[4, 5], [4, 7], [4, 6]])
     G.name = "Sedgewick Maze"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def tetrahedral_graph(create_using=None):
     """
     Returns the 3-regular Platonic Tetrahedral graph.
 
     Tetrahedral graph has 4 nodes and 6 edges. It is a
     special case of the complete graph, K4, and wheel graph, W4.
     It is one of the 5 platonic graphs [1]_.
@@ -805,20 +820,20 @@
 
     References
     ----------
     .. [1] https://en.wikipedia.org/wiki/Tetrahedron#Tetrahedral_graph
 
     """
     G = complete_graph(4, create_using)
-    G.name = "Platonic Tetrahedral graph"
+    G.name = "Platonic Tetrahedral Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def truncated_cube_graph(create_using=None):
     """
     Returns the skeleton of the truncated cube.
 
     The truncated cube is an Archimedean solid with 14 regular
     faces (6 octagonal and 8 triangular), 36 edges and 24 nodes [1]_.
     The truncated cube is created by truncating (cutting off) the tips
@@ -868,15 +883,15 @@
         },
         create_using=create_using,
     )
     G.name = "Truncated Cube Graph"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def truncated_tetrahedron_graph(create_using=None):
     """
     Returns the skeleton of the truncated Platonic tetrahedron.
 
     The truncated tetrahedron is an Archimedean solid with 4 regular hexagonal faces,
     4 equilateral triangle faces, 12 nodes and 18 edges. It can be constructed by truncating
     all 4 vertices of a regular tetrahedron at one third of the original edge length [1]_.
@@ -899,15 +914,15 @@
     G = path_graph(12, create_using)
     G.add_edges_from([(0, 2), (0, 9), (1, 6), (3, 11), (4, 11), (5, 7), (8, 10)])
     G.name = "Truncated Tetrahedron Graph"
     return G
 
 
 @_raise_on_directed
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def tutte_graph(create_using=None):
     """
     Returns the Tutte graph.
 
     The Tutte graph is a cubic polyhedral, non-Hamiltonian graph. It has
     46 nodes and 69 edges.
     It is a counterexample to Tait's conjecture that every 3-regular polyhedron
```

### Comparing `networkx-3.2rc0/networkx/generators/social.py` & `networkx-3.3rc0/networkx/generators/social.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
     "karate_club_graph",
     "davis_southern_women_graph",
     "florentine_families_graph",
     "les_miserables_graph",
 ]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def karate_club_graph():
     """Returns Zachary's Karate Club graph.
 
     Each node in the returned graph has a node attribute 'club' that
     indicates the name of the club to which the member represented by that node
     belongs, either 'Mr. Hi' or 'Officer'. Each edge has a weight based on the
     number of contexts in which that edge's incident node members interacted.
@@ -89,15 +89,15 @@
 
     # Add the name of each member's club as a node attribute.
     for v in G:
         G.nodes[v]["club"] = "Mr. Hi" if v in club1 else "Officer"
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def davis_southern_women_graph():
     """Returns Davis Southern women social network.
 
     This is a bipartite graph.
 
     References
     ----------
@@ -240,15 +240,15 @@
         ]
     )
     G.graph["top"] = women
     G.graph["bottom"] = events
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def florentine_families_graph():
     """Returns Florentine families graph.
 
     References
     ----------
     .. [1] Ronald L. Breiger and Philippa E. Pattison
        Cumulated social roles: The duality of persons and their algebras,1
@@ -274,15 +274,15 @@
     G.add_edge("Albizzi", "Ginori")
     G.add_edge("Albizzi", "Guadagni")
     G.add_edge("Bischeri", "Guadagni")
     G.add_edge("Guadagni", "Lamberteschi")
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def les_miserables_graph():
     """Returns coappearance network of characters in the novel Les Miserables.
 
     References
     ----------
     .. [1] D. E. Knuth, 1993.
        The Stanford GraphBase: a platform for combinatorial computing,
```

### Comparing `networkx-3.2rc0/networkx/generators/spectral_graph_forge.py` & `networkx-3.3rc0/networkx/generators/spectral_graph_forge.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import networkx as nx
 from networkx.utils import np_random_state
 
 __all__ = ["spectral_graph_forge"]
 
 
 @np_random_state(3)
-@nx._dispatch
+@nx._dispatchable(returns_graph=True)
 def spectral_graph_forge(G, alpha, transformation="identity", seed=None):
     """Returns a random simple graph with spectrum resembling that of `G`
 
     This algorithm, called Spectral Graph Forge (SGF), computes the
     eigenvectors of a given graph adjacency matrix, filters them and
     builds a random graph with a similar eigenstructure.
     SGF has been proved to be particularly useful for synthesizing
```

### Comparing `networkx-3.2rc0/networkx/generators/stochastic.py` & `networkx-3.3rc0/networkx/generators/stochastic.py`

 * *Files 4% similar despite different names*

```diff
@@ -7,15 +7,17 @@
 from networkx.classes import DiGraph, MultiDiGraph
 from networkx.utils import not_implemented_for
 
 __all__ = ["stochastic_graph"]
 
 
 @not_implemented_for("undirected")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(
+    edge_attrs="weight", mutates_input={"not copy": 1}, returns_graph=True
+)
 def stochastic_graph(G, copy=True, weight="weight"):
     """Returns a right-stochastic representation of directed graph `G`.
 
     A right-stochastic graph is a weighted digraph in which for each
     node, the sum of the weights of all the out-edges of that node is
     1. If the graph is already weighted (for example, via a 'weight'
     edge attribute), the reweighting takes that into account.
```

### Comparing `networkx-3.2rc0/networkx/generators/sudoku.py` & `networkx-3.3rc0/networkx/generators/sudoku.py`

 * *Files 1% similar despite different names*

```diff
@@ -43,15 +43,15 @@
 
 import networkx as nx
 from networkx.exception import NetworkXError
 
 __all__ = ["sudoku_graph"]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def sudoku_graph(n=3):
     """Returns the n-Sudoku graph. The default value of n is 3.
 
     The n-Sudoku graph is a graph with n^4 vertices, corresponding to the
     cells of an n^2 by n^2 grid. Two distinct vertices are adjacent if and
     only if they belong to the same row, column, or n-by-n box.
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_atlas.py` & `networkx-3.3rc0/networkx/generators/tests/test_atlas.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_classic.py` & `networkx-3.3rc0/networkx/generators/tests/test_classic.py`

 * *Files 13% similar despite different names*

```diff
@@ -339,26 +339,25 @@
 
         pytest.raises(nx.NetworkXError, nx.ladder_graph, 2, create_using=nx.DiGraph)
 
         g = nx.ladder_graph(2)
         mg = nx.ladder_graph(2, create_using=nx.MultiGraph)
         assert edges_equal(mg.edges(), g.edges())
 
-    def test_lollipop_graph_right_sizes(self):
-        # number of nodes = m1 + m2
-        # number of edges = nx.number_of_edges(nx.complete_graph(m1)) + m2
-        for m1, m2 in [(3, 5), (4, 10), (3, 20)]:
-            G = nx.lollipop_graph(m1, m2)
-            assert nx.number_of_nodes(G) == m1 + m2
-            assert nx.number_of_edges(G) == m1 * (m1 - 1) / 2 + m2
-        for first, second in [("ab", ""), ("abc", "defg")]:
-            m1, m2 = len(first), len(second)
-            G = nx.lollipop_graph(first, second)
-            assert nx.number_of_nodes(G) == m1 + m2
-            assert nx.number_of_edges(G) == m1 * (m1 - 1) / 2 + m2
+    @pytest.mark.parametrize(("m", "n"), [(3, 5), (4, 10), (3, 20)])
+    def test_lollipop_graph_right_sizes(self, m, n):
+        G = nx.lollipop_graph(m, n)
+        assert nx.number_of_nodes(G) == m + n
+        assert nx.number_of_edges(G) == m * (m - 1) / 2 + n
+
+    @pytest.mark.parametrize(("m", "n"), [("ab", ""), ("abc", "defg")])
+    def test_lollipop_graph_size_node_sequence(self, m, n):
+        G = nx.lollipop_graph(m, n)
+        assert nx.number_of_nodes(G) == len(m) + len(n)
+        assert nx.number_of_edges(G) == len(m) * (len(m) - 1) / 2 + len(n)
 
     def test_lollipop_graph_exceptions(self):
         # Raise NetworkXError if m<2
         pytest.raises(nx.NetworkXError, nx.lollipop_graph, -1, 2)
         pytest.raises(nx.NetworkXError, nx.lollipop_graph, 1, 20)
         pytest.raises(nx.NetworkXError, nx.lollipop_graph, "", 20)
         pytest.raises(nx.NetworkXError, nx.lollipop_graph, "a", 20)
@@ -368,38 +367,39 @@
 
         # raise NetworkXError if create_using is directed
         with pytest.raises(nx.NetworkXError):
             nx.lollipop_graph(2, 20, create_using=nx.DiGraph)
         with pytest.raises(nx.NetworkXError):
             nx.lollipop_graph(2, 20, create_using=nx.MultiDiGraph)
 
-    def test_lollipop_graph_same_as_path_when_m1_is_2(self):
-        # lollipop_graph(2,m) = path_graph(m+2)
-        for m1, m2 in [(2, 0), (2, 5), (2, 10), ("ab", 20)]:
-            G = nx.lollipop_graph(m1, m2)
-            assert is_isomorphic(G, nx.path_graph(m2 + 2))
+    @pytest.mark.parametrize(("m", "n"), [(2, 0), (2, 5), (2, 10), ("ab", 20)])
+    def test_lollipop_graph_same_as_path_when_m1_is_2(self, m, n):
+        G = nx.lollipop_graph(m, n)
+        assert is_isomorphic(G, nx.path_graph(n + 2))
 
     def test_lollipop_graph_for_multigraph(self):
         G = nx.lollipop_graph(5, 20)
         MG = nx.lollipop_graph(5, 20, create_using=nx.MultiGraph)
         assert edges_equal(MG.edges(), G.edges())
 
-    def test_lollipop_graph_mixing_input_types(self):
-        cases = [(4, "abc"), ("abcd", 3), ([1, 2, 3, 4], "abc"), ("abcd", [1, 2, 3])]
-        for m1, m2 in cases:
-            G = nx.lollipop_graph(m1, m2)
-            assert len(G) == 7
-            assert G.size() == 9
+    @pytest.mark.parametrize(
+        ("m", "n"),
+        [(4, "abc"), ("abcd", 3), ([1, 2, 3, 4], "abc"), ("abcd", [1, 2, 3])],
+    )
+    def test_lollipop_graph_mixing_input_types(self, m, n):
+        expected = nx.compose(nx.complete_graph(4), nx.path_graph(range(100, 103)))
+        expected.add_edge(0, 100)  # Connect complete graph and path graph
+        assert is_isomorphic(nx.lollipop_graph(m, n), expected)
 
-    def test_lollipop_graph_not_int_integer_inputs(self):
-        # test non-int integers
+    def test_lollipop_graph_non_builtin_ints(self):
         np = pytest.importorskip("numpy")
         G = nx.lollipop_graph(np.int32(4), np.int64(3))
-        assert len(G) == 7
-        assert G.size() == 9
+        expected = nx.compose(nx.complete_graph(4), nx.path_graph(range(100, 103)))
+        expected.add_edge(0, 100)  # Connect complete graph and path graph
+        assert is_isomorphic(G, expected)
 
     def test_null_graph(self):
         assert nx.number_of_nodes(nx.null_graph()) == 0
 
     def test_path_graph(self):
         p = nx.path_graph(0)
         assert is_isomorphic(p, nx.null_graph())
@@ -469,14 +469,72 @@
 
     def test_non_int_integers_for_star_graph(self):
         np = pytest.importorskip("numpy")
         G = nx.star_graph(np.int32(3))
         assert len(G) == 4
         assert G.size() == 3
 
+    @pytest.mark.parametrize(("m", "n"), [(3, 0), (3, 5), (4, 10), (3, 20)])
+    def test_tadpole_graph_right_sizes(self, m, n):
+        G = nx.tadpole_graph(m, n)
+        assert nx.number_of_nodes(G) == m + n
+        assert nx.number_of_edges(G) == m + n - (m == 2)
+
+    @pytest.mark.parametrize(("m", "n"), [("ab", ""), ("ab", "c"), ("abc", "defg")])
+    def test_tadpole_graph_size_node_sequences(self, m, n):
+        G = nx.tadpole_graph(m, n)
+        assert nx.number_of_nodes(G) == len(m) + len(n)
+        assert nx.number_of_edges(G) == len(m) + len(n) - (len(m) == 2)
+
+    def test_tadpole_graph_exceptions(self):
+        # Raise NetworkXError if m<2
+        pytest.raises(nx.NetworkXError, nx.tadpole_graph, -1, 3)
+        pytest.raises(nx.NetworkXError, nx.tadpole_graph, 0, 3)
+        pytest.raises(nx.NetworkXError, nx.tadpole_graph, 1, 3)
+
+        # Raise NetworkXError if n<0
+        pytest.raises(nx.NetworkXError, nx.tadpole_graph, 5, -2)
+
+        # Raise NetworkXError for digraphs
+        with pytest.raises(nx.NetworkXError):
+            nx.tadpole_graph(2, 20, create_using=nx.DiGraph)
+        with pytest.raises(nx.NetworkXError):
+            nx.tadpole_graph(2, 20, create_using=nx.MultiDiGraph)
+
+    @pytest.mark.parametrize(("m", "n"), [(2, 0), (2, 5), (2, 10), ("ab", 20)])
+    def test_tadpole_graph_same_as_path_when_m_is_2(self, m, n):
+        G = nx.tadpole_graph(m, n)
+        assert is_isomorphic(G, nx.path_graph(n + 2))
+
+    @pytest.mark.parametrize("m", [4, 7])
+    def test_tadpole_graph_same_as_cycle_when_m2_is_0(self, m):
+        G = nx.tadpole_graph(m, 0)
+        assert is_isomorphic(G, nx.cycle_graph(m))
+
+    def test_tadpole_graph_for_multigraph(self):
+        G = nx.tadpole_graph(5, 20)
+        MG = nx.tadpole_graph(5, 20, create_using=nx.MultiGraph)
+        assert edges_equal(MG.edges(), G.edges())
+
+    @pytest.mark.parametrize(
+        ("m", "n"),
+        [(4, "abc"), ("abcd", 3), ([1, 2, 3, 4], "abc"), ("abcd", [1, 2, 3])],
+    )
+    def test_tadpole_graph_mixing_input_types(self, m, n):
+        expected = nx.compose(nx.cycle_graph(4), nx.path_graph(range(100, 103)))
+        expected.add_edge(0, 100)  # Connect cycle and path
+        assert is_isomorphic(nx.tadpole_graph(m, n), expected)
+
+    def test_tadpole_graph_non_builtin_integers(self):
+        np = pytest.importorskip("numpy")
+        G = nx.tadpole_graph(np.int32(4), np.int64(3))
+        expected = nx.compose(nx.cycle_graph(4), nx.path_graph(range(100, 103)))
+        expected.add_edge(0, 100)  # Connect cycle and path
+        assert is_isomorphic(G, expected)
+
     def test_trivial_graph(self):
         assert nx.number_of_nodes(nx.trivial_graph()) == 1
 
     def test_turan_graph(self):
         assert nx.number_of_edges(nx.turan_graph(13, 4)) == 63
         assert is_isomorphic(
             nx.turan_graph(13, 4), nx.complete_multipartite_graph(3, 4, 3, 3)
@@ -553,7 +611,25 @@
                 assert v not in G[u]
                 assert G.nodes[u] == G.nodes[v]
         # Across blocks, all vertices should be adjacent.
         for block1, block2 in itertools.combinations(blocks, 2):
             for u, v in itertools.product(block1, block2):
                 assert v in G[u]
                 assert G.nodes[u] != G.nodes[v]
+        with pytest.raises(nx.NetworkXError, match="Negative number of nodes"):
+            nx.complete_multipartite_graph(2, -3, 4)
+
+    def test_kneser_graph(self):
+        # the petersen graph is a special case of the kneser graph when n=5 and k=2
+        assert is_isomorphic(nx.kneser_graph(5, 2), nx.petersen_graph())
+
+        # when k is 1, the kneser graph returns a complete graph with n vertices
+        for i in range(1, 7):
+            assert is_isomorphic(nx.kneser_graph(i, 1), nx.complete_graph(i))
+
+        # the kneser graph of n and n-1 is the empty graph with n vertices
+        for j in range(3, 7):
+            assert is_isomorphic(nx.kneser_graph(j, j - 1), nx.empty_graph(j))
+
+        # in general the number of edges of the kneser graph is equal to
+        # (n choose k) times (n-k choose k) divided by 2
+        assert nx.number_of_edges(nx.kneser_graph(8, 3)) == 280
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_community.py` & `networkx-3.3rc0/networkx/generators/tests/test_community.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_degree_seq.py` & `networkx-3.3rc0/networkx/generators/tests/test_degree_seq.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_directed.py` & `networkx-3.3rc0/networkx/generators/tests/test_directed.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_duplication.py` & `networkx-3.3rc0/networkx/generators/tests/test_duplication.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,26 +14,37 @@
     """Unit tests for the
     :func:`networkx.generators.duplication.duplication_divergence_graph`
     function.
 
     """
 
     def test_final_size(self):
-        G = duplication_divergence_graph(3, 1)
+        G = duplication_divergence_graph(3, p=1)
         assert len(G) == 3
-        G = duplication_divergence_graph(3, 1, seed=42)
+        G = duplication_divergence_graph(3, p=1, seed=42)
         assert len(G) == 3
 
     def test_probability_too_large(self):
         with pytest.raises(NetworkXError):
-            duplication_divergence_graph(3, 2)
+            duplication_divergence_graph(3, p=2)
 
     def test_probability_too_small(self):
         with pytest.raises(NetworkXError):
-            duplication_divergence_graph(3, -1)
+            duplication_divergence_graph(3, p=-1)
+
+    def test_non_extreme_probability_value(self):
+        G = duplication_divergence_graph(6, p=0.3, seed=42)
+        assert len(G) == 6
+        assert list(G.degree()) == [(0, 2), (1, 3), (2, 2), (3, 3), (4, 1), (5, 1)]
+
+    def test_minimum_desired_nodes(self):
+        with pytest.raises(
+            NetworkXError, match=".*n must be greater than or equal to 2"
+        ):
+            duplication_divergence_graph(1, p=1)
 
 
 class TestPartialDuplicationGraph:
     """Unit tests for the
     :func:`networkx.generators.duplication.partial_duplication_graph`
     function.
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_ego.py` & `networkx-3.3rc0/networkx/generators/tests/test_ego.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_harary_graph.py` & `networkx-3.3rc0/networkx/generators/tests/test_harary_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_internet_as_graphs.py` & `networkx-3.3rc0/networkx/generators/tests/test_internet_as_graphs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_intersection.py` & `networkx-3.3rc0/networkx/generators/tests/test_intersection.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_interval_graph.py` & `networkx-3.3rc0/networkx/generators/tests/test_interval_graph.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_joint_degree_seq.py` & `networkx-3.3rc0/networkx/generators/tests/test_joint_degree_seq.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_lattice.py` & `networkx-3.3rc0/networkx/generators/tests/test_lattice.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_line.py` & `networkx-3.3rc0/networkx/generators/tests/test_line.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_mycielski.py` & `networkx-3.3rc0/networkx/generators/tests/test_mycielski.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,11 @@
 """Unit tests for the :mod:`networkx.generators.mycielski` module."""
 
+import pytest
+
 import networkx as nx
 
 
 class TestMycielski:
     def test_construction(self):
         G = nx.path_graph(2)
         M = nx.mycielskian(G)
@@ -20,7 +22,9 @@
         assert nx.is_isomorphic(G, nx.empty_graph(1))
         G = nx.mycielski_graph(2)
         assert nx.is_isomorphic(G, nx.path_graph(2))
         G = nx.mycielski_graph(3)
         assert nx.is_isomorphic(G, nx.cycle_graph(5))
         G = nx.mycielski_graph(4)
         assert nx.is_isomorphic(G, nx.mycielskian(nx.cycle_graph(5)))
+        with pytest.raises(nx.NetworkXError, match="must satisfy n >= 1"):
+            nx.mycielski_graph(0)
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_nonisomorphic_trees.py` & `networkx-3.3rc0/networkx/generators/tests/test_nonisomorphic_trees.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,12 @@
 """
-====================
-Generators - Non Isomorphic Trees
-====================
-
 Unit tests for WROM algorithm generator in generators/nonisomorphic_trees.py
 """
+import pytest
+
 import networkx as nx
 from networkx.utils import edges_equal
 
 
 class TestGeneratorNonIsomorphicTrees:
     def test_tree_structure(self):
         # test for tree structure for nx.nonisomorphic_trees()
@@ -50,15 +48,20 @@
 
         assert edges_equal(f(3)[0].edges(), [(0, 1), (0, 2)])
         assert edges_equal(f(4)[0].edges(), [(0, 1), (0, 3), (1, 2)])
         assert edges_equal(f(4)[1].edges(), [(0, 1), (0, 2), (0, 3)])
 
     def test_nonisomorphic_trees_matrix(self):
         trees_2 = [[[0, 1], [1, 0]]]
-        assert list(nx.nonisomorphic_trees(2, create="matrix")) == trees_2
+        with pytest.deprecated_call():
+            assert list(nx.nonisomorphic_trees(2, create="matrix")) == trees_2
+
         trees_3 = [[[0, 1, 1], [1, 0, 0], [1, 0, 0]]]
-        assert list(nx.nonisomorphic_trees(3, create="matrix")) == trees_3
+        with pytest.deprecated_call():
+            assert list(nx.nonisomorphic_trees(3, create="matrix")) == trees_3
+
         trees_4 = [
             [[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]],
             [[0, 1, 1, 1], [1, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0]],
         ]
-        assert list(nx.nonisomorphic_trees(4, create="matrix")) == trees_4
+        with pytest.deprecated_call():
+            assert list(nx.nonisomorphic_trees(4, create="matrix")) == trees_4
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_random_graphs.py` & `networkx-3.3rc0/networkx/generators/tests/test_random_graphs.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_small.py` & `networkx-3.3rc0/networkx/generators/tests/test_small.py`

 * *Files 1% similar despite different names*

```diff
@@ -30,14 +30,17 @@
             assert is_isomorphic(G, nx.cycle_graph(a))
 
         # Generate the utility graph K_{3,3}
         G = nx.LCF_graph(6, [3, -3], 3)
         utility_graph = nx.complete_bipartite_graph(3, 3)
         assert is_isomorphic(G, utility_graph)
 
+        with pytest.raises(nx.NetworkXError, match="Directed Graph not supported"):
+            G = nx.LCF_graph(6, [3, -3], 3, create_using=nx.DiGraph)
+
     def test_properties_named_small_graphs(self):
         G = nx.bull_graph()
         assert sorted(G) == list(range(5))
         assert G.number_of_edges() == 5
         assert sorted(d for n, d in G.degree()) == [1, 1, 2, 3, 3]
         assert nx.diameter(G) == 3
         assert nx.radius(G) == 2
```

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_spectral_graph_forge.py` & `networkx-3.3rc0/networkx/generators/tests/test_spectral_graph_forge.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_stochastic.py` & `networkx-3.3rc0/networkx/generators/tests/test_stochastic.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_sudoku.py` & `networkx-3.3rc0/networkx/generators/tests/test_sudoku.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_time_series.py` & `networkx-3.3rc0/networkx/generators/tests/test_time_series.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/tests/test_trees.py` & `networkx-3.3rc0/networkx/generators/tests/test_trees.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/generators/time_series.py` & `networkx-3.3rc0/networkx/generators/time_series.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import itertools
 
 import networkx as nx
 
 __all__ = ["visibility_graph"]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def visibility_graph(series):
     """
     Return a Visibility Graph of an input Time Series.
 
     A visibility graph converts a time series into a graph. The constructed graph
     uses integer nodes to indicate which event in the series the node represents.
     Edges are formed as follows: consider a bar plot of the series and view that
@@ -23,15 +23,15 @@
     The resulting graph inherits several properties of the series in its structure.
     Thereby, periodic series convert into regular graphs, random series convert
     into random graphs, and fractal series convert into scale-free networks [1]_.
 
     Parameters
     ----------
     series : Sequence[Number]
-       A Time Series sequence (iterable and slicable) of numeric values
+       A Time Series sequence (iterable and sliceable) of numeric values
        representing times.
 
     Returns
     -------
     NetworkX Graph
         The Visibility Graph of the input series
```

### Comparing `networkx-3.2rc0/networkx/generators/trees.py` & `networkx-3.3rc0/networkx/generators/trees.py`

 * *Files 1% similar despite different names*

```diff
@@ -44,15 +44,15 @@
     "random_labeled_rooted_forest",
     "random_unlabeled_tree",
     "random_unlabeled_rooted_tree",
     "random_unlabeled_rooted_forest",
 ]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def prefix_tree(paths):
     """Creates a directed prefix tree from a list of paths.
 
     Usually the paths are described as strings or lists of integers.
 
     A "prefix tree" represents the prefix structure of the strings.
     Each node represents a prefix of some string. The root represents
@@ -177,15 +177,15 @@
         tree.add_edge(parent, new_name)
         children = get_children(new_name, remaining_paths)
         stack.append((new_name, iter(children.items())))
 
     return tree
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def prefix_tree_recursive(paths):
     """Recursively creates a directed prefix tree from a list of paths.
 
     The original recursive version of prefix_tree for comparison. It is
     the same algorithm but the recursion is unrolled onto a stack.
 
     Usually the paths are described as strings or lists of integers.
@@ -320,15 +320,15 @@
     tree.add_node(NIL, source="NIL")
     # Populate the tree.
     _helper(paths, root, tree)
     return tree
 
 
 @py_random_state(1)
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_tree(n, seed=None, create_using=None):
     """Returns a uniformly random tree on `n` nodes.
 
     .. deprecated:: 3.2
 
        ``random_tree`` is deprecated and will be removed in NX v3.4
        Use ``random_labeled_tree`` instead.
@@ -422,15 +422,15 @@
         tree.add_nodes_from(utree.nodes)
         tree.add_edges_from(edges)
 
     return tree
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_labeled_tree(n, *, seed=None):
     """Returns a labeled tree on `n` nodes chosen uniformly at random.
 
     Generating uniformly distributed random Prüfer sequences and
     converting them into the corresponding trees is a straightforward
     method of generating uniformly distributed random labeled trees.
     This function implements this method.
@@ -458,15 +458,15 @@
         raise nx.NetworkXPointlessConcept("the null graph is not a tree")
     if n == 1:
         return nx.empty_graph(1)
     return nx.from_prufer_sequence([seed.choice(range(n)) for i in range(n - 2)])
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_labeled_rooted_tree(n, *, seed=None):
     """Returns a labeled rooted tree with `n` nodes.
 
     The returned tree is chosen uniformly at random from all labeled rooted trees.
 
     Parameters
     ----------
@@ -495,15 +495,15 @@
     """
     t = random_labeled_tree(n, seed=seed)
     t.graph["root"] = seed.randint(0, n - 1)
     return t
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_labeled_rooted_forest(n, *, seed=None):
     """Returns a labeled rooted forest with `n` nodes.
 
     The returned forest is chosen uniformly at random using a
     generalization of Prüfer sequences [1]_ in the form described in [2]_.
 
     Parameters
@@ -733,15 +733,15 @@
         t1.extend((n1 + t1_nodes, n2 + t1_nodes) for n1, n2 in t2)
         t1_nodes += t2_nodes
 
     return t1, t1_nodes
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_unlabeled_rooted_tree(n, *, number_of_trees=None, seed=None):
     """Returns a number of unlabeled rooted trees uniformly at random
 
     Returns one or more (depending on `number_of_trees`)
     unlabeled rooted trees with `n` nodes drawn uniformly
     at random.
 
@@ -918,15 +918,15 @@
         r1.append(t1_nodes)
         t1.extend((n1 + t1_nodes, n2 + t1_nodes) for n1, n2 in t2)
         t1_nodes += t2_nodes
     return t1, t1_nodes, r1
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_unlabeled_rooted_forest(n, *, q=None, number_of_forests=None, seed=None):
     """Returns a forest or list of forests selected at random.
 
     Returns one or more (depending on `number_of_forests`)
     unlabeled rooted forests with `n` nodes, and with no more than
     `q` nodes per tree, drawn uniformly at random.
     The "roots" graph attribute identifies the roots of the forest.
@@ -1095,15 +1095,15 @@
         )
         for i in r:
             f.append((i, n_f))
         return f, n_f + 1
 
 
 @py_random_state("seed")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def random_unlabeled_tree(n, *, number_of_trees=None, seed=None):
     """Returns a tree or list of trees chosen randomly.
 
     Returns one or more (depending on `number_of_trees`)
     unlabeled trees with `n` nodes drawn uniformly at random.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/generators/triads.py` & `networkx-3.3rc0/networkx/generators/triads.py`

 * *Files 12% similar despite different names*

```diff
@@ -29,22 +29,38 @@
     "120U": ["ab", "cb", "ac", "ca"],
     "120C": ["ab", "bc", "ac", "ca"],
     "210": ["ab", "bc", "cb", "ac", "ca"],
     "300": ["ab", "ba", "bc", "cb", "ac", "ca"],
 }
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def triad_graph(triad_name):
     """Returns the triad graph with the given name.
 
     Each string in the following tuple is a valid triad name::
 
-        ('003', '012', '102', '021D', '021U', '021C', '111D', '111U',
-         '030T', '030C', '201', '120D', '120U', '120C', '210', '300')
+        (
+            "003",
+            "012",
+            "102",
+            "021D",
+            "021U",
+            "021C",
+            "111D",
+            "111U",
+            "030T",
+            "030C",
+            "201",
+            "120D",
+            "120U",
+            "120C",
+            "210",
+            "300",
+        )
 
     Each triad name corresponds to one of the possible valid digraph on
     three nodes.
 
     Parameters
     ----------
     triad_name : string
```

### Comparing `networkx-3.2rc0/networkx/lazy_imports.py` & `networkx-3.3rc0/networkx/lazy_imports.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,17 +22,15 @@
     module's `__getattr__`, `__dir__`, and `__all__` attributes such that
     all imports work exactly the way they normally would, except that the
     actual import is delayed until the resulting module object is first used.
 
     The typical way to call this function, replacing the above imports, is::
 
       __getattr__, __lazy_dir__, __all__ = lazy.attach(
-          __name__,
-          ['mysubmodule', 'anothersubmodule'],
-          {'foo': 'someattr'}
+          __name__, ["mysubmodule", "anothersubmodule"], {"foo": "someattr"}
       )
 
     This functionality requires Python 3.7 or higher.
 
     Parameters
     ----------
     module_name : str
@@ -91,15 +89,15 @@
             super().__getattr__(x)
         else:
             fd = self.__frame_data
             raise ModuleNotFoundError(
                 f"No module named '{fd['spec']}'\n\n"
                 "This error is lazily reported, having originally occurred in\n"
                 f'  File {fd["filename"]}, line {fd["lineno"]}, in {fd["function"]}\n\n'
-                f'----> {"".join(fd["code_context"]).strip()}'
+                f'----> {"".join(fd["code_context"] or "").strip()}'
             )
 
 
 def _lazy_import(fullname):
     """Return a lazily imported proxy for a module or library.
 
     Warning
@@ -145,16 +143,16 @@
     of the library.
 
     Parameters
     ----------
     fullname : str
         The full name of the package or subpackage to import.  For example::
 
-          sp = lazy.load('scipy')  # import scipy as sp
-          spla = lazy.load('scipy.linalg')  # import scipy.linalg as spla
+          sp = lazy.load("scipy")  # import scipy as sp
+          spla = lazy.load("scipy.linalg")  # import scipy.linalg as spla
 
     Returns
     -------
     pm : importlib.util._LazyModule
         Proxy module. Can be used like any regularly imported module.
         Actual loading of the module occurs upon first attribute request.
```

### Comparing `networkx-3.2rc0/networkx/linalg/__init__.py` & `networkx-3.3rc0/networkx/linalg/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/algebraicconnectivity.py` & `networkx-3.3rc0/networkx/linalg/algebraicconnectivity.py`

 * *Files 1% similar despite different names*

```diff
@@ -218,15 +218,15 @@
         # Convert A to CSC to suppress SparseEfficiencyWarning.
         A = sp.sparse.csc_array(L, dtype=float, copy=True)
         # Force A to be nonsingular. Since A is the Laplacian matrix of a
         # connected graph, its rank deficiency is one, and thus one diagonal
         # element needs to modified. Changing to infinity forces a zero in the
         # corresponding element in the solution.
         i = (A.indptr[1:] - A.indptr[:-1]).argmax()
-        A[i, i] = float("inf")
+        A[i, i] = np.inf
         solver = _LUSolver(A)
     else:
         raise nx.NetworkXError(f"Unknown linear system solver: {method}")
 
     # Initialize.
     Lnorm = abs(L).sum(axis=1).flatten().max()
     project(X)
@@ -308,15 +308,15 @@
         raise nx.NetworkXError(f"unknown method {method!r}.")
 
     return find_fiedler
 
 
 @not_implemented_for("directed")
 @np_random_state(5)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def algebraic_connectivity(
     G, weight="weight", normalized=False, tol=1e-8, method="tracemin_pcg", seed=None
 ):
     r"""Returns the algebraic connectivity of an undirected graph.
 
     The algebraic connectivity of a connected undirected graph is the second
     smallest eigenvalue of its Laplacian matrix.
@@ -394,25 +394,25 @@
         raise nx.NetworkXError("graph has less than two nodes.")
     G = _preprocess_graph(G, weight)
     if not nx.is_connected(G):
         return 0.0
 
     L = nx.laplacian_matrix(G)
     if L.shape[0] == 2:
-        return 2.0 * L[0, 0] if not normalized else 2.0
+        return 2.0 * float(L[0, 0]) if not normalized else 2.0
 
     find_fiedler = _get_fiedler_func(method)
     x = None if method != "lobpcg" else _rcm_estimate(G, G)
     sigma, fiedler = find_fiedler(L, x, normalized, tol, seed)
-    return sigma
+    return float(sigma)
 
 
 @not_implemented_for("directed")
 @np_random_state(5)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def fiedler_vector(
     G, weight="weight", normalized=False, tol=1e-8, method="tracemin_pcg", seed=None
 ):
     """Returns the Fiedler vector of a connected undirected graph.
 
     The Fiedler vector of a connected undirected graph is the eigenvector
     corresponding to the second smallest eigenvalue of the Laplacian matrix
@@ -501,15 +501,15 @@
     L = nx.laplacian_matrix(G)
     x = None if method != "lobpcg" else _rcm_estimate(G, G)
     sigma, fiedler = find_fiedler(L, x, normalized, tol, seed)
     return fiedler
 
 
 @np_random_state(5)
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def spectral_ordering(
     G, weight="weight", normalized=False, tol=1e-8, method="tracemin_pcg", seed=None
 ):
     """Compute the spectral_ordering of a graph.
 
     The spectral ordering of a graph is an ordering of its nodes where nodes
     in the same weakly connected components appear contiguous and ordered by
@@ -584,15 +584,15 @@
             order.extend(u for x, c, u in sorted(sort_info))
         else:
             order.extend(component)
 
     return order
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def spectral_bisection(
     G, weight="weight", normalized=False, tol=1e-8, method="tracemin_pcg", seed=None
 ):
     """Bisect the graph using the Fiedler vector.
 
     This method uses the Fiedler vector to bisect a graph.
     The partition is defined by the nodes which are associated with
@@ -649,8 +649,8 @@
     """
     import numpy as np
 
     v = nx.fiedler_vector(G, weight, normalized, tol, method, seed)
     nodes = np.array(list(G))
     pos_vals = v >= 0
 
-    return set(nodes[~pos_vals]), set(nodes[pos_vals])
+    return set(nodes[~pos_vals].tolist()), set(nodes[pos_vals].tolist())
```

### Comparing `networkx-3.2rc0/networkx/linalg/attrmatrix.py` & `networkx-3.3rc0/networkx/linalg/attrmatrix.py`

 * *Files 1% similar despite different names*

```diff
@@ -138,15 +138,15 @@
         #     edge_attr = lambda u,v: 1 if len(G[u][v]) else 0
         #
         value = edge_attr
 
     return value
 
 
-@nx._dispatch(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
+@nx._dispatchable(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
 def attr_matrix(
     G,
     edge_attr=None,
     node_attr=None,
     normalized=False,
     rc_order=None,
     dtype=None,
@@ -302,15 +302,15 @@
 
     if rc_order is None:
         return M, ordering
     else:
         return M
 
 
-@nx._dispatch(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
+@nx._dispatchable(edge_attrs={"edge_attr": None}, node_attrs="node_attr")
 def attr_sparse_matrix(
     G, edge_attr=None, node_attr=None, normalized=False, rc_order=None, dtype=None
 ):
     """Returns a SciPy sparse array using attributes from G.
 
     If only `G` is passed in, then the adjacency matrix is constructed.
```

### Comparing `networkx-3.2rc0/networkx/linalg/bethehessianmatrix.py` & `networkx-3.3rc0/networkx/linalg/bethehessianmatrix.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["bethe_hessian_matrix"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch
+@nx._dispatchable
 def bethe_hessian_matrix(G, r=None, nodelist=None):
     r"""Returns the Bethe Hessian matrix of G.
 
     The Bethe Hessian is a family of matrices parametrized by r, defined as
     H(r) = (r^2 - 1) I - r A + D where A is the adjacency matrix, D is the
     diagonal matrix of node degrees, and I is the identify matrix. It is equal
     to the graph laplacian when the regularizer r = 1.
```

### Comparing `networkx-3.2rc0/networkx/linalg/graphmatrix.py` & `networkx-3.3rc0/networkx/linalg/graphmatrix.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 Adjacency matrix and incidence matrix of graphs.
 """
 import networkx as nx
 
 __all__ = ["incidence_matrix", "adjacency_matrix"]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def incidence_matrix(
     G, nodelist=None, edgelist=None, oriented=False, weight=None, *, dtype=None
 ):
     """Returns incidence matrix of G.
 
     The incidence matrix assigns each row to a node and each column to an edge.
     For a standard incidence matrix a 1 appears wherever a row's node is
@@ -100,15 +100,15 @@
             A[vi, ei] = wt
         else:
             A[ui, ei] = wt
             A[vi, ei] = wt
     return A.asformat("csc")
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def adjacency_matrix(G, nodelist=None, dtype=None, weight="weight"):
     """Returns adjacency matrix of G.
 
     Parameters
     ----------
     G : graph
        A NetworkX graph
```

### Comparing `networkx-3.2rc0/networkx/linalg/laplacianmatrix.py` & `networkx-3.3rc0/networkx/linalg/laplacianmatrix.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,23 +1,29 @@
 """Laplacian matrix of graphs.
+
+All calculations here are done using the out-degree. For Laplacians using
+in-degree, use `G.reverse(copy=False)` instead of `G` and take the transpose.
+
+The `laplacian_matrix` function provides an unnormalized matrix, 
+while `normalized_laplacian_matrix`, `directed_laplacian_matrix`, 
+and `directed_combinatorial_laplacian_matrix` are all normalized.
 """
 import networkx as nx
 from networkx.utils import not_implemented_for
 
 __all__ = [
     "laplacian_matrix",
     "normalized_laplacian_matrix",
     "total_spanning_tree_weight",
     "directed_laplacian_matrix",
     "directed_combinatorial_laplacian_matrix",
 ]
 
 
-@not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def laplacian_matrix(G, nodelist=None, weight="weight"):
     """Returns the Laplacian matrix of G.
 
     The graph Laplacian is the matrix L = D - A, where
     A is the adjacency matrix and D is the diagonal matrix of node degrees.
 
     Parameters
@@ -38,18 +44,28 @@
     L : SciPy sparse array
       The Laplacian matrix of G.
 
     Notes
     -----
     For MultiGraph, the edges weights are summed.
 
+    This returns an unnormalized matrix. For a normalized output,
+    use `normalized_laplacian_matrix`, `directed_laplacian_matrix`,
+    or `directed_combinatorial_laplacian_matrix`.
+
+    This calculation uses the out-degree of the graph `G`. To use the
+    in-degree for calculations instead, use `G.reverse(copy=False)` and
+    take the transpose.
+
     See Also
     --------
     :func:`~networkx.convert_matrix.to_numpy_array`
     normalized_laplacian_matrix
+    directed_laplacian_matrix
+    directed_combinatorial_laplacian_matrix
     :func:`~networkx.linalg.spectrum.laplacian_spectrum`
 
     Examples
     --------
     For graphs with multiple connected components, L is permutation-similar
     to a block diagonal matrix where each block is the respective Laplacian
     matrix for each component.
@@ -58,28 +74,67 @@
     >>> print(nx.laplacian_matrix(G).toarray())
     [[ 1 -1  0  0  0]
      [-1  2 -1  0  0]
      [ 0 -1  1  0  0]
      [ 0  0  0  1 -1]
      [ 0  0  0 -1  1]]
 
+    >>> edges = [
+    ...     (1, 2),
+    ...     (2, 1),
+    ...     (2, 4),
+    ...     (4, 3),
+    ...     (3, 4),
+    ... ]
+    >>> DiG = nx.DiGraph(edges)
+    >>> print(nx.laplacian_matrix(DiG).toarray())
+    [[ 1 -1  0  0]
+     [-1  2 -1  0]
+     [ 0  0  1 -1]
+     [ 0  0 -1  1]]
+
+    Notice that node 4 is represented by the third column and row. This is because
+    by default the row/column order is the order of `G.nodes` (i.e. the node added
+    order -- in the edgelist, 4 first appears in (2, 4), before node 3 in edge (4, 3).)
+    To control the node order of the matrix, use the `nodelist` argument.
+
+    >>> print(nx.laplacian_matrix(DiG, nodelist=[1, 2, 3, 4]).toarray())
+    [[ 1 -1  0  0]
+     [-1  2  0 -1]
+     [ 0  0  1 -1]
+     [ 0  0 -1  1]]
+
+    This calculation uses the out-degree of the graph `G`. To use the
+    in-degree for calculations instead, use `G.reverse(copy=False)` and
+    take the transpose.
+
+    >>> print(nx.laplacian_matrix(DiG.reverse(copy=False)).toarray().T)
+    [[ 1 -1  0  0]
+     [-1  1 -1  0]
+     [ 0  0  2 -1]
+     [ 0  0 -1  1]]
+
+    References
+    ----------
+    .. [1] Langville, Amy N., and Carl D. Meyer. Google’s PageRank and Beyond:
+       The Science of Search Engine Rankings. Princeton University Press, 2006.
+
     """
     import scipy as sp
 
     if nodelist is None:
         nodelist = list(G)
     A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format="csr")
     n, m = A.shape
     # TODO: rm csr_array wrapper when spdiags can produce arrays
     D = sp.sparse.csr_array(sp.sparse.spdiags(A.sum(axis=1), 0, m, n, format="csr"))
     return D - A
 
 
-@not_implemented_for("directed")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def normalized_laplacian_matrix(G, nodelist=None, weight="weight"):
     r"""Returns the normalized Laplacian matrix of G.
 
     The normalized graph Laplacian is the matrix
 
     .. math::
 
@@ -110,96 +165,204 @@
     -----
     For MultiGraph, the edges weights are summed.
     See :func:`to_numpy_array` for other options.
 
     If the Graph contains selfloops, D is defined as ``diag(sum(A, 1))``, where A is
     the adjacency matrix [2]_.
 
+    This calculation uses the out-degree of the graph `G`. To use the
+    in-degree for calculations instead, use `G.reverse(copy=False)` and
+    take the transpose.
+
+    For an unnormalized output, use `laplacian_matrix`.
+
+    Examples
+    --------
+
+    >>> import numpy as np
+    >>> edges = [
+    ...     (1, 2),
+    ...     (2, 1),
+    ...     (2, 4),
+    ...     (4, 3),
+    ...     (3, 4),
+    ... ]
+    >>> DiG = nx.DiGraph(edges)
+    >>> print(nx.normalized_laplacian_matrix(DiG).toarray())
+    [[ 1.         -0.70710678  0.          0.        ]
+     [-0.70710678  1.         -0.70710678  0.        ]
+     [ 0.          0.          1.         -1.        ]
+     [ 0.          0.         -1.          1.        ]]
+
+    Notice that node 4 is represented by the third column and row. This is because
+    by default the row/column order is the order of `G.nodes` (i.e. the node added
+    order -- in the edgelist, 4 first appears in (2, 4), before node 3 in edge (4, 3).)
+    To control the node order of the matrix, use the `nodelist` argument.
+
+    >>> print(nx.normalized_laplacian_matrix(DiG, nodelist=[1, 2, 3, 4]).toarray())
+    [[ 1.         -0.70710678  0.          0.        ]
+     [-0.70710678  1.          0.         -0.70710678]
+     [ 0.          0.          1.         -1.        ]
+     [ 0.          0.         -1.          1.        ]]
+    >>> G = nx.Graph(edges)
+    >>> print(nx.normalized_laplacian_matrix(G).toarray())
+    [[ 1.         -0.70710678  0.          0.        ]
+     [-0.70710678  1.         -0.5         0.        ]
+     [ 0.         -0.5         1.         -0.70710678]
+     [ 0.          0.         -0.70710678  1.        ]]
+
     See Also
     --------
     laplacian_matrix
     normalized_laplacian_spectrum
+    directed_laplacian_matrix
+    directed_combinatorial_laplacian_matrix
 
     References
     ----------
     .. [1] Fan Chung-Graham, Spectral Graph Theory,
        CBMS Regional Conference Series in Mathematics, Number 92, 1997.
     .. [2] Steve Butler, Interlacing For Weighted Graphs Using The Normalized
        Laplacian, Electronic Journal of Linear Algebra, Volume 16, pp. 90-98,
        March 2007.
+    .. [3] Langville, Amy N., and Carl D. Meyer. Google’s PageRank and Beyond:
+       The Science of Search Engine Rankings. Princeton University Press, 2006.
     """
     import numpy as np
     import scipy as sp
 
     if nodelist is None:
         nodelist = list(G)
     A = nx.to_scipy_sparse_array(G, nodelist=nodelist, weight=weight, format="csr")
-    n, m = A.shape
+    n, _ = A.shape
     diags = A.sum(axis=1)
     # TODO: rm csr_array wrapper when spdiags can produce arrays
-    D = sp.sparse.csr_array(sp.sparse.spdiags(diags, 0, m, n, format="csr"))
+    D = sp.sparse.csr_array(sp.sparse.spdiags(diags, 0, n, n, format="csr"))
     L = D - A
     with np.errstate(divide="ignore"):
         diags_sqrt = 1.0 / np.sqrt(diags)
     diags_sqrt[np.isinf(diags_sqrt)] = 0
     # TODO: rm csr_array wrapper when spdiags can produce arrays
-    DH = sp.sparse.csr_array(sp.sparse.spdiags(diags_sqrt, 0, m, n, format="csr"))
+    DH = sp.sparse.csr_array(sp.sparse.spdiags(diags_sqrt, 0, n, n, format="csr"))
     return DH @ (L @ DH)
 
 
-@nx._dispatch(edge_attrs="weight")
-def total_spanning_tree_weight(G, weight=None):
+@nx._dispatchable(edge_attrs="weight")
+def total_spanning_tree_weight(G, weight=None, root=None):
     """
     Returns the total weight of all spanning trees of `G`.
 
-    Kirchoff's Tree Matrix Theorem states that the determinant of any cofactor of the
-    Laplacian matrix of a graph is the number of spanning trees in the graph. For a
-    weighted Laplacian matrix, it is the sum across all spanning trees of the
-    multiplicative weight of each tree. That is, the weight of each tree is the
-    product of its edge weights.
+    Kirchoff's Tree Matrix Theorem [1]_, [2]_ states that the determinant of any
+    cofactor of the Laplacian matrix of a graph is the number of spanning trees
+    in the graph. For a weighted Laplacian matrix, it is the sum across all
+    spanning trees of the multiplicative weight of each tree. That is, the
+    weight of each tree is the product of its edge weights.
+
+    For unweighted graphs, the total weight equals the number of spanning trees in `G`.
+
+    For directed graphs, the total weight follows by summing over all directed
+    spanning trees in `G` that start in the `root` node [3]_.
+
+    .. deprecated:: 3.3
+
+       ``total_spanning_tree_weight`` is deprecated and will be removed in v3.5.
+       Use ``nx.number_of_spanning_trees(G)`` instead.
 
     Parameters
     ----------
     G : NetworkX Graph
-        The graph to use Kirchhoff's theorem on.
 
-    weight : string or None
-        The key for the edge attribute holding the edge weight. If `None`, then
-        each edge is assumed to have a weight of 1 and this function returns the
-        total number of spanning trees in `G`.
+    weight : string or None, optional (default=None)
+        The key for the edge attribute holding the edge weight.
+        If None, then each edge has weight 1.
+
+    root : node (only required for directed graphs)
+       A node in the directed graph `G`.
 
     Returns
     -------
-    float
-        The sum of the total multiplicative weights for all spanning trees in `G`
+    total_weight : float
+        Undirected graphs:
+            The sum of the total multiplicative weights for all spanning trees in `G`.
+        Directed graphs:
+            The sum of the total multiplicative weights for all spanning trees of `G`,
+            rooted at node `root`.
+
+    Raises
+    ------
+    NetworkXPointlessConcept
+        If `G` does not contain any nodes.
+
+    NetworkXError
+        If the graph `G` is not (weakly) connected,
+        or if `G` is directed and the root node is not specified or not in G.
+
+    Examples
+    --------
+    >>> G = nx.complete_graph(5)
+    >>> round(nx.total_spanning_tree_weight(G))
+    125
+
+    >>> G = nx.Graph()
+    >>> G.add_edge(1, 2, weight=2)
+    >>> G.add_edge(1, 3, weight=1)
+    >>> G.add_edge(2, 3, weight=1)
+    >>> round(nx.total_spanning_tree_weight(G, "weight"))
+    5
+
+    Notes
+    -----
+    Self-loops are excluded. Multi-edges are contracted in one edge
+    equal to the sum of the weights.
+
+    References
+    ----------
+    .. [1] Wikipedia
+       "Kirchhoff's theorem."
+       https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem
+    .. [2] Kirchhoff, G. R.
+        Über die Auflösung der Gleichungen, auf welche man
+        bei der Untersuchung der linearen Vertheilung
+        Galvanischer Ströme geführt wird
+        Annalen der Physik und Chemie, vol. 72, pp. 497-508, 1847.
+    .. [3] Margoliash, J.
+        "Matrix-Tree Theorem for Directed Graphs"
+        https://www.math.uchicago.edu/~may/VIGRE/VIGRE2010/REUPapers/Margoliash.pdf
     """
-    import numpy as np
+    import warnings
+
+    warnings.warn(
+        (
+            "\n\ntotal_spanning_tree_weight is deprecated and will be removed in v3.5.\n"
+            "Use `nx.number_of_spanning_trees(G)` instead."
+        ),
+        category=DeprecationWarning,
+        stacklevel=3,
+    )
 
-    G_laplacian = nx.laplacian_matrix(G, weight=weight).toarray()
-    # Determinant ignoring first row and column
-    return abs(np.linalg.det(G_laplacian[1:, 1:]))
+    return nx.number_of_spanning_trees(G, weight=weight, root=root)
 
 
 ###############################################################################
 # Code based on work from https://github.com/bjedwards
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def directed_laplacian_matrix(
     G, nodelist=None, weight="weight", walk_type=None, alpha=0.95
 ):
     r"""Returns the directed Laplacian matrix of G.
 
     The graph directed Laplacian is the matrix
 
     .. math::
 
-        L = I - (\Phi^{1/2} P \Phi^{-1/2} + \Phi^{-1/2} P^T \Phi^{1/2} ) / 2
+        L = I - \frac{1}{2} \left (\Phi^{1/2} P \Phi^{-1/2} + \Phi^{-1/2} P^T \Phi^{1/2} \right )
 
     where `I` is the identity matrix, `P` is the transition matrix of the
     graph, and `\Phi` a matrix with the Perron vector of `P` in the diagonal and
     zeros elsewhere [1]_.
 
     Depending on the value of walk_type, `P` can be the transition matrix
     induced by a random walk, a lazy random walk, or a random walk with
@@ -215,32 +378,43 @@
        If nodelist is None, then the ordering is produced by G.nodes().
 
     weight : string or None, optional (default='weight')
        The edge data key used to compute each value in the matrix.
        If None, then each edge has weight 1.
 
     walk_type : string or None, optional (default=None)
-       If None, `P` is selected depending on the properties of the
-       graph. Otherwise is one of 'random', 'lazy', or 'pagerank'
+       One of ``"random"``, ``"lazy"``, or ``"pagerank"``. If ``walk_type=None``
+       (the default), then a value is selected according to the properties of `G`:
+       - ``walk_type="random"`` if `G` is strongly connected and aperiodic
+       - ``walk_type="lazy"`` if `G` is strongly connected but not aperiodic
+       - ``walk_type="pagerank"`` for all other cases.
 
     alpha : real
        (1 - alpha) is the teleportation probability used with pagerank
 
     Returns
     -------
     L : NumPy matrix
       Normalized Laplacian of G.
 
     Notes
     -----
     Only implemented for DiGraphs
 
+    The result is always a symmetric matrix.
+
+    This calculation uses the out-degree of the graph `G`. To use the
+    in-degree for calculations instead, use `G.reverse(copy=False)` and
+    take the transpose.
+
     See Also
     --------
     laplacian_matrix
+    normalized_laplacian_matrix
+    directed_combinatorial_laplacian_matrix
 
     References
     ----------
     .. [1] Fan Chung (2005).
        Laplacians and the Cheeger inequality for directed graphs.
        Annals of Combinatorics, 9(1), 2005
     """
@@ -270,25 +444,25 @@
     I = np.identity(len(G))
 
     return I - (Q + Q.T) / 2.0
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def directed_combinatorial_laplacian_matrix(
     G, nodelist=None, weight="weight", walk_type=None, alpha=0.95
 ):
     r"""Return the directed combinatorial Laplacian matrix of G.
 
     The graph directed combinatorial Laplacian is the matrix
 
     .. math::
 
-        L = \Phi - (\Phi P + P^T \Phi) / 2
+        L = \Phi - \frac{1}{2} \left (\Phi P + P^T \Phi \right)
 
     where `P` is the transition matrix of the graph and `\Phi` a matrix
     with the Perron vector of `P` in the diagonal and zeros elsewhere [1]_.
 
     Depending on the value of walk_type, `P` can be the transition matrix
     induced by a random walk, a lazy random walk, or a random walk with
     teleportation (PageRank).
@@ -303,32 +477,43 @@
        If nodelist is None, then the ordering is produced by G.nodes().
 
     weight : string or None, optional (default='weight')
        The edge data key used to compute each value in the matrix.
        If None, then each edge has weight 1.
 
     walk_type : string or None, optional (default=None)
-       If None, `P` is selected depending on the properties of the
-       graph. Otherwise is one of 'random', 'lazy', or 'pagerank'
+        One of ``"random"``, ``"lazy"``, or ``"pagerank"``. If ``walk_type=None``
+        (the default), then a value is selected according to the properties of `G`:
+        - ``walk_type="random"`` if `G` is strongly connected and aperiodic
+        - ``walk_type="lazy"`` if `G` is strongly connected but not aperiodic
+        - ``walk_type="pagerank"`` for all other cases.
 
     alpha : real
        (1 - alpha) is the teleportation probability used with pagerank
 
     Returns
     -------
     L : NumPy matrix
       Combinatorial Laplacian of G.
 
     Notes
     -----
     Only implemented for DiGraphs
 
+    The result is always a symmetric matrix.
+
+    This calculation uses the out-degree of the graph `G`. To use the
+    in-degree for calculations instead, use `G.reverse(copy=False)` and
+    take the transpose.
+
     See Also
     --------
     laplacian_matrix
+    normalized_laplacian_matrix
+    directed_laplacian_matrix
 
     References
     ----------
     .. [1] Fan Chung (2005).
        Laplacians and the Cheeger inequality for directed graphs.
        Annals of Combinatorics, 9(1), 2005
     """
@@ -368,16 +553,19 @@
        If nodelist is None, then the ordering is produced by G.nodes().
 
     weight : string or None, optional (default='weight')
        The edge data key used to compute each value in the matrix.
        If None, then each edge has weight 1.
 
     walk_type : string or None, optional (default=None)
-       If None, `P` is selected depending on the properties of the
-       graph. Otherwise is one of 'random', 'lazy', or 'pagerank'
+       One of ``"random"``, ``"lazy"``, or ``"pagerank"``. If ``walk_type=None``
+       (the default), then a value is selected according to the properties of `G`:
+        - ``walk_type="random"`` if `G` is strongly connected and aperiodic
+        - ``walk_type="lazy"`` if `G` is strongly connected but not aperiodic
+        - ``walk_type="pagerank"`` for all other cases.
 
     alpha : real
        (1 - alpha) is the teleportation probability used with pagerank
 
     Returns
     -------
     P : numpy.ndarray
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `networkx-3.2rc0/networkx/linalg/modularitymatrix.py` & `networkx-3.3rc0/networkx/linalg/modularitymatrix.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from networkx.utils import not_implemented_for
 
 __all__ = ["modularity_matrix", "directed_modularity_matrix"]
 
 
 @not_implemented_for("directed")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def modularity_matrix(G, nodelist=None, weight=None):
     r"""Returns the modularity matrix of G.
 
     The modularity matrix is the matrix B = A - <A>, where A is the adjacency
     matrix and <A> is the average adjacency matrix, assuming that the graph
     is described by the configuration model.
 
@@ -73,15 +73,15 @@
     X = np.outer(k, k) / (2 * m)
 
     return A - X
 
 
 @not_implemented_for("undirected")
 @not_implemented_for("multigraph")
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def directed_modularity_matrix(G, nodelist=None, weight=None):
     """Returns the directed modularity matrix of G.
 
     The modularity matrix is the matrix B = A - <A>, where A is the adjacency
     matrix and <A> is the expected adjacency matrix, assuming that the graph
     is described by the configuration model.
```

### Comparing `networkx-3.2rc0/networkx/linalg/spectrum.py` & `networkx-3.3rc0/networkx/linalg/spectrum.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,15 @@
     "adjacency_spectrum",
     "modularity_spectrum",
     "normalized_laplacian_spectrum",
     "bethe_hessian_spectrum",
 ]
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def laplacian_spectrum(G, weight="weight"):
     """Returns eigenvalues of the Laplacian of G
 
     Parameters
     ----------
     G : graph
        A NetworkX graph
@@ -52,15 +52,15 @@
 
     """
     import scipy as sp
 
     return sp.linalg.eigvalsh(nx.laplacian_matrix(G, weight=weight).todense())
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def normalized_laplacian_spectrum(G, weight="weight"):
     """Return eigenvalues of the normalized Laplacian of G
 
     Parameters
     ----------
     G : graph
        A NetworkX graph
@@ -86,15 +86,15 @@
     import scipy as sp
 
     return sp.linalg.eigvalsh(
         nx.normalized_laplacian_matrix(G, weight=weight).todense()
     )
 
 
-@nx._dispatch(edge_attrs="weight")
+@nx._dispatchable(edge_attrs="weight")
 def adjacency_spectrum(G, weight="weight"):
     """Returns eigenvalues of the adjacency matrix of G.
 
     Parameters
     ----------
     G : graph
        A NetworkX graph
@@ -118,15 +118,15 @@
     adjacency_matrix
     """
     import scipy as sp
 
     return sp.linalg.eigvals(nx.adjacency_matrix(G, weight=weight).todense())
 
 
-@nx._dispatch
+@nx._dispatchable
 def modularity_spectrum(G):
     """Returns eigenvalues of the modularity matrix of G.
 
     Parameters
     ----------
     G : Graph
        A NetworkX Graph or DiGraph
@@ -149,15 +149,15 @@
 
     if G.is_directed():
         return sp.linalg.eigvals(nx.directed_modularity_matrix(G))
     else:
         return sp.linalg.eigvals(nx.modularity_matrix(G))
 
 
-@nx._dispatch
+@nx._dispatchable
 def bethe_hessian_spectrum(G, r=None):
     """Returns eigenvalues of the Bethe Hessian matrix of G.
 
     Parameters
     ----------
     G : Graph
        A NetworkX Graph or DiGraph
```

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_algebraic_connectivity.py` & `networkx-3.3rc0/networkx/linalg/tests/test_algebraic_connectivity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_attrmatrix.py` & `networkx-3.3rc0/networkx/linalg/tests/test_attrmatrix.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_bethehessian.py` & `networkx-3.3rc0/networkx/linalg/tests/test_bethehessian.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_graphmatrix.py` & `networkx-3.3rc0/networkx/linalg/tests/test_graphmatrix.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_modularity.py` & `networkx-3.3rc0/networkx/linalg/tests/test_modularity.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/linalg/tests/test_spectrum.py` & `networkx-3.3rc0/networkx/linalg/tests/test_spectrum.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/__init__.py` & `networkx-3.3rc0/networkx/readwrite/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/adjlist.py` & `networkx-3.3rc0/networkx/readwrite/adjlist.py`

 * *Files 2% similar despite different names*

```diff
@@ -146,15 +146,15 @@
     path.write(header.encode(encoding))
 
     for line in generate_adjlist(G, delimiter):
         line += "\n"
         path.write(line.encode(encoding))
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_adjlist(
     lines, comments="#", delimiter=None, create_using=None, nodetype=None
 ):
     """Parse lines of a graph adjacency list representation.
 
     Parameters
     ----------
@@ -205,30 +205,30 @@
         u = vlist.pop(0)
         # convert types
         if nodetype is not None:
             try:
                 u = nodetype(u)
             except BaseException as err:
                 raise TypeError(
-                    f"Failed to convert node ({u}) to type " f"{nodetype}"
+                    f"Failed to convert node ({u}) to type {nodetype}"
                 ) from err
         G.add_node(u)
         if nodetype is not None:
             try:
                 vlist = list(map(nodetype, vlist))
             except BaseException as err:
                 raise TypeError(
                     f"Failed to convert nodes ({','.join(vlist)}) to type {nodetype}"
                 ) from err
         G.add_edges_from([(u, v) for v in vlist])
     return G
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_adjlist(
     path,
     comments="#",
     delimiter=None,
     create_using=None,
     nodetype=None,
     encoding="utf-8",
```

### Comparing `networkx-3.2rc0/networkx/readwrite/edgelist.py` & `networkx-3.3rc0/networkx/readwrite/edgelist.py`

 * *Files 2% similar despite different names*

```diff
@@ -169,15 +169,15 @@
     """
 
     for line in generate_edgelist(G, delimiter, data):
         line += "\n"
         path.write(line.encode(encoding))
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_edgelist(
     lines, comments="#", delimiter=None, create_using=None, nodetype=None, data=True
 ):
     """Parse lines of an edge list representation of a graph.
 
     Parameters
     ----------
@@ -294,15 +294,15 @@
                     ) from err
                 edgedata.update({edge_key: edge_value})
         G.add_edge(u, v, **edgedata)
     return G
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_edgelist(
     path,
     comments="#",
     delimiter=None,
     create_using=None,
     nodetype=None,
     data=True,
@@ -421,15 +421,15 @@
         comments=comments,
         delimiter=delimiter,
         data=("weight",),
         encoding=encoding,
     )
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_weighted_edgelist(
     path,
     comments="#",
     delimiter=None,
     create_using=None,
     nodetype=None,
     encoding="utf-8",
```

### Comparing `networkx-3.2rc0/networkx/readwrite/gexf.py` & `networkx-3.3rc0/networkx/readwrite/gexf.py`

 * *Files 0% similar despite different names*

```diff
@@ -129,15 +129,15 @@
     """
     writer = GEXFWriter(encoding=encoding, prettyprint=prettyprint, version=version)
     writer.add_graph(G)
     yield from str(writer).splitlines()
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_gexf(path, node_type=None, relabel=False, version="1.2draft"):
     """Read graph in GEXF format from path.
 
     "GEXF (Graph Exchange XML Format) is a language for describing
     complex networks structures, their associated data and dynamics" [1]_.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/readwrite/gml.py` & `networkx-3.3rc0/networkx/readwrite/gml.py`

 * *Files 2% similar despite different names*

```diff
@@ -108,15 +108,15 @@
         except SyntaxError as err:
             raise ValueError(f"{orig_rep!r} is not a valid Python literal") from err
     else:
         raise ValueError(f"{rep!r} is not a string")
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_gml(path, label="label", destringizer=None):
     """Read graph in GML format from `path`.
 
     Parameters
     ----------
     path : filename or filehandle
         The filename or filehandle to read from.
@@ -191,15 +191,15 @@
                 line = line[:-1]
             yield line
 
     G = parse_gml_lines(filter_lines(path), label, destringizer)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_gml(lines, label="label", destringizer=None):
     """Parse GML graph from a string or iterable.
 
     Parameters
     ----------
     lines : string or iterable of strings
        Data in GML format.
@@ -543,30 +543,30 @@
     Notes
     -----
     The original value can be recovered using the
     :func:`networkx.readwrite.gml.literal_destringizer` function.
     """
 
     def stringize(value):
-        if isinstance(value, (int, bool)) or value is None:
+        if isinstance(value, int | bool) or value is None:
             if value is True:  # GML uses 1/0 for boolean values.
                 buf.write(str(1))
             elif value is False:
                 buf.write(str(0))
             else:
                 buf.write(str(value))
         elif isinstance(value, str):
             text = repr(value)
             if text[0] != "u":
                 try:
                     value.encode("latin1")
                 except UnicodeEncodeError:
                     text = "u" + text
             buf.write(text)
-        elif isinstance(value, (float, complex, str, bytes)):
+        elif isinstance(value, float | complex | str | bytes):
             buf.write(repr(value))
         elif isinstance(value, list):
             buf.write("[")
             first = True
             for item in value:
                 if not first:
                     buf.write(",")
@@ -711,15 +711,15 @@
         if not isinstance(key, str):
             raise NetworkXError(f"{key!r} is not a string")
         if not valid_keys.match(key):
             raise NetworkXError(f"{key!r} is not a valid key")
         if not isinstance(key, str):
             key = str(key)
         if key not in ignored_keys:
-            if isinstance(value, (int, bool)):
+            if isinstance(value, int | bool):
                 if key == "label":
                     yield indent + key + ' "' + str(value) + '"'
                 elif value is True:
                     # python bool is an instance of int
                     yield indent + key + " 1"
                 elif value is False:
                     yield indent + key + " 0"
@@ -749,15 +749,15 @@
                 yield indent + key + " ["
                 next_indent = indent + "  "
                 for key, value in value.items():
                     yield from stringize(key, value, (), next_indent)
                 yield indent + "]"
             elif isinstance(value, tuple) and key == "label":
                 yield indent + key + f" \"({','.join(repr(v) for v in value)})\""
-            elif isinstance(value, (list, tuple)) and key != "label" and not in_list:
+            elif isinstance(value, list | tuple) and key != "label" and not in_list:
                 if len(value) == 0:
                     yield indent + key + " " + f'"{value!r}"'
                 if len(value) == 1:
                     yield indent + key + " " + f'"{LIST_START_VALUE}"'
                 for val in value:
                     yield from stringize(key, val, (), indent, True)
             else:
```

### Comparing `networkx-3.2rc0/networkx/readwrite/graph6.py` & `networkx-3.3rc0/networkx/readwrite/graph6.py`

 * *Files 1% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     This function raises :exc:`ValueError` if the graph is too large for
     the graph6 format (that is, greater than ``2 ** 36`` nodes).
 
     """
     n = len(G)
     if n >= 2**36:
         raise ValueError(
-            "graph6 is only defined if number of nodes is less " "than 2 ** 36"
+            "graph6 is only defined if number of nodes is less than 2 ** 36"
         )
     if header:
         yield b">>graph6<<"
     for d in n_to_data(n):
         yield str.encode(chr(d + 63))
     # This generates the same as `(v in G[u] for u, v in combinations(G, 2))`,
     # but in "column-major" order instead of "row-major" order.
@@ -56,15 +56,15 @@
     while chunk:
         d = sum(b << 5 - i for i, b in enumerate(chunk))
         yield str.encode(chr(d + 63))
         chunk = list(islice(bits, 6))
     yield b"\n"
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_graph6_bytes(bytes_in):
     """Read a simple undirected graph in graph6 format from bytes.
 
     Parameters
     ----------
     bytes_in : bytes
        Data in graph6 format, without a trailing newline.
@@ -180,15 +180,15 @@
         G = G.subgraph(nodes)
     H = nx.convert_node_labels_to_integers(G)
     nodes = sorted(H.nodes())
     return b"".join(_generate_graph6_bytes(H, nodes, header))
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_graph6(path):
     """Read simple undirected graphs in graph6 format from path.
 
     Parameters
     ----------
     path : file or string
        File or filename to write.
```

### Comparing `networkx-3.2rc0/networkx/readwrite/graphml.py` & `networkx-3.3rc0/networkx/readwrite/graphml.py`

 * *Files 1% similar despite different names*

```diff
@@ -229,15 +229,15 @@
         edge_id_from_attribute=edge_id_from_attribute,
     )
     writer.add_graph_element(G)
     yield from str(writer).splitlines()
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_graphml(path, node_type=str, edge_key_type=int, force_multigraph=False):
     """Read graph in GraphML format from path.
 
     Parameters
     ----------
     path : file or string
        File or filename to write.
@@ -302,15 +302,15 @@
         new_bytes = old_bytes.replace(b"<graphml>", header)
         glist = list(reader(string=new_bytes))
         if len(glist) == 0:
             raise nx.NetworkXError("file not successfully read as graphml")
     return glist[0]
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_graphml(
     graphml_string, node_type=str, edge_key_type=int, force_multigraph=False
 ):
     """Read graph in GraphML format from string.
 
     Parameters
     ----------
@@ -451,15 +451,15 @@
         """Wrapper around the xml_type dict that raises a more informative
         exception message when a user attempts to use data of a type not
         supported by GraphML."""
         try:
             return self.xml_type[key]
         except KeyError as err:
             raise TypeError(
-                f"GraphML does not support type {type(key)} as data values."
+                f"GraphML does not support type {key} as data values."
             ) from err
 
 
 class GraphMLWriter(GraphML):
     def __init__(
         self,
         graph=None,
@@ -822,15 +822,15 @@
                 str(k), self.attr_type(str(k), scope, v), str(v), scope, default.get(k)
             )
             xml_obj.append(data_element)
 
     def __str__(self):
         return object.__str__(self)
 
-    def dump(self):
+    def dump(self, stream=None):
         self._graphml.__exit__(None, None, None)
         self._xml_base.__exit__(None, None, None)
 
 
 # default is lxml is present.
 write_graphml = write_graphml_lxml
 
@@ -978,15 +978,15 @@
                 else:
                     data[data_name] = data_type(text)
             elif len(list(data_element)) > 0:
                 # Assume yfiles as subelements, try to extract node_label
                 node_label = None
                 # set GenericNode's configuration as shape type
                 gn = data_element.find(f"{{{self.NS_Y}}}GenericNode")
-                if gn:
+                if gn is not None:
                     data["shape_type"] = gn.get("configuration")
                 for node_type in ["GenericNode", "ShapeNode", "SVGNode", "ImageNode"]:
                     pref = f"{{{self.NS_Y}}}{node_type}/{{{self.NS_Y}}}"
                     geometry = data_element.find(f"{pref}Geometry")
                     if geometry is not None:
                         data["x"] = geometry.get("x")
                         data["y"] = geometry.get("y")
@@ -1006,17 +1006,18 @@
                     "BezierEdge",
                     "ArcEdge",
                 ]:
                     pref = f"{{{self.NS_Y}}}{edge_type}/{{{self.NS_Y}}}"
                     edge_label = data_element.find(f"{pref}EdgeLabel")
                     if edge_label is not None:
                         break
-
                 if edge_label is not None:
                     data["label"] = edge_label.text
+            elif text is None:
+                data[data_name] = ""
         return data
 
     def find_graphml_keys(self, graph_element):
         """Extracts all the keys and key defaults from the xml."""
         graphml_keys = {}
         graphml_key_defaults = {}
         for k in graph_element.findall(f"{{{self.NS_GRAPHML}}}key"):
```

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/__init__.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/__init__.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/adjacency.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/adjacency.py`

 * *Files 2% similar despite different names*

```diff
@@ -77,15 +77,15 @@
         else:
             for nbr, d in nbrdict.items():
                 adj.append({**d, id_: nbr})
         data["adjacency"].append(adj)
     return data
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def adjacency_graph(data, directed=False, multigraph=True, attrs=_attrs):
     """Returns graph from adjacency data format.
 
     Parameters
     ----------
     data : dict
         Adjacency list formatted graph data
```

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/cytoscape.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/cytoscape.py`

 * *Files 4% similar despite different names*

```diff
@@ -76,15 +76,15 @@
             n = {"data": G.adj[e[0]][e[1]].copy()}
             n["data"]["source"] = e[0]
             n["data"]["target"] = e[1]
             edges.append(n)
     return jsondata
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def cytoscape_graph(data, name="name", ident="id"):
     """
     Create a NetworkX graph from a dictionary in cytoscape JSON format.
 
     Parameters
     ----------
     data : dict
@@ -115,20 +115,24 @@
     ----------
     .. [1] Cytoscape user's manual:
        http://manual.cytoscape.org/en/stable/index.html
 
     Examples
     --------
     >>> data_dict = {
-    ...     'data': [],
-    ...     'directed': False,
-    ...     'multigraph': False,
-    ...     'elements': {'nodes': [{'data': {'id': '0', 'value': 0, 'name': '0'}},
-    ...       {'data': {'id': '1', 'value': 1, 'name': '1'}}],
-    ...      'edges': [{'data': {'source': 0, 'target': 1}}]}
+    ...     "data": [],
+    ...     "directed": False,
+    ...     "multigraph": False,
+    ...     "elements": {
+    ...         "nodes": [
+    ...             {"data": {"id": "0", "value": 0, "name": "0"}},
+    ...             {"data": {"id": "1", "value": 1, "name": "1"}},
+    ...         ],
+    ...         "edges": [{"data": {"source": 0, "target": 1}}],
+    ...     },
     ... }
     >>> G = nx.cytoscape_graph(data_dict)
     >>> G.name
     ''
     >>> G.nodes()
     NodeView((0, 1))
     >>> G.nodes(data=True)[0]
```

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/node_link.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/node_link.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,15 +22,15 @@
     into valid nodes.
 
     Examples
     --------
     >>> _to_tuple([1, 2, [3, 4]])
     (1, 2, (3, 4))
     """
-    if not isinstance(x, (tuple, list)):
+    if not isinstance(x, tuple | list):
         return x
     return tuple(map(_to_tuple, x))
 
 
 def node_link_data(
     G,
     *,
@@ -128,15 +128,15 @@
             for u, v, k, d in G.edges(keys=True, data=True)
         ]
     else:
         data[link] = [{**d, source: u, target: v} for u, v, d in G.edges(data=True)]
     return data
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def node_link_graph(
     data,
     directed=False,
     multigraph=True,
     *,
     source="source",
     target="target",
@@ -175,15 +175,15 @@
         A NetworkX graph object
 
     Examples
     --------
 
     Create data in node-link format by converting a graph.
 
-    >>> G = nx.Graph([('A', 'B')])
+    >>> G = nx.Graph([("A", "B")])
     >>> data = nx.node_link_data(G)
     >>> data
     {'directed': False, 'multigraph': False, 'graph': {}, 'nodes': [{'id': 'A'}, {'id': 'B'}], 'links': [{'source': 'A', 'target': 'B'}]}
 
     Revert data in node-link format to a graph.
 
     >>> H = nx.node_link_graph(data)
```

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_adjacency.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_adjacency.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_cytoscape.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_cytoscape.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_node_link.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_node_link.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/tests/test_tree.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/tests/test_tree.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/json_graph/tree.py` & `networkx-3.3rc0/networkx/readwrite/json_graph/tree.py`

 * *Files 2% similar despite different names*

```diff
@@ -79,15 +79,15 @@
                 d[children] = c
             children_.append(d)
         return children_
 
     return {**G.nodes[root], ident: root, children: add_children(root, G)}
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def tree_graph(data, ident="id", children="children"):
     """Returns graph from tree data format.
 
     Parameters
     ----------
     data : dict
         Tree formatted graph data
```

### Comparing `networkx-3.2rc0/networkx/readwrite/leda.py` & `networkx-3.3rc0/networkx/readwrite/leda.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 import networkx as nx
 from networkx.exception import NetworkXError
 from networkx.utils import open_file
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_leda(path, encoding="UTF-8"):
     """Read graph in LEDA format from path.
 
     Parameters
     ----------
     path : file or string
        File or filename to read.  Filenames ending in .gz or .bz2  will be
@@ -42,15 +42,15 @@
     .. [1] http://www.algorithmic-solutions.info/leda_guide/graphs/leda_native_graph_fileformat.html
     """
     lines = (line.decode(encoding) for line in path)
     G = parse_leda(lines)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_leda(lines):
     """Read graph in LEDA format from string or iterable.
 
     Parameters
     ----------
     lines : string or iterable
        Data in LEDA format.
```

### Comparing `networkx-3.2rc0/networkx/readwrite/multiline_adjlist.py` & `networkx-3.3rc0/networkx/readwrite/multiline_adjlist.py`

 * *Files 4% similar despite different names*

```diff
@@ -187,15 +187,15 @@
     path.write(header.encode(encoding))
 
     for multiline in generate_multiline_adjlist(G, delimiter):
         multiline += "\n"
         path.write(multiline.encode(encoding))
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_multiline_adjlist(
     lines, comments="#", delimiter=None, create_using=None, nodetype=None, edgetype=None
 ):
     """Parse lines of a multiline adjacency list representation of a graph.
 
     Parameters
     ----------
@@ -251,15 +251,15 @@
         except BaseException as err:
             raise TypeError(f"Failed to read node and degree on line ({line})") from err
         if nodetype is not None:
             try:
                 u = nodetype(u)
             except BaseException as err:
                 raise TypeError(
-                    f"Failed to convert node ({u}) to " f"type {nodetype}"
+                    f"Failed to convert node ({u}) to type {nodetype}"
                 ) from err
         G.add_node(u)
         for i in range(deg):
             while True:
                 try:
                     line = next(lines)
                 except StopIteration as err:
@@ -277,35 +277,35 @@
             v = vlist.pop(0)
             data = "".join(vlist)
             if nodetype is not None:
                 try:
                     v = nodetype(v)
                 except BaseException as err:
                     raise TypeError(
-                        f"Failed to convert node ({v}) " f"to type {nodetype}"
+                        f"Failed to convert node ({v}) to type {nodetype}"
                     ) from err
             if edgetype is not None:
                 try:
                     edgedata = {"weight": edgetype(data)}
                 except BaseException as err:
                     raise TypeError(
-                        f"Failed to convert edge data ({data}) " f"to type {edgetype}"
+                        f"Failed to convert edge data ({data}) to type {edgetype}"
                     ) from err
             else:
                 try:  # try to evaluate
                     edgedata = literal_eval(data)
                 except:
                     edgedata = {}
             G.add_edge(u, v, **edgedata)
 
     return G
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_multiline_adjlist(
     path,
     comments="#",
     delimiter=None,
     create_using=None,
     nodetype=None,
     edgetype=None,
```

### Comparing `networkx-3.2rc0/networkx/readwrite/p2g.py` & `networkx-3.3rc0/networkx/readwrite/p2g.py`

 * *Files 2% similar despite different names*

```diff
@@ -53,15 +53,15 @@
         path.write((f"{n}\n").encode(encoding))
         for nbr in G.neighbors(n):
             path.write((f"{nodenumber[nbr]} ").encode(encoding))
         path.write("\n".encode(encoding))
 
 
 @open_file(0, mode="r")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_p2g(path, encoding="utf-8"):
     """Read graph in p2g format from path.
 
     Returns
     -------
     MultiDiGraph
 
@@ -71,15 +71,15 @@
     use D=nx.DiGraph(read_p2g(path))
     """
     lines = (line.decode(encoding) for line in path)
     G = parse_p2g(lines)
     return G
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_p2g(lines):
     """Parse p2g format graph from string or iterable.
 
     Returns
     -------
     MultiDiGraph
     """
```

### Comparing `networkx-3.2rc0/networkx/readwrite/pajek.py` & `networkx-3.3rc0/networkx/readwrite/pajek.py`

 * *Files 1% similar despite different names*

```diff
@@ -126,15 +126,15 @@
     """
     for line in generate_pajek(G):
         line += "\n"
         path.write(line.encode(encoding))
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_pajek(path, encoding="UTF-8"):
     """Read graph in Pajek format from path.
 
     Parameters
     ----------
     path : file or string
        File or filename to write.
@@ -159,15 +159,15 @@
     See http://vlado.fmf.uni-lj.si/pub/networks/pajek/doc/draweps.htm
     for format information.
     """
     lines = (line.decode(encoding) for line in path)
     return parse_pajek(lines)
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def parse_pajek(lines):
     """Parse Pajek format graph from string or iterable.
 
     Parameters
     ----------
     lines : string or iterable
        Data in Pajek format.
```

### Comparing `networkx-3.2rc0/networkx/readwrite/sparse6.py` & `networkx-3.3rc0/networkx/readwrite/sparse6.py`

 * *Files 4% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     This function raises :exc:`ValueError` if the graph is too large for
     the graph6 format (that is, greater than ``2 ** 36`` nodes).
 
     """
     n = len(G)
     if n >= 2**36:
         raise ValueError(
-            "sparse6 is only defined if number of nodes is less " "than 2 ** 36"
+            "sparse6 is only defined if number of nodes is less than 2 ** 36"
         )
     if header:
         yield b">>sparse6<<"
     yield b":"
     for d in n_to_data(n):
         yield str.encode(chr(d + 63))
 
@@ -97,15 +97,15 @@
     ]
 
     for d in data:
         yield str.encode(chr(d + 63))
     yield b"\n"
 
 
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def from_sparse6_bytes(string):
     """Read an undirected graph in sparse6 format from string.
 
     Parameters
     ----------
     string : string
        Data in sparse6 format
@@ -246,15 +246,15 @@
     if nodes is not None:
         G = G.subgraph(nodes)
     G = nx.convert_node_labels_to_integers(G, ordering="sorted")
     return b"".join(_generate_sparse6_bytes(G, nodes, header))
 
 
 @open_file(0, mode="rb")
-@nx._dispatch(graphs=None)
+@nx._dispatchable(graphs=None, returns_graph=True)
 def read_sparse6(path):
     """Read an undirected graph in sparse6 format from path.
 
     Parameters
     ----------
     path : file or string
        File or filename to write.
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_adjlist.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_adjlist.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 """
     Unit tests for adjlist.
 """
 import io
-import os
-import tempfile
 
 import pytest
 
 import networkx as nx
 from networkx.utils import edges_equal, graphs_equal, nodes_equal
 
 
@@ -32,118 +30,102 @@
 3
 """
         bytesIO = io.BytesIO(s)
         G = nx.read_multiline_adjlist(bytesIO)
         adj = {"1": {"3": {}, "2": {}}, "3": {"1": {}}, "2": {"1": {}}}
         assert graphs_equal(G, nx.Graph(adj))
 
-    def test_unicode(self):
+    def test_unicode(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
+
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(fname)
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_latin1_err(self):
+    def test_latin1_err(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
-        pytest.raises(
-            UnicodeEncodeError, nx.write_multiline_adjlist, G, fname, encoding="latin-1"
-        )
-        os.close(fd)
-        os.unlink(fname)
+        fname = tmp_path / "adjlist.txt"
+        with pytest.raises(UnicodeEncodeError):
+            nx.write_multiline_adjlist(G, fname, encoding="latin-1")
 
-    def test_latin1(self):
+    def test_latin1(self, tmp_path):
         G = nx.Graph()
         name1 = "Bj" + chr(246) + "rk"
         name2 = chr(220) + "ber"
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname, encoding="latin-1")
         H = nx.read_multiline_adjlist(fname, encoding="latin-1")
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
     def test_parse_adjlist(self):
         lines = ["1 2 5", "2 3 4", "3 5", "4", "5"]
         nx.parse_adjlist(lines, nodetype=int)  # smoke test
         with pytest.raises(TypeError):
             nx.parse_adjlist(lines, nodetype="int")
         lines = ["1 2 5", "2 b", "c"]
         with pytest.raises(TypeError):
             nx.parse_adjlist(lines, nodetype=int)
 
-    def test_adjlist_graph(self):
+    def test_adjlist_graph(self, tmp_path):
         G = self.G
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_adjlist(G, fname)
         H = nx.read_adjlist(fname)
         H2 = nx.read_adjlist(fname)
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_adjlist_digraph(self):
+    def test_adjlist_digraph(self, tmp_path):
         G = self.DG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_adjlist(G, fname)
         H = nx.read_adjlist(fname, create_using=nx.DiGraph())
         H2 = nx.read_adjlist(fname, create_using=nx.DiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_adjlist_integers(self):
-        (fd, fname) = tempfile.mkstemp()
+    def test_adjlist_integers(self, tmp_path):
+        fname = tmp_path / "adjlist.txt"
         G = nx.convert_node_labels_to_integers(self.G)
         nx.write_adjlist(G, fname)
         H = nx.read_adjlist(fname, nodetype=int)
         H2 = nx.read_adjlist(fname, nodetype=int)
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_adjlist_multigraph(self):
+    def test_adjlist_multigraph(self, tmp_path):
         G = self.XG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_adjlist(G, fname)
         H = nx.read_adjlist(fname, nodetype=int, create_using=nx.MultiGraph())
         H2 = nx.read_adjlist(fname, nodetype=int, create_using=nx.MultiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_adjlist_multidigraph(self):
+    def test_adjlist_multidigraph(self, tmp_path):
         G = self.XDG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_adjlist(G, fname)
         H = nx.read_adjlist(fname, nodetype=int, create_using=nx.MultiDiGraph())
         H2 = nx.read_adjlist(fname, nodetype=int, create_using=nx.MultiDiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
     def test_adjlist_delimiter(self):
         fh = io.BytesIO()
         G = nx.path_graph(3)
         nx.write_adjlist(G, fh, delimiter=":")
         fh.seek(0)
         H = nx.read_adjlist(fh, nodetype=int, delimiter=":")
@@ -188,79 +170,69 @@
         lines = ["1 2"]
         with pytest.raises(TypeError):
             nx.parse_multiline_adjlist(iter(lines))
         lines = ["1 2", "2 {}"]
         with pytest.raises(TypeError):
             nx.parse_multiline_adjlist(iter(lines))
 
-    def test_multiline_adjlist_graph(self):
+    def test_multiline_adjlist_graph(self, tmp_path):
         G = self.G
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(fname)
         H2 = nx.read_multiline_adjlist(fname)
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_multiline_adjlist_digraph(self):
+    def test_multiline_adjlist_digraph(self, tmp_path):
         G = self.DG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(fname, create_using=nx.DiGraph())
         H2 = nx.read_multiline_adjlist(fname, create_using=nx.DiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_multiline_adjlist_integers(self):
-        (fd, fname) = tempfile.mkstemp()
+    def test_multiline_adjlist_integers(self, tmp_path):
+        fname = tmp_path / "adjlist.txt"
         G = nx.convert_node_labels_to_integers(self.G)
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(fname, nodetype=int)
         H2 = nx.read_multiline_adjlist(fname, nodetype=int)
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_multiline_adjlist_multigraph(self):
+    def test_multiline_adjlist_multigraph(self, tmp_path):
         G = self.XG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(fname, nodetype=int, create_using=nx.MultiGraph())
         H2 = nx.read_multiline_adjlist(
             fname, nodetype=int, create_using=nx.MultiGraph()
         )
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_multiline_adjlist_multidigraph(self):
+    def test_multiline_adjlist_multidigraph(self, tmp_path):
         G = self.XDG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "adjlist.txt"
         nx.write_multiline_adjlist(G, fname)
         H = nx.read_multiline_adjlist(
             fname, nodetype=int, create_using=nx.MultiDiGraph()
         )
         H2 = nx.read_multiline_adjlist(
             fname, nodetype=int, create_using=nx.MultiDiGraph()
         )
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
     def test_multiline_adjlist_delimiter(self):
         fh = io.BytesIO()
         G = nx.path_graph(3)
         nx.write_multiline_adjlist(G, fh, delimiter=":")
         fh.seek(0)
         H = nx.read_multiline_adjlist(fh, nodetype=int, delimiter=":")
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_edgelist.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_edgelist.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 """
     Unit tests for edgelists.
 """
 import io
-import os
-import tempfile
 import textwrap
 
 import pytest
 
 import networkx as nx
 from networkx.utils import edges_equal, graphs_equal, nodes_equal
 
@@ -211,104 +209,88 @@
         G = nx.Graph()
         G.add_edge(1, 2, weight=2.0)
         G.add_edge(2, 3, weight=3.0)
         nx.write_edgelist(G, fh, data=[("weight")])
         fh.seek(0)
         assert fh.read() == b"1 2 2.0\n2 3 3.0\n"
 
-    def test_unicode(self):
+    def test_unicode(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname)
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_latin1_issue(self):
+    def test_latin1_issue(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
-        pytest.raises(
-            UnicodeEncodeError, nx.write_edgelist, G, fname, encoding="latin-1"
-        )
-        os.close(fd)
-        os.unlink(fname)
+        fname = tmp_path / "el.txt"
+        with pytest.raises(UnicodeEncodeError):
+            nx.write_edgelist(G, fname, encoding="latin-1")
 
-    def test_latin1(self):
+    def test_latin1(self, tmp_path):
         G = nx.Graph()
         name1 = "Bj" + chr(246) + "rk"
         name2 = chr(220) + "ber"
         G.add_edge(name1, "Radiohead", **{name2: 3})
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
+
         nx.write_edgelist(G, fname, encoding="latin-1")
         H = nx.read_edgelist(fname, encoding="latin-1")
         assert graphs_equal(G, H)
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_graph(self):
+    def test_edgelist_graph(self, tmp_path):
         G = self.G
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname)
         H2 = nx.read_edgelist(fname)
         assert H is not H2  # they should be different graphs
         G.remove_node("g")  # isolated nodes are not written in edgelist
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_digraph(self):
+    def test_edgelist_digraph(self, tmp_path):
         G = self.DG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname, create_using=nx.DiGraph())
         H2 = nx.read_edgelist(fname, create_using=nx.DiGraph())
         assert H is not H2  # they should be different graphs
         G.remove_node("g")  # isolated nodes are not written in edgelist
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_integers(self):
+    def test_edgelist_integers(self, tmp_path):
         G = nx.convert_node_labels_to_integers(self.G)
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname, nodetype=int)
         # isolated nodes are not written in edgelist
         G.remove_nodes_from(list(nx.isolates(G)))
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_multigraph(self):
+    def test_edgelist_multigraph(self, tmp_path):
         G = self.XG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname, nodetype=int, create_using=nx.MultiGraph())
         H2 = nx.read_edgelist(fname, nodetype=int, create_using=nx.MultiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_edgelist_multidigraph(self):
+    def test_edgelist_multidigraph(self, tmp_path):
         G = self.XDG
-        (fd, fname) = tempfile.mkstemp()
+        fname = tmp_path / "el.txt"
         nx.write_edgelist(G, fname)
         H = nx.read_edgelist(fname, nodetype=int, create_using=nx.MultiDiGraph())
         H2 = nx.read_edgelist(fname, nodetype=int, create_using=nx.MultiDiGraph())
         assert H is not H2  # they should be different graphs
         assert nodes_equal(list(H), list(G))
         assert edges_equal(list(H.edges()), list(G.edges()))
-        os.close(fd)
-        os.unlink(fname)
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_gexf.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_gexf.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_gml.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_gml.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 import codecs
 import io
 import math
-import os
-import tempfile
 from ast import literal_eval
 from contextlib import contextmanager
 from textwrap import dedent
 
 import pytest
 
 import networkx as nx
@@ -161,25 +159,22 @@
                     "label": "Edge from node 1 to node 2",
                 },
             ),
             ("Node 2", "Node 3", {"label": "Edge from node 2 to node 3"}),
             ("Node 3", "Node 1", {"label": "Edge from node 3 to node 1"}),
         ]
 
-    def test_read_gml(self):
-        (fd, fname) = tempfile.mkstemp()
-        fh = open(fname, "w")
-        fh.write(self.simple_data)
-        fh.close()
+    def test_read_gml(self, tmp_path):
+        fname = tmp_path / "test.gml"
+        with open(fname, "w") as fh:
+            fh.write(self.simple_data)
         Gin = nx.read_gml(fname, label="label")
         G = nx.parse_gml(self.simple_data, label="label")
         assert sorted(G.nodes(data=True)) == sorted(Gin.nodes(data=True))
         assert sorted(G.edges(data=True)) == sorted(Gin.edges(data=True))
-        os.close(fd)
-        os.unlink(fname)
 
     def test_labels_are_strings(self):
         # GML requires labels to be strings (i.e., in quotes)
         answer = """graph [
   node [
     id 0
     label "1203"
@@ -231,71 +226,71 @@
   edge [
     source 0
     target 1
   ]
 ]"""
         assert data == answer
 
-    def test_quotes(self):
+    def test_quotes(self, tmp_path):
         # https://github.com/networkx/networkx/issues/1061
         # Encoding quotes as HTML entities.
         G = nx.path_graph(1)
         G.name = "path_graph(1)"
         attr = 'This is "quoted" and this is a copyright: ' + chr(169)
         G.nodes[0]["demo"] = attr
-        fobj = tempfile.NamedTemporaryFile()
-        nx.write_gml(G, fobj)
-        fobj.seek(0)
-        # Should be bytes in 2.x and 3.x
-        data = fobj.read().strip().decode("ascii")
+        with open(tmp_path / "test.gml", "w+b") as fobj:
+            nx.write_gml(G, fobj)
+            fobj.seek(0)
+            # Should be bytes in 2.x and 3.x
+            data = fobj.read().strip().decode("ascii")
         answer = """graph [
   name "path_graph(1)"
   node [
     id 0
     label "0"
     demo "This is &#34;quoted&#34; and this is a copyright: &#169;"
   ]
 ]"""
         assert data == answer
 
-    def test_unicode_node(self):
+    def test_unicode_node(self, tmp_path):
         node = "node" + chr(169)
         G = nx.Graph()
         G.add_node(node)
-        fobj = tempfile.NamedTemporaryFile()
-        nx.write_gml(G, fobj)
-        fobj.seek(0)
-        # Should be bytes in 2.x and 3.x
-        data = fobj.read().strip().decode("ascii")
+        with open(tmp_path / "test.gml", "w+b") as fobj:
+            nx.write_gml(G, fobj)
+            fobj.seek(0)
+            # Should be bytes in 2.x and 3.x
+            data = fobj.read().strip().decode("ascii")
         answer = """graph [
   node [
     id 0
     label "node&#169;"
   ]
 ]"""
         assert data == answer
 
-    def test_float_label(self):
+    def test_float_label(self, tmp_path):
         node = 1.0
         G = nx.Graph()
         G.add_node(node)
-        fobj = tempfile.NamedTemporaryFile()
-        nx.write_gml(G, fobj)
-        fobj.seek(0)
-        # Should be bytes in 2.x and 3.x
-        data = fobj.read().strip().decode("ascii")
+        with open(tmp_path / "test.gml", "w+b") as fobj:
+            nx.write_gml(G, fobj)
+            fobj.seek(0)
+            # Should be bytes in 2.x and 3.x
+            data = fobj.read().strip().decode("ascii")
         answer = """graph [
   node [
     id 0
     label "1.0"
   ]
 ]"""
         assert data == answer
 
-    def test_special_float_label(self):
+    def test_special_float_label(self, tmp_path):
         special_floats = [float("nan"), float("+inf"), float("-inf")]
         try:
             import numpy as np
 
             special_floats += [np.nan, np.inf, np.inf * -1]
         except ImportError:
             special_floats += special_floats
@@ -303,20 +298,20 @@
         G = nx.cycle_graph(len(special_floats))
         attrs = dict(enumerate(special_floats))
         nx.set_node_attributes(G, attrs, "nodefloat")
         edges = list(G.edges)
         attrs = {edges[i]: value for i, value in enumerate(special_floats)}
         nx.set_edge_attributes(G, attrs, "edgefloat")
 
-        fobj = tempfile.NamedTemporaryFile()
-        nx.write_gml(G, fobj)
-        fobj.seek(0)
-        # Should be bytes in 2.x and 3.x
-        data = fobj.read().strip().decode("ascii")
-        answer = """graph [
+        with open(tmp_path / "test.gml", "w+b") as fobj:
+            nx.write_gml(G, fobj)
+            fobj.seek(0)
+            # Should be bytes in 2.x and 3.x
+            data = fobj.read().strip().decode("ascii")
+            answer = """graph [
   node [
     id 0
     label "0"
     nodefloat NAN
   ]
   node [
     id 1
@@ -370,32 +365,32 @@
   ]
   edge [
     source 4
     target 5
     edgefloat -INF
   ]
 ]"""
-        assert data == answer
+            assert data == answer
 
-        fobj.seek(0)
-        graph = nx.read_gml(fobj)
-        for indx, value in enumerate(special_floats):
-            node_value = graph.nodes[str(indx)]["nodefloat"]
-            if math.isnan(value):
-                assert math.isnan(node_value)
-            else:
-                assert node_value == value
+            fobj.seek(0)
+            graph = nx.read_gml(fobj)
+            for indx, value in enumerate(special_floats):
+                node_value = graph.nodes[str(indx)]["nodefloat"]
+                if math.isnan(value):
+                    assert math.isnan(node_value)
+                else:
+                    assert node_value == value
 
-            edge = edges[indx]
-            string_edge = (str(edge[0]), str(edge[1]))
-            edge_value = graph.edges[string_edge]["edgefloat"]
-            if math.isnan(value):
-                assert math.isnan(edge_value)
-            else:
-                assert edge_value == value
+                edge = edges[indx]
+                string_edge = (str(edge[0]), str(edge[1]))
+                edge_value = graph.edges[string_edge]["edgefloat"]
+                if math.isnan(value):
+                    assert math.isnan(edge_value)
+                else:
+                    assert edge_value == value
 
     def test_name(self):
         G = nx.parse_gml('graph [ name "x" node [ id 0 label "x" ] ]')
         assert "x" == G.graph["name"]
         G = nx.parse_gml('graph [ node [ id 0 label "x" ] ]')
         assert "" == G.name
         assert "name" not in G.graph
@@ -476,21 +471,21 @@
   name "&#38;&#34;&#15;&#17476;&#38;"""
             + alnu
             + """;&#38;unknown;"
 ]"""
         )
         assert answer == gml
 
-    def test_exceptions(self):
+    def test_exceptions(self, tmp_path):
         pytest.raises(ValueError, literal_destringizer, "(")
         pytest.raises(ValueError, literal_destringizer, "frozenset([1, 2, 3])")
         pytest.raises(ValueError, literal_destringizer, literal_destringizer)
         pytest.raises(ValueError, literal_stringizer, frozenset([1, 2, 3]))
         pytest.raises(ValueError, literal_stringizer, literal_stringizer)
-        with tempfile.TemporaryFile() as f:
+        with open(tmp_path / "test.gml", "w+b") as f:
             f.write(codecs.BOM_UTF8 + b"graph[]")
             f.seek(0)
             pytest.raises(nx.NetworkXError, nx.read_gml, f)
 
         def assert_parse_error(gml):
             pytest.raises(nx.NetworkXError, nx.parse_gml, gml)
 
@@ -550,16 +545,16 @@
         nx.parse_gml(
             "graph [ node [ id n42 label 0 ] node [ id x43 label 1 ]"
             "edge [ source n42 target x43 key 0 ]"
             "edge [ source x43 target n42 key 0 ]"
             "directed 1 multigraph 1 ]"
         )
         assert_parse_error(
-            "graph [edge [ source u'u\4200' target u'u\4200' ] "
-            + "node [ id u'u\4200' label b ] ]"
+            "graph [edge [ source '\u4200' target '\u4200' ] "
+            + "node [ id '\u4200' label b ] ]"
         )
 
         def assert_generate_error(*args, **kwargs):
             pytest.raises(
                 nx.NetworkXError, lambda: list(nx.generate_gml(*args, **kwargs))
             )
 
@@ -580,15 +575,15 @@
         assert labels == ["Node 1", "Node 2", "Node 3"]
 
         G = nx.parse_gml(self.simple_data, label=None)
         assert sorted(G.nodes) == [1, 2, 3]
         labels = [G.nodes[n]["label"] for n in sorted(G.nodes)]
         assert labels == ["Node 1", "Node 2", "Node 3"]
 
-    def test_outofrange_integers(self):
+    def test_outofrange_integers(self, tmp_path):
         # GML restricts integers to 32 signed bits.
         # Check that we honor this restriction on export
         G = nx.Graph()
         # Test export for numbers that barely fit or don't fit into 32 bits,
         # and 3 numbers in the middle
         numbers = {
             "toosmall": (-(2**31)) - 1,
@@ -597,27 +592,23 @@
             "med2": 0,
             "med3": 17,
             "big": (2**31) - 1,
             "toobig": 2**31,
         }
         G.add_node("Node", **numbers)
 
-        fd, fname = tempfile.mkstemp()
-        try:
-            nx.write_gml(G, fname)
-            # Check that the export wrote the nonfitting numbers as strings
-            G2 = nx.read_gml(fname)
-            for attr, value in G2.nodes["Node"].items():
-                if attr == "toosmall" or attr == "toobig":
-                    assert type(value) == str
-                else:
-                    assert type(value) == int
-        finally:
-            os.close(fd)
-            os.unlink(fname)
+        fname = tmp_path / "test.gml"
+        nx.write_gml(G, fname)
+        # Check that the export wrote the nonfitting numbers as strings
+        G2 = nx.read_gml(fname)
+        for attr, value in G2.nodes["Node"].items():
+            if attr == "toosmall" or attr == "toobig":
+                assert type(value) == str
+            else:
+                assert type(value) == int
 
     def test_multiline(self):
         # example from issue #6836
         multiline_example = """
 graph
 [
     node
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_graph6.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_graph6.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import tempfile
 from io import BytesIO
 
 import pytest
 
 import networkx as nx
 import networkx.readwrite.graph6 as g6
 from networkx.utils import edges_equal, nodes_equal
@@ -100,16 +99,16 @@
             f = BytesIO()
             nx.write_graph6(G, f)
             f.seek(0)
             H = nx.read_graph6(f)
             assert nodes_equal(G.nodes(), H.nodes())
             assert edges_equal(G.edges(), H.edges())
 
-    def test_write_path(self):
-        with tempfile.NamedTemporaryFile() as f:
+    def test_write_path(self, tmp_path):
+        with open(tmp_path / "test.g6", "w+b") as f:
             g6.write_graph6_file(nx.null_graph(), f)
             f.seek(0)
             assert f.read() == b">>graph6<<?\n"
 
     @pytest.mark.parametrize("edge", ((0, 1), (1, 2), (1, 42)))
     def test_relabeling(self, edge):
         G = nx.Graph([edge])
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_graphml.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_graphml.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,8 @@
 import io
-import os
-import tempfile
 
 import pytest
 
 import networkx as nx
 from networkx.readwrite.graphml import GraphMLWriter
 from networkx.utils import edges_equal, nodes_equal
 
@@ -1206,30 +1204,28 @@
 
         keys = [child.items() for child in children[:2]]
 
         assert len(keys) == 2
         assert ("attr.type", "double") in keys[0]
         assert ("attr.type", "double") in keys[1]
 
-    def test_more_multigraph_keys(self):
+    def test_more_multigraph_keys(self, tmp_path):
         """Writing keys as edge id attributes means keys become strings.
         The original keys are stored as data, so read them back in
         if `str(key) == edge_id`
         This allows the adjacency to remain the same.
         """
         G = nx.MultiGraph()
         G.add_edges_from([("a", "b", 2), ("a", "b", 3)])
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname)
         assert H.is_multigraph()
         assert edges_equal(G.edges(keys=True), H.edges(keys=True))
         assert G._adj == H._adj
-        os.close(fd)
-        os.unlink(fname)
 
     def test_default_attribute(self):
         G = nx.Graph(name="Fred")
         G.add_node(1, label=1, color="green")
         nx.add_path(G, [0, 1, 2, 3])
         G.add_edge(1, 2, weight=3)
         G.graph["node_default"] = {"color": "yellow"}
@@ -1284,46 +1280,42 @@
         fh.seek(0)
         H = nx.read_graphml(fh)
         assert H.nodes["n0"]["special"] == 0
         assert H.nodes["n1"]["special"] == 1
         assert H.edges["n0", "n1", 0]["special"] == 2
         assert H.edges["n0", "n1", 1]["special"] == 3
 
-    def test_multigraph_to_graph(self):
+    def test_multigraph_to_graph(self, tmp_path):
         # test converting multigraph to graph if no parallel edges found
         G = nx.MultiGraph()
         G.add_edges_from([("a", "b", 2), ("b", "c", 3)])  # no multiedges
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname)
         assert not H.is_multigraph()
         H = nx.read_graphml(fname, force_multigraph=True)
         assert H.is_multigraph()
-        os.close(fd)
-        os.unlink(fname)
 
         # add a multiedge
         G.add_edge("a", "b", "e-id")
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname)
         assert H.is_multigraph()
         H = nx.read_graphml(fname, force_multigraph=True)
         assert H.is_multigraph()
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_write_generate_edge_id_from_attribute(self):
+    def test_write_generate_edge_id_from_attribute(self, tmp_path):
         from xml.etree.ElementTree import parse
 
         G = nx.Graph()
         G.add_edges_from([("a", "b"), ("b", "c"), ("a", "c")])
         edge_attributes = {e: str(e) for e in G.edges}
         nx.set_edge_attributes(G, edge_attributes, "eid")
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         # set edge_id_from_attribute e.g. "eid" for write_graphml()
         self.writer(G, fname, edge_id_from_attribute="eid")
         # set edge_id_from_attribute e.g. "eid" for generate_graphml()
         generator = nx.generate_graphml(G, edge_id_from_attribute="eid")
 
         H = nx.read_graphml(fname)
         assert nodes_equal(G.nodes(), H.nodes())
@@ -1349,25 +1341,22 @@
         J = nx.parse_graphml(data)
         assert sorted(G.nodes()) == sorted(J.nodes())
         assert sorted(G.edges()) == sorted(J.edges())
         # NetworkX adds explicit edge "id" from file as attribute
         nx.set_edge_attributes(G, edge_attributes, "id")
         assert edges_equal(G.edges(data=True), J.edges(data=True))
 
-        os.close(fd)
-        os.unlink(fname)
-
-    def test_multigraph_write_generate_edge_id_from_attribute(self):
+    def test_multigraph_write_generate_edge_id_from_attribute(self, tmp_path):
         from xml.etree.ElementTree import parse
 
         G = nx.MultiGraph()
         G.add_edges_from([("a", "b"), ("b", "c"), ("a", "c"), ("a", "b")])
         edge_attributes = {e: str(e) for e in G.edges}
         nx.set_edge_attributes(G, edge_attributes, "eid")
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         # set edge_id_from_attribute e.g. "eid" for write_graphml()
         self.writer(G, fname, edge_id_from_attribute="eid")
         # set edge_id_from_attribute e.g. "eid" for generate_graphml()
         generator = nx.generate_graphml(G, edge_id_from_attribute="eid")
 
         H = nx.read_graphml(fname)
         assert H.is_multigraph()
@@ -1407,72 +1396,61 @@
             edge_attributes.values()
         )
         # NetworkX uses edge_ids as keys in multigraphs if no key
         assert sorted(key for u, v, key in J.edges(keys=True)) == sorted(
             edge_attributes.values()
         )
 
-        os.close(fd)
-        os.unlink(fname)
-
-    def test_numpy_float64(self):
+    def test_numpy_float64(self, tmp_path):
         np = pytest.importorskip("numpy")
         wt = np.float64(3.4)
         G = nx.Graph([(1, 2, {"weight": wt})])
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname, node_type=int)
         assert G.edges == H.edges
         wtG = G[1][2]["weight"]
         wtH = H[1][2]["weight"]
         assert wtG == pytest.approx(wtH, abs=1e-6)
         assert type(wtG) == np.float64
         assert type(wtH) == float
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_numpy_float32(self):
+    def test_numpy_float32(self, tmp_path):
         np = pytest.importorskip("numpy")
         wt = np.float32(3.4)
         G = nx.Graph([(1, 2, {"weight": wt})])
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname, node_type=int)
         assert G.edges == H.edges
         wtG = G[1][2]["weight"]
         wtH = H[1][2]["weight"]
         assert wtG == pytest.approx(wtH, abs=1e-6)
         assert type(wtG) == np.float32
         assert type(wtH) == float
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_numpy_float64_inference(self):
+    def test_numpy_float64_inference(self, tmp_path):
         np = pytest.importorskip("numpy")
         G = self.attribute_numeric_type_graph
         G.edges[("n1", "n1")]["weight"] = np.float64(1.1)
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname, infer_numeric_types=True)
         H = nx.read_graphml(fname)
         assert G._adj == H._adj
-        os.close(fd)
-        os.unlink(fname)
 
-    def test_unicode_attributes(self):
+    def test_unicode_attributes(self, tmp_path):
         G = nx.Graph()
         name1 = chr(2344) + chr(123) + chr(6543)
         name2 = chr(5543) + chr(1543) + chr(324)
         node_type = str
         G.add_edge(name1, "Radiohead", foo=name2)
-        fd, fname = tempfile.mkstemp()
+        fname = tmp_path / "test.graphml"
         self.writer(G, fname)
         H = nx.read_graphml(fname, node_type=node_type)
         assert G._adj == H._adj
-        os.close(fd)
-        os.unlink(fname)
 
     def test_unicode_escape(self):
         # test for handling json escaped strings in python 2 Issue #1880
         import json
 
         a = {"a": '{"a": "123"}'}  # an object with many chars to escape
         sa = json.dumps(a)
@@ -1523,7 +1501,31 @@
     pytest.importorskip("lxml.etree")
     # graph attribute
     G = nx.Graph()
     G.graph["my_list_attribute"] = [0, 1, 2]
     fh = io.BytesIO()
     with pytest.raises(TypeError, match="GraphML does not support"):
         nx.write_graphml(G, fh)
+
+
+def test_empty_attribute():
+    """Tests that a GraphML string with an empty attribute can be parsed
+    correctly."""
+    s = """<?xml version='1.0' encoding='utf-8'?>
+    <graphml>
+      <key id="d1" for="node" attr.name="foo" attr.type="string"/>
+      <key id="d2" for="node" attr.name="bar" attr.type="string"/>
+      <graph>
+        <node id="0">
+          <data key="d1">aaa</data>
+          <data key="d2">bbb</data>
+        </node>
+        <node id="1">
+          <data key="d1">ccc</data>
+          <data key="d2"></data>
+        </node>
+      </graph>
+    </graphml>"""
+    fh = io.BytesIO(s.encode("UTF-8"))
+    G = nx.read_graphml(fh)
+    assert G.nodes["0"] == {"foo": "aaa", "bar": "bbb"}
+    assert G.nodes["1"] == {"foo": "ccc", "bar": ""}
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_leda.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_leda.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_p2g.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_p2g.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_pajek.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_pajek.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,10 @@
 """
 Pajek tests
 """
-import os
-import tempfile
-
 import networkx as nx
 from networkx.utils import edges_equal, nodes_equal
 
 
 class TestPajek:
     @classmethod
     def setup_class(cls):
@@ -23,21 +20,14 @@
                 ("C", "C"),
                 ("C", "D2"),
                 ("D2", "Bb"),
             ]
         )
 
         cls.G.graph["name"] = "Tralala"
-        (fd, cls.fname) = tempfile.mkstemp()
-        with os.fdopen(fd, "wb") as fh:
-            fh.write(cls.data.encode("UTF-8"))
-
-    @classmethod
-    def teardown_class(cls):
-        os.unlink(cls.fname)
 
     def test_parse_pajek_simple(self):
         # Example without node positions or shape
         data = """*Vertices 2\n1 "1"\n2 "2"\n*Edges\n1 2\n2 1"""
         G = nx.parse_pajek(data)
         assert sorted(G.nodes()) == ["1", "2"]
         assert edges_equal(G.edges(), [("1", "2"), ("1", "2")])
@@ -64,17 +54,22 @@
         assert set(G.nodes()) == {"one", "two", "three"}
         assert G.nodes["two"] == {"id": "2"}
         assert edges_equal(
             set(G.edges()),
             {("one", "one"), ("two", "one"), ("two", "two"), ("two", "three")},
         )
 
-    def test_read_pajek(self):
+    def test_read_pajek(self, tmp_path):
         G = nx.parse_pajek(self.data)
-        Gin = nx.read_pajek(self.fname)
+        # Read data from file
+        fname = tmp_path / "test.pjk"
+        with open(fname, "wb") as fh:
+            fh.write(self.data.encode("UTF-8"))
+
+        Gin = nx.read_pajek(fname)
         assert sorted(G.nodes()) == sorted(Gin.nodes())
         assert edges_equal(G.edges(), Gin.edges())
         assert self.G.graph == Gin.graph
         for n in G:
             assert G.nodes[n] == Gin.nodes[n]
 
     def test_write_pajek(self):
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_sparse6.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_sparse6.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import tempfile
 from io import BytesIO
 
 import pytest
 
 import networkx as nx
 from networkx.utils import edges_equal, nodes_equal
 
@@ -154,20 +153,14 @@
             assert g2.order() == g.order()
             assert edges_equal(g2.edges(), g.edges())
 
     def test_no_directed_graphs(self):
         with pytest.raises(nx.NetworkXNotImplemented):
             nx.write_sparse6(nx.DiGraph(), BytesIO())
 
-    def test_write_path(self):
-        # On Windows, we can't reopen a file that is open
-        # So, for test we get a valid name from tempfile but close it.
-        with tempfile.NamedTemporaryFile() as f:
-            fullfilename = f.name
+    def test_write_path(self, tmp_path):
+        # Get a valid temporary file name
+        fullfilename = str(tmp_path / "test.s6")
         # file should be closed now, so write_sparse6 can open it
         nx.write_sparse6(nx.null_graph(), fullfilename)
-        fh = open(fullfilename, mode="rb")
-        assert fh.read() == b">>sparse6<<:?\n"
-        fh.close()
-        import os
-
-        os.remove(fullfilename)
+        with open(fullfilename, mode="rb") as fh:
+            assert fh.read() == b">>sparse6<<:?\n"
```

### Comparing `networkx-3.2rc0/networkx/readwrite/tests/test_text.py` & `networkx-3.3rc0/networkx/readwrite/tests/test_text.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/readwrite/text.py` & `networkx-3.3rc0/networkx/readwrite/text.py`

 * *Files 1% similar despite different names*

```diff
@@ -153,24 +153,24 @@
     Yields
     ------
     str : a line of generated text
 
     Examples
     --------
     >>> graph = nx.path_graph(10)
-    >>> graph.add_node('A')
-    >>> graph.add_node('B')
-    >>> graph.add_node('C')
-    >>> graph.add_node('D')
-    >>> graph.add_edge(9, 'A')
-    >>> graph.add_edge(9, 'B')
-    >>> graph.add_edge(9, 'C')
-    >>> graph.add_edge('C', 'D')
-    >>> graph.add_edge('C', 'E')
-    >>> graph.add_edge('C', 'F')
+    >>> graph.add_node("A")
+    >>> graph.add_node("B")
+    >>> graph.add_node("C")
+    >>> graph.add_node("D")
+    >>> graph.add_edge(9, "A")
+    >>> graph.add_edge(9, "B")
+    >>> graph.add_edge(9, "C")
+    >>> graph.add_edge("C", "D")
+    >>> graph.add_edge("C", "E")
+    >>> graph.add_edge("C", "F")
     >>> nx.write_network_text(graph)
     ╙── 0
         └── 1
             └── 2
                 └── 3
                     └── 4
                         └── 5
@@ -764,15 +764,15 @@
     """
     from itertools import chain
     from typing import Any, NamedTuple, Union
 
     class ParseStackFrame(NamedTuple):
         node: Any
         indent: int
-        has_vertical_child: Union[int, None]
+        has_vertical_child: int | None
 
     initial_line_iter = iter(lines)
 
     is_ascii = None
     is_directed = None
 
     ##############
```

### Comparing `networkx-3.2rc0/networkx/relabel.py` & `networkx-3.3rc0/networkx/relabel.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,15 @@
 import networkx as nx
 
 __all__ = ["convert_node_labels_to_integers", "relabel_nodes"]
 
 
-@nx._dispatch(preserve_all_attrs=True)
+@nx._dispatchable(
+    preserve_all_attrs=True, mutates_input={"not copy": 2}, returns_graph=True
+)
 def relabel_nodes(G, mapping, copy=True):
     """Relabel the nodes of the graph G according to a given mapping.
 
     The original node ordering may not be preserved if `copy` is `False` and the
     mapping includes overlap between old and new labels.
 
     Parameters
@@ -61,15 +63,15 @@
     >>> G = nx.relabel_nodes(G, mapping, copy=False)
     >>> sorted(G, key=str)
     [2, 'a', 'b']
 
     A mapping can also be given as a function:
 
     >>> G = nx.path_graph(3)
-    >>> H = nx.relabel_nodes(G, lambda x: x ** 2)
+    >>> H = nx.relabel_nodes(G, lambda x: x**2)
     >>> list(H)
     [0, 1, 4]
 
     In a multigraph, relabeling two or more nodes to the same new node
     will retain all edges, but may change the edge keys in the process:
 
     >>> G = nx.MultiGraph()
@@ -164,15 +166,15 @@
                     (new if old == source else source, new, key, data)
                     for (source, _, key, data) in G.in_edges(old, data=True, keys=True)
                 ]
             # Ensure new edges won't overwrite existing ones
             seen = set()
             for i, (source, target, key, data) in enumerate(new_edges):
                 if target in G[source] and key in G[source][target]:
-                    new_key = 0 if not isinstance(key, (int, float)) else key
+                    new_key = 0 if not isinstance(key, int | float) else key
                     while new_key in G[source][target] or (target, new_key) in seen:
                         new_key += 1
                     new_edges[i] = (source, target, new_key, data)
                     seen.add((target, new_key))
         else:
             new_edges = [
                 (new, new if old == target else target, data)
@@ -199,15 +201,15 @@
         ]
 
         # check for conflicting edge-keys
         undirected = not G.is_directed()
         seen_edges = set()
         for i, (source, target, key, data) in enumerate(new_edges):
             while (source, target, key) in seen_edges:
-                if not isinstance(key, (int, float)):
+                if not isinstance(key, int | float):
                     key = 0
                 key += 1
             seen_edges.add((source, target, key))
             if undirected:
                 seen_edges.add((target, source, key))
             new_edges[i] = (source, target, key, data)
 
@@ -217,17 +219,15 @@
             (mapping.get(n1, n1), mapping.get(n2, n2), d.copy())
             for (n1, n2, d) in G.edges(data=True)
         )
     H.graph.update(G.graph)
     return H
 
 
-@nx._dispatch(
-    preserve_edge_attrs=True, preserve_node_attrs=True, preserve_graph_attrs=True
-)
+@nx._dispatchable(preserve_all_attrs=True, returns_graph=True)
 def convert_node_labels_to_integers(
     G, first_label=0, ordering="default", label_attribute=None
 ):
     """Returns a copy of the graph G with the nodes relabeled using
     consecutive integers.
 
     Parameters
```

### Comparing `networkx-3.2rc0/networkx/tests/test_all_random_functions.py` & `networkx-3.3rc0/networkx/tests/test_all_random_functions.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_convert.py` & `networkx-3.3rc0/networkx/tests/test_convert.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_convert_numpy.py` & `networkx-3.3rc0/networkx/tests/test_convert_numpy.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_convert_pandas.py` & `networkx-3.3rc0/networkx/tests/test_convert_pandas.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_convert_scipy.py` & `networkx-3.3rc0/networkx/tests/test_convert_scipy.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_exceptions.py` & `networkx-3.3rc0/networkx/tests/test_exceptions.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_lazy_imports.py` & `networkx-3.3rc0/networkx/tests/test_lazy_imports.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/tests/test_relabel.py` & `networkx-3.3rc0/networkx/tests/test_relabel.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/decorators.py` & `networkx-3.3rc0/networkx/utils/decorators.py`

 * *Files 2% similar despite different names*

```diff
@@ -53,19 +53,21 @@
     --------
     Decorate functions like this::
 
        @not_implemented_for("directed")
        def sp_function(G):
            pass
 
+
        # rule out MultiDiGraph
-       @not_implemented_for("directed","multigraph")
+       @not_implemented_for("directed", "multigraph")
        def sp_np_function(G):
            pass
 
+
        # rule out all except DiGraph
        @not_implemented_for("undirected")
        @not_implemented_for("multigraph")
        def sp_np_function(G):
            pass
     """
     if ("directed" in graph_types) and ("undirected" in graph_types):
@@ -120,30 +122,34 @@
     _open_file : function
         Function which cleanly executes the io.
 
     Examples
     --------
     Decorate functions like this::
 
-       @open_file(0,"r")
+       @open_file(0, "r")
        def read_function(pathname):
            pass
 
-       @open_file(1,"w")
+
+       @open_file(1, "w")
        def write_function(G, pathname):
            pass
 
-       @open_file(1,"w")
+
+       @open_file(1, "w")
        def write_function(G, pathname="graph.dot"):
            pass
 
-       @open_file("pathname","w")
+
+       @open_file("pathname", "w")
        def write_function(G, pathname="graph.dot"):
            pass
 
+
        @open_file("path", "w+")
        def another_function(arg, **kwargs):
            path = kwargs["path"]
            pass
 
     Notes
     -----
@@ -151,27 +157,27 @@
     specified as a string, but it does not handle the situation when the
     function wants to accept a default of None (and then handle it).
 
     Here is an example of how to handle this case::
 
       @open_file("path")
       def some_function(arg1, arg2, path=None):
-         if path is None:
-             fobj = tempfile.NamedTemporaryFile(delete=False)
-         else:
-             # `path` could have been a string or file object or something
-             # similar. In any event, the decorator has given us a file object
-             # and it will close it for us, if it should.
-             fobj = path
-
-         try:
-             fobj.write("blah")
-         finally:
-             if path is None:
-                 fobj.close()
+          if path is None:
+              fobj = tempfile.NamedTemporaryFile(delete=False)
+          else:
+              # `path` could have been a string or file object or something
+              # similar. In any event, the decorator has given us a file object
+              # and it will close it for us, if it should.
+              fobj = path
+
+          try:
+              fobj.write("blah")
+          finally:
+              if path is None:
+                  fobj.close()
 
     Normally, we'd want to use "with" to ensure that fobj gets closed.
     However, the decorator will make `path` a file object for us,
     and using "with" would undesirably close that file object.
     Instead, we use a try block, as shown above.
     When we exit the function, fobj will be closed, if it should be, by the decorator.
     """
@@ -257,22 +263,23 @@
     except TypeError:
         iter_wa = (which_args,)
 
     return argmap(_nodes_or_number, *iter_wa)
 
 
 def np_random_state(random_state_argument):
-    """Decorator to generate a `numpy.random.RandomState` instance.
+    """Decorator to generate a numpy RandomState or Generator instance.
 
     The decorator processes the argument indicated by `random_state_argument`
     using :func:`nx.utils.create_random_state`.
     The argument value can be a seed (integer), or a `numpy.random.RandomState`
-    instance or (`None` or `numpy.random`). The latter options use the glocal
-    random number generator used by `numpy.random`.
-    The result is a `numpy.random.RandomState` instance.
+    or `numpy.random.RandomState` instance or (`None` or `numpy.random`).
+    The latter two options use the global random number generator for `numpy.random`.
+
+    The returned instance is a `numpy.random.RandomState` or `numpy.random.Generator`.
 
     Parameters
     ----------
     random_state_argument : string or int
         The name or index of the argument to be converted
         to a `numpy.random.RandomState` instance.
 
@@ -285,45 +292,52 @@
     --------
     Decorate functions like this::
 
        @np_random_state("seed")
        def random_float(seed=None):
            return seed.rand()
 
+
        @np_random_state(0)
        def random_float(rng=None):
            return rng.rand()
 
+
        @np_random_state(1)
        def random_array(dims, random_state=1):
            return random_state.rand(*dims)
 
     See Also
     --------
     py_random_state
     """
     return argmap(create_random_state, random_state_argument)
 
 
 def py_random_state(random_state_argument):
     """Decorator to generate a random.Random instance (or equiv).
 
-    The decorator processes the argument indicated by `random_state_argument`
-    using :func:`nx.utils.create_py_random_state`.
-    The argument value can be a seed (integer), or a random number generator::
+    This decorator processes `random_state_argument` using
+    :func:`nx.utils.create_py_random_state`.
+    The input value can be a seed (integer), or a random number generator::
 
         If int, return a random.Random instance set with seed=int.
         If random.Random instance, return it.
         If None or the `random` package, return the global random number
         generator used by `random`.
-        If np.random package, return the global numpy random number
-        generator wrapped in a PythonRandomInterface class.
-        If np.random.RandomState instance, return it wrapped in
-        PythonRandomInterface
-        If a PythonRandomInterface instance, return it
+        If np.random package, or the default numpy RandomState instance,
+        return the default numpy random number generator wrapped in a
+        `PythonRandomViaNumpyBits`  class.
+        If np.random.Generator instance, return it wrapped in a
+        `PythonRandomViaNumpyBits`  class.
+
+        # Legacy options
+        If np.random.RandomState instance, return it wrapped in a
+        `PythonRandomInterface` class.
+        If a `PythonRandomInterface` instance, return it
 
     Parameters
     ----------
     random_state_argument : string or int
         The name of the argument or the index of the argument in args that is
         to be converted to the random.Random instance or numpy.random.RandomState
         instance that mimics basic methods of random.Random.
@@ -337,18 +351,20 @@
     --------
     Decorate functions like this::
 
        @py_random_state("random_state")
        def random_float(random_state=None):
            return random_state.rand()
 
+
        @py_random_state(0)
        def random_float(rng=None):
            return rng.rand()
 
+
        @py_random_state(1)
        def random_array(dims, seed=12345):
            return seed.rand(*dims)
 
     See Also
     --------
     np_random_state
@@ -410,14 +426,15 @@
     And the code to create the decorator might be::
 
         def convert_to(currency, which_arg):
             def _convert(amount):
                 if amount.currency != currency:
                     amount = amount.to_currency(currency)
                 return amount
+
             return argmap(_convert, which_arg)
 
     Despite this common idiom for argmap, most of the following examples
     use the `@argmap(...)` idiom to save space.
 
     Here's an example use of argmap to sum the elements of two of the functions
     arguments. The decorated function::
@@ -469,18 +486,20 @@
 
     Also, note that an index larger than the number of named parameters is allowed
     for variadic functions. For example::
 
         def double(a):
             return 2 * a
 
+
         @argmap(double, 3)
         def overflow(a, *args):
             return a, args
 
+
         print(overflow(1, 2, 3, 4, 5, 6))  # output is 1, (2, 3, 8, 5, 6)
 
     **Try Finally**
 
     Additionally, this `argmap` class can be used to create a decorator that
     initiates a try...finally block. The decorator must be written to return
     both the transformed argument and a closing function.
@@ -522,14 +541,15 @@
                 if path is None:
                     path = open(path)
                     fclose = path.close
                 else:
                     # assume `path` handles the closing
                     fclose = lambda: None
                 return path, fclose
+
             return argmap(_opener, which_arg, try_finally=True)
 
     which can then be used as::
 
         @my_closing_decorator("file")
         def fancy_reader(file=None):
             # this code doesn't need to worry about closing the file
@@ -545,14 +565,15 @@
 
     is equivalent to::
 
         def file_to_lines_wrapped(file):
             for line in file.readlines():
                 yield line
 
+
         def file_to_lines_wrapper(file):
             try:
                 file = open_file(file)
                 return file_to_lines_wrapped(file)
             finally:
                 file.close()
 
@@ -682,18 +703,16 @@
     to implement when handling the multiple arguments.
 
     See Also
     --------
     not_implemented_for
     open_file
     nodes_or_number
-    random_state
     py_random_state
-    networkx.community.quality.require_partition
-    require_partition
+    networkx.algorithms.community.quality.require_partition
 
     """
 
     def __init__(self, func, *args, try_finally=False):
         self._func = func
         self._args = args
         self._finally = try_finally
@@ -1090,15 +1109,21 @@
             # in any combination, but only in the order as above.  we do edge
             # detection to add the appropriate punctuation
             prev = kind
             kind = param.kind
             if prev == param.POSITIONAL_ONLY != kind:
                 # the last token was position-only, but this one isn't
                 def_sig.append("/")
-            if prev != param.KEYWORD_ONLY == kind != param.VAR_POSITIONAL:
+            if (
+                param.VAR_POSITIONAL
+                != prev
+                != param.KEYWORD_ONLY
+                == kind
+                != param.VAR_POSITIONAL
+            ):
                 # param is the first keyword-only arg and isn't starred
                 def_sig.append("*")
 
             # star arguments as appropriate
             if kind == param.VAR_POSITIONAL:
                 name = "*" + param.name
                 args = param.name
```

### Comparing `networkx-3.2rc0/networkx/utils/heaps.py` & `networkx-3.3rc0/networkx/utils/heaps.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/mapped_queue.py` & `networkx-3.3rc0/networkx/utils/mapped_queue.py`

 * *Files 2% similar despite different names*

```diff
@@ -110,19 +110,19 @@
     Examples
     --------
 
     A `MappedQueue` can be created empty, or optionally, given a dictionary
     of initial elements and priorities.  The methods `push`, `pop`,
     `remove`, and `update` operate on the queue.
 
-    >>> colors_nm = {'red':665, 'blue': 470, 'green': 550}
+    >>> colors_nm = {"red": 665, "blue": 470, "green": 550}
     >>> q = MappedQueue(colors_nm)
-    >>> q.remove('red')
-    >>> q.update('green', 'violet', 400)
-    >>> q.push('indigo', 425)
+    >>> q.remove("red")
+    >>> q.update("green", "violet", 400)
+    >>> q.push("indigo", 425)
     True
     >>> [q.pop().element for i in range(len(q.heap))]
     ['violet', 'indigo', 'blue']
 
     A `MappedQueue` can also be initialized with a list or other iterable. The priority is assumed
     to be the sort order of the items in the list.
 
@@ -130,22 +130,22 @@
     >>> q.remove(493)
     >>> q.update(237, 1117)
     >>> [q.pop() for i in range(len(q.heap))]
     [50, 916, 1117, 4609]
 
     An exception is raised if the elements are not comparable.
 
-    >>> q = MappedQueue([100, 'a'])
+    >>> q = MappedQueue([100, "a"])
     Traceback (most recent call last):
     ...
     TypeError: '<' not supported between instances of 'int' and 'str'
 
     To avoid the exception, use a dictionary to assign priorities to the elements.
 
-    >>> q = MappedQueue({100: 0, 'a': 1 })
+    >>> q = MappedQueue({100: 0, "a": 1})
 
     References
     ----------
     .. [1] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001).
        Introduction to algorithms second edition.
     .. [2] Knuth, D. E. (1997). The art of computer programming (Vol. 3).
        Pearson Education.
```

### Comparing `networkx-3.2rc0/networkx/utils/misc.py` & `networkx-3.3rc0/networkx/utils/misc.py`

 * *Files 26% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 >>> import networkx
 >>> networkx.utils.make_list_of_ints({1, 2, 3})
 [1, 2, 3]
 >>> networkx.utils.arbitrary_element({5, 1, 7})  # doctest: +SKIP
 1
 """
 
+import random
 import sys
 import uuid
 import warnings
 from collections import defaultdict, deque
 from collections.abc import Iterable, Iterator, Sized
 from itertools import chain, tee
 
@@ -26,33 +27,34 @@
     "dict_to_numpy_array",
     "arbitrary_element",
     "pairwise",
     "groups",
     "create_random_state",
     "create_py_random_state",
     "PythonRandomInterface",
+    "PythonRandomViaNumpyBits",
     "nodes_equal",
     "edges_equal",
     "graphs_equal",
 ]
 
 
 # some cookbook stuff
 # used in deciding whether something is a bunch of nodes, edges, etc.
 # see G.add_nodes and others in Graph Class in networkx/base.py
 
 
 def flatten(obj, result=None):
     """Return flattened version of (possibly nested) iterable object."""
-    if not isinstance(obj, (Iterable, Sized)) or isinstance(obj, str):
+    if not isinstance(obj, Iterable | Sized) or isinstance(obj, str):
         return obj
     if result is None:
         result = []
     for item in obj:
-        if not isinstance(item, (Iterable, Sized)) or isinstance(item, str):
+        if not isinstance(item, Iterable | Sized) or isinstance(item, str):
             result.append(item)
         else:
             flatten(item, result)
     return tuple(result)
 
 
 def make_list_of_ints(sequence):
@@ -171,15 +173,15 @@
     >>> nx.utils.arbitrary_element((1, 2, 3))  # tuple
     1
     >>> nx.utils.arbitrary_element({1, 2, 3})  # set
     1
     >>> d = {k: v for k, v in zip([1, 2, 3], [3, 2, 1])}
     >>> nx.utils.arbitrary_element(d)  # dict_keys
     1
-    >>> nx.utils.arbitrary_element(d.values())   # dict values
+    >>> nx.utils.arbitrary_element(d.values())  # dict values
     3
 
     `str` is also an Iterable:
 
     >>> nx.utils.arbitrary_element("hello")
     'h'
 
@@ -267,15 +269,77 @@
     msg = (
         f"{random_state} cannot be used to create a numpy.random.RandomState or\n"
         "numpy.random.Generator instance"
     )
     raise ValueError(msg)
 
 
+class PythonRandomViaNumpyBits(random.Random):
+    """Provide the random.random algorithms using a numpy.random bit generator
+
+    The intent is to allow people to contribute code that uses Python's random
+    library, but still allow users to provide a single easily controlled random
+    bit-stream for all work with NetworkX. This implementation is based on helpful
+    comments and code from Robert Kern on NumPy's GitHub Issue #24458.
+
+    This implementation supercedes that of `PythonRandomInterface` which rewrote
+    methods to account for subtle differences in API between `random` and
+    `numpy.random`. Instead this subclasses `random.Random` and overwrites
+    the methods `random`, `getrandbits`, `getstate`, `setstate` and `seed`.
+    It makes them use the rng values from an input numpy `RandomState` or `Generator`.
+    Those few methods allow the rest of the `random.Random` methods to provide
+    the API interface of `random.random` while using randomness generated by
+    a numpy generator.
+    """
+
+    def __init__(self, rng=None):
+        try:
+            import numpy as np
+        except ImportError:
+            msg = "numpy not found, only random.random available."
+            warnings.warn(msg, ImportWarning)
+
+        if rng is None:
+            self._rng = np.random.mtrand._rand
+        else:
+            self._rng = rng
+
+        # Not necessary, given our overriding of gauss() below, but it's
+        # in the superclass and nominally public, so initialize it here.
+        self.gauss_next = None
+
+    def random(self):
+        """Get the next random number in the range 0.0 <= X < 1.0."""
+        return self._rng.random()
+
+    def getrandbits(self, k):
+        """getrandbits(k) -> x.  Generates an int with k random bits."""
+        if k < 0:
+            raise ValueError("number of bits must be non-negative")
+        numbytes = (k + 7) // 8  # bits / 8 and rounded up
+        x = int.from_bytes(self._rng.bytes(numbytes), "big")
+        return x >> (numbytes * 8 - k)  # trim excess bits
+
+    def getstate(self):
+        return self._rng.__getstate__()
+
+    def setstate(self, state):
+        self._rng.__setstate__(state)
+
+    def seed(self, *args, **kwds):
+        "Do nothing override method."
+        raise NotImplementedError("seed() not implemented in PythonRandomViaNumpyBits")
+
+
+##################################################################
 class PythonRandomInterface:
+    """PythonRandomInterface is included for backward compatibility
+    New code should use PythonRandomViaNumpyBits instead.
+    """
+
     def __init__(self, rng=None):
         try:
             import numpy as np
         except ImportError:
             msg = "numpy not found, only random.random available."
             warnings.warn(msg, ImportWarning)
 
@@ -289,14 +353,20 @@
 
     def uniform(self, a, b):
         return a + (b - a) * self._rng.random()
 
     def randrange(self, a, b=None):
         import numpy as np
 
+        if b is None:
+            a, b = 0, a
+        if b > 9223372036854775807:  # from np.iinfo(np.int64).max
+            tmp_rng = PythonRandomViaNumpyBits(self._rng)
+            return tmp_rng.randrange(a, b)
+
         if isinstance(self._rng, np.random.Generator):
             return self._rng.integers(a, b)
         return self._rng.randint(a, b)
 
     # NOTE: the numpy implementations of `choice` don't support strings, so
     # this cannot be replaced with self._rng.choice
     def choice(self, seq):
@@ -319,14 +389,18 @@
 
     def sample(self, seq, k):
         return self._rng.choice(list(seq), size=(k,), replace=False)
 
     def randint(self, a, b):
         import numpy as np
 
+        if b > 9223372036854775807:  # from np.iinfo(np.int64).max
+            tmp_rng = PythonRandomViaNumpyBits(self._rng)
+            return tmp_rng.randint(a, b)
+
         if isinstance(self._rng, np.random.Generator):
             return self._rng.integers(a, b + 1)
         return self._rng.randint(a, b + 1)
 
     #    exponential as expovariate with 1/argument,
     def expovariate(self, scale):
         return self._rng.exponential(1 / scale)
@@ -349,44 +423,70 @@
 
 def create_py_random_state(random_state=None):
     """Returns a random.Random instance depending on input.
 
     Parameters
     ----------
     random_state : int or random number generator or None (default=None)
-        If int, return a random.Random instance set with seed=int.
-        if random.Random instance, return it.
-        if None or the `random` package, return the global random number
-        generator used by `random`.
-        if np.random package, return the global numpy random number
-        generator wrapped in a PythonRandomInterface class.
-        if np.random.RandomState or np.random.Generator instance, return it
-        wrapped in PythonRandomInterface
-        if a PythonRandomInterface instance, return it
-    """
-    import random
-
-    try:
-        import numpy as np
-
-        if random_state is np.random:
-            return PythonRandomInterface(np.random.mtrand._rand)
-        if isinstance(random_state, (np.random.RandomState, np.random.Generator)):
-            return PythonRandomInterface(random_state)
-        if isinstance(random_state, PythonRandomInterface):
-            return random_state
-    except ImportError:
-        pass
+        - If int, return a `random.Random` instance set with seed=int.
+        - If `random.Random` instance, return it.
+        - If None or the `np.random` package, return the global random number
+          generator used by `np.random`.
+        - If an `np.random.Generator` instance, or the `np.random` package, or
+          the global numpy random number generator, then return it.
+          wrapped in a `PythonRandomViaNumpyBits` class.
+        - If a `PythonRandomViaNumpyBits` instance, return it.
+        - If a `PythonRandomInterface` instance, return it.
+        - If a `np.random.RandomState` instance and not the global numpy default,
+          return it wrapped in `PythonRandomInterface` for backward bit-stream
+          matching with legacy code.
 
+    Notes
+    -----
+    - A diagram intending to illustrate the relationships behind our support
+      for numpy random numbers is called
+      `NetworkX Numpy Random Numbers <https://excalidraw.com/#room=b5303f2b03d3af7ccc6a,e5ZDIWdWWCTTsg8OqoRvPA>`_.
+    - More discussion about this support also appears in
+      `gh-6869#comment <https://github.com/networkx/networkx/pull/6869#issuecomment-1944799534>`_.
+    - Wrappers of numpy.random number generators allow them to mimic the Python random
+      number generation algorithms. For example, Python can create arbitrarily large
+      random ints, and the wrappers use Numpy bit-streams with CPython's random module
+      to choose arbitrarily large random integers too.
+    - We provide two wrapper classes:
+      `PythonRandomViaNumpyBits` is usually what you want and is always used for
+      `np.Generator` instances. But for users who need to recreate random numbers
+      produced in NetworkX 3.2 or earlier, we maintain the `PythonRandomInterface`
+      wrapper as well. We use it only used if passed a (non-default) `np.RandomState`
+      instance pre-initialized from a seed. Otherwise the newer wrapper is used.
+    """
     if random_state is None or random_state is random:
         return random._inst
     if isinstance(random_state, random.Random):
         return random_state
     if isinstance(random_state, int):
         return random.Random(random_state)
+
+    try:
+        import numpy as np
+    except ImportError:
+        pass
+    else:
+        if isinstance(random_state, PythonRandomInterface | PythonRandomViaNumpyBits):
+            return random_state
+        if isinstance(random_state, np.random.Generator):
+            return PythonRandomViaNumpyBits(random_state)
+        if random_state is np.random:
+            return PythonRandomViaNumpyBits(np.random.mtrand._rand)
+
+        if isinstance(random_state, np.random.RandomState):
+            if random_state is np.random.mtrand._rand:
+                return PythonRandomViaNumpyBits(random_state)
+            # Only need older interface if specially constructed RandomState used
+            return PythonRandomInterface(random_state)
+
     msg = f"{random_state} cannot be used to generate a random.Random instance"
     raise ValueError(msg)
 
 
 def nodes_equal(nodes1, nodes2):
     """Check if nodes are equal.
```

### Comparing `networkx-3.2rc0/networkx/utils/random_sequence.py` & `networkx-3.3rc0/networkx/utils/random_sequence.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/rcm.py` & `networkx-3.3rc0/networkx/utils/rcm.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_decorators.py` & `networkx-3.3rc0/networkx/utils/tests/test_decorators.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from networkx.utils.decorators import (
     argmap,
     not_implemented_for,
     np_random_state,
     open_file,
     py_random_state,
 )
-from networkx.utils.misc import PythonRandomInterface
+from networkx.utils.misc import PythonRandomInterface, PythonRandomViaNumpyBits
 
 
 def test_not_implemented_decorator():
     @not_implemented_for("directed")
     def test_d(G):
         pass
 
@@ -208,84 +208,103 @@
     @classmethod
     def setup_class(cls):
         global np
         np = pytest.importorskip("numpy")
 
     @np_random_state(1)
     def instantiate_np_random_state(self, random_state):
-        assert isinstance(random_state, np.random.RandomState)
-        return random_state.random_sample()
+        allowed = (np.random.RandomState, np.random.Generator)
+        assert isinstance(random_state, allowed)
+        return random_state.random()
 
     @py_random_state(1)
     def instantiate_py_random_state(self, random_state):
-        assert isinstance(random_state, (random.Random, PythonRandomInterface))
+        allowed = (random.Random, PythonRandomInterface, PythonRandomViaNumpyBits)
+        assert isinstance(random_state, allowed)
         return random_state.random()
 
     def test_random_state_None(self):
         np.random.seed(42)
-        rv = np.random.random_sample()
+        rv = np.random.random()
         np.random.seed(42)
         assert rv == self.instantiate_np_random_state(None)
 
         random.seed(42)
         rv = random.random()
         random.seed(42)
         assert rv == self.instantiate_py_random_state(None)
 
     def test_random_state_np_random(self):
         np.random.seed(42)
-        rv = np.random.random_sample()
+        rv = np.random.random()
         np.random.seed(42)
         assert rv == self.instantiate_np_random_state(np.random)
         np.random.seed(42)
         assert rv == self.instantiate_py_random_state(np.random)
 
     def test_random_state_int(self):
         np.random.seed(42)
-        np_rv = np.random.random_sample()
+        np_rv = np.random.random()
         random.seed(42)
         py_rv = random.random()
 
         np.random.seed(42)
         seed = 1
         rval = self.instantiate_np_random_state(seed)
         rval_expected = np.random.RandomState(seed).rand()
-        assert rval, rval_expected
+        assert rval == rval_expected
         # test that global seed wasn't changed in function
-        assert np_rv == np.random.random_sample()
+        assert np_rv == np.random.random()
 
         random.seed(42)
         rval = self.instantiate_py_random_state(seed)
         rval_expected = random.Random(seed).random()
-        assert rval, rval_expected
+        assert rval == rval_expected
         # test that global seed wasn't changed in function
         assert py_rv == random.random()
 
-    def test_random_state_np_random_RandomState(self):
+    def test_random_state_np_random_Generator(self):
         np.random.seed(42)
-        np_rv = np.random.random_sample()
+        np_rv = np.random.random()
+        np.random.seed(42)
+        seed = 1
 
+        rng = np.random.default_rng(seed)
+        rval = self.instantiate_np_random_state(rng)
+        rval_expected = np.random.default_rng(seed).random()
+        assert rval == rval_expected
+
+        rval = self.instantiate_py_random_state(rng)
+        rval_expected = np.random.default_rng(seed).random(size=2)[1]
+        assert rval == rval_expected
+        # test that global seed wasn't changed in function
+        assert np_rv == np.random.random()
+
+    def test_random_state_np_random_RandomState(self):
+        np.random.seed(42)
+        np_rv = np.random.random()
         np.random.seed(42)
         seed = 1
-        rng = np.random.RandomState(seed)
-        rval = self.instantiate_np_random_state(seed)
-        rval_expected = np.random.RandomState(seed).rand()
-        assert rval, rval_expected
 
-        rval = self.instantiate_py_random_state(seed)
-        rval_expected = np.random.RandomState(seed).rand()
-        assert rval, rval_expected
+        rng = np.random.RandomState(seed)
+        rval = self.instantiate_np_random_state(rng)
+        rval_expected = np.random.RandomState(seed).random()
+        assert rval == rval_expected
+
+        rval = self.instantiate_py_random_state(rng)
+        rval_expected = np.random.RandomState(seed).random(size=2)[1]
+        assert rval == rval_expected
         # test that global seed wasn't changed in function
-        assert np_rv == np.random.random_sample()
+        assert np_rv == np.random.random()
 
     def test_random_state_py_random(self):
         seed = 1
         rng = random.Random(seed)
         rv = self.instantiate_py_random_state(rng)
-        assert rv, random.Random(seed).random()
+        assert rv == random.Random(seed).random()
 
         pytest.raises(ValueError, self.instantiate_np_random_state, rng)
 
 
 def test_random_state_string_arg_index():
     with pytest.raises(nx.NetworkXError):
```

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_heaps.py` & `networkx-3.3rc0/networkx/utils/tests/test_heaps.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_mapped_queue.py` & `networkx-3.3rc0/networkx/utils/tests/test_mapped_queue.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_misc.py` & `networkx-3.3rc0/networkx/utils/tests/test_misc.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 from copy import copy
 
 import pytest
 
 import networkx as nx
 from networkx.utils import (
     PythonRandomInterface,
+    PythonRandomViaNumpyBits,
     arbitrary_element,
     create_py_random_state,
     create_random_state,
     dict_to_numpy_array,
     discrete_sequence,
     flatten,
     groups,
@@ -180,29 +181,39 @@
     pytest.raises(ValueError, create_py_random_state, "a")
 
     np = pytest.importorskip("numpy")
 
     rs = np.random.RandomState
     rng = np.random.default_rng(1000)
     rng_explicit = np.random.Generator(np.random.SFC64())
-    nprs = PythonRandomInterface
+    old_nprs = PythonRandomInterface
+    nprs = PythonRandomViaNumpyBits
     assert isinstance(create_py_random_state(np.random), nprs)
-    assert isinstance(create_py_random_state(rs(1)), nprs)
+    assert isinstance(create_py_random_state(rs(1)), old_nprs)
     assert isinstance(create_py_random_state(rng), nprs)
     assert isinstance(create_py_random_state(rng_explicit), nprs)
     # test default rng input
-    assert isinstance(PythonRandomInterface(), nprs)
+    assert isinstance(PythonRandomInterface(), old_nprs)
+    assert isinstance(PythonRandomViaNumpyBits(), nprs)
+
+    # VeryLargeIntegers Smoke test (they raise error for np.random)
+    int64max = 9223372036854775807  # from np.iinfo(np.int64).max
+    for r in (rng, rs(1)):
+        prs = create_py_random_state(r)
+        prs.randrange(3, int64max + 5)
+        prs.randint(3, int64max + 5)
 
 
 def test_PythonRandomInterface_RandomState():
     np = pytest.importorskip("numpy")
 
+    seed = 42
     rs = np.random.RandomState
-    rng = PythonRandomInterface(rs(42))
-    rs42 = rs(42)
+    rng = PythonRandomInterface(rs(seed))
+    rs42 = rs(seed)
 
     # make sure these functions are same as expected outcome
     assert rng.randrange(3, 5) == rs42.randint(3, 5)
     assert rng.choice([1, 2, 3]) == rs42.choice([1, 2, 3])
     assert rng.gauss(0, 1) == rs42.normal(0, 1)
     assert rng.expovariate(1.5) == rs42.exponential(1 / 1.5)
     assert np.all(rng.shuffle([1, 2, 3]) == rs42.shuffle([1, 2, 3]))
@@ -215,16 +226,17 @@
     )
     assert rng.random() == rs42.random_sample()
 
 
 def test_PythonRandomInterface_Generator():
     np = pytest.importorskip("numpy")
 
-    rng = np.random.default_rng(42)
-    pri = PythonRandomInterface(np.random.default_rng(42))
+    seed = 42
+    rng = np.random.default_rng(seed)
+    pri = PythonRandomInterface(np.random.default_rng(seed))
 
     # make sure these functions are same as expected outcome
     assert pri.randrange(3, 5) == rng.integers(3, 5)
     assert pri.choice([1, 2, 3]) == rng.choice([1, 2, 3])
     assert pri.gauss(0, 1) == rng.normal(0, 1)
     assert pri.expovariate(1.5) == rng.exponential(1 / 1.5)
     assert np.all(pri.shuffle([1, 2, 3]) == rng.shuffle([1, 2, 3]))
@@ -243,13 +255,14 @@
 )
 def test_arbitrary_element(iterable_type, expected):
     iterable = iterable_type([1, 2, 3])
     assert arbitrary_element(iterable) == expected
 
 
 @pytest.mark.parametrize(
-    "iterator", ((i for i in range(3)), iter([1, 2, 3]))  # generator
+    "iterator",
+    ((i for i in range(3)), iter([1, 2, 3])),  # generator
 )
 def test_arbitrary_element_raises(iterator):
     """Value error is raised when input is an iterator."""
     with pytest.raises(ValueError, match="from an iterator"):
         arbitrary_element(iterator)
```

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_random_sequence.py` & `networkx-3.3rc0/networkx/utils/tests/test_random_sequence.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_rcm.py` & `networkx-3.3rc0/networkx/utils/tests/test_rcm.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/tests/test_unionfind.py` & `networkx-3.3rc0/networkx/utils/tests/test_unionfind.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx/utils/union_find.py` & `networkx-3.3rc0/networkx/utils/union_find.py`

 * *Files identical despite different names*

### Comparing `networkx-3.2rc0/networkx.egg-info/PKG-INFO` & `networkx-3.3rc0/networkx.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: networkx
-Version: 3.2rc0
+Version: 3.3rc0
 Summary: Python package for creating and manipulating graphs and networks
 Author-email: Aric Hagberg <hagberg@lanl.gov>
 Maintainer-email: NetworkX Developers <networkx-discuss@googlegroups.com>
 Project-URL: Homepage, https://networkx.org/
 Project-URL: Bug Tracker, https://github.com/networkx/networkx/issues
 Project-URL: Documentation, https://networkx.org/documentation/stable/
 Project-URL: Source Code, https://github.com/networkx/networkx
@@ -15,49 +15,48 @@
 Platform: Unix
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
 Classifier: Topic :: Scientific/Engineering :: Information Analysis
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Physics
-Requires-Python: >=3.9
+Requires-Python: >=3.10
 Description-Content-Type: text/x-rst
 License-File: LICENSE.txt
 Provides-Extra: default
-Requires-Dist: numpy>=1.22; extra == "default"
+Requires-Dist: numpy>=1.23; extra == "default"
 Requires-Dist: scipy!=1.11.0,!=1.11.1,>=1.9; extra == "default"
-Requires-Dist: matplotlib>=3.5; extra == "default"
+Requires-Dist: matplotlib>=3.6; extra == "default"
 Requires-Dist: pandas>=1.4; extra == "default"
 Provides-Extra: developer
+Requires-Dist: changelist==0.5; extra == "developer"
 Requires-Dist: pre-commit>=3.2; extra == "developer"
 Requires-Dist: mypy>=1.1; extra == "developer"
 Requires-Dist: rtoml; extra == "developer"
 Provides-Extra: doc
 Requires-Dist: sphinx>=7; extra == "doc"
 Requires-Dist: pydata-sphinx-theme>=0.14; extra == "doc"
 Requires-Dist: sphinx-gallery>=0.14; extra == "doc"
 Requires-Dist: numpydoc>=1.6; extra == "doc"
 Requires-Dist: pillow>=9.4; extra == "doc"
-Requires-Dist: nb2plots>=0.7; extra == "doc"
 Requires-Dist: texext>=0.6.7; extra == "doc"
-Requires-Dist: nbconvert<7.9; extra == "doc"
+Requires-Dist: myst-nb>=1.0; extra == "doc"
 Provides-Extra: extra
 Requires-Dist: lxml>=4.6; extra == "extra"
-Requires-Dist: pygraphviz>=1.11; extra == "extra"
-Requires-Dist: pydot>=1.4.2; extra == "extra"
+Requires-Dist: pygraphviz>=1.12; extra == "extra"
+Requires-Dist: pydot>=2.0; extra == "extra"
 Requires-Dist: sympy>=1.10; extra == "extra"
 Provides-Extra: test
 Requires-Dist: pytest>=7.2; extra == "test"
 Requires-Dist: pytest-cov>=4.0; extra == "test"
 
 NetworkX
 ========
@@ -124,11 +123,11 @@
 see `CONTRIBUTING.rst`).
 
 License
 -------
 
 Released under the 3-Clause BSD license (see `LICENSE.txt`)::
 
-   Copyright (C) 2004-2023 NetworkX Developers
+   Copyright (C) 2004-2024 NetworkX Developers
    Aric Hagberg <hagberg@lanl.gov>
    Dan Schult <dschult@colgate.edu>
    Pieter Swart <swart@lanl.gov>
```

### Comparing `networkx-3.2rc0/networkx.egg-info/SOURCES.txt` & `networkx-3.3rc0/networkx.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 README.rst
 pyproject.toml
 doc/Makefile
 doc/README.rst
 doc/conf.py
 doc/index.rst
 doc/install.rst
-doc/tutorial.rst
 doc/_static/copybutton.js
 doc/_static/custom.css
 doc/_templates/autosummary/base.rst
 doc/_templates/autosummary/class.rst
 doc/developer/about_us.rst
 doc/developer/code_of_conduct.rst
 doc/developer/contribute.rst
@@ -37,25 +36,25 @@
 doc/reference/convert.rst
 doc/reference/drawing.rst
 doc/reference/exceptions.rst
 doc/reference/functions.rst
 doc/reference/generators.rst
 doc/reference/glossary.rst
 doc/reference/index.rst
-doc/reference/introduction.rst
 doc/reference/linalg.rst
 doc/reference/randomness.rst
 doc/reference/relabel.rst
 doc/reference/utils.rst
 doc/reference/algorithms/approximation.rst
 doc/reference/algorithms/assortativity.rst
 doc/reference/algorithms/asteroidal.rst
 doc/reference/algorithms/bipartite.rst
 doc/reference/algorithms/boundary.rst
 doc/reference/algorithms/bridges.rst
+doc/reference/algorithms/broadcasting.rst
 doc/reference/algorithms/centrality.rst
 doc/reference/algorithms/chains.rst
 doc/reference/algorithms/chordal.rst
 doc/reference/algorithms/clique.rst
 doc/reference/algorithms/clustering.rst
 doc/reference/algorithms/coloring.rst
 doc/reference/algorithms/communicability_alg.rst
@@ -121,14 +120,15 @@
 doc/reference/algorithms/wiener.rst
 doc/reference/classes/digraph.rst
 doc/reference/classes/graph.rst
 doc/reference/classes/index.rst
 doc/reference/classes/multidigraph.rst
 doc/reference/classes/multigraph.rst
 doc/reference/readwrite/adjlist.rst
+doc/reference/readwrite/dot.rst
 doc/reference/readwrite/edgelist.rst
 doc/reference/readwrite/gexf.rst
 doc/reference/readwrite/gml.rst
 doc/reference/readwrite/graphml.rst
 doc/reference/readwrite/index.rst
 doc/reference/readwrite/json_graph.rst
 doc/reference/readwrite/leda.rst
@@ -168,31 +168,35 @@
 doc/release/release_2.8.5.rst
 doc/release/release_2.8.6.rst
 doc/release/release_2.8.7.rst
 doc/release/release_2.8.8.rst
 doc/release/release_2.8.rst
 doc/release/release_3.0.rst
 doc/release/release_3.1.rst
-doc/release/release_dev.rst
+doc/release/release_3.2.1.rst
+doc/release/release_3.2.rst
 doc/release/report_functions_without_rst_generated.py
 examples/README.txt
 examples/3d_drawing/README.txt
 examples/3d_drawing/mayavi2_spring.py
+examples/3d_drawing/plot_3d_rotation_animation.py
 examples/3d_drawing/plot_basic.py
 examples/algorithms/README.txt
 examples/algorithms/WormNet.v3.benchmark.txt
 examples/algorithms/hartford_drug.edgelist
 examples/algorithms/plot_beam_search.py
 examples/algorithms/plot_betweenness_centrality.py
 examples/algorithms/plot_blockmodel.py
 examples/algorithms/plot_circuits.py
+examples/algorithms/plot_cycle_detection.py
 examples/algorithms/plot_davis_club.py
 examples/algorithms/plot_dedensification.py
 examples/algorithms/plot_girvan_newman.py
 examples/algorithms/plot_greedy_coloring.py
+examples/algorithms/plot_image_segmentation_spectral_graph_partiion.py
 examples/algorithms/plot_iterated_dynamical_systems.py
 examples/algorithms/plot_krackhardt_centrality.py
 examples/algorithms/plot_lca.py
 examples/algorithms/plot_maximum_independent_set.py
 examples/algorithms/plot_parallel_betweenness.py
 examples/algorithms/plot_rcm.py
 examples/algorithms/plot_shortest_path.py
@@ -203,24 +207,26 @@
 examples/basic/plot_read_write.py
 examples/basic/plot_simple_graph.py
 examples/drawing/README.txt
 examples/drawing/chess_masters_WCC.pgn.bz2
 examples/drawing/knuth_miles.txt.gz
 examples/drawing/plot_center_node.py
 examples/drawing/plot_chess_masters.py
+examples/drawing/plot_clusters.py
 examples/drawing/plot_custom_node_icons.py
 examples/drawing/plot_degree.py
 examples/drawing/plot_directed.py
 examples/drawing/plot_edge_colormap.py
 examples/drawing/plot_ego_graph.py
 examples/drawing/plot_eigenvalues.py
 examples/drawing/plot_four_grids.py
 examples/drawing/plot_house_with_colors.py
 examples/drawing/plot_knuth_miles.py
 examples/drawing/plot_labels_and_colors.py
+examples/drawing/plot_multigraphs.py
 examples/drawing/plot_multipartite_graph.py
 examples/drawing/plot_node_colormap.py
 examples/drawing/plot_rainbow_coloring.py
 examples/drawing/plot_random_geometric_graph.py
 examples/drawing/plot_sampson.py
 examples/drawing/plot_selfloops.py
 examples/drawing/plot_simple_path.py
@@ -288,14 +294,15 @@
 networkx.egg-info/not-zip-safe
 networkx.egg-info/requires.txt
 networkx.egg-info/top_level.txt
 networkx/algorithms/__init__.py
 networkx/algorithms/asteroidal.py
 networkx/algorithms/boundary.py
 networkx/algorithms/bridges.py
+networkx/algorithms/broadcasting.py
 networkx/algorithms/chains.py
 networkx/algorithms/chordal.py
 networkx/algorithms/clique.py
 networkx/algorithms/cluster.py
 networkx/algorithms/communicability_alg.py
 networkx/algorithms/core.py
 networkx/algorithms/covering.py
@@ -386,26 +393,28 @@
 networkx/algorithms/assortativity/tests/test_pairs.py
 networkx/algorithms/bipartite/__init__.py
 networkx/algorithms/bipartite/basic.py
 networkx/algorithms/bipartite/centrality.py
 networkx/algorithms/bipartite/cluster.py
 networkx/algorithms/bipartite/covering.py
 networkx/algorithms/bipartite/edgelist.py
+networkx/algorithms/bipartite/extendability.py
 networkx/algorithms/bipartite/generators.py
 networkx/algorithms/bipartite/matching.py
 networkx/algorithms/bipartite/matrix.py
 networkx/algorithms/bipartite/projection.py
 networkx/algorithms/bipartite/redundancy.py
 networkx/algorithms/bipartite/spectral.py
 networkx/algorithms/bipartite/tests/__init__.py
 networkx/algorithms/bipartite/tests/test_basic.py
 networkx/algorithms/bipartite/tests/test_centrality.py
 networkx/algorithms/bipartite/tests/test_cluster.py
 networkx/algorithms/bipartite/tests/test_covering.py
 networkx/algorithms/bipartite/tests/test_edgelist.py
+networkx/algorithms/bipartite/tests/test_extendability.py
 networkx/algorithms/bipartite/tests/test_generators.py
 networkx/algorithms/bipartite/tests/test_matching.py
 networkx/algorithms/bipartite/tests/test_matrix.py
 networkx/algorithms/bipartite/tests/test_project.py
 networkx/algorithms/bipartite/tests/test_redundancy.py
 networkx/algorithms/bipartite/tests/test_spectral_bipartivity.py
 networkx/algorithms/centrality/__init__.py
@@ -456,24 +465,26 @@
 networkx/algorithms/coloring/greedy_coloring.py
 networkx/algorithms/coloring/tests/__init__.py
 networkx/algorithms/coloring/tests/test_coloring.py
 networkx/algorithms/community/__init__.py
 networkx/algorithms/community/asyn_fluid.py
 networkx/algorithms/community/centrality.py
 networkx/algorithms/community/community_utils.py
+networkx/algorithms/community/divisive.py
 networkx/algorithms/community/kclique.py
 networkx/algorithms/community/kernighan_lin.py
 networkx/algorithms/community/label_propagation.py
 networkx/algorithms/community/louvain.py
 networkx/algorithms/community/lukes.py
 networkx/algorithms/community/modularity_max.py
 networkx/algorithms/community/quality.py
 networkx/algorithms/community/tests/__init__.py
 networkx/algorithms/community/tests/test_asyn_fluid.py
 networkx/algorithms/community/tests/test_centrality.py
+networkx/algorithms/community/tests/test_divisive.py
 networkx/algorithms/community/tests/test_kclique.py
 networkx/algorithms/community/tests/test_kernighan_lin.py
 networkx/algorithms/community/tests/test_label_propagation.py
 networkx/algorithms/community/tests/test_louvain.py
 networkx/algorithms/community/tests/test_lukes.py
 networkx/algorithms/community/tests/test_modularity_max.py
 networkx/algorithms/community/tests/test_quality.py
@@ -588,14 +599,15 @@
 networkx/algorithms/shortest_paths/tests/test_generic.py
 networkx/algorithms/shortest_paths/tests/test_unweighted.py
 networkx/algorithms/shortest_paths/tests/test_weighted.py
 networkx/algorithms/tests/__init__.py
 networkx/algorithms/tests/test_asteroidal.py
 networkx/algorithms/tests/test_boundary.py
 networkx/algorithms/tests/test_bridges.py
+networkx/algorithms/tests/test_broadcasting.py
 networkx/algorithms/tests/test_chains.py
 networkx/algorithms/tests/test_chordal.py
 networkx/algorithms/tests/test_clique.py
 networkx/algorithms/tests/test_cluster.py
 networkx/algorithms/tests/test_communicability.py
 networkx/algorithms/tests/test_core.py
 networkx/algorithms/tests/test_covering.py
@@ -829,23 +841,25 @@
 networkx/tests/test_convert_scipy.py
 networkx/tests/test_exceptions.py
 networkx/tests/test_import.py
 networkx/tests/test_lazy_imports.py
 networkx/tests/test_relabel.py
 networkx/utils/__init__.py
 networkx/utils/backends.py
+networkx/utils/configs.py
 networkx/utils/decorators.py
 networkx/utils/heaps.py
 networkx/utils/mapped_queue.py
 networkx/utils/misc.py
 networkx/utils/random_sequence.py
 networkx/utils/rcm.py
 networkx/utils/union_find.py
 networkx/utils/tests/__init__.py
 networkx/utils/tests/test__init.py
+networkx/utils/tests/test_config.py
 networkx/utils/tests/test_decorators.py
 networkx/utils/tests/test_heaps.py
 networkx/utils/tests/test_mapped_queue.py
 networkx/utils/tests/test_misc.py
 networkx/utils/tests/test_random_sequence.py
 networkx/utils/tests/test_rcm.py
 networkx/utils/tests/test_unionfind.py
```

### Comparing `networkx-3.2rc0/pyproject.toml` & `networkx-3.3rc0/pyproject.toml`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 build-backend = 'setuptools.build_meta'
 requires = ['setuptools>=61.2']
 
 [project]
 name = 'networkx'
 description = 'Python package for creating and manipulating graphs and networks'
 readme = 'README.rst'
-requires-python = '>=3.9'
+requires-python = '>=3.10'
 dynamic = ['version']
 keywords = [
     'Networks',
     'Graph Theory',
     'Mathematics',
     'network',
     'graph',
@@ -20,15 +20,14 @@
 classifiers = [
     'Development Status :: 5 - Production/Stable',
     'Intended Audience :: Developers',
     'Intended Audience :: Science/Research',
     'License :: OSI Approved :: BSD License',
     'Operating System :: OS Independent',
     'Programming Language :: Python :: 3',
-    'Programming Language :: Python :: 3.9',
     'Programming Language :: Python :: 3.10',
     'Programming Language :: Python :: 3.11',
     'Programming Language :: Python :: 3.12',
     'Programming Language :: Python :: 3 :: Only',
     'Topic :: Software Development :: Libraries :: Python Modules',
     'Topic :: Scientific/Engineering :: Bio-Informatics',
     'Topic :: Scientific/Engineering :: Information Analysis',
@@ -52,38 +51,38 @@
 "Source Code" = 'https://github.com/networkx/networkx'
 
 [project.entry-points."networkx.backends"]
 nx-loopback = 'networkx.classes.tests.dispatch_interface:dispatcher'
 
 [project.optional-dependencies]
 default = [
-    'numpy>=1.22',
+    'numpy>=1.23',
     'scipy>=1.9,!=1.11.0,!=1.11.1',
-    'matplotlib>=3.5',
+    'matplotlib>=3.6',
     'pandas>=1.4',
 ]
 developer = [
+    'changelist==0.5',
     'pre-commit>=3.2',
     'mypy>=1.1',
     'rtoml',
 ]
 doc = [
     'sphinx>=7',
     'pydata-sphinx-theme>=0.14',
     'sphinx-gallery>=0.14',
     'numpydoc>=1.6',
     'pillow>=9.4',
-    'nb2plots>=0.7',
     'texext>=0.6.7',
-    'nbconvert<7.9',
+    'myst-nb>=1.0',
 ]
 extra = [
     'lxml>=4.6',
-    'pygraphviz>=1.11',
-    'pydot>=1.4.2',
+    'pygraphviz>=1.12',
+    'pydot>=2.0',
     'sympy>=1.10',
 ]
 test = [
     'pytest>=7.2',
     'pytest-cov>=4.0',
 ]
 
@@ -165,15 +164,15 @@
 "networkx.linalg" = ['tests/*.py']
 "networkx.readwrite" = ['tests/*.py']
 "networkx.readwrite.json_graph" = ['tests/*.py']
 "networkx.utils" = ['tests/*.py']
 
 [tool.ruff]
 line-length = 88
-target-version = 'py39'
+target-version = 'py310'
 select = [
     'I',
     'UP',
     'C4',
     'E713',
     'PIE',
     'PGH003',
@@ -189,14 +188,17 @@
 [tool.ruff.per-file-ignores]
 "__init__.py" = ['I']
 "examples/*.py" = ['I']
 "doc/*.py" = ['I']
 "tools/*.py" = ['I']
 "networkx/classes/filters.py" = ['C416']
 
+[tool.ruff.format]
+docstring-code-format = true
+
 [tool.mypy]
 ignore_missing_imports = true
 exclude = 'subgraphviews|reportviews'
 
 [[tool.mypy.overrides]]
 module = 'networkx.classes.reportviews'
 ignore_errors = true
```

### Comparing `networkx-3.2rc0/requirements/README.md` & `networkx-3.3rc0/requirements/README.md`

 * *Files identical despite different names*

